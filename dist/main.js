/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./component/AudioPost.js":
/*!********************************!*\
  !*** ./component/AudioPost.js ***!
  \********************************/
/***/ ((module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.a(module, async (__webpack_handle_async_dependencies__, __webpack_async_result__) => { try {
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
function _typeof(obj) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof(obj); }
function _regeneratorRuntime() { "use strict"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return exports; }; var exports = {}, Op = Object.prototype, hasOwn = Op.hasOwnProperty, defineProperty = Object.defineProperty || function (obj, key, desc) { obj[key] = desc.value; }, $Symbol = "function" == typeof Symbol ? Symbol : {}, iteratorSymbol = $Symbol.iterator || "@@iterator", asyncIteratorSymbol = $Symbol.asyncIterator || "@@asyncIterator", toStringTagSymbol = $Symbol.toStringTag || "@@toStringTag"; function define(obj, key, value) { return Object.defineProperty(obj, key, { value: value, enumerable: !0, configurable: !0, writable: !0 }), obj[key]; } try { define({}, ""); } catch (err) { define = function define(obj, key, value) { return obj[key] = value; }; } function wrap(innerFn, outerFn, self, tryLocsList) { var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator, generator = Object.create(protoGenerator.prototype), context = new Context(tryLocsList || []); return defineProperty(generator, "_invoke", { value: makeInvokeMethod(innerFn, self, context) }), generator; } function tryCatch(fn, obj, arg) { try { return { type: "normal", arg: fn.call(obj, arg) }; } catch (err) { return { type: "throw", arg: err }; } } exports.wrap = wrap; var ContinueSentinel = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var IteratorPrototype = {}; define(IteratorPrototype, iteratorSymbol, function () { return this; }); var getProto = Object.getPrototypeOf, NativeIteratorPrototype = getProto && getProto(getProto(values([]))); NativeIteratorPrototype && NativeIteratorPrototype !== Op && hasOwn.call(NativeIteratorPrototype, iteratorSymbol) && (IteratorPrototype = NativeIteratorPrototype); var Gp = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(IteratorPrototype); function defineIteratorMethods(prototype) { ["next", "throw", "return"].forEach(function (method) { define(prototype, method, function (arg) { return this._invoke(method, arg); }); }); } function AsyncIterator(generator, PromiseImpl) { function invoke(method, arg, resolve, reject) { var record = tryCatch(generator[method], generator, arg); if ("throw" !== record.type) { var result = record.arg, value = result.value; return value && "object" == _typeof(value) && hasOwn.call(value, "__await") ? PromiseImpl.resolve(value.__await).then(function (value) { invoke("next", value, resolve, reject); }, function (err) { invoke("throw", err, resolve, reject); }) : PromiseImpl.resolve(value).then(function (unwrapped) { result.value = unwrapped, resolve(result); }, function (error) { return invoke("throw", error, resolve, reject); }); } reject(record.arg); } var previousPromise; defineProperty(this, "_invoke", { value: function value(method, arg) { function callInvokeWithMethodAndArg() { return new PromiseImpl(function (resolve, reject) { invoke(method, arg, resolve, reject); }); } return previousPromise = previousPromise ? previousPromise.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); } }); } function makeInvokeMethod(innerFn, self, context) { var state = "suspendedStart"; return function (method, arg) { if ("executing" === state) throw new Error("Generator is already running"); if ("completed" === state) { if ("throw" === method) throw arg; return doneResult(); } for (context.method = method, context.arg = arg;;) { var delegate = context.delegate; if (delegate) { var delegateResult = maybeInvokeDelegate(delegate, context); if (delegateResult) { if (delegateResult === ContinueSentinel) continue; return delegateResult; } } if ("next" === context.method) context.sent = context._sent = context.arg;else if ("throw" === context.method) { if ("suspendedStart" === state) throw state = "completed", context.arg; context.dispatchException(context.arg); } else "return" === context.method && context.abrupt("return", context.arg); state = "executing"; var record = tryCatch(innerFn, self, context); if ("normal" === record.type) { if (state = context.done ? "completed" : "suspendedYield", record.arg === ContinueSentinel) continue; return { value: record.arg, done: context.done }; } "throw" === record.type && (state = "completed", context.method = "throw", context.arg = record.arg); } }; } function maybeInvokeDelegate(delegate, context) { var methodName = context.method, method = delegate.iterator[methodName]; if (undefined === method) return context.delegate = null, "throw" === methodName && delegate.iterator["return"] && (context.method = "return", context.arg = undefined, maybeInvokeDelegate(delegate, context), "throw" === context.method) || "return" !== methodName && (context.method = "throw", context.arg = new TypeError("The iterator does not provide a '" + methodName + "' method")), ContinueSentinel; var record = tryCatch(method, delegate.iterator, context.arg); if ("throw" === record.type) return context.method = "throw", context.arg = record.arg, context.delegate = null, ContinueSentinel; var info = record.arg; return info ? info.done ? (context[delegate.resultName] = info.value, context.next = delegate.nextLoc, "return" !== context.method && (context.method = "next", context.arg = undefined), context.delegate = null, ContinueSentinel) : info : (context.method = "throw", context.arg = new TypeError("iterator result is not an object"), context.delegate = null, ContinueSentinel); } function pushTryEntry(locs) { var entry = { tryLoc: locs[0] }; 1 in locs && (entry.catchLoc = locs[1]), 2 in locs && (entry.finallyLoc = locs[2], entry.afterLoc = locs[3]), this.tryEntries.push(entry); } function resetTryEntry(entry) { var record = entry.completion || {}; record.type = "normal", delete record.arg, entry.completion = record; } function Context(tryLocsList) { this.tryEntries = [{ tryLoc: "root" }], tryLocsList.forEach(pushTryEntry, this), this.reset(!0); } function values(iterable) { if (iterable) { var iteratorMethod = iterable[iteratorSymbol]; if (iteratorMethod) return iteratorMethod.call(iterable); if ("function" == typeof iterable.next) return iterable; if (!isNaN(iterable.length)) { var i = -1, next = function next() { for (; ++i < iterable.length;) if (hasOwn.call(iterable, i)) return next.value = iterable[i], next.done = !1, next; return next.value = undefined, next.done = !0, next; }; return next.next = next; } } return { next: doneResult }; } function doneResult() { return { value: undefined, done: !0 }; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, defineProperty(Gp, "constructor", { value: GeneratorFunctionPrototype, configurable: !0 }), defineProperty(GeneratorFunctionPrototype, "constructor", { value: GeneratorFunction, configurable: !0 }), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, toStringTagSymbol, "GeneratorFunction"), exports.isGeneratorFunction = function (genFun) { var ctor = "function" == typeof genFun && genFun.constructor; return !!ctor && (ctor === GeneratorFunction || "GeneratorFunction" === (ctor.displayName || ctor.name)); }, exports.mark = function (genFun) { return Object.setPrototypeOf ? Object.setPrototypeOf(genFun, GeneratorFunctionPrototype) : (genFun.__proto__ = GeneratorFunctionPrototype, define(genFun, toStringTagSymbol, "GeneratorFunction")), genFun.prototype = Object.create(Gp), genFun; }, exports.awrap = function (arg) { return { __await: arg }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, asyncIteratorSymbol, function () { return this; }), exports.AsyncIterator = AsyncIterator, exports.async = function (innerFn, outerFn, self, tryLocsList, PromiseImpl) { void 0 === PromiseImpl && (PromiseImpl = Promise); var iter = new AsyncIterator(wrap(innerFn, outerFn, self, tryLocsList), PromiseImpl); return exports.isGeneratorFunction(outerFn) ? iter : iter.next().then(function (result) { return result.done ? result.value : iter.next(); }); }, defineIteratorMethods(Gp), define(Gp, toStringTagSymbol, "Generator"), define(Gp, iteratorSymbol, function () { return this; }), define(Gp, "toString", function () { return "[object Generator]"; }), exports.keys = function (val) { var object = Object(val), keys = []; for (var key in object) keys.push(key); return keys.reverse(), function next() { for (; keys.length;) { var key = keys.pop(); if (key in object) return next.value = key, next.done = !1, next; } return next.done = !0, next; }; }, exports.values = values, Context.prototype = { constructor: Context, reset: function reset(skipTempReset) { if (this.prev = 0, this.next = 0, this.sent = this._sent = undefined, this.done = !1, this.delegate = null, this.method = "next", this.arg = undefined, this.tryEntries.forEach(resetTryEntry), !skipTempReset) for (var name in this) "t" === name.charAt(0) && hasOwn.call(this, name) && !isNaN(+name.slice(1)) && (this[name] = undefined); }, stop: function stop() { this.done = !0; var rootRecord = this.tryEntries[0].completion; if ("throw" === rootRecord.type) throw rootRecord.arg; return this.rval; }, dispatchException: function dispatchException(exception) { if (this.done) throw exception; var context = this; function handle(loc, caught) { return record.type = "throw", record.arg = exception, context.next = loc, caught && (context.method = "next", context.arg = undefined), !!caught; } for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i], record = entry.completion; if ("root" === entry.tryLoc) return handle("end"); if (entry.tryLoc <= this.prev) { var hasCatch = hasOwn.call(entry, "catchLoc"), hasFinally = hasOwn.call(entry, "finallyLoc"); if (hasCatch && hasFinally) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } else if (hasCatch) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); } else { if (!hasFinally) throw new Error("try statement without catch or finally"); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } } } }, abrupt: function abrupt(type, arg) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc <= this.prev && hasOwn.call(entry, "finallyLoc") && this.prev < entry.finallyLoc) { var finallyEntry = entry; break; } } finallyEntry && ("break" === type || "continue" === type) && finallyEntry.tryLoc <= arg && arg <= finallyEntry.finallyLoc && (finallyEntry = null); var record = finallyEntry ? finallyEntry.completion : {}; return record.type = type, record.arg = arg, finallyEntry ? (this.method = "next", this.next = finallyEntry.finallyLoc, ContinueSentinel) : this.complete(record); }, complete: function complete(record, afterLoc) { if ("throw" === record.type) throw record.arg; return "break" === record.type || "continue" === record.type ? this.next = record.arg : "return" === record.type ? (this.rval = this.arg = record.arg, this.method = "return", this.next = "end") : "normal" === record.type && afterLoc && (this.next = afterLoc), ContinueSentinel; }, finish: function finish(finallyLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.finallyLoc === finallyLoc) return this.complete(entry.completion, entry.afterLoc), resetTryEntry(entry), ContinueSentinel; } }, "catch": function _catch(tryLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc === tryLoc) { var record = entry.completion; if ("throw" === record.type) { var thrown = record.arg; resetTryEntry(entry); } return thrown; } } throw new Error("illegal catch attempt"); }, delegateYield: function delegateYield(iterable, resultName, nextLoc) { return this.delegate = { iterator: values(iterable), resultName: resultName, nextLoc: nextLoc }, "next" === this.method && (this.arg = undefined), ContinueSentinel; } }, exports; }
function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }
function _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err); } _next(undefined); }); }; }
function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }
function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor); } }
function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, "prototype", { writable: false }); return Constructor; }
function _toPropertyKey(arg) { var key = _toPrimitive(arg, "string"); return _typeof(key) === "symbol" ? key : String(key); }
function _toPrimitive(input, hint) { if (_typeof(input) !== "object" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || "default"); if (_typeof(res) !== "object") return res; throw new TypeError("@@toPrimitive must return a primitive value."); } return (hint === "string" ? String : Number)(input); }
function _inherits(subClass, superClass) { if (typeof superClass !== "function" && superClass !== null) { throw new TypeError("Super expression must either be null or a function"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); Object.defineProperty(subClass, "prototype", { writable: false }); if (superClass) _setPrototypeOf(subClass, superClass); }
function _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }
function _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === "object" || typeof call === "function")) { return call; } else if (call !== void 0) { throw new TypeError("Derived constructors may only return object or undefined"); } return _assertThisInitialized(self); }
function _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError("this hasn't been initialised - super() hasn't been called"); } return self; }
function _wrapNativeSuper(Class) { var _cache = typeof Map === "function" ? new Map() : undefined; _wrapNativeSuper = function _wrapNativeSuper(Class) { if (Class === null || !_isNativeFunction(Class)) return Class; if (typeof Class !== "function") { throw new TypeError("Super expression must either be null or a function"); } if (typeof _cache !== "undefined") { if (_cache.has(Class)) return _cache.get(Class); _cache.set(Class, Wrapper); } function Wrapper() { return _construct(Class, arguments, _getPrototypeOf(this).constructor); } Wrapper.prototype = Object.create(Class.prototype, { constructor: { value: Wrapper, enumerable: false, writable: true, configurable: true } }); return _setPrototypeOf(Wrapper, Class); }; return _wrapNativeSuper(Class); }
function _construct(Parent, args, Class) { if (_isNativeReflectConstruct()) { _construct = Reflect.construct.bind(); } else { _construct = function _construct(Parent, args, Class) { var a = [null]; a.push.apply(a, args); var Constructor = Function.bind.apply(Parent, a); var instance = new Constructor(); if (Class) _setPrototypeOf(instance, Class.prototype); return instance; }; } return _construct.apply(null, arguments); }
function _isNativeReflectConstruct() { if (typeof Reflect === "undefined" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === "function") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }
function _isNativeFunction(fn) { return Function.toString.call(fn).indexOf("[native code]") !== -1; }
function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf ? Object.setPrototypeOf.bind() : function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }
function _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf.bind() : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }
var res = await __webpack_require__.e(/*! import() */ "component_AudioPost_htm").then(__webpack_require__.bind(__webpack_require__, /*! ./AudioPost.htm */ "./component/AudioPost.htm"));
var text = await res["default"];
var dom = new DOMParser().parseFromString(text, "text/html");
var html = dom.querySelector("body").innerHTML;
var template = document.createElement("template");
template.innerHTML = html;
var content = template.content;
var AudioPost = /*#__PURE__*/function (_HTMLElement) {
  _inherits(AudioPost, _HTMLElement);
  var _super = _createSuper(AudioPost);
  function AudioPost(src, script, api, id) {
    var _this;
    _classCallCheck(this, AudioPost);
    _this = _super.call(this);
    _this.id = id;
    _this.root = _this.attachShadow({
      mode: "open"
    });
    _this.root.appendChild(content.cloneNode(true));
    _this.audio = _this.root.querySelector("audio");
    _this.button = _this.root.querySelector("button#script");
    _this.p = _this.root.querySelector("p");
    function loadScript(_x) {
      return _loadScript.apply(this, arguments);
    }
    function _loadScript() {
      _loadScript = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(blob) {
        var file;
        return _regeneratorRuntime().wrap(function _callee2$(_context2) {
          while (1) switch (_context2.prev = _context2.next) {
            case 0:
              file = new File([blob], 'temp.wav');
              _context2.next = 3;
              return api.recognize(file);
            case 3:
              return _context2.abrupt("return", _context2.sent);
            case 4:
            case "end":
              return _context2.stop();
          }
        }, _callee2);
      }));
      return _loadScript.apply(this, arguments);
    }
    if (src) {
      _this.src = src;
    }
    if (script) {
      _this.script = script;
    }
    if (_this.getAttribute("src")) {
      _this.src = _this.getAttribute("src");
    }
    if (_this.getAttribute("script")) {
      _this.script = _this.getAttribute("script");
    }
    _this.button.dataset.open = "false";
    _this.button.dataset.lock = "false";
    _this.button.onclick = /*#__PURE__*/_asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {
      var _res, blob;
      return _regeneratorRuntime().wrap(function _callee$(_context) {
        while (1) switch (_context.prev = _context.next) {
          case 0:
            if (!(_this.button.dataset.lock == "true")) {
              _context.next = 2;
              break;
            }
            return _context.abrupt("return");
          case 2:
            if (!(_this.button.dataset.open == "true")) {
              _context.next = 7;
              break;
            }
            _this.p.classList.remove("open");
            _this.button.dataset.open = "false";
            _context.next = 21;
            break;
          case 7:
            _this.button.dataset.lock = "true";
            if (_this.p.textContent) {
              _context.next = 18;
              break;
            }
            _context.next = 11;
            return fetch(_this.src);
          case 11:
            _res = _context.sent;
            _context.next = 14;
            return _res.blob();
          case 14:
            blob = _context.sent;
            _context.next = 17;
            return loadScript(blob);
          case 17:
            _this.p.textContent = _context.sent;
          case 18:
            _this.button.dataset.lock = "false";
            _this.p.classList.add("open");
            _this.button.dataset.open = "true";
          case 21:
          case "end":
            return _context.stop();
        }
      }, _callee);
    }));
    return _this;
  }
  _createClass(AudioPost, [{
    key: "src",
    get: function get() {
      return this.audio.src;
    },
    set: function set(value) {
      this.audio.src = value;
    }
  }, {
    key: "script",
    get: function get() {
      return this.p.textContent;
    },
    set: function set(value) {
      this.p.textContent = value;
    }
  }, {
    key: "onDelete",
    set: function set(handler) {
      var _this2 = this;
      this.root.querySelector("button#delete").onclick = function () {
        handler(Number(_this2.id));
      };
    }
  }]);
  return AudioPost;
}( /*#__PURE__*/_wrapNativeSuper(HTMLElement));
customElements.define("audio-post", AudioPost);
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AudioPost);
__webpack_async_result__();
} catch(e) { __webpack_async_result__(e); } }, 1);

/***/ }),

/***/ "./index.js":
/*!******************!*\
  !*** ./index.js ***!
  \******************/
/***/ ((module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.a(module, async (__webpack_handle_async_dependencies__, __webpack_async_result__) => { try {
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var webm_to_wav_converter__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! webm-to-wav-converter */ "./node_modules/webm-to-wav-converter/index.js");
/* harmony import */ var _src_AMRecorder_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./src/AMRecorder.js */ "./src/AMRecorder.js");
/* harmony import */ var _src_BtnControl_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./src/BtnControl.js */ "./src/BtnControl.js");
/* harmony import */ var _src_MockStream_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./src/MockStream.js */ "./src/MockStream.js");
/* harmony import */ var _component_AudioPost_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./component/AudioPost.js */ "./component/AudioPost.js");
/* harmony import */ var _src_Record_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./src/Record.js */ "./src/Record.js");
/* harmony import */ var _src_API_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./src/API.js */ "./src/API.js");
var __webpack_async_dependencies__ = __webpack_handle_async_dependencies__([_component_AudioPost_js__WEBPACK_IMPORTED_MODULE_4__, _src_API_js__WEBPACK_IMPORTED_MODULE_6__]);
([_component_AudioPost_js__WEBPACK_IMPORTED_MODULE_4__, _src_API_js__WEBPACK_IMPORTED_MODULE_6__] = __webpack_async_dependencies__.then ? (await __webpack_async_dependencies__)() : __webpack_async_dependencies__);
function _typeof(obj) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof(obj); }
function ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); enumerableOnly && (symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; })), keys.push.apply(keys, symbols); } return keys; }
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = null != arguments[i] ? arguments[i] : {}; i % 2 ? ownKeys(Object(source), !0).forEach(function (key) { _defineProperty(target, key, source[key]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } return target; }
function _defineProperty(obj, key, value) { key = _toPropertyKey(key); if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }
function _toPropertyKey(arg) { var key = _toPrimitive(arg, "string"); return _typeof(key) === "symbol" ? key : String(key); }
function _toPrimitive(input, hint) { if (_typeof(input) !== "object" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || "default"); if (_typeof(res) !== "object") return res; throw new TypeError("@@toPrimitive must return a primitive value."); } return (hint === "string" ? String : Number)(input); }
function _regeneratorRuntime() { "use strict"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return exports; }; var exports = {}, Op = Object.prototype, hasOwn = Op.hasOwnProperty, defineProperty = Object.defineProperty || function (obj, key, desc) { obj[key] = desc.value; }, $Symbol = "function" == typeof Symbol ? Symbol : {}, iteratorSymbol = $Symbol.iterator || "@@iterator", asyncIteratorSymbol = $Symbol.asyncIterator || "@@asyncIterator", toStringTagSymbol = $Symbol.toStringTag || "@@toStringTag"; function define(obj, key, value) { return Object.defineProperty(obj, key, { value: value, enumerable: !0, configurable: !0, writable: !0 }), obj[key]; } try { define({}, ""); } catch (err) { define = function define(obj, key, value) { return obj[key] = value; }; } function wrap(innerFn, outerFn, self, tryLocsList) { var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator, generator = Object.create(protoGenerator.prototype), context = new Context(tryLocsList || []); return defineProperty(generator, "_invoke", { value: makeInvokeMethod(innerFn, self, context) }), generator; } function tryCatch(fn, obj, arg) { try { return { type: "normal", arg: fn.call(obj, arg) }; } catch (err) { return { type: "throw", arg: err }; } } exports.wrap = wrap; var ContinueSentinel = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var IteratorPrototype = {}; define(IteratorPrototype, iteratorSymbol, function () { return this; }); var getProto = Object.getPrototypeOf, NativeIteratorPrototype = getProto && getProto(getProto(values([]))); NativeIteratorPrototype && NativeIteratorPrototype !== Op && hasOwn.call(NativeIteratorPrototype, iteratorSymbol) && (IteratorPrototype = NativeIteratorPrototype); var Gp = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(IteratorPrototype); function defineIteratorMethods(prototype) { ["next", "throw", "return"].forEach(function (method) { define(prototype, method, function (arg) { return this._invoke(method, arg); }); }); } function AsyncIterator(generator, PromiseImpl) { function invoke(method, arg, resolve, reject) { var record = tryCatch(generator[method], generator, arg); if ("throw" !== record.type) { var result = record.arg, value = result.value; return value && "object" == _typeof(value) && hasOwn.call(value, "__await") ? PromiseImpl.resolve(value.__await).then(function (value) { invoke("next", value, resolve, reject); }, function (err) { invoke("throw", err, resolve, reject); }) : PromiseImpl.resolve(value).then(function (unwrapped) { result.value = unwrapped, resolve(result); }, function (error) { return invoke("throw", error, resolve, reject); }); } reject(record.arg); } var previousPromise; defineProperty(this, "_invoke", { value: function value(method, arg) { function callInvokeWithMethodAndArg() { return new PromiseImpl(function (resolve, reject) { invoke(method, arg, resolve, reject); }); } return previousPromise = previousPromise ? previousPromise.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); } }); } function makeInvokeMethod(innerFn, self, context) { var state = "suspendedStart"; return function (method, arg) { if ("executing" === state) throw new Error("Generator is already running"); if ("completed" === state) { if ("throw" === method) throw arg; return doneResult(); } for (context.method = method, context.arg = arg;;) { var delegate = context.delegate; if (delegate) { var delegateResult = maybeInvokeDelegate(delegate, context); if (delegateResult) { if (delegateResult === ContinueSentinel) continue; return delegateResult; } } if ("next" === context.method) context.sent = context._sent = context.arg;else if ("throw" === context.method) { if ("suspendedStart" === state) throw state = "completed", context.arg; context.dispatchException(context.arg); } else "return" === context.method && context.abrupt("return", context.arg); state = "executing"; var record = tryCatch(innerFn, self, context); if ("normal" === record.type) { if (state = context.done ? "completed" : "suspendedYield", record.arg === ContinueSentinel) continue; return { value: record.arg, done: context.done }; } "throw" === record.type && (state = "completed", context.method = "throw", context.arg = record.arg); } }; } function maybeInvokeDelegate(delegate, context) { var methodName = context.method, method = delegate.iterator[methodName]; if (undefined === method) return context.delegate = null, "throw" === methodName && delegate.iterator["return"] && (context.method = "return", context.arg = undefined, maybeInvokeDelegate(delegate, context), "throw" === context.method) || "return" !== methodName && (context.method = "throw", context.arg = new TypeError("The iterator does not provide a '" + methodName + "' method")), ContinueSentinel; var record = tryCatch(method, delegate.iterator, context.arg); if ("throw" === record.type) return context.method = "throw", context.arg = record.arg, context.delegate = null, ContinueSentinel; var info = record.arg; return info ? info.done ? (context[delegate.resultName] = info.value, context.next = delegate.nextLoc, "return" !== context.method && (context.method = "next", context.arg = undefined), context.delegate = null, ContinueSentinel) : info : (context.method = "throw", context.arg = new TypeError("iterator result is not an object"), context.delegate = null, ContinueSentinel); } function pushTryEntry(locs) { var entry = { tryLoc: locs[0] }; 1 in locs && (entry.catchLoc = locs[1]), 2 in locs && (entry.finallyLoc = locs[2], entry.afterLoc = locs[3]), this.tryEntries.push(entry); } function resetTryEntry(entry) { var record = entry.completion || {}; record.type = "normal", delete record.arg, entry.completion = record; } function Context(tryLocsList) { this.tryEntries = [{ tryLoc: "root" }], tryLocsList.forEach(pushTryEntry, this), this.reset(!0); } function values(iterable) { if (iterable) { var iteratorMethod = iterable[iteratorSymbol]; if (iteratorMethod) return iteratorMethod.call(iterable); if ("function" == typeof iterable.next) return iterable; if (!isNaN(iterable.length)) { var i = -1, next = function next() { for (; ++i < iterable.length;) if (hasOwn.call(iterable, i)) return next.value = iterable[i], next.done = !1, next; return next.value = undefined, next.done = !0, next; }; return next.next = next; } } return { next: doneResult }; } function doneResult() { return { value: undefined, done: !0 }; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, defineProperty(Gp, "constructor", { value: GeneratorFunctionPrototype, configurable: !0 }), defineProperty(GeneratorFunctionPrototype, "constructor", { value: GeneratorFunction, configurable: !0 }), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, toStringTagSymbol, "GeneratorFunction"), exports.isGeneratorFunction = function (genFun) { var ctor = "function" == typeof genFun && genFun.constructor; return !!ctor && (ctor === GeneratorFunction || "GeneratorFunction" === (ctor.displayName || ctor.name)); }, exports.mark = function (genFun) { return Object.setPrototypeOf ? Object.setPrototypeOf(genFun, GeneratorFunctionPrototype) : (genFun.__proto__ = GeneratorFunctionPrototype, define(genFun, toStringTagSymbol, "GeneratorFunction")), genFun.prototype = Object.create(Gp), genFun; }, exports.awrap = function (arg) { return { __await: arg }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, asyncIteratorSymbol, function () { return this; }), exports.AsyncIterator = AsyncIterator, exports.async = function (innerFn, outerFn, self, tryLocsList, PromiseImpl) { void 0 === PromiseImpl && (PromiseImpl = Promise); var iter = new AsyncIterator(wrap(innerFn, outerFn, self, tryLocsList), PromiseImpl); return exports.isGeneratorFunction(outerFn) ? iter : iter.next().then(function (result) { return result.done ? result.value : iter.next(); }); }, defineIteratorMethods(Gp), define(Gp, toStringTagSymbol, "Generator"), define(Gp, iteratorSymbol, function () { return this; }), define(Gp, "toString", function () { return "[object Generator]"; }), exports.keys = function (val) { var object = Object(val), keys = []; for (var key in object) keys.push(key); return keys.reverse(), function next() { for (; keys.length;) { var key = keys.pop(); if (key in object) return next.value = key, next.done = !1, next; } return next.done = !0, next; }; }, exports.values = values, Context.prototype = { constructor: Context, reset: function reset(skipTempReset) { if (this.prev = 0, this.next = 0, this.sent = this._sent = undefined, this.done = !1, this.delegate = null, this.method = "next", this.arg = undefined, this.tryEntries.forEach(resetTryEntry), !skipTempReset) for (var name in this) "t" === name.charAt(0) && hasOwn.call(this, name) && !isNaN(+name.slice(1)) && (this[name] = undefined); }, stop: function stop() { this.done = !0; var rootRecord = this.tryEntries[0].completion; if ("throw" === rootRecord.type) throw rootRecord.arg; return this.rval; }, dispatchException: function dispatchException(exception) { if (this.done) throw exception; var context = this; function handle(loc, caught) { return record.type = "throw", record.arg = exception, context.next = loc, caught && (context.method = "next", context.arg = undefined), !!caught; } for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i], record = entry.completion; if ("root" === entry.tryLoc) return handle("end"); if (entry.tryLoc <= this.prev) { var hasCatch = hasOwn.call(entry, "catchLoc"), hasFinally = hasOwn.call(entry, "finallyLoc"); if (hasCatch && hasFinally) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } else if (hasCatch) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); } else { if (!hasFinally) throw new Error("try statement without catch or finally"); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } } } }, abrupt: function abrupt(type, arg) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc <= this.prev && hasOwn.call(entry, "finallyLoc") && this.prev < entry.finallyLoc) { var finallyEntry = entry; break; } } finallyEntry && ("break" === type || "continue" === type) && finallyEntry.tryLoc <= arg && arg <= finallyEntry.finallyLoc && (finallyEntry = null); var record = finallyEntry ? finallyEntry.completion : {}; return record.type = type, record.arg = arg, finallyEntry ? (this.method = "next", this.next = finallyEntry.finallyLoc, ContinueSentinel) : this.complete(record); }, complete: function complete(record, afterLoc) { if ("throw" === record.type) throw record.arg; return "break" === record.type || "continue" === record.type ? this.next = record.arg : "return" === record.type ? (this.rval = this.arg = record.arg, this.method = "return", this.next = "end") : "normal" === record.type && afterLoc && (this.next = afterLoc), ContinueSentinel; }, finish: function finish(finallyLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.finallyLoc === finallyLoc) return this.complete(entry.completion, entry.afterLoc), resetTryEntry(entry), ContinueSentinel; } }, "catch": function _catch(tryLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc === tryLoc) { var record = entry.completion; if ("throw" === record.type) { var thrown = record.arg; resetTryEntry(entry); } return thrown; } } throw new Error("illegal catch attempt"); }, delegateYield: function delegateYield(iterable, resultName, nextLoc) { return this.delegate = { iterator: values(iterable), resultName: resultName, nextLoc: nextLoc }, "next" === this.method && (this.arg = undefined), ContinueSentinel; } }, exports; }
function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }
function _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err); } _next(undefined); }); }; }







var api = new _src_API_js__WEBPACK_IMPORTED_MODULE_6__["default"]();
var record = new _src_Record_js__WEBPACK_IMPORTED_MODULE_5__["default"]();
function add(data) {
  var url = URL.createObjectURL(data.blob);
  var ul = document.querySelector("main ul");
  var li = document.createElement("li");
  var post = new _component_AudioPost_js__WEBPACK_IMPORTED_MODULE_4__["default"](url, data.script, api, data.id);
  post.onDelete = /*#__PURE__*/function () {
    var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(id) {
      return _regeneratorRuntime().wrap(function _callee$(_context) {
        while (1) switch (_context.prev = _context.next) {
          case 0:
            _context.next = 2;
            return record["delete"](id);
          case 2:
            ul.removeChild(li);
          case 3:
          case "end":
            return _context.stop();
        }
      }, _callee);
    }));
    return function (_x) {
      return _ref.apply(this, arguments);
    };
  }();
  li.appendChild(post);
  ul.appendChild(li);
}
function init() {
  return _init.apply(this, arguments);
}
function _init() {
  _init = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee5() {
    var data;
    return _regeneratorRuntime().wrap(function _callee5$(_context5) {
      while (1) switch (_context5.prev = _context5.next) {
        case 0:
          _context5.next = 2;
          return record.connect();
        case 2:
          _context5.next = 4;
          return record.list();
        case 4:
          data = _context5.sent;
          data.forEach(add);
        case 6:
        case "end":
          return _context5.stop();
      }
    }, _callee5);
  }));
  return _init.apply(this, arguments);
}
function save(_x2) {
  return _save.apply(this, arguments);
}
function _save() {
  _save = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee6(blob) {
    var data, id;
    return _regeneratorRuntime().wrap(function _callee6$(_context6) {
      while (1) switch (_context6.prev = _context6.next) {
        case 0:
          data = {
            blob: blob,
            script: null
          };
          _context6.next = 3;
          return record.connect();
        case 3:
          _context6.next = 5;
          return record.save(data);
        case 5:
          id = _context6.sent;
          add(_objectSpread(_objectSpread({}, data), {}, {
            id: id
          }));
        case 7:
        case "end":
          return _context6.stop();
      }
    }, _callee6);
  }));
  return _save.apply(this, arguments);
}
function configure(stream) {
  var recorder = new window.MediaRecorder(stream);
  var chunks = [];
  var recording = false;
  recorder.ondataavailable = function (event) {
    if (event.data.size > 0) {
      chunks.push(event.data);
    }
  };
  recorder.onstop = /*#__PURE__*/_asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2() {
    var blob;
    return _regeneratorRuntime().wrap(function _callee2$(_context2) {
      while (1) switch (_context2.prev = _context2.next) {
        case 0:
          _context2.next = 2;
          return (0,webm_to_wav_converter__WEBPACK_IMPORTED_MODULE_0__.getWaveBlob)(new Blob(chunks));
        case 2:
          blob = _context2.sent;
          chunks = [];
          save(blob);
        case 5:
        case "end":
          return _context2.stop();
      }
    }, _callee2);
  }));
  function onDown() {
    switch (amr.state) {
      case "init":
        amr.toTrans();
        break;
      case "rec":
        break;
      default:
        alert("error");
        break;
    }
  }
  function onLong() {
    switch (amr.state) {
      case "trans":
        amr.toShot();
        break;
      case "rec":
        break;
      default:
        alert("error");
        break;
    }
  }
  function onUp() {
    switch (amr.state) {
      case "trans":
        amr.toRec();
        break;
      case "rec":
        amr.toInit();
        break;
      case "shot":
        amr.toInit();
        break;
      default:
        alert("error");
        break;
    }
  }
  var button = document.querySelector("button#record");
  var bc = new _src_BtnControl_js__WEBPACK_IMPORTED_MODULE_2__["default"](button, onDown, onLong, onUp);
  function start() {
    if (!recording) {
      recording = true;
      button.classList.add("on");
      recorder.start();
      return true;
    } else {
      return false;
    }
  }
  function stop() {
    if (recording) {
      recording = false;
      recorder.stop();
      button.classList.remove("on");
      return true;
    } else {
      return false;
    }
  }
  var amr = new _src_AMRecorder_js__WEBPACK_IMPORTED_MODULE_1__["default"](start, stop);
}
if (navigator.mediaDevices) {
  navigator.mediaDevices.getUserMedia({
    audio: true,
    video: false
  }).then(configure);
}
var accountElement = document.querySelector("section#account");
var signupElements = document.querySelectorAll(".account_signup");
var loginElements = document.querySelectorAll(".account_login");
var login = document.querySelector("#login");
var logout = document.querySelector("#logout");
var register = document.querySelector("#register");
var form = document.querySelector("form");
var conversation = null;
__webpack_require__.e(/*! import() */ "credentials_json").then(__webpack_require__.t.bind(__webpack_require__, /*! ./credentials.json */ "./credentials.json", 23)).then( /*#__PURE__*/function () {
  var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3(data) {
    var speech_key, speech_region, openai_key;
    return _regeneratorRuntime().wrap(function _callee3$(_context3) {
      while (1) switch (_context3.prev = _context3.next) {
        case 0:
          speech_key = document.querySelector("#speech_key");
          speech_region = document.querySelector("#speech_region");
          openai_key = document.querySelector("#openai_key");
          speech_key.value = data.azure.key;
          speech_region.value = data.azure.region;
          openai_key.value = data.openai.key;
        case 6:
        case "end":
          return _context3.stop();
      }
    }, _callee3);
  }));
  return function (_x3) {
    return _ref3.apply(this, arguments);
  };
}())["catch"](function (err) {
  console.log(err);
});
if (!api.loggedin()) {
  accountElement.classList.add("open");
  if (api.exists()) {
    loginElements.forEach(function (elem) {
      return elem.classList.add("open");
    });
  } else {
    signupElements.forEach(function (elem) {
      return elem.classList.add("open");
    });
  }
}
form.onsubmit = function (event) {
  return event.preventDefault();
};
login.onclick = function (event) {
  var formData = new FormData(form);
  var passwd = formData.get("passwd");
  if (!api.login(passwd)) {
    alert("Failed to login.");
    return;
  }
  loginElements.forEach(function (elem) {
    return elem.classList.remove("open");
  });
  accountElement.classList.remove("open");
  conversation = api.conversation();
};
register.onclick = function (event) {
  var formData = new FormData(form);
  var speech_key = formData.get("speech_key");
  var speech_region = formData.get("speech_region");
  var openai_key = formData.get("openai_key");
  var passwd = formData.get("passwd");
  api.signup(speech_key, speech_region, openai_key, passwd);
  accountElement.classList.remove("open");
  conversation = api.conversation();
};
logout.onclick = function (event) {
  api.logout();
  loginElements.forEach(function (elem) {
    return elem.classList.remove("open");
  });
  signupElements.forEach(function (elem) {
    return elem.classList.add("open");
  });
  conversation = null;
};
function write(msg) {
  var ul = document.querySelector("main ul");
  var li = document.createElement("li");
  li.textContent = msg;
  ul.appendChild(li);
}
var say = document.querySelector("#say");
var textarea = document.querySelector("textarea");
say.onclick = /*#__PURE__*/_asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee4() {
  var req, rep;
  return _regeneratorRuntime().wrap(function _callee4$(_context4) {
    while (1) switch (_context4.prev = _context4.next) {
      case 0:
        if (!conversation) {
          _context4.next = 7;
          break;
        }
        req = textarea.value;
        write(req);
        _context4.next = 5;
        return conversation.say(req);
      case 5:
        rep = _context4.sent;
        write(rep);
      case 7:
      case "end":
        return _context4.stop();
    }
  }, _callee4);
}));
init();
__webpack_async_result__();
} catch(e) { __webpack_async_result__(e); } });

/***/ }),

/***/ "./node_modules/axios/index.js":
/*!*************************************!*\
  !*** ./node_modules/axios/index.js ***!
  \*************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

module.exports = __webpack_require__(/*! ./lib/axios */ "./node_modules/axios/lib/axios.js");

/***/ }),

/***/ "./node_modules/axios/lib/adapters/xhr.js":
/*!************************************************!*\
  !*** ./node_modules/axios/lib/adapters/xhr.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ./../utils */ "./node_modules/axios/lib/utils.js");
var settle = __webpack_require__(/*! ./../core/settle */ "./node_modules/axios/lib/core/settle.js");
var cookies = __webpack_require__(/*! ./../helpers/cookies */ "./node_modules/axios/lib/helpers/cookies.js");
var buildURL = __webpack_require__(/*! ./../helpers/buildURL */ "./node_modules/axios/lib/helpers/buildURL.js");
var buildFullPath = __webpack_require__(/*! ../core/buildFullPath */ "./node_modules/axios/lib/core/buildFullPath.js");
var parseHeaders = __webpack_require__(/*! ./../helpers/parseHeaders */ "./node_modules/axios/lib/helpers/parseHeaders.js");
var isURLSameOrigin = __webpack_require__(/*! ./../helpers/isURLSameOrigin */ "./node_modules/axios/lib/helpers/isURLSameOrigin.js");
var createError = __webpack_require__(/*! ../core/createError */ "./node_modules/axios/lib/core/createError.js");
var transitionalDefaults = __webpack_require__(/*! ../defaults/transitional */ "./node_modules/axios/lib/defaults/transitional.js");
var Cancel = __webpack_require__(/*! ../cancel/Cancel */ "./node_modules/axios/lib/cancel/Cancel.js");
module.exports = function xhrAdapter(config) {
  return new Promise(function dispatchXhrRequest(resolve, reject) {
    var requestData = config.data;
    var requestHeaders = config.headers;
    var responseType = config.responseType;
    var onCanceled;
    function done() {
      if (config.cancelToken) {
        config.cancelToken.unsubscribe(onCanceled);
      }
      if (config.signal) {
        config.signal.removeEventListener('abort', onCanceled);
      }
    }
    if (utils.isFormData(requestData)) {
      delete requestHeaders['Content-Type']; // Let the browser set it
    }

    var request = new XMLHttpRequest();

    // HTTP basic authentication
    if (config.auth) {
      var username = config.auth.username || '';
      var password = config.auth.password ? unescape(encodeURIComponent(config.auth.password)) : '';
      requestHeaders.Authorization = 'Basic ' + btoa(username + ':' + password);
    }
    var fullPath = buildFullPath(config.baseURL, config.url);
    request.open(config.method.toUpperCase(), buildURL(fullPath, config.params, config.paramsSerializer), true);

    // Set the request timeout in MS
    request.timeout = config.timeout;
    function onloadend() {
      if (!request) {
        return;
      }
      // Prepare the response
      var responseHeaders = 'getAllResponseHeaders' in request ? parseHeaders(request.getAllResponseHeaders()) : null;
      var responseData = !responseType || responseType === 'text' || responseType === 'json' ? request.responseText : request.response;
      var response = {
        data: responseData,
        status: request.status,
        statusText: request.statusText,
        headers: responseHeaders,
        config: config,
        request: request
      };
      settle(function _resolve(value) {
        resolve(value);
        done();
      }, function _reject(err) {
        reject(err);
        done();
      }, response);

      // Clean up request
      request = null;
    }
    if ('onloadend' in request) {
      // Use onloadend if available
      request.onloadend = onloadend;
    } else {
      // Listen for ready state to emulate onloadend
      request.onreadystatechange = function handleLoad() {
        if (!request || request.readyState !== 4) {
          return;
        }

        // The request errored out and we didn't get a response, this will be
        // handled by onerror instead
        // With one exception: request that using file: protocol, most browsers
        // will return status as 0 even though it's a successful request
        if (request.status === 0 && !(request.responseURL && request.responseURL.indexOf('file:') === 0)) {
          return;
        }
        // readystate handler is calling before onerror or ontimeout handlers,
        // so we should call onloadend on the next 'tick'
        setTimeout(onloadend);
      };
    }

    // Handle browser request cancellation (as opposed to a manual cancellation)
    request.onabort = function handleAbort() {
      if (!request) {
        return;
      }
      reject(createError('Request aborted', config, 'ECONNABORTED', request));

      // Clean up request
      request = null;
    };

    // Handle low level network errors
    request.onerror = function handleError() {
      // Real errors are hidden from us by the browser
      // onerror should only fire if it's a network error
      reject(createError('Network Error', config, null, request));

      // Clean up request
      request = null;
    };

    // Handle timeout
    request.ontimeout = function handleTimeout() {
      var timeoutErrorMessage = config.timeout ? 'timeout of ' + config.timeout + 'ms exceeded' : 'timeout exceeded';
      var transitional = config.transitional || transitionalDefaults;
      if (config.timeoutErrorMessage) {
        timeoutErrorMessage = config.timeoutErrorMessage;
      }
      reject(createError(timeoutErrorMessage, config, transitional.clarifyTimeoutError ? 'ETIMEDOUT' : 'ECONNABORTED', request));

      // Clean up request
      request = null;
    };

    // Add xsrf header
    // This is only done if running in a standard browser environment.
    // Specifically not if we're in a web worker, or react-native.
    if (utils.isStandardBrowserEnv()) {
      // Add xsrf header
      var xsrfValue = (config.withCredentials || isURLSameOrigin(fullPath)) && config.xsrfCookieName ? cookies.read(config.xsrfCookieName) : undefined;
      if (xsrfValue) {
        requestHeaders[config.xsrfHeaderName] = xsrfValue;
      }
    }

    // Add headers to the request
    if ('setRequestHeader' in request) {
      utils.forEach(requestHeaders, function setRequestHeader(val, key) {
        if (typeof requestData === 'undefined' && key.toLowerCase() === 'content-type') {
          // Remove Content-Type if data is undefined
          delete requestHeaders[key];
        } else {
          // Otherwise add header to the request
          request.setRequestHeader(key, val);
        }
      });
    }

    // Add withCredentials to request if needed
    if (!utils.isUndefined(config.withCredentials)) {
      request.withCredentials = !!config.withCredentials;
    }

    // Add responseType to request if needed
    if (responseType && responseType !== 'json') {
      request.responseType = config.responseType;
    }

    // Handle progress if needed
    if (typeof config.onDownloadProgress === 'function') {
      request.addEventListener('progress', config.onDownloadProgress);
    }

    // Not all browsers support upload events
    if (typeof config.onUploadProgress === 'function' && request.upload) {
      request.upload.addEventListener('progress', config.onUploadProgress);
    }
    if (config.cancelToken || config.signal) {
      // Handle cancellation
      // eslint-disable-next-line func-names
      onCanceled = function (cancel) {
        if (!request) {
          return;
        }
        reject(!cancel || cancel && cancel.type ? new Cancel('canceled') : cancel);
        request.abort();
        request = null;
      };
      config.cancelToken && config.cancelToken.subscribe(onCanceled);
      if (config.signal) {
        config.signal.aborted ? onCanceled() : config.signal.addEventListener('abort', onCanceled);
      }
    }
    if (!requestData) {
      requestData = null;
    }

    // Send the request
    request.send(requestData);
  });
};

/***/ }),

/***/ "./node_modules/axios/lib/axios.js":
/*!*****************************************!*\
  !*** ./node_modules/axios/lib/axios.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ./utils */ "./node_modules/axios/lib/utils.js");
var bind = __webpack_require__(/*! ./helpers/bind */ "./node_modules/axios/lib/helpers/bind.js");
var Axios = __webpack_require__(/*! ./core/Axios */ "./node_modules/axios/lib/core/Axios.js");
var mergeConfig = __webpack_require__(/*! ./core/mergeConfig */ "./node_modules/axios/lib/core/mergeConfig.js");
var defaults = __webpack_require__(/*! ./defaults */ "./node_modules/axios/lib/defaults/index.js");

/**
 * Create an instance of Axios
 *
 * @param {Object} defaultConfig The default config for the instance
 * @return {Axios} A new instance of Axios
 */
function createInstance(defaultConfig) {
  var context = new Axios(defaultConfig);
  var instance = bind(Axios.prototype.request, context);

  // Copy axios.prototype to instance
  utils.extend(instance, Axios.prototype, context);

  // Copy context to instance
  utils.extend(instance, context);

  // Factory for creating new instances
  instance.create = function create(instanceConfig) {
    return createInstance(mergeConfig(defaultConfig, instanceConfig));
  };
  return instance;
}

// Create the default instance to be exported
var axios = createInstance(defaults);

// Expose Axios class to allow class inheritance
axios.Axios = Axios;

// Expose Cancel & CancelToken
axios.Cancel = __webpack_require__(/*! ./cancel/Cancel */ "./node_modules/axios/lib/cancel/Cancel.js");
axios.CancelToken = __webpack_require__(/*! ./cancel/CancelToken */ "./node_modules/axios/lib/cancel/CancelToken.js");
axios.isCancel = __webpack_require__(/*! ./cancel/isCancel */ "./node_modules/axios/lib/cancel/isCancel.js");
axios.VERSION = (__webpack_require__(/*! ./env/data */ "./node_modules/axios/lib/env/data.js").version);

// Expose all/spread
axios.all = function all(promises) {
  return Promise.all(promises);
};
axios.spread = __webpack_require__(/*! ./helpers/spread */ "./node_modules/axios/lib/helpers/spread.js");

// Expose isAxiosError
axios.isAxiosError = __webpack_require__(/*! ./helpers/isAxiosError */ "./node_modules/axios/lib/helpers/isAxiosError.js");
module.exports = axios;

// Allow use of default import syntax in TypeScript
module.exports["default"] = axios;

/***/ }),

/***/ "./node_modules/axios/lib/cancel/Cancel.js":
/*!*************************************************!*\
  !*** ./node_modules/axios/lib/cancel/Cancel.js ***!
  \*************************************************/
/***/ ((module) => {

"use strict";


/**
 * A `Cancel` is an object that is thrown when an operation is canceled.
 *
 * @class
 * @param {string=} message The message.
 */
function Cancel(message) {
  this.message = message;
}
Cancel.prototype.toString = function toString() {
  return 'Cancel' + (this.message ? ': ' + this.message : '');
};
Cancel.prototype.__CANCEL__ = true;
module.exports = Cancel;

/***/ }),

/***/ "./node_modules/axios/lib/cancel/CancelToken.js":
/*!******************************************************!*\
  !*** ./node_modules/axios/lib/cancel/CancelToken.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var Cancel = __webpack_require__(/*! ./Cancel */ "./node_modules/axios/lib/cancel/Cancel.js");

/**
 * A `CancelToken` is an object that can be used to request cancellation of an operation.
 *
 * @class
 * @param {Function} executor The executor function.
 */
function CancelToken(executor) {
  if (typeof executor !== 'function') {
    throw new TypeError('executor must be a function.');
  }
  var resolvePromise;
  this.promise = new Promise(function promiseExecutor(resolve) {
    resolvePromise = resolve;
  });
  var token = this;

  // eslint-disable-next-line func-names
  this.promise.then(function (cancel) {
    if (!token._listeners) return;
    var i;
    var l = token._listeners.length;
    for (i = 0; i < l; i++) {
      token._listeners[i](cancel);
    }
    token._listeners = null;
  });

  // eslint-disable-next-line func-names
  this.promise.then = function (onfulfilled) {
    var _resolve;
    // eslint-disable-next-line func-names
    var promise = new Promise(function (resolve) {
      token.subscribe(resolve);
      _resolve = resolve;
    }).then(onfulfilled);
    promise.cancel = function reject() {
      token.unsubscribe(_resolve);
    };
    return promise;
  };
  executor(function cancel(message) {
    if (token.reason) {
      // Cancellation has already been requested
      return;
    }
    token.reason = new Cancel(message);
    resolvePromise(token.reason);
  });
}

/**
 * Throws a `Cancel` if cancellation has been requested.
 */
CancelToken.prototype.throwIfRequested = function throwIfRequested() {
  if (this.reason) {
    throw this.reason;
  }
};

/**
 * Subscribe to the cancel signal
 */

CancelToken.prototype.subscribe = function subscribe(listener) {
  if (this.reason) {
    listener(this.reason);
    return;
  }
  if (this._listeners) {
    this._listeners.push(listener);
  } else {
    this._listeners = [listener];
  }
};

/**
 * Unsubscribe from the cancel signal
 */

CancelToken.prototype.unsubscribe = function unsubscribe(listener) {
  if (!this._listeners) {
    return;
  }
  var index = this._listeners.indexOf(listener);
  if (index !== -1) {
    this._listeners.splice(index, 1);
  }
};

/**
 * Returns an object that contains a new `CancelToken` and a function that, when called,
 * cancels the `CancelToken`.
 */
CancelToken.source = function source() {
  var cancel;
  var token = new CancelToken(function executor(c) {
    cancel = c;
  });
  return {
    token: token,
    cancel: cancel
  };
};
module.exports = CancelToken;

/***/ }),

/***/ "./node_modules/axios/lib/cancel/isCancel.js":
/*!***************************************************!*\
  !*** ./node_modules/axios/lib/cancel/isCancel.js ***!
  \***************************************************/
/***/ ((module) => {

"use strict";


module.exports = function isCancel(value) {
  return !!(value && value.__CANCEL__);
};

/***/ }),

/***/ "./node_modules/axios/lib/core/Axios.js":
/*!**********************************************!*\
  !*** ./node_modules/axios/lib/core/Axios.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ./../utils */ "./node_modules/axios/lib/utils.js");
var buildURL = __webpack_require__(/*! ../helpers/buildURL */ "./node_modules/axios/lib/helpers/buildURL.js");
var InterceptorManager = __webpack_require__(/*! ./InterceptorManager */ "./node_modules/axios/lib/core/InterceptorManager.js");
var dispatchRequest = __webpack_require__(/*! ./dispatchRequest */ "./node_modules/axios/lib/core/dispatchRequest.js");
var mergeConfig = __webpack_require__(/*! ./mergeConfig */ "./node_modules/axios/lib/core/mergeConfig.js");
var validator = __webpack_require__(/*! ../helpers/validator */ "./node_modules/axios/lib/helpers/validator.js");
var validators = validator.validators;
/**
 * Create a new instance of Axios
 *
 * @param {Object} instanceConfig The default config for the instance
 */
function Axios(instanceConfig) {
  this.defaults = instanceConfig;
  this.interceptors = {
    request: new InterceptorManager(),
    response: new InterceptorManager()
  };
}

/**
 * Dispatch a request
 *
 * @param {Object} config The config specific for this request (merged with this.defaults)
 */
Axios.prototype.request = function request(configOrUrl, config) {
  /*eslint no-param-reassign:0*/
  // Allow for axios('example/url'[, config]) a la fetch API
  if (typeof configOrUrl === 'string') {
    config = config || {};
    config.url = configOrUrl;
  } else {
    config = configOrUrl || {};
  }
  config = mergeConfig(this.defaults, config);

  // Set config.method
  if (config.method) {
    config.method = config.method.toLowerCase();
  } else if (this.defaults.method) {
    config.method = this.defaults.method.toLowerCase();
  } else {
    config.method = 'get';
  }
  var transitional = config.transitional;
  if (transitional !== undefined) {
    validator.assertOptions(transitional, {
      silentJSONParsing: validators.transitional(validators.boolean),
      forcedJSONParsing: validators.transitional(validators.boolean),
      clarifyTimeoutError: validators.transitional(validators.boolean)
    }, false);
  }

  // filter out skipped interceptors
  var requestInterceptorChain = [];
  var synchronousRequestInterceptors = true;
  this.interceptors.request.forEach(function unshiftRequestInterceptors(interceptor) {
    if (typeof interceptor.runWhen === 'function' && interceptor.runWhen(config) === false) {
      return;
    }
    synchronousRequestInterceptors = synchronousRequestInterceptors && interceptor.synchronous;
    requestInterceptorChain.unshift(interceptor.fulfilled, interceptor.rejected);
  });
  var responseInterceptorChain = [];
  this.interceptors.response.forEach(function pushResponseInterceptors(interceptor) {
    responseInterceptorChain.push(interceptor.fulfilled, interceptor.rejected);
  });
  var promise;
  if (!synchronousRequestInterceptors) {
    var chain = [dispatchRequest, undefined];
    Array.prototype.unshift.apply(chain, requestInterceptorChain);
    chain = chain.concat(responseInterceptorChain);
    promise = Promise.resolve(config);
    while (chain.length) {
      promise = promise.then(chain.shift(), chain.shift());
    }
    return promise;
  }
  var newConfig = config;
  while (requestInterceptorChain.length) {
    var onFulfilled = requestInterceptorChain.shift();
    var onRejected = requestInterceptorChain.shift();
    try {
      newConfig = onFulfilled(newConfig);
    } catch (error) {
      onRejected(error);
      break;
    }
  }
  try {
    promise = dispatchRequest(newConfig);
  } catch (error) {
    return Promise.reject(error);
  }
  while (responseInterceptorChain.length) {
    promise = promise.then(responseInterceptorChain.shift(), responseInterceptorChain.shift());
  }
  return promise;
};
Axios.prototype.getUri = function getUri(config) {
  config = mergeConfig(this.defaults, config);
  return buildURL(config.url, config.params, config.paramsSerializer).replace(/^\?/, '');
};

// Provide aliases for supported request methods
utils.forEach(['delete', 'get', 'head', 'options'], function forEachMethodNoData(method) {
  /*eslint func-names:0*/
  Axios.prototype[method] = function (url, config) {
    return this.request(mergeConfig(config || {}, {
      method: method,
      url: url,
      data: (config || {}).data
    }));
  };
});
utils.forEach(['post', 'put', 'patch'], function forEachMethodWithData(method) {
  /*eslint func-names:0*/
  Axios.prototype[method] = function (url, data, config) {
    return this.request(mergeConfig(config || {}, {
      method: method,
      url: url,
      data: data
    }));
  };
});
module.exports = Axios;

/***/ }),

/***/ "./node_modules/axios/lib/core/InterceptorManager.js":
/*!***********************************************************!*\
  !*** ./node_modules/axios/lib/core/InterceptorManager.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ./../utils */ "./node_modules/axios/lib/utils.js");
function InterceptorManager() {
  this.handlers = [];
}

/**
 * Add a new interceptor to the stack
 *
 * @param {Function} fulfilled The function to handle `then` for a `Promise`
 * @param {Function} rejected The function to handle `reject` for a `Promise`
 *
 * @return {Number} An ID used to remove interceptor later
 */
InterceptorManager.prototype.use = function use(fulfilled, rejected, options) {
  this.handlers.push({
    fulfilled: fulfilled,
    rejected: rejected,
    synchronous: options ? options.synchronous : false,
    runWhen: options ? options.runWhen : null
  });
  return this.handlers.length - 1;
};

/**
 * Remove an interceptor from the stack
 *
 * @param {Number} id The ID that was returned by `use`
 */
InterceptorManager.prototype.eject = function eject(id) {
  if (this.handlers[id]) {
    this.handlers[id] = null;
  }
};

/**
 * Iterate over all the registered interceptors
 *
 * This method is particularly useful for skipping over any
 * interceptors that may have become `null` calling `eject`.
 *
 * @param {Function} fn The function to call for each interceptor
 */
InterceptorManager.prototype.forEach = function forEach(fn) {
  utils.forEach(this.handlers, function forEachHandler(h) {
    if (h !== null) {
      fn(h);
    }
  });
};
module.exports = InterceptorManager;

/***/ }),

/***/ "./node_modules/axios/lib/core/buildFullPath.js":
/*!******************************************************!*\
  !*** ./node_modules/axios/lib/core/buildFullPath.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var isAbsoluteURL = __webpack_require__(/*! ../helpers/isAbsoluteURL */ "./node_modules/axios/lib/helpers/isAbsoluteURL.js");
var combineURLs = __webpack_require__(/*! ../helpers/combineURLs */ "./node_modules/axios/lib/helpers/combineURLs.js");

/**
 * Creates a new URL by combining the baseURL with the requestedURL,
 * only when the requestedURL is not already an absolute URL.
 * If the requestURL is absolute, this function returns the requestedURL untouched.
 *
 * @param {string} baseURL The base URL
 * @param {string} requestedURL Absolute or relative URL to combine
 * @returns {string} The combined full path
 */
module.exports = function buildFullPath(baseURL, requestedURL) {
  if (baseURL && !isAbsoluteURL(requestedURL)) {
    return combineURLs(baseURL, requestedURL);
  }
  return requestedURL;
};

/***/ }),

/***/ "./node_modules/axios/lib/core/createError.js":
/*!****************************************************!*\
  !*** ./node_modules/axios/lib/core/createError.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var enhanceError = __webpack_require__(/*! ./enhanceError */ "./node_modules/axios/lib/core/enhanceError.js");

/**
 * Create an Error with the specified message, config, error code, request and response.
 *
 * @param {string} message The error message.
 * @param {Object} config The config.
 * @param {string} [code] The error code (for example, 'ECONNABORTED').
 * @param {Object} [request] The request.
 * @param {Object} [response] The response.
 * @returns {Error} The created error.
 */
module.exports = function createError(message, config, code, request, response) {
  var error = new Error(message);
  return enhanceError(error, config, code, request, response);
};

/***/ }),

/***/ "./node_modules/axios/lib/core/dispatchRequest.js":
/*!********************************************************!*\
  !*** ./node_modules/axios/lib/core/dispatchRequest.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ./../utils */ "./node_modules/axios/lib/utils.js");
var transformData = __webpack_require__(/*! ./transformData */ "./node_modules/axios/lib/core/transformData.js");
var isCancel = __webpack_require__(/*! ../cancel/isCancel */ "./node_modules/axios/lib/cancel/isCancel.js");
var defaults = __webpack_require__(/*! ../defaults */ "./node_modules/axios/lib/defaults/index.js");
var Cancel = __webpack_require__(/*! ../cancel/Cancel */ "./node_modules/axios/lib/cancel/Cancel.js");

/**
 * Throws a `Cancel` if cancellation has been requested.
 */
function throwIfCancellationRequested(config) {
  if (config.cancelToken) {
    config.cancelToken.throwIfRequested();
  }
  if (config.signal && config.signal.aborted) {
    throw new Cancel('canceled');
  }
}

/**
 * Dispatch a request to the server using the configured adapter.
 *
 * @param {object} config The config that is to be used for the request
 * @returns {Promise} The Promise to be fulfilled
 */
module.exports = function dispatchRequest(config) {
  throwIfCancellationRequested(config);

  // Ensure headers exist
  config.headers = config.headers || {};

  // Transform request data
  config.data = transformData.call(config, config.data, config.headers, config.transformRequest);

  // Flatten headers
  config.headers = utils.merge(config.headers.common || {}, config.headers[config.method] || {}, config.headers);
  utils.forEach(['delete', 'get', 'head', 'post', 'put', 'patch', 'common'], function cleanHeaderConfig(method) {
    delete config.headers[method];
  });
  var adapter = config.adapter || defaults.adapter;
  return adapter(config).then(function onAdapterResolution(response) {
    throwIfCancellationRequested(config);

    // Transform response data
    response.data = transformData.call(config, response.data, response.headers, config.transformResponse);
    return response;
  }, function onAdapterRejection(reason) {
    if (!isCancel(reason)) {
      throwIfCancellationRequested(config);

      // Transform response data
      if (reason && reason.response) {
        reason.response.data = transformData.call(config, reason.response.data, reason.response.headers, config.transformResponse);
      }
    }
    return Promise.reject(reason);
  });
};

/***/ }),

/***/ "./node_modules/axios/lib/core/enhanceError.js":
/*!*****************************************************!*\
  !*** ./node_modules/axios/lib/core/enhanceError.js ***!
  \*****************************************************/
/***/ ((module) => {

"use strict";


/**
 * Update an Error with the specified config, error code, and response.
 *
 * @param {Error} error The error to update.
 * @param {Object} config The config.
 * @param {string} [code] The error code (for example, 'ECONNABORTED').
 * @param {Object} [request] The request.
 * @param {Object} [response] The response.
 * @returns {Error} The error.
 */
module.exports = function enhanceError(error, config, code, request, response) {
  error.config = config;
  if (code) {
    error.code = code;
  }
  error.request = request;
  error.response = response;
  error.isAxiosError = true;
  error.toJSON = function toJSON() {
    return {
      // Standard
      message: this.message,
      name: this.name,
      // Microsoft
      description: this.description,
      number: this.number,
      // Mozilla
      fileName: this.fileName,
      lineNumber: this.lineNumber,
      columnNumber: this.columnNumber,
      stack: this.stack,
      // Axios
      config: this.config,
      code: this.code,
      status: this.response && this.response.status ? this.response.status : null
    };
  };
  return error;
};

/***/ }),

/***/ "./node_modules/axios/lib/core/mergeConfig.js":
/*!****************************************************!*\
  !*** ./node_modules/axios/lib/core/mergeConfig.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ../utils */ "./node_modules/axios/lib/utils.js");

/**
 * Config-specific merge-function which creates a new config-object
 * by merging two configuration objects together.
 *
 * @param {Object} config1
 * @param {Object} config2
 * @returns {Object} New object resulting from merging config2 to config1
 */
module.exports = function mergeConfig(config1, config2) {
  // eslint-disable-next-line no-param-reassign
  config2 = config2 || {};
  var config = {};
  function getMergedValue(target, source) {
    if (utils.isPlainObject(target) && utils.isPlainObject(source)) {
      return utils.merge(target, source);
    } else if (utils.isPlainObject(source)) {
      return utils.merge({}, source);
    } else if (utils.isArray(source)) {
      return source.slice();
    }
    return source;
  }

  // eslint-disable-next-line consistent-return
  function mergeDeepProperties(prop) {
    if (!utils.isUndefined(config2[prop])) {
      return getMergedValue(config1[prop], config2[prop]);
    } else if (!utils.isUndefined(config1[prop])) {
      return getMergedValue(undefined, config1[prop]);
    }
  }

  // eslint-disable-next-line consistent-return
  function valueFromConfig2(prop) {
    if (!utils.isUndefined(config2[prop])) {
      return getMergedValue(undefined, config2[prop]);
    }
  }

  // eslint-disable-next-line consistent-return
  function defaultToConfig2(prop) {
    if (!utils.isUndefined(config2[prop])) {
      return getMergedValue(undefined, config2[prop]);
    } else if (!utils.isUndefined(config1[prop])) {
      return getMergedValue(undefined, config1[prop]);
    }
  }

  // eslint-disable-next-line consistent-return
  function mergeDirectKeys(prop) {
    if (prop in config2) {
      return getMergedValue(config1[prop], config2[prop]);
    } else if (prop in config1) {
      return getMergedValue(undefined, config1[prop]);
    }
  }
  var mergeMap = {
    'url': valueFromConfig2,
    'method': valueFromConfig2,
    'data': valueFromConfig2,
    'baseURL': defaultToConfig2,
    'transformRequest': defaultToConfig2,
    'transformResponse': defaultToConfig2,
    'paramsSerializer': defaultToConfig2,
    'timeout': defaultToConfig2,
    'timeoutMessage': defaultToConfig2,
    'withCredentials': defaultToConfig2,
    'adapter': defaultToConfig2,
    'responseType': defaultToConfig2,
    'xsrfCookieName': defaultToConfig2,
    'xsrfHeaderName': defaultToConfig2,
    'onUploadProgress': defaultToConfig2,
    'onDownloadProgress': defaultToConfig2,
    'decompress': defaultToConfig2,
    'maxContentLength': defaultToConfig2,
    'maxBodyLength': defaultToConfig2,
    'transport': defaultToConfig2,
    'httpAgent': defaultToConfig2,
    'httpsAgent': defaultToConfig2,
    'cancelToken': defaultToConfig2,
    'socketPath': defaultToConfig2,
    'responseEncoding': defaultToConfig2,
    'validateStatus': mergeDirectKeys
  };
  utils.forEach(Object.keys(config1).concat(Object.keys(config2)), function computeConfigValue(prop) {
    var merge = mergeMap[prop] || mergeDeepProperties;
    var configValue = merge(prop);
    utils.isUndefined(configValue) && merge !== mergeDirectKeys || (config[prop] = configValue);
  });
  return config;
};

/***/ }),

/***/ "./node_modules/axios/lib/core/settle.js":
/*!***********************************************!*\
  !*** ./node_modules/axios/lib/core/settle.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var createError = __webpack_require__(/*! ./createError */ "./node_modules/axios/lib/core/createError.js");

/**
 * Resolve or reject a Promise based on response status.
 *
 * @param {Function} resolve A function that resolves the promise.
 * @param {Function} reject A function that rejects the promise.
 * @param {object} response The response.
 */
module.exports = function settle(resolve, reject, response) {
  var validateStatus = response.config.validateStatus;
  if (!response.status || !validateStatus || validateStatus(response.status)) {
    resolve(response);
  } else {
    reject(createError('Request failed with status code ' + response.status, response.config, null, response.request, response));
  }
};

/***/ }),

/***/ "./node_modules/axios/lib/core/transformData.js":
/*!******************************************************!*\
  !*** ./node_modules/axios/lib/core/transformData.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ./../utils */ "./node_modules/axios/lib/utils.js");
var defaults = __webpack_require__(/*! ../defaults */ "./node_modules/axios/lib/defaults/index.js");

/**
 * Transform the data for a request or a response
 *
 * @param {Object|String} data The data to be transformed
 * @param {Array} headers The headers for the request or response
 * @param {Array|Function} fns A single function or Array of functions
 * @returns {*} The resulting transformed data
 */
module.exports = function transformData(data, headers, fns) {
  var context = this || defaults;
  /*eslint no-param-reassign:0*/
  utils.forEach(fns, function transform(fn) {
    data = fn.call(context, data, headers);
  });
  return data;
};

/***/ }),

/***/ "./node_modules/axios/lib/defaults/index.js":
/*!**************************************************!*\
  !*** ./node_modules/axios/lib/defaults/index.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ../utils */ "./node_modules/axios/lib/utils.js");
var normalizeHeaderName = __webpack_require__(/*! ../helpers/normalizeHeaderName */ "./node_modules/axios/lib/helpers/normalizeHeaderName.js");
var enhanceError = __webpack_require__(/*! ../core/enhanceError */ "./node_modules/axios/lib/core/enhanceError.js");
var transitionalDefaults = __webpack_require__(/*! ./transitional */ "./node_modules/axios/lib/defaults/transitional.js");
var DEFAULT_CONTENT_TYPE = {
  'Content-Type': 'application/x-www-form-urlencoded'
};
function setContentTypeIfUnset(headers, value) {
  if (!utils.isUndefined(headers) && utils.isUndefined(headers['Content-Type'])) {
    headers['Content-Type'] = value;
  }
}
function getDefaultAdapter() {
  var adapter;
  if (typeof XMLHttpRequest !== 'undefined') {
    // For browsers use XHR adapter
    adapter = __webpack_require__(/*! ../adapters/xhr */ "./node_modules/axios/lib/adapters/xhr.js");
  } else if (typeof process !== 'undefined' && Object.prototype.toString.call(process) === '[object process]') {
    // For node use HTTP adapter
    adapter = __webpack_require__(/*! ../adapters/http */ "./node_modules/axios/lib/adapters/xhr.js");
  }
  return adapter;
}
function stringifySafely(rawValue, parser, encoder) {
  if (utils.isString(rawValue)) {
    try {
      (parser || JSON.parse)(rawValue);
      return utils.trim(rawValue);
    } catch (e) {
      if (e.name !== 'SyntaxError') {
        throw e;
      }
    }
  }
  return (encoder || JSON.stringify)(rawValue);
}
var defaults = {
  transitional: transitionalDefaults,
  adapter: getDefaultAdapter(),
  transformRequest: [function transformRequest(data, headers) {
    normalizeHeaderName(headers, 'Accept');
    normalizeHeaderName(headers, 'Content-Type');
    if (utils.isFormData(data) || utils.isArrayBuffer(data) || utils.isBuffer(data) || utils.isStream(data) || utils.isFile(data) || utils.isBlob(data)) {
      return data;
    }
    if (utils.isArrayBufferView(data)) {
      return data.buffer;
    }
    if (utils.isURLSearchParams(data)) {
      setContentTypeIfUnset(headers, 'application/x-www-form-urlencoded;charset=utf-8');
      return data.toString();
    }
    if (utils.isObject(data) || headers && headers['Content-Type'] === 'application/json') {
      setContentTypeIfUnset(headers, 'application/json');
      return stringifySafely(data);
    }
    return data;
  }],
  transformResponse: [function transformResponse(data) {
    var transitional = this.transitional || defaults.transitional;
    var silentJSONParsing = transitional && transitional.silentJSONParsing;
    var forcedJSONParsing = transitional && transitional.forcedJSONParsing;
    var strictJSONParsing = !silentJSONParsing && this.responseType === 'json';
    if (strictJSONParsing || forcedJSONParsing && utils.isString(data) && data.length) {
      try {
        return JSON.parse(data);
      } catch (e) {
        if (strictJSONParsing) {
          if (e.name === 'SyntaxError') {
            throw enhanceError(e, this, 'E_JSON_PARSE');
          }
          throw e;
        }
      }
    }
    return data;
  }],
  /**
   * A timeout in milliseconds to abort a request. If set to 0 (default) a
   * timeout is not created.
   */
  timeout: 0,
  xsrfCookieName: 'XSRF-TOKEN',
  xsrfHeaderName: 'X-XSRF-TOKEN',
  maxContentLength: -1,
  maxBodyLength: -1,
  validateStatus: function validateStatus(status) {
    return status >= 200 && status < 300;
  },
  headers: {
    common: {
      'Accept': 'application/json, text/plain, */*'
    }
  }
};
utils.forEach(['delete', 'get', 'head'], function forEachMethodNoData(method) {
  defaults.headers[method] = {};
});
utils.forEach(['post', 'put', 'patch'], function forEachMethodWithData(method) {
  defaults.headers[method] = utils.merge(DEFAULT_CONTENT_TYPE);
});
module.exports = defaults;

/***/ }),

/***/ "./node_modules/axios/lib/defaults/transitional.js":
/*!*********************************************************!*\
  !*** ./node_modules/axios/lib/defaults/transitional.js ***!
  \*********************************************************/
/***/ ((module) => {

"use strict";


module.exports = {
  silentJSONParsing: true,
  forcedJSONParsing: true,
  clarifyTimeoutError: false
};

/***/ }),

/***/ "./node_modules/axios/lib/env/data.js":
/*!********************************************!*\
  !*** ./node_modules/axios/lib/env/data.js ***!
  \********************************************/
/***/ ((module) => {

module.exports = {
  "version": "0.26.1"
};

/***/ }),

/***/ "./node_modules/axios/lib/helpers/bind.js":
/*!************************************************!*\
  !*** ./node_modules/axios/lib/helpers/bind.js ***!
  \************************************************/
/***/ ((module) => {

"use strict";


module.exports = function bind(fn, thisArg) {
  return function wrap() {
    var args = new Array(arguments.length);
    for (var i = 0; i < args.length; i++) {
      args[i] = arguments[i];
    }
    return fn.apply(thisArg, args);
  };
};

/***/ }),

/***/ "./node_modules/axios/lib/helpers/buildURL.js":
/*!****************************************************!*\
  !*** ./node_modules/axios/lib/helpers/buildURL.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ./../utils */ "./node_modules/axios/lib/utils.js");
function encode(val) {
  return encodeURIComponent(val).replace(/%3A/gi, ':').replace(/%24/g, '$').replace(/%2C/gi, ',').replace(/%20/g, '+').replace(/%5B/gi, '[').replace(/%5D/gi, ']');
}

/**
 * Build a URL by appending params to the end
 *
 * @param {string} url The base of the url (e.g., http://www.google.com)
 * @param {object} [params] The params to be appended
 * @returns {string} The formatted url
 */
module.exports = function buildURL(url, params, paramsSerializer) {
  /*eslint no-param-reassign:0*/
  if (!params) {
    return url;
  }
  var serializedParams;
  if (paramsSerializer) {
    serializedParams = paramsSerializer(params);
  } else if (utils.isURLSearchParams(params)) {
    serializedParams = params.toString();
  } else {
    var parts = [];
    utils.forEach(params, function serialize(val, key) {
      if (val === null || typeof val === 'undefined') {
        return;
      }
      if (utils.isArray(val)) {
        key = key + '[]';
      } else {
        val = [val];
      }
      utils.forEach(val, function parseValue(v) {
        if (utils.isDate(v)) {
          v = v.toISOString();
        } else if (utils.isObject(v)) {
          v = JSON.stringify(v);
        }
        parts.push(encode(key) + '=' + encode(v));
      });
    });
    serializedParams = parts.join('&');
  }
  if (serializedParams) {
    var hashmarkIndex = url.indexOf('#');
    if (hashmarkIndex !== -1) {
      url = url.slice(0, hashmarkIndex);
    }
    url += (url.indexOf('?') === -1 ? '?' : '&') + serializedParams;
  }
  return url;
};

/***/ }),

/***/ "./node_modules/axios/lib/helpers/combineURLs.js":
/*!*******************************************************!*\
  !*** ./node_modules/axios/lib/helpers/combineURLs.js ***!
  \*******************************************************/
/***/ ((module) => {

"use strict";


/**
 * Creates a new URL by combining the specified URLs
 *
 * @param {string} baseURL The base URL
 * @param {string} relativeURL The relative URL
 * @returns {string} The combined URL
 */
module.exports = function combineURLs(baseURL, relativeURL) {
  return relativeURL ? baseURL.replace(/\/+$/, '') + '/' + relativeURL.replace(/^\/+/, '') : baseURL;
};

/***/ }),

/***/ "./node_modules/axios/lib/helpers/cookies.js":
/*!***************************************************!*\
  !*** ./node_modules/axios/lib/helpers/cookies.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ./../utils */ "./node_modules/axios/lib/utils.js");
module.exports = utils.isStandardBrowserEnv() ?
// Standard browser envs support document.cookie
function standardBrowserEnv() {
  return {
    write: function write(name, value, expires, path, domain, secure) {
      var cookie = [];
      cookie.push(name + '=' + encodeURIComponent(value));
      if (utils.isNumber(expires)) {
        cookie.push('expires=' + new Date(expires).toGMTString());
      }
      if (utils.isString(path)) {
        cookie.push('path=' + path);
      }
      if (utils.isString(domain)) {
        cookie.push('domain=' + domain);
      }
      if (secure === true) {
        cookie.push('secure');
      }
      document.cookie = cookie.join('; ');
    },
    read: function read(name) {
      var match = document.cookie.match(new RegExp('(^|;\\s*)(' + name + ')=([^;]*)'));
      return match ? decodeURIComponent(match[3]) : null;
    },
    remove: function remove(name) {
      this.write(name, '', Date.now() - 86400000);
    }
  };
}() :
// Non standard browser env (web workers, react-native) lack needed support.
function nonStandardBrowserEnv() {
  return {
    write: function write() {},
    read: function read() {
      return null;
    },
    remove: function remove() {}
  };
}();

/***/ }),

/***/ "./node_modules/axios/lib/helpers/isAbsoluteURL.js":
/*!*********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/isAbsoluteURL.js ***!
  \*********************************************************/
/***/ ((module) => {

"use strict";


/**
 * Determines whether the specified URL is absolute
 *
 * @param {string} url The URL to test
 * @returns {boolean} True if the specified URL is absolute, otherwise false
 */
module.exports = function isAbsoluteURL(url) {
  // A URL is considered absolute if it begins with "<scheme>://" or "//" (protocol-relative URL).
  // RFC 3986 defines scheme name as a sequence of characters beginning with a letter and followed
  // by any combination of letters, digits, plus, period, or hyphen.
  return /^([a-z][a-z\d+\-.]*:)?\/\//i.test(url);
};

/***/ }),

/***/ "./node_modules/axios/lib/helpers/isAxiosError.js":
/*!********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/isAxiosError.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ./../utils */ "./node_modules/axios/lib/utils.js");

/**
 * Determines whether the payload is an error thrown by Axios
 *
 * @param {*} payload The value to test
 * @returns {boolean} True if the payload is an error thrown by Axios, otherwise false
 */
module.exports = function isAxiosError(payload) {
  return utils.isObject(payload) && payload.isAxiosError === true;
};

/***/ }),

/***/ "./node_modules/axios/lib/helpers/isURLSameOrigin.js":
/*!***********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/isURLSameOrigin.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ./../utils */ "./node_modules/axios/lib/utils.js");
module.exports = utils.isStandardBrowserEnv() ?
// Standard browser envs have full support of the APIs needed to test
// whether the request URL is of the same origin as current location.
function standardBrowserEnv() {
  var msie = /(msie|trident)/i.test(navigator.userAgent);
  var urlParsingNode = document.createElement('a');
  var originURL;

  /**
  * Parse a URL to discover it's components
  *
  * @param {String} url The URL to be parsed
  * @returns {Object}
  */
  function resolveURL(url) {
    var href = url;
    if (msie) {
      // IE needs attribute set twice to normalize properties
      urlParsingNode.setAttribute('href', href);
      href = urlParsingNode.href;
    }
    urlParsingNode.setAttribute('href', href);

    // urlParsingNode provides the UrlUtils interface - http://url.spec.whatwg.org/#urlutils
    return {
      href: urlParsingNode.href,
      protocol: urlParsingNode.protocol ? urlParsingNode.protocol.replace(/:$/, '') : '',
      host: urlParsingNode.host,
      search: urlParsingNode.search ? urlParsingNode.search.replace(/^\?/, '') : '',
      hash: urlParsingNode.hash ? urlParsingNode.hash.replace(/^#/, '') : '',
      hostname: urlParsingNode.hostname,
      port: urlParsingNode.port,
      pathname: urlParsingNode.pathname.charAt(0) === '/' ? urlParsingNode.pathname : '/' + urlParsingNode.pathname
    };
  }
  originURL = resolveURL(window.location.href);

  /**
  * Determine if a URL shares the same origin as the current location
  *
  * @param {String} requestURL The URL to test
  * @returns {boolean} True if URL shares the same origin, otherwise false
  */
  return function isURLSameOrigin(requestURL) {
    var parsed = utils.isString(requestURL) ? resolveURL(requestURL) : requestURL;
    return parsed.protocol === originURL.protocol && parsed.host === originURL.host;
  };
}() :
// Non standard browser envs (web workers, react-native) lack needed support.
function nonStandardBrowserEnv() {
  return function isURLSameOrigin() {
    return true;
  };
}();

/***/ }),

/***/ "./node_modules/axios/lib/helpers/normalizeHeaderName.js":
/*!***************************************************************!*\
  !*** ./node_modules/axios/lib/helpers/normalizeHeaderName.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ../utils */ "./node_modules/axios/lib/utils.js");
module.exports = function normalizeHeaderName(headers, normalizedName) {
  utils.forEach(headers, function processHeader(value, name) {
    if (name !== normalizedName && name.toUpperCase() === normalizedName.toUpperCase()) {
      headers[normalizedName] = value;
      delete headers[name];
    }
  });
};

/***/ }),

/***/ "./node_modules/axios/lib/helpers/parseHeaders.js":
/*!********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/parseHeaders.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var utils = __webpack_require__(/*! ./../utils */ "./node_modules/axios/lib/utils.js");

// Headers whose duplicates are ignored by node
// c.f. https://nodejs.org/api/http.html#http_message_headers
var ignoreDuplicateOf = ['age', 'authorization', 'content-length', 'content-type', 'etag', 'expires', 'from', 'host', 'if-modified-since', 'if-unmodified-since', 'last-modified', 'location', 'max-forwards', 'proxy-authorization', 'referer', 'retry-after', 'user-agent'];

/**
 * Parse headers into an object
 *
 * ```
 * Date: Wed, 27 Aug 2014 08:58:49 GMT
 * Content-Type: application/json
 * Connection: keep-alive
 * Transfer-Encoding: chunked
 * ```
 *
 * @param {String} headers Headers needing to be parsed
 * @returns {Object} Headers parsed into an object
 */
module.exports = function parseHeaders(headers) {
  var parsed = {};
  var key;
  var val;
  var i;
  if (!headers) {
    return parsed;
  }
  utils.forEach(headers.split('\n'), function parser(line) {
    i = line.indexOf(':');
    key = utils.trim(line.substr(0, i)).toLowerCase();
    val = utils.trim(line.substr(i + 1));
    if (key) {
      if (parsed[key] && ignoreDuplicateOf.indexOf(key) >= 0) {
        return;
      }
      if (key === 'set-cookie') {
        parsed[key] = (parsed[key] ? parsed[key] : []).concat([val]);
      } else {
        parsed[key] = parsed[key] ? parsed[key] + ', ' + val : val;
      }
    }
  });
  return parsed;
};

/***/ }),

/***/ "./node_modules/axios/lib/helpers/spread.js":
/*!**************************************************!*\
  !*** ./node_modules/axios/lib/helpers/spread.js ***!
  \**************************************************/
/***/ ((module) => {

"use strict";


/**
 * Syntactic sugar for invoking a function and expanding an array for arguments.
 *
 * Common use case would be to use `Function.prototype.apply`.
 *
 *  ```js
 *  function f(x, y, z) {}
 *  var args = [1, 2, 3];
 *  f.apply(null, args);
 *  ```
 *
 * With `spread` this example can be re-written.
 *
 *  ```js
 *  spread(function(x, y, z) {})([1, 2, 3]);
 *  ```
 *
 * @param {Function} callback
 * @returns {Function}
 */
module.exports = function spread(callback) {
  return function wrap(arr) {
    return callback.apply(null, arr);
  };
};

/***/ }),

/***/ "./node_modules/axios/lib/helpers/validator.js":
/*!*****************************************************!*\
  !*** ./node_modules/axios/lib/helpers/validator.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var VERSION = (__webpack_require__(/*! ../env/data */ "./node_modules/axios/lib/env/data.js").version);
var validators = {};

// eslint-disable-next-line func-names
['object', 'boolean', 'number', 'function', 'string', 'symbol'].forEach(function (type, i) {
  validators[type] = function validator(thing) {
    return typeof thing === type || 'a' + (i < 1 ? 'n ' : ' ') + type;
  };
});
var deprecatedWarnings = {};

/**
 * Transitional option validator
 * @param {function|boolean?} validator - set to false if the transitional option has been removed
 * @param {string?} version - deprecated version / removed since version
 * @param {string?} message - some message with additional info
 * @returns {function}
 */
validators.transitional = function transitional(validator, version, message) {
  function formatMessage(opt, desc) {
    return '[Axios v' + VERSION + '] Transitional option \'' + opt + '\'' + desc + (message ? '. ' + message : '');
  }

  // eslint-disable-next-line func-names
  return function (value, opt, opts) {
    if (validator === false) {
      throw new Error(formatMessage(opt, ' has been removed' + (version ? ' in ' + version : '')));
    }
    if (version && !deprecatedWarnings[opt]) {
      deprecatedWarnings[opt] = true;
      // eslint-disable-next-line no-console
      console.warn(formatMessage(opt, ' has been deprecated since v' + version + ' and will be removed in the near future'));
    }
    return validator ? validator(value, opt, opts) : true;
  };
};

/**
 * Assert object's properties type
 * @param {object} options
 * @param {object} schema
 * @param {boolean?} allowUnknown
 */

function assertOptions(options, schema, allowUnknown) {
  if (typeof options !== 'object') {
    throw new TypeError('options must be an object');
  }
  var keys = Object.keys(options);
  var i = keys.length;
  while (i-- > 0) {
    var opt = keys[i];
    var validator = schema[opt];
    if (validator) {
      var value = options[opt];
      var result = value === undefined || validator(value, opt, options);
      if (result !== true) {
        throw new TypeError('option ' + opt + ' must be ' + result);
      }
      continue;
    }
    if (allowUnknown !== true) {
      throw Error('Unknown option ' + opt);
    }
  }
}
module.exports = {
  assertOptions: assertOptions,
  validators: validators
};

/***/ }),

/***/ "./node_modules/axios/lib/utils.js":
/*!*****************************************!*\
  !*** ./node_modules/axios/lib/utils.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


var bind = __webpack_require__(/*! ./helpers/bind */ "./node_modules/axios/lib/helpers/bind.js");

// utils is a library of generic helper functions non-specific to axios

var toString = Object.prototype.toString;

/**
 * Determine if a value is an Array
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is an Array, otherwise false
 */
function isArray(val) {
  return Array.isArray(val);
}

/**
 * Determine if a value is undefined
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if the value is undefined, otherwise false
 */
function isUndefined(val) {
  return typeof val === 'undefined';
}

/**
 * Determine if a value is a Buffer
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is a Buffer, otherwise false
 */
function isBuffer(val) {
  return val !== null && !isUndefined(val) && val.constructor !== null && !isUndefined(val.constructor) && typeof val.constructor.isBuffer === 'function' && val.constructor.isBuffer(val);
}

/**
 * Determine if a value is an ArrayBuffer
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is an ArrayBuffer, otherwise false
 */
function isArrayBuffer(val) {
  return toString.call(val) === '[object ArrayBuffer]';
}

/**
 * Determine if a value is a FormData
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is an FormData, otherwise false
 */
function isFormData(val) {
  return toString.call(val) === '[object FormData]';
}

/**
 * Determine if a value is a view on an ArrayBuffer
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is a view on an ArrayBuffer, otherwise false
 */
function isArrayBufferView(val) {
  var result;
  if (typeof ArrayBuffer !== 'undefined' && ArrayBuffer.isView) {
    result = ArrayBuffer.isView(val);
  } else {
    result = val && val.buffer && isArrayBuffer(val.buffer);
  }
  return result;
}

/**
 * Determine if a value is a String
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is a String, otherwise false
 */
function isString(val) {
  return typeof val === 'string';
}

/**
 * Determine if a value is a Number
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is a Number, otherwise false
 */
function isNumber(val) {
  return typeof val === 'number';
}

/**
 * Determine if a value is an Object
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is an Object, otherwise false
 */
function isObject(val) {
  return val !== null && typeof val === 'object';
}

/**
 * Determine if a value is a plain Object
 *
 * @param {Object} val The value to test
 * @return {boolean} True if value is a plain Object, otherwise false
 */
function isPlainObject(val) {
  if (toString.call(val) !== '[object Object]') {
    return false;
  }
  var prototype = Object.getPrototypeOf(val);
  return prototype === null || prototype === Object.prototype;
}

/**
 * Determine if a value is a Date
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is a Date, otherwise false
 */
function isDate(val) {
  return toString.call(val) === '[object Date]';
}

/**
 * Determine if a value is a File
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is a File, otherwise false
 */
function isFile(val) {
  return toString.call(val) === '[object File]';
}

/**
 * Determine if a value is a Blob
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is a Blob, otherwise false
 */
function isBlob(val) {
  return toString.call(val) === '[object Blob]';
}

/**
 * Determine if a value is a Function
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is a Function, otherwise false
 */
function isFunction(val) {
  return toString.call(val) === '[object Function]';
}

/**
 * Determine if a value is a Stream
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is a Stream, otherwise false
 */
function isStream(val) {
  return isObject(val) && isFunction(val.pipe);
}

/**
 * Determine if a value is a URLSearchParams object
 *
 * @param {Object} val The value to test
 * @returns {boolean} True if value is a URLSearchParams object, otherwise false
 */
function isURLSearchParams(val) {
  return toString.call(val) === '[object URLSearchParams]';
}

/**
 * Trim excess whitespace off the beginning and end of a string
 *
 * @param {String} str The String to trim
 * @returns {String} The String freed of excess whitespace
 */
function trim(str) {
  return str.trim ? str.trim() : str.replace(/^\s+|\s+$/g, '');
}

/**
 * Determine if we're running in a standard browser environment
 *
 * This allows axios to run in a web worker, and react-native.
 * Both environments support XMLHttpRequest, but not fully standard globals.
 *
 * web workers:
 *  typeof window -> undefined
 *  typeof document -> undefined
 *
 * react-native:
 *  navigator.product -> 'ReactNative'
 * nativescript
 *  navigator.product -> 'NativeScript' or 'NS'
 */
function isStandardBrowserEnv() {
  if (typeof navigator !== 'undefined' && (navigator.product === 'ReactNative' || navigator.product === 'NativeScript' || navigator.product === 'NS')) {
    return false;
  }
  return typeof window !== 'undefined' && typeof document !== 'undefined';
}

/**
 * Iterate over an Array or an Object invoking a function for each item.
 *
 * If `obj` is an Array callback will be called passing
 * the value, index, and complete array for each item.
 *
 * If 'obj' is an Object callback will be called passing
 * the value, key, and complete object for each property.
 *
 * @param {Object|Array} obj The object to iterate
 * @param {Function} fn The callback to invoke for each item
 */
function forEach(obj, fn) {
  // Don't bother if no value provided
  if (obj === null || typeof obj === 'undefined') {
    return;
  }

  // Force an array if not already something iterable
  if (typeof obj !== 'object') {
    /*eslint no-param-reassign:0*/
    obj = [obj];
  }
  if (isArray(obj)) {
    // Iterate over array values
    for (var i = 0, l = obj.length; i < l; i++) {
      fn.call(null, obj[i], i, obj);
    }
  } else {
    // Iterate over object keys
    for (var key in obj) {
      if (Object.prototype.hasOwnProperty.call(obj, key)) {
        fn.call(null, obj[key], key, obj);
      }
    }
  }
}

/**
 * Accepts varargs expecting each argument to be an object, then
 * immutably merges the properties of each object and returns result.
 *
 * When multiple objects contain the same key the later object in
 * the arguments list will take precedence.
 *
 * Example:
 *
 * ```js
 * var result = merge({foo: 123}, {foo: 456});
 * console.log(result.foo); // outputs 456
 * ```
 *
 * @param {Object} obj1 Object to merge
 * @returns {Object} Result of all merge properties
 */
function merge( /* obj1, obj2, obj3, ... */
) {
  var result = {};
  function assignValue(val, key) {
    if (isPlainObject(result[key]) && isPlainObject(val)) {
      result[key] = merge(result[key], val);
    } else if (isPlainObject(val)) {
      result[key] = merge({}, val);
    } else if (isArray(val)) {
      result[key] = val.slice();
    } else {
      result[key] = val;
    }
  }
  for (var i = 0, l = arguments.length; i < l; i++) {
    forEach(arguments[i], assignValue);
  }
  return result;
}

/**
 * Extends object a by mutably adding to it the properties of object b.
 *
 * @param {Object} a The object to be extended
 * @param {Object} b The object to copy properties from
 * @param {Object} thisArg The object to bind function to
 * @return {Object} The resulting value of object a
 */
function extend(a, b, thisArg) {
  forEach(b, function assignValue(val, key) {
    if (thisArg && typeof val === 'function') {
      a[key] = bind(val, thisArg);
    } else {
      a[key] = val;
    }
  });
  return a;
}

/**
 * Remove byte order marker. This catches EF BB BF (the UTF-8 BOM)
 *
 * @param {string} content with BOM
 * @return {string} content value without BOM
 */
function stripBOM(content) {
  if (content.charCodeAt(0) === 0xFEFF) {
    content = content.slice(1);
  }
  return content;
}
module.exports = {
  isArray: isArray,
  isArrayBuffer: isArrayBuffer,
  isBuffer: isBuffer,
  isFormData: isFormData,
  isArrayBufferView: isArrayBufferView,
  isString: isString,
  isNumber: isNumber,
  isObject: isObject,
  isPlainObject: isPlainObject,
  isUndefined: isUndefined,
  isDate: isDate,
  isFile: isFile,
  isBlob: isBlob,
  isFunction: isFunction,
  isStream: isStream,
  isURLSearchParams: isURLSearchParams,
  isStandardBrowserEnv: isStandardBrowserEnv,
  forEach: forEach,
  merge: merge,
  extend: extend,
  trim: trim,
  stripBOM: stripBOM
};

/***/ }),

/***/ "./node_modules/bent/src/browser.js":
/*!******************************************!*\
  !*** ./node_modules/bent/src/browser.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";


/* global fetch, btoa, Headers */
const core = __webpack_require__(/*! ./core */ "./node_modules/bent/src/core.js");
class StatusError extends Error {
  constructor(res, ...params) {
    super(...params);
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, StatusError);
    }
    this.name = 'StatusError';
    this.message = res.statusMessage;
    this.statusCode = res.status;
    this.res = res;
    this.json = res.json.bind(res);
    this.text = res.text.bind(res);
    this.arrayBuffer = res.arrayBuffer.bind(res);
    let buffer;
    const get = () => {
      if (!buffer) buffer = this.arrayBuffer();
      return buffer;
    };
    Object.defineProperty(this, 'responseBody', {
      get
    });
    // match Node.js headers object
    this.headers = {};
    for (const [key, value] of res.headers.entries()) {
      this.headers[key.toLowerCase()] = value;
    }
  }
}
const mkrequest = (statusCodes, method, encoding, headers, baseurl) => async (_url, body, _headers = {}) => {
  _url = baseurl + (_url || '');
  let parsed = new URL(_url);
  if (!headers) headers = {};
  if (parsed.username) {
    headers.Authorization = 'Basic ' + btoa(parsed.username + ':' + parsed.password);
    parsed = new URL(parsed.protocol + '//' + parsed.host + parsed.pathname + parsed.search);
  }
  if (parsed.protocol !== 'https:' && parsed.protocol !== 'http:') {
    throw new Error(`Unknown protocol, ${parsed.protocol}`);
  }
  if (body) {
    if (body instanceof ArrayBuffer || ArrayBuffer.isView(body) || typeof body === 'string') {
      // noop
    } else if (typeof body === 'object') {
      body = JSON.stringify(body);
      headers['Content-Type'] = 'application/json';
    } else {
      throw new Error('Unknown body type.');
    }
  }
  _headers = new Headers({
    ...(headers || {}),
    ..._headers
  });
  const resp = await fetch(parsed, {
    method,
    headers: _headers,
    body
  });
  resp.statusCode = resp.status;
  if (!statusCodes.has(resp.status)) {
    throw new StatusError(resp);
  }
  if (encoding === 'json') return resp.json();else if (encoding === 'buffer') return resp.arrayBuffer();else if (encoding === 'string') return resp.text();else return resp;
};
module.exports = core(mkrequest);

/***/ }),

/***/ "./node_modules/bent/src/core.js":
/*!***************************************!*\
  !*** ./node_modules/bent/src/core.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";


const encodings = new Set(['json', 'buffer', 'string']);
module.exports = mkrequest => (...args) => {
  const statusCodes = new Set();
  let method;
  let encoding;
  let headers;
  let baseurl = '';
  args.forEach(arg => {
    if (typeof arg === 'string') {
      if (arg.toUpperCase() === arg) {
        if (method) {
          const msg = `Can't set method to ${arg}, already set to ${method}.`;
          throw new Error(msg);
        } else {
          method = arg;
        }
      } else if (arg.startsWith('http:') || arg.startsWith('https:')) {
        baseurl = arg;
      } else {
        if (encodings.has(arg)) {
          encoding = arg;
        } else {
          throw new Error(`Unknown encoding, ${arg}`);
        }
      }
    } else if (typeof arg === 'number') {
      statusCodes.add(arg);
    } else if (typeof arg === 'object') {
      if (Array.isArray(arg) || arg instanceof Set) {
        arg.forEach(code => statusCodes.add(code));
      } else {
        if (headers) {
          throw new Error('Cannot set headers twice.');
        }
        headers = arg;
      }
    } else {
      throw new Error(`Unknown type: ${typeof arg}`);
    }
  });
  if (!method) method = 'GET';
  if (statusCodes.size === 0) {
    statusCodes.add(200);
  }
  return mkrequest(statusCodes, method, encoding, headers, baseurl);
};

/***/ }),

/***/ "./node_modules/crypto-js/aes.js":
/*!***************************************!*\
  !*** ./node_modules/crypto-js/aes.js ***!
  \***************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./enc-base64 */ "./node_modules/crypto-js/enc-base64.js"), __webpack_require__(/*! ./md5 */ "./node_modules/crypto-js/md5.js"), __webpack_require__(/*! ./evpkdf */ "./node_modules/crypto-js/evpkdf.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var BlockCipher = C_lib.BlockCipher;
    var C_algo = C.algo;

    // Lookup tables
    var SBOX = [];
    var INV_SBOX = [];
    var SUB_MIX_0 = [];
    var SUB_MIX_1 = [];
    var SUB_MIX_2 = [];
    var SUB_MIX_3 = [];
    var INV_SUB_MIX_0 = [];
    var INV_SUB_MIX_1 = [];
    var INV_SUB_MIX_2 = [];
    var INV_SUB_MIX_3 = [];

    // Compute lookup tables
    (function () {
      // Compute double table
      var d = [];
      for (var i = 0; i < 256; i++) {
        if (i < 128) {
          d[i] = i << 1;
        } else {
          d[i] = i << 1 ^ 0x11b;
        }
      }

      // Walk GF(2^8)
      var x = 0;
      var xi = 0;
      for (var i = 0; i < 256; i++) {
        // Compute sbox
        var sx = xi ^ xi << 1 ^ xi << 2 ^ xi << 3 ^ xi << 4;
        sx = sx >>> 8 ^ sx & 0xff ^ 0x63;
        SBOX[x] = sx;
        INV_SBOX[sx] = x;

        // Compute multiplication
        var x2 = d[x];
        var x4 = d[x2];
        var x8 = d[x4];

        // Compute sub bytes, mix columns tables
        var t = d[sx] * 0x101 ^ sx * 0x1010100;
        SUB_MIX_0[x] = t << 24 | t >>> 8;
        SUB_MIX_1[x] = t << 16 | t >>> 16;
        SUB_MIX_2[x] = t << 8 | t >>> 24;
        SUB_MIX_3[x] = t;

        // Compute inv sub bytes, inv mix columns tables
        var t = x8 * 0x1010101 ^ x4 * 0x10001 ^ x2 * 0x101 ^ x * 0x1010100;
        INV_SUB_MIX_0[sx] = t << 24 | t >>> 8;
        INV_SUB_MIX_1[sx] = t << 16 | t >>> 16;
        INV_SUB_MIX_2[sx] = t << 8 | t >>> 24;
        INV_SUB_MIX_3[sx] = t;

        // Compute next counter
        if (!x) {
          x = xi = 1;
        } else {
          x = x2 ^ d[d[d[x8 ^ x2]]];
          xi ^= d[d[xi]];
        }
      }
    })();

    // Precomputed Rcon lookup
    var RCON = [0x00, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36];

    /**
     * AES block cipher algorithm.
     */
    var AES = C_algo.AES = BlockCipher.extend({
      _doReset: function () {
        var t;

        // Skip reset of nRounds has been set before and key did not change
        if (this._nRounds && this._keyPriorReset === this._key) {
          return;
        }

        // Shortcuts
        var key = this._keyPriorReset = this._key;
        var keyWords = key.words;
        var keySize = key.sigBytes / 4;

        // Compute number of rounds
        var nRounds = this._nRounds = keySize + 6;

        // Compute number of key schedule rows
        var ksRows = (nRounds + 1) * 4;

        // Compute key schedule
        var keySchedule = this._keySchedule = [];
        for (var ksRow = 0; ksRow < ksRows; ksRow++) {
          if (ksRow < keySize) {
            keySchedule[ksRow] = keyWords[ksRow];
          } else {
            t = keySchedule[ksRow - 1];
            if (!(ksRow % keySize)) {
              // Rot word
              t = t << 8 | t >>> 24;

              // Sub word
              t = SBOX[t >>> 24] << 24 | SBOX[t >>> 16 & 0xff] << 16 | SBOX[t >>> 8 & 0xff] << 8 | SBOX[t & 0xff];

              // Mix Rcon
              t ^= RCON[ksRow / keySize | 0] << 24;
            } else if (keySize > 6 && ksRow % keySize == 4) {
              // Sub word
              t = SBOX[t >>> 24] << 24 | SBOX[t >>> 16 & 0xff] << 16 | SBOX[t >>> 8 & 0xff] << 8 | SBOX[t & 0xff];
            }
            keySchedule[ksRow] = keySchedule[ksRow - keySize] ^ t;
          }
        }

        // Compute inv key schedule
        var invKeySchedule = this._invKeySchedule = [];
        for (var invKsRow = 0; invKsRow < ksRows; invKsRow++) {
          var ksRow = ksRows - invKsRow;
          if (invKsRow % 4) {
            var t = keySchedule[ksRow];
          } else {
            var t = keySchedule[ksRow - 4];
          }
          if (invKsRow < 4 || ksRow <= 4) {
            invKeySchedule[invKsRow] = t;
          } else {
            invKeySchedule[invKsRow] = INV_SUB_MIX_0[SBOX[t >>> 24]] ^ INV_SUB_MIX_1[SBOX[t >>> 16 & 0xff]] ^ INV_SUB_MIX_2[SBOX[t >>> 8 & 0xff]] ^ INV_SUB_MIX_3[SBOX[t & 0xff]];
          }
        }
      },
      encryptBlock: function (M, offset) {
        this._doCryptBlock(M, offset, this._keySchedule, SUB_MIX_0, SUB_MIX_1, SUB_MIX_2, SUB_MIX_3, SBOX);
      },
      decryptBlock: function (M, offset) {
        // Swap 2nd and 4th rows
        var t = M[offset + 1];
        M[offset + 1] = M[offset + 3];
        M[offset + 3] = t;
        this._doCryptBlock(M, offset, this._invKeySchedule, INV_SUB_MIX_0, INV_SUB_MIX_1, INV_SUB_MIX_2, INV_SUB_MIX_3, INV_SBOX);

        // Inv swap 2nd and 4th rows
        var t = M[offset + 1];
        M[offset + 1] = M[offset + 3];
        M[offset + 3] = t;
      },
      _doCryptBlock: function (M, offset, keySchedule, SUB_MIX_0, SUB_MIX_1, SUB_MIX_2, SUB_MIX_3, SBOX) {
        // Shortcut
        var nRounds = this._nRounds;

        // Get input, add round key
        var s0 = M[offset] ^ keySchedule[0];
        var s1 = M[offset + 1] ^ keySchedule[1];
        var s2 = M[offset + 2] ^ keySchedule[2];
        var s3 = M[offset + 3] ^ keySchedule[3];

        // Key schedule row counter
        var ksRow = 4;

        // Rounds
        for (var round = 1; round < nRounds; round++) {
          // Shift rows, sub bytes, mix columns, add round key
          var t0 = SUB_MIX_0[s0 >>> 24] ^ SUB_MIX_1[s1 >>> 16 & 0xff] ^ SUB_MIX_2[s2 >>> 8 & 0xff] ^ SUB_MIX_3[s3 & 0xff] ^ keySchedule[ksRow++];
          var t1 = SUB_MIX_0[s1 >>> 24] ^ SUB_MIX_1[s2 >>> 16 & 0xff] ^ SUB_MIX_2[s3 >>> 8 & 0xff] ^ SUB_MIX_3[s0 & 0xff] ^ keySchedule[ksRow++];
          var t2 = SUB_MIX_0[s2 >>> 24] ^ SUB_MIX_1[s3 >>> 16 & 0xff] ^ SUB_MIX_2[s0 >>> 8 & 0xff] ^ SUB_MIX_3[s1 & 0xff] ^ keySchedule[ksRow++];
          var t3 = SUB_MIX_0[s3 >>> 24] ^ SUB_MIX_1[s0 >>> 16 & 0xff] ^ SUB_MIX_2[s1 >>> 8 & 0xff] ^ SUB_MIX_3[s2 & 0xff] ^ keySchedule[ksRow++];

          // Update state
          s0 = t0;
          s1 = t1;
          s2 = t2;
          s3 = t3;
        }

        // Shift rows, sub bytes, add round key
        var t0 = (SBOX[s0 >>> 24] << 24 | SBOX[s1 >>> 16 & 0xff] << 16 | SBOX[s2 >>> 8 & 0xff] << 8 | SBOX[s3 & 0xff]) ^ keySchedule[ksRow++];
        var t1 = (SBOX[s1 >>> 24] << 24 | SBOX[s2 >>> 16 & 0xff] << 16 | SBOX[s3 >>> 8 & 0xff] << 8 | SBOX[s0 & 0xff]) ^ keySchedule[ksRow++];
        var t2 = (SBOX[s2 >>> 24] << 24 | SBOX[s3 >>> 16 & 0xff] << 16 | SBOX[s0 >>> 8 & 0xff] << 8 | SBOX[s1 & 0xff]) ^ keySchedule[ksRow++];
        var t3 = (SBOX[s3 >>> 24] << 24 | SBOX[s0 >>> 16 & 0xff] << 16 | SBOX[s1 >>> 8 & 0xff] << 8 | SBOX[s2 & 0xff]) ^ keySchedule[ksRow++];

        // Set output
        M[offset] = t0;
        M[offset + 1] = t1;
        M[offset + 2] = t2;
        M[offset + 3] = t3;
      },
      keySize: 256 / 32
    });

    /**
     * Shortcut functions to the cipher's object interface.
     *
     * @example
     *
     *     var ciphertext = CryptoJS.AES.encrypt(message, key, cfg);
     *     var plaintext  = CryptoJS.AES.decrypt(ciphertext, key, cfg);
     */
    C.AES = BlockCipher._createHelper(AES);
  })();
  return CryptoJS.AES;
});

/***/ }),

/***/ "./node_modules/crypto-js/cipher-core.js":
/*!***********************************************!*\
  !*** ./node_modules/crypto-js/cipher-core.js ***!
  \***********************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./evpkdf */ "./node_modules/crypto-js/evpkdf.js"));
  } else {}
})(this, function (CryptoJS) {
  /**
   * Cipher core components.
   */
  CryptoJS.lib.Cipher || function (undefined) {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var Base = C_lib.Base;
    var WordArray = C_lib.WordArray;
    var BufferedBlockAlgorithm = C_lib.BufferedBlockAlgorithm;
    var C_enc = C.enc;
    var Utf8 = C_enc.Utf8;
    var Base64 = C_enc.Base64;
    var C_algo = C.algo;
    var EvpKDF = C_algo.EvpKDF;

    /**
     * Abstract base cipher template.
     *
     * @property {number} keySize This cipher's key size. Default: 4 (128 bits)
     * @property {number} ivSize This cipher's IV size. Default: 4 (128 bits)
     * @property {number} _ENC_XFORM_MODE A constant representing encryption mode.
     * @property {number} _DEC_XFORM_MODE A constant representing decryption mode.
     */
    var Cipher = C_lib.Cipher = BufferedBlockAlgorithm.extend({
      /**
       * Configuration options.
       *
       * @property {WordArray} iv The IV to use for this operation.
       */
      cfg: Base.extend(),
      /**
       * Creates this cipher in encryption mode.
       *
       * @param {WordArray} key The key.
       * @param {Object} cfg (Optional) The configuration options to use for this operation.
       *
       * @return {Cipher} A cipher instance.
       *
       * @static
       *
       * @example
       *
       *     var cipher = CryptoJS.algo.AES.createEncryptor(keyWordArray, { iv: ivWordArray });
       */
      createEncryptor: function (key, cfg) {
        return this.create(this._ENC_XFORM_MODE, key, cfg);
      },
      /**
       * Creates this cipher in decryption mode.
       *
       * @param {WordArray} key The key.
       * @param {Object} cfg (Optional) The configuration options to use for this operation.
       *
       * @return {Cipher} A cipher instance.
       *
       * @static
       *
       * @example
       *
       *     var cipher = CryptoJS.algo.AES.createDecryptor(keyWordArray, { iv: ivWordArray });
       */
      createDecryptor: function (key, cfg) {
        return this.create(this._DEC_XFORM_MODE, key, cfg);
      },
      /**
       * Initializes a newly created cipher.
       *
       * @param {number} xformMode Either the encryption or decryption transormation mode constant.
       * @param {WordArray} key The key.
       * @param {Object} cfg (Optional) The configuration options to use for this operation.
       *
       * @example
       *
       *     var cipher = CryptoJS.algo.AES.create(CryptoJS.algo.AES._ENC_XFORM_MODE, keyWordArray, { iv: ivWordArray });
       */
      init: function (xformMode, key, cfg) {
        // Apply config defaults
        this.cfg = this.cfg.extend(cfg);

        // Store transform mode and key
        this._xformMode = xformMode;
        this._key = key;

        // Set initial values
        this.reset();
      },
      /**
       * Resets this cipher to its initial state.
       *
       * @example
       *
       *     cipher.reset();
       */
      reset: function () {
        // Reset data buffer
        BufferedBlockAlgorithm.reset.call(this);

        // Perform concrete-cipher logic
        this._doReset();
      },
      /**
       * Adds data to be encrypted or decrypted.
       *
       * @param {WordArray|string} dataUpdate The data to encrypt or decrypt.
       *
       * @return {WordArray} The data after processing.
       *
       * @example
       *
       *     var encrypted = cipher.process('data');
       *     var encrypted = cipher.process(wordArray);
       */
      process: function (dataUpdate) {
        // Append
        this._append(dataUpdate);

        // Process available blocks
        return this._process();
      },
      /**
       * Finalizes the encryption or decryption process.
       * Note that the finalize operation is effectively a destructive, read-once operation.
       *
       * @param {WordArray|string} dataUpdate The final data to encrypt or decrypt.
       *
       * @return {WordArray} The data after final processing.
       *
       * @example
       *
       *     var encrypted = cipher.finalize();
       *     var encrypted = cipher.finalize('data');
       *     var encrypted = cipher.finalize(wordArray);
       */
      finalize: function (dataUpdate) {
        // Final data update
        if (dataUpdate) {
          this._append(dataUpdate);
        }

        // Perform concrete-cipher logic
        var finalProcessedData = this._doFinalize();
        return finalProcessedData;
      },
      keySize: 128 / 32,
      ivSize: 128 / 32,
      _ENC_XFORM_MODE: 1,
      _DEC_XFORM_MODE: 2,
      /**
       * Creates shortcut functions to a cipher's object interface.
       *
       * @param {Cipher} cipher The cipher to create a helper for.
       *
       * @return {Object} An object with encrypt and decrypt shortcut functions.
       *
       * @static
       *
       * @example
       *
       *     var AES = CryptoJS.lib.Cipher._createHelper(CryptoJS.algo.AES);
       */
      _createHelper: function () {
        function selectCipherStrategy(key) {
          if (typeof key == 'string') {
            return PasswordBasedCipher;
          } else {
            return SerializableCipher;
          }
        }
        return function (cipher) {
          return {
            encrypt: function (message, key, cfg) {
              return selectCipherStrategy(key).encrypt(cipher, message, key, cfg);
            },
            decrypt: function (ciphertext, key, cfg) {
              return selectCipherStrategy(key).decrypt(cipher, ciphertext, key, cfg);
            }
          };
        };
      }()
    });

    /**
     * Abstract base stream cipher template.
     *
     * @property {number} blockSize The number of 32-bit words this cipher operates on. Default: 1 (32 bits)
     */
    var StreamCipher = C_lib.StreamCipher = Cipher.extend({
      _doFinalize: function () {
        // Process partial blocks
        var finalProcessedBlocks = this._process(!!'flush');
        return finalProcessedBlocks;
      },
      blockSize: 1
    });

    /**
     * Mode namespace.
     */
    var C_mode = C.mode = {};

    /**
     * Abstract base block cipher mode template.
     */
    var BlockCipherMode = C_lib.BlockCipherMode = Base.extend({
      /**
       * Creates this mode for encryption.
       *
       * @param {Cipher} cipher A block cipher instance.
       * @param {Array} iv The IV words.
       *
       * @static
       *
       * @example
       *
       *     var mode = CryptoJS.mode.CBC.createEncryptor(cipher, iv.words);
       */
      createEncryptor: function (cipher, iv) {
        return this.Encryptor.create(cipher, iv);
      },
      /**
       * Creates this mode for decryption.
       *
       * @param {Cipher} cipher A block cipher instance.
       * @param {Array} iv The IV words.
       *
       * @static
       *
       * @example
       *
       *     var mode = CryptoJS.mode.CBC.createDecryptor(cipher, iv.words);
       */
      createDecryptor: function (cipher, iv) {
        return this.Decryptor.create(cipher, iv);
      },
      /**
       * Initializes a newly created mode.
       *
       * @param {Cipher} cipher A block cipher instance.
       * @param {Array} iv The IV words.
       *
       * @example
       *
       *     var mode = CryptoJS.mode.CBC.Encryptor.create(cipher, iv.words);
       */
      init: function (cipher, iv) {
        this._cipher = cipher;
        this._iv = iv;
      }
    });

    /**
     * Cipher Block Chaining mode.
     */
    var CBC = C_mode.CBC = function () {
      /**
       * Abstract base CBC mode.
       */
      var CBC = BlockCipherMode.extend();

      /**
       * CBC encryptor.
       */
      CBC.Encryptor = CBC.extend({
        /**
         * Processes the data block at offset.
         *
         * @param {Array} words The data words to operate on.
         * @param {number} offset The offset where the block starts.
         *
         * @example
         *
         *     mode.processBlock(data.words, offset);
         */
        processBlock: function (words, offset) {
          // Shortcuts
          var cipher = this._cipher;
          var blockSize = cipher.blockSize;

          // XOR and encrypt
          xorBlock.call(this, words, offset, blockSize);
          cipher.encryptBlock(words, offset);

          // Remember this block to use with next block
          this._prevBlock = words.slice(offset, offset + blockSize);
        }
      });

      /**
       * CBC decryptor.
       */
      CBC.Decryptor = CBC.extend({
        /**
         * Processes the data block at offset.
         *
         * @param {Array} words The data words to operate on.
         * @param {number} offset The offset where the block starts.
         *
         * @example
         *
         *     mode.processBlock(data.words, offset);
         */
        processBlock: function (words, offset) {
          // Shortcuts
          var cipher = this._cipher;
          var blockSize = cipher.blockSize;

          // Remember this block to use with next block
          var thisBlock = words.slice(offset, offset + blockSize);

          // Decrypt and XOR
          cipher.decryptBlock(words, offset);
          xorBlock.call(this, words, offset, blockSize);

          // This block becomes the previous block
          this._prevBlock = thisBlock;
        }
      });
      function xorBlock(words, offset, blockSize) {
        var block;

        // Shortcut
        var iv = this._iv;

        // Choose mixing block
        if (iv) {
          block = iv;

          // Remove IV for subsequent blocks
          this._iv = undefined;
        } else {
          block = this._prevBlock;
        }

        // XOR blocks
        for (var i = 0; i < blockSize; i++) {
          words[offset + i] ^= block[i];
        }
      }
      return CBC;
    }();

    /**
     * Padding namespace.
     */
    var C_pad = C.pad = {};

    /**
     * PKCS #5/7 padding strategy.
     */
    var Pkcs7 = C_pad.Pkcs7 = {
      /**
       * Pads data using the algorithm defined in PKCS #5/7.
       *
       * @param {WordArray} data The data to pad.
       * @param {number} blockSize The multiple that the data should be padded to.
       *
       * @static
       *
       * @example
       *
       *     CryptoJS.pad.Pkcs7.pad(wordArray, 4);
       */
      pad: function (data, blockSize) {
        // Shortcut
        var blockSizeBytes = blockSize * 4;

        // Count padding bytes
        var nPaddingBytes = blockSizeBytes - data.sigBytes % blockSizeBytes;

        // Create padding word
        var paddingWord = nPaddingBytes << 24 | nPaddingBytes << 16 | nPaddingBytes << 8 | nPaddingBytes;

        // Create padding
        var paddingWords = [];
        for (var i = 0; i < nPaddingBytes; i += 4) {
          paddingWords.push(paddingWord);
        }
        var padding = WordArray.create(paddingWords, nPaddingBytes);

        // Add padding
        data.concat(padding);
      },
      /**
       * Unpads data that had been padded using the algorithm defined in PKCS #5/7.
       *
       * @param {WordArray} data The data to unpad.
       *
       * @static
       *
       * @example
       *
       *     CryptoJS.pad.Pkcs7.unpad(wordArray);
       */
      unpad: function (data) {
        // Get number of padding bytes from last byte
        var nPaddingBytes = data.words[data.sigBytes - 1 >>> 2] & 0xff;

        // Remove padding
        data.sigBytes -= nPaddingBytes;
      }
    };

    /**
     * Abstract base block cipher template.
     *
     * @property {number} blockSize The number of 32-bit words this cipher operates on. Default: 4 (128 bits)
     */
    var BlockCipher = C_lib.BlockCipher = Cipher.extend({
      /**
       * Configuration options.
       *
       * @property {Mode} mode The block mode to use. Default: CBC
       * @property {Padding} padding The padding strategy to use. Default: Pkcs7
       */
      cfg: Cipher.cfg.extend({
        mode: CBC,
        padding: Pkcs7
      }),
      reset: function () {
        var modeCreator;

        // Reset cipher
        Cipher.reset.call(this);

        // Shortcuts
        var cfg = this.cfg;
        var iv = cfg.iv;
        var mode = cfg.mode;

        // Reset block mode
        if (this._xformMode == this._ENC_XFORM_MODE) {
          modeCreator = mode.createEncryptor;
        } else /* if (this._xformMode == this._DEC_XFORM_MODE) */{
            modeCreator = mode.createDecryptor;
            // Keep at least one block in the buffer for unpadding
            this._minBufferSize = 1;
          }
        if (this._mode && this._mode.__creator == modeCreator) {
          this._mode.init(this, iv && iv.words);
        } else {
          this._mode = modeCreator.call(mode, this, iv && iv.words);
          this._mode.__creator = modeCreator;
        }
      },
      _doProcessBlock: function (words, offset) {
        this._mode.processBlock(words, offset);
      },
      _doFinalize: function () {
        var finalProcessedBlocks;

        // Shortcut
        var padding = this.cfg.padding;

        // Finalize
        if (this._xformMode == this._ENC_XFORM_MODE) {
          // Pad data
          padding.pad(this._data, this.blockSize);

          // Process final blocks
          finalProcessedBlocks = this._process(!!'flush');
        } else /* if (this._xformMode == this._DEC_XFORM_MODE) */{
            // Process final blocks
            finalProcessedBlocks = this._process(!!'flush');

            // Unpad data
            padding.unpad(finalProcessedBlocks);
          }
        return finalProcessedBlocks;
      },
      blockSize: 128 / 32
    });

    /**
     * A collection of cipher parameters.
     *
     * @property {WordArray} ciphertext The raw ciphertext.
     * @property {WordArray} key The key to this ciphertext.
     * @property {WordArray} iv The IV used in the ciphering operation.
     * @property {WordArray} salt The salt used with a key derivation function.
     * @property {Cipher} algorithm The cipher algorithm.
     * @property {Mode} mode The block mode used in the ciphering operation.
     * @property {Padding} padding The padding scheme used in the ciphering operation.
     * @property {number} blockSize The block size of the cipher.
     * @property {Format} formatter The default formatting strategy to convert this cipher params object to a string.
     */
    var CipherParams = C_lib.CipherParams = Base.extend({
      /**
       * Initializes a newly created cipher params object.
       *
       * @param {Object} cipherParams An object with any of the possible cipher parameters.
       *
       * @example
       *
       *     var cipherParams = CryptoJS.lib.CipherParams.create({
       *         ciphertext: ciphertextWordArray,
       *         key: keyWordArray,
       *         iv: ivWordArray,
       *         salt: saltWordArray,
       *         algorithm: CryptoJS.algo.AES,
       *         mode: CryptoJS.mode.CBC,
       *         padding: CryptoJS.pad.PKCS7,
       *         blockSize: 4,
       *         formatter: CryptoJS.format.OpenSSL
       *     });
       */
      init: function (cipherParams) {
        this.mixIn(cipherParams);
      },
      /**
       * Converts this cipher params object to a string.
       *
       * @param {Format} formatter (Optional) The formatting strategy to use.
       *
       * @return {string} The stringified cipher params.
       *
       * @throws Error If neither the formatter nor the default formatter is set.
       *
       * @example
       *
       *     var string = cipherParams + '';
       *     var string = cipherParams.toString();
       *     var string = cipherParams.toString(CryptoJS.format.OpenSSL);
       */
      toString: function (formatter) {
        return (formatter || this.formatter).stringify(this);
      }
    });

    /**
     * Format namespace.
     */
    var C_format = C.format = {};

    /**
     * OpenSSL formatting strategy.
     */
    var OpenSSLFormatter = C_format.OpenSSL = {
      /**
       * Converts a cipher params object to an OpenSSL-compatible string.
       *
       * @param {CipherParams} cipherParams The cipher params object.
       *
       * @return {string} The OpenSSL-compatible string.
       *
       * @static
       *
       * @example
       *
       *     var openSSLString = CryptoJS.format.OpenSSL.stringify(cipherParams);
       */
      stringify: function (cipherParams) {
        var wordArray;

        // Shortcuts
        var ciphertext = cipherParams.ciphertext;
        var salt = cipherParams.salt;

        // Format
        if (salt) {
          wordArray = WordArray.create([0x53616c74, 0x65645f5f]).concat(salt).concat(ciphertext);
        } else {
          wordArray = ciphertext;
        }
        return wordArray.toString(Base64);
      },
      /**
       * Converts an OpenSSL-compatible string to a cipher params object.
       *
       * @param {string} openSSLStr The OpenSSL-compatible string.
       *
       * @return {CipherParams} The cipher params object.
       *
       * @static
       *
       * @example
       *
       *     var cipherParams = CryptoJS.format.OpenSSL.parse(openSSLString);
       */
      parse: function (openSSLStr) {
        var salt;

        // Parse base64
        var ciphertext = Base64.parse(openSSLStr);

        // Shortcut
        var ciphertextWords = ciphertext.words;

        // Test for salt
        if (ciphertextWords[0] == 0x53616c74 && ciphertextWords[1] == 0x65645f5f) {
          // Extract salt
          salt = WordArray.create(ciphertextWords.slice(2, 4));

          // Remove salt from ciphertext
          ciphertextWords.splice(0, 4);
          ciphertext.sigBytes -= 16;
        }
        return CipherParams.create({
          ciphertext: ciphertext,
          salt: salt
        });
      }
    };

    /**
     * A cipher wrapper that returns ciphertext as a serializable cipher params object.
     */
    var SerializableCipher = C_lib.SerializableCipher = Base.extend({
      /**
       * Configuration options.
       *
       * @property {Formatter} format The formatting strategy to convert cipher param objects to and from a string. Default: OpenSSL
       */
      cfg: Base.extend({
        format: OpenSSLFormatter
      }),
      /**
       * Encrypts a message.
       *
       * @param {Cipher} cipher The cipher algorithm to use.
       * @param {WordArray|string} message The message to encrypt.
       * @param {WordArray} key The key.
       * @param {Object} cfg (Optional) The configuration options to use for this operation.
       *
       * @return {CipherParams} A cipher params object.
       *
       * @static
       *
       * @example
       *
       *     var ciphertextParams = CryptoJS.lib.SerializableCipher.encrypt(CryptoJS.algo.AES, message, key);
       *     var ciphertextParams = CryptoJS.lib.SerializableCipher.encrypt(CryptoJS.algo.AES, message, key, { iv: iv });
       *     var ciphertextParams = CryptoJS.lib.SerializableCipher.encrypt(CryptoJS.algo.AES, message, key, { iv: iv, format: CryptoJS.format.OpenSSL });
       */
      encrypt: function (cipher, message, key, cfg) {
        // Apply config defaults
        cfg = this.cfg.extend(cfg);

        // Encrypt
        var encryptor = cipher.createEncryptor(key, cfg);
        var ciphertext = encryptor.finalize(message);

        // Shortcut
        var cipherCfg = encryptor.cfg;

        // Create and return serializable cipher params
        return CipherParams.create({
          ciphertext: ciphertext,
          key: key,
          iv: cipherCfg.iv,
          algorithm: cipher,
          mode: cipherCfg.mode,
          padding: cipherCfg.padding,
          blockSize: cipher.blockSize,
          formatter: cfg.format
        });
      },
      /**
       * Decrypts serialized ciphertext.
       *
       * @param {Cipher} cipher The cipher algorithm to use.
       * @param {CipherParams|string} ciphertext The ciphertext to decrypt.
       * @param {WordArray} key The key.
       * @param {Object} cfg (Optional) The configuration options to use for this operation.
       *
       * @return {WordArray} The plaintext.
       *
       * @static
       *
       * @example
       *
       *     var plaintext = CryptoJS.lib.SerializableCipher.decrypt(CryptoJS.algo.AES, formattedCiphertext, key, { iv: iv, format: CryptoJS.format.OpenSSL });
       *     var plaintext = CryptoJS.lib.SerializableCipher.decrypt(CryptoJS.algo.AES, ciphertextParams, key, { iv: iv, format: CryptoJS.format.OpenSSL });
       */
      decrypt: function (cipher, ciphertext, key, cfg) {
        // Apply config defaults
        cfg = this.cfg.extend(cfg);

        // Convert string to CipherParams
        ciphertext = this._parse(ciphertext, cfg.format);

        // Decrypt
        var plaintext = cipher.createDecryptor(key, cfg).finalize(ciphertext.ciphertext);
        return plaintext;
      },
      /**
       * Converts serialized ciphertext to CipherParams,
       * else assumed CipherParams already and returns ciphertext unchanged.
       *
       * @param {CipherParams|string} ciphertext The ciphertext.
       * @param {Formatter} format The formatting strategy to use to parse serialized ciphertext.
       *
       * @return {CipherParams} The unserialized ciphertext.
       *
       * @static
       *
       * @example
       *
       *     var ciphertextParams = CryptoJS.lib.SerializableCipher._parse(ciphertextStringOrParams, format);
       */
      _parse: function (ciphertext, format) {
        if (typeof ciphertext == 'string') {
          return format.parse(ciphertext, this);
        } else {
          return ciphertext;
        }
      }
    });

    /**
     * Key derivation function namespace.
     */
    var C_kdf = C.kdf = {};

    /**
     * OpenSSL key derivation function.
     */
    var OpenSSLKdf = C_kdf.OpenSSL = {
      /**
       * Derives a key and IV from a password.
       *
       * @param {string} password The password to derive from.
       * @param {number} keySize The size in words of the key to generate.
       * @param {number} ivSize The size in words of the IV to generate.
       * @param {WordArray|string} salt (Optional) A 64-bit salt to use. If omitted, a salt will be generated randomly.
       *
       * @return {CipherParams} A cipher params object with the key, IV, and salt.
       *
       * @static
       *
       * @example
       *
       *     var derivedParams = CryptoJS.kdf.OpenSSL.execute('Password', 256/32, 128/32);
       *     var derivedParams = CryptoJS.kdf.OpenSSL.execute('Password', 256/32, 128/32, 'saltsalt');
       */
      execute: function (password, keySize, ivSize, salt) {
        // Generate random salt
        if (!salt) {
          salt = WordArray.random(64 / 8);
        }

        // Derive key and IV
        var key = EvpKDF.create({
          keySize: keySize + ivSize
        }).compute(password, salt);

        // Separate key and IV
        var iv = WordArray.create(key.words.slice(keySize), ivSize * 4);
        key.sigBytes = keySize * 4;

        // Return params
        return CipherParams.create({
          key: key,
          iv: iv,
          salt: salt
        });
      }
    };

    /**
     * A serializable cipher wrapper that derives the key from a password,
     * and returns ciphertext as a serializable cipher params object.
     */
    var PasswordBasedCipher = C_lib.PasswordBasedCipher = SerializableCipher.extend({
      /**
       * Configuration options.
       *
       * @property {KDF} kdf The key derivation function to use to generate a key and IV from a password. Default: OpenSSL
       */
      cfg: SerializableCipher.cfg.extend({
        kdf: OpenSSLKdf
      }),
      /**
       * Encrypts a message using a password.
       *
       * @param {Cipher} cipher The cipher algorithm to use.
       * @param {WordArray|string} message The message to encrypt.
       * @param {string} password The password.
       * @param {Object} cfg (Optional) The configuration options to use for this operation.
       *
       * @return {CipherParams} A cipher params object.
       *
       * @static
       *
       * @example
       *
       *     var ciphertextParams = CryptoJS.lib.PasswordBasedCipher.encrypt(CryptoJS.algo.AES, message, 'password');
       *     var ciphertextParams = CryptoJS.lib.PasswordBasedCipher.encrypt(CryptoJS.algo.AES, message, 'password', { format: CryptoJS.format.OpenSSL });
       */
      encrypt: function (cipher, message, password, cfg) {
        // Apply config defaults
        cfg = this.cfg.extend(cfg);

        // Derive key and other params
        var derivedParams = cfg.kdf.execute(password, cipher.keySize, cipher.ivSize);

        // Add IV to config
        cfg.iv = derivedParams.iv;

        // Encrypt
        var ciphertext = SerializableCipher.encrypt.call(this, cipher, message, derivedParams.key, cfg);

        // Mix in derived params
        ciphertext.mixIn(derivedParams);
        return ciphertext;
      },
      /**
       * Decrypts serialized ciphertext using a password.
       *
       * @param {Cipher} cipher The cipher algorithm to use.
       * @param {CipherParams|string} ciphertext The ciphertext to decrypt.
       * @param {string} password The password.
       * @param {Object} cfg (Optional) The configuration options to use for this operation.
       *
       * @return {WordArray} The plaintext.
       *
       * @static
       *
       * @example
       *
       *     var plaintext = CryptoJS.lib.PasswordBasedCipher.decrypt(CryptoJS.algo.AES, formattedCiphertext, 'password', { format: CryptoJS.format.OpenSSL });
       *     var plaintext = CryptoJS.lib.PasswordBasedCipher.decrypt(CryptoJS.algo.AES, ciphertextParams, 'password', { format: CryptoJS.format.OpenSSL });
       */
      decrypt: function (cipher, ciphertext, password, cfg) {
        // Apply config defaults
        cfg = this.cfg.extend(cfg);

        // Convert string to CipherParams
        ciphertext = this._parse(ciphertext, cfg.format);

        // Derive key and other params
        var derivedParams = cfg.kdf.execute(password, cipher.keySize, cipher.ivSize, ciphertext.salt);

        // Add IV to config
        cfg.iv = derivedParams.iv;

        // Decrypt
        var plaintext = SerializableCipher.decrypt.call(this, cipher, ciphertext, derivedParams.key, cfg);
        return plaintext;
      }
    });
  }();
});

/***/ }),

/***/ "./node_modules/crypto-js/core.js":
/*!****************************************!*\
  !*** ./node_modules/crypto-js/core.js ***!
  \****************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory) {
  if (true) {
    // CommonJS
    module.exports = exports = factory();
  } else {}
})(this, function () {
  /*globals window, global, require*/

  /**
   * CryptoJS core components.
   */
  var CryptoJS = CryptoJS || function (Math, undefined) {
    var crypto;

    // Native crypto from window (Browser)
    if (typeof window !== 'undefined' && window.crypto) {
      crypto = window.crypto;
    }

    // Native crypto in web worker (Browser)
    if (typeof self !== 'undefined' && self.crypto) {
      crypto = self.crypto;
    }

    // Native crypto from worker
    if (typeof globalThis !== 'undefined' && globalThis.crypto) {
      crypto = globalThis.crypto;
    }

    // Native (experimental IE 11) crypto from window (Browser)
    if (!crypto && typeof window !== 'undefined' && window.msCrypto) {
      crypto = window.msCrypto;
    }

    // Native crypto from global (NodeJS)
    if (!crypto && typeof __webpack_require__.g !== 'undefined' && __webpack_require__.g.crypto) {
      crypto = __webpack_require__.g.crypto;
    }

    // Native crypto import via require (NodeJS)
    if (!crypto && "function" === 'function') {
      try {
        crypto = __webpack_require__(/*! crypto */ "?9157");
      } catch (err) {}
    }

    /*
     * Cryptographically secure pseudorandom number generator
     *
     * As Math.random() is cryptographically not safe to use
     */
    var cryptoSecureRandomInt = function () {
      if (crypto) {
        // Use getRandomValues method (Browser)
        if (typeof crypto.getRandomValues === 'function') {
          try {
            return crypto.getRandomValues(new Uint32Array(1))[0];
          } catch (err) {}
        }

        // Use randomBytes method (NodeJS)
        if (typeof crypto.randomBytes === 'function') {
          try {
            return crypto.randomBytes(4).readInt32LE();
          } catch (err) {}
        }
      }
      throw new Error('Native crypto module could not be used to get secure random number.');
    };

    /*
     * Local polyfill of Object.create
      */
    var create = Object.create || function () {
      function F() {}
      return function (obj) {
        var subtype;
        F.prototype = obj;
        subtype = new F();
        F.prototype = null;
        return subtype;
      };
    }();

    /**
     * CryptoJS namespace.
     */
    var C = {};

    /**
     * Library namespace.
     */
    var C_lib = C.lib = {};

    /**
     * Base object for prototypal inheritance.
     */
    var Base = C_lib.Base = function () {
      return {
        /**
         * Creates a new object that inherits from this object.
         *
         * @param {Object} overrides Properties to copy into the new object.
         *
         * @return {Object} The new object.
         *
         * @static
         *
         * @example
         *
         *     var MyType = CryptoJS.lib.Base.extend({
         *         field: 'value',
         *
         *         method: function () {
         *         }
         *     });
         */
        extend: function (overrides) {
          // Spawn
          var subtype = create(this);

          // Augment
          if (overrides) {
            subtype.mixIn(overrides);
          }

          // Create default initializer
          if (!subtype.hasOwnProperty('init') || this.init === subtype.init) {
            subtype.init = function () {
              subtype.$super.init.apply(this, arguments);
            };
          }

          // Initializer's prototype is the subtype object
          subtype.init.prototype = subtype;

          // Reference supertype
          subtype.$super = this;
          return subtype;
        },
        /**
         * Extends this object and runs the init method.
         * Arguments to create() will be passed to init().
         *
         * @return {Object} The new object.
         *
         * @static
         *
         * @example
         *
         *     var instance = MyType.create();
         */
        create: function () {
          var instance = this.extend();
          instance.init.apply(instance, arguments);
          return instance;
        },
        /**
         * Initializes a newly created object.
         * Override this method to add some logic when your objects are created.
         *
         * @example
         *
         *     var MyType = CryptoJS.lib.Base.extend({
         *         init: function () {
         *             // ...
         *         }
         *     });
         */
        init: function () {},
        /**
         * Copies properties into this object.
         *
         * @param {Object} properties The properties to mix in.
         *
         * @example
         *
         *     MyType.mixIn({
         *         field: 'value'
         *     });
         */
        mixIn: function (properties) {
          for (var propertyName in properties) {
            if (properties.hasOwnProperty(propertyName)) {
              this[propertyName] = properties[propertyName];
            }
          }

          // IE won't copy toString using the loop above
          if (properties.hasOwnProperty('toString')) {
            this.toString = properties.toString;
          }
        },
        /**
         * Creates a copy of this object.
         *
         * @return {Object} The clone.
         *
         * @example
         *
         *     var clone = instance.clone();
         */
        clone: function () {
          return this.init.prototype.extend(this);
        }
      };
    }();

    /**
     * An array of 32-bit words.
     *
     * @property {Array} words The array of 32-bit words.
     * @property {number} sigBytes The number of significant bytes in this word array.
     */
    var WordArray = C_lib.WordArray = Base.extend({
      /**
       * Initializes a newly created word array.
       *
       * @param {Array} words (Optional) An array of 32-bit words.
       * @param {number} sigBytes (Optional) The number of significant bytes in the words.
       *
       * @example
       *
       *     var wordArray = CryptoJS.lib.WordArray.create();
       *     var wordArray = CryptoJS.lib.WordArray.create([0x00010203, 0x04050607]);
       *     var wordArray = CryptoJS.lib.WordArray.create([0x00010203, 0x04050607], 6);
       */
      init: function (words, sigBytes) {
        words = this.words = words || [];
        if (sigBytes != undefined) {
          this.sigBytes = sigBytes;
        } else {
          this.sigBytes = words.length * 4;
        }
      },
      /**
       * Converts this word array to a string.
       *
       * @param {Encoder} encoder (Optional) The encoding strategy to use. Default: CryptoJS.enc.Hex
       *
       * @return {string} The stringified word array.
       *
       * @example
       *
       *     var string = wordArray + '';
       *     var string = wordArray.toString();
       *     var string = wordArray.toString(CryptoJS.enc.Utf8);
       */
      toString: function (encoder) {
        return (encoder || Hex).stringify(this);
      },
      /**
       * Concatenates a word array to this word array.
       *
       * @param {WordArray} wordArray The word array to append.
       *
       * @return {WordArray} This word array.
       *
       * @example
       *
       *     wordArray1.concat(wordArray2);
       */
      concat: function (wordArray) {
        // Shortcuts
        var thisWords = this.words;
        var thatWords = wordArray.words;
        var thisSigBytes = this.sigBytes;
        var thatSigBytes = wordArray.sigBytes;

        // Clamp excess bits
        this.clamp();

        // Concat
        if (thisSigBytes % 4) {
          // Copy one byte at a time
          for (var i = 0; i < thatSigBytes; i++) {
            var thatByte = thatWords[i >>> 2] >>> 24 - i % 4 * 8 & 0xff;
            thisWords[thisSigBytes + i >>> 2] |= thatByte << 24 - (thisSigBytes + i) % 4 * 8;
          }
        } else {
          // Copy one word at a time
          for (var j = 0; j < thatSigBytes; j += 4) {
            thisWords[thisSigBytes + j >>> 2] = thatWords[j >>> 2];
          }
        }
        this.sigBytes += thatSigBytes;

        // Chainable
        return this;
      },
      /**
       * Removes insignificant bits.
       *
       * @example
       *
       *     wordArray.clamp();
       */
      clamp: function () {
        // Shortcuts
        var words = this.words;
        var sigBytes = this.sigBytes;

        // Clamp
        words[sigBytes >>> 2] &= 0xffffffff << 32 - sigBytes % 4 * 8;
        words.length = Math.ceil(sigBytes / 4);
      },
      /**
       * Creates a copy of this word array.
       *
       * @return {WordArray} The clone.
       *
       * @example
       *
       *     var clone = wordArray.clone();
       */
      clone: function () {
        var clone = Base.clone.call(this);
        clone.words = this.words.slice(0);
        return clone;
      },
      /**
       * Creates a word array filled with random bytes.
       *
       * @param {number} nBytes The number of random bytes to generate.
       *
       * @return {WordArray} The random word array.
       *
       * @static
       *
       * @example
       *
       *     var wordArray = CryptoJS.lib.WordArray.random(16);
       */
      random: function (nBytes) {
        var words = [];
        for (var i = 0; i < nBytes; i += 4) {
          words.push(cryptoSecureRandomInt());
        }
        return new WordArray.init(words, nBytes);
      }
    });

    /**
     * Encoder namespace.
     */
    var C_enc = C.enc = {};

    /**
     * Hex encoding strategy.
     */
    var Hex = C_enc.Hex = {
      /**
       * Converts a word array to a hex string.
       *
       * @param {WordArray} wordArray The word array.
       *
       * @return {string} The hex string.
       *
       * @static
       *
       * @example
       *
       *     var hexString = CryptoJS.enc.Hex.stringify(wordArray);
       */
      stringify: function (wordArray) {
        // Shortcuts
        var words = wordArray.words;
        var sigBytes = wordArray.sigBytes;

        // Convert
        var hexChars = [];
        for (var i = 0; i < sigBytes; i++) {
          var bite = words[i >>> 2] >>> 24 - i % 4 * 8 & 0xff;
          hexChars.push((bite >>> 4).toString(16));
          hexChars.push((bite & 0x0f).toString(16));
        }
        return hexChars.join('');
      },
      /**
       * Converts a hex string to a word array.
       *
       * @param {string} hexStr The hex string.
       *
       * @return {WordArray} The word array.
       *
       * @static
       *
       * @example
       *
       *     var wordArray = CryptoJS.enc.Hex.parse(hexString);
       */
      parse: function (hexStr) {
        // Shortcut
        var hexStrLength = hexStr.length;

        // Convert
        var words = [];
        for (var i = 0; i < hexStrLength; i += 2) {
          words[i >>> 3] |= parseInt(hexStr.substr(i, 2), 16) << 24 - i % 8 * 4;
        }
        return new WordArray.init(words, hexStrLength / 2);
      }
    };

    /**
     * Latin1 encoding strategy.
     */
    var Latin1 = C_enc.Latin1 = {
      /**
       * Converts a word array to a Latin1 string.
       *
       * @param {WordArray} wordArray The word array.
       *
       * @return {string} The Latin1 string.
       *
       * @static
       *
       * @example
       *
       *     var latin1String = CryptoJS.enc.Latin1.stringify(wordArray);
       */
      stringify: function (wordArray) {
        // Shortcuts
        var words = wordArray.words;
        var sigBytes = wordArray.sigBytes;

        // Convert
        var latin1Chars = [];
        for (var i = 0; i < sigBytes; i++) {
          var bite = words[i >>> 2] >>> 24 - i % 4 * 8 & 0xff;
          latin1Chars.push(String.fromCharCode(bite));
        }
        return latin1Chars.join('');
      },
      /**
       * Converts a Latin1 string to a word array.
       *
       * @param {string} latin1Str The Latin1 string.
       *
       * @return {WordArray} The word array.
       *
       * @static
       *
       * @example
       *
       *     var wordArray = CryptoJS.enc.Latin1.parse(latin1String);
       */
      parse: function (latin1Str) {
        // Shortcut
        var latin1StrLength = latin1Str.length;

        // Convert
        var words = [];
        for (var i = 0; i < latin1StrLength; i++) {
          words[i >>> 2] |= (latin1Str.charCodeAt(i) & 0xff) << 24 - i % 4 * 8;
        }
        return new WordArray.init(words, latin1StrLength);
      }
    };

    /**
     * UTF-8 encoding strategy.
     */
    var Utf8 = C_enc.Utf8 = {
      /**
       * Converts a word array to a UTF-8 string.
       *
       * @param {WordArray} wordArray The word array.
       *
       * @return {string} The UTF-8 string.
       *
       * @static
       *
       * @example
       *
       *     var utf8String = CryptoJS.enc.Utf8.stringify(wordArray);
       */
      stringify: function (wordArray) {
        try {
          return decodeURIComponent(escape(Latin1.stringify(wordArray)));
        } catch (e) {
          throw new Error('Malformed UTF-8 data');
        }
      },
      /**
       * Converts a UTF-8 string to a word array.
       *
       * @param {string} utf8Str The UTF-8 string.
       *
       * @return {WordArray} The word array.
       *
       * @static
       *
       * @example
       *
       *     var wordArray = CryptoJS.enc.Utf8.parse(utf8String);
       */
      parse: function (utf8Str) {
        return Latin1.parse(unescape(encodeURIComponent(utf8Str)));
      }
    };

    /**
     * Abstract buffered block algorithm template.
     *
     * The property blockSize must be implemented in a concrete subtype.
     *
     * @property {number} _minBufferSize The number of blocks that should be kept unprocessed in the buffer. Default: 0
     */
    var BufferedBlockAlgorithm = C_lib.BufferedBlockAlgorithm = Base.extend({
      /**
       * Resets this block algorithm's data buffer to its initial state.
       *
       * @example
       *
       *     bufferedBlockAlgorithm.reset();
       */
      reset: function () {
        // Initial values
        this._data = new WordArray.init();
        this._nDataBytes = 0;
      },
      /**
       * Adds new data to this block algorithm's buffer.
       *
       * @param {WordArray|string} data The data to append. Strings are converted to a WordArray using UTF-8.
       *
       * @example
       *
       *     bufferedBlockAlgorithm._append('data');
       *     bufferedBlockAlgorithm._append(wordArray);
       */
      _append: function (data) {
        // Convert string to WordArray, else assume WordArray already
        if (typeof data == 'string') {
          data = Utf8.parse(data);
        }

        // Append
        this._data.concat(data);
        this._nDataBytes += data.sigBytes;
      },
      /**
       * Processes available data blocks.
       *
       * This method invokes _doProcessBlock(offset), which must be implemented by a concrete subtype.
       *
       * @param {boolean} doFlush Whether all blocks and partial blocks should be processed.
       *
       * @return {WordArray} The processed data.
       *
       * @example
       *
       *     var processedData = bufferedBlockAlgorithm._process();
       *     var processedData = bufferedBlockAlgorithm._process(!!'flush');
       */
      _process: function (doFlush) {
        var processedWords;

        // Shortcuts
        var data = this._data;
        var dataWords = data.words;
        var dataSigBytes = data.sigBytes;
        var blockSize = this.blockSize;
        var blockSizeBytes = blockSize * 4;

        // Count blocks ready
        var nBlocksReady = dataSigBytes / blockSizeBytes;
        if (doFlush) {
          // Round up to include partial blocks
          nBlocksReady = Math.ceil(nBlocksReady);
        } else {
          // Round down to include only full blocks,
          // less the number of blocks that must remain in the buffer
          nBlocksReady = Math.max((nBlocksReady | 0) - this._minBufferSize, 0);
        }

        // Count words ready
        var nWordsReady = nBlocksReady * blockSize;

        // Count bytes ready
        var nBytesReady = Math.min(nWordsReady * 4, dataSigBytes);

        // Process blocks
        if (nWordsReady) {
          for (var offset = 0; offset < nWordsReady; offset += blockSize) {
            // Perform concrete-algorithm logic
            this._doProcessBlock(dataWords, offset);
          }

          // Remove processed words
          processedWords = dataWords.splice(0, nWordsReady);
          data.sigBytes -= nBytesReady;
        }

        // Return processed words
        return new WordArray.init(processedWords, nBytesReady);
      },
      /**
       * Creates a copy of this object.
       *
       * @return {Object} The clone.
       *
       * @example
       *
       *     var clone = bufferedBlockAlgorithm.clone();
       */
      clone: function () {
        var clone = Base.clone.call(this);
        clone._data = this._data.clone();
        return clone;
      },
      _minBufferSize: 0
    });

    /**
     * Abstract hasher template.
     *
     * @property {number} blockSize The number of 32-bit words this hasher operates on. Default: 16 (512 bits)
     */
    var Hasher = C_lib.Hasher = BufferedBlockAlgorithm.extend({
      /**
       * Configuration options.
       */
      cfg: Base.extend(),
      /**
       * Initializes a newly created hasher.
       *
       * @param {Object} cfg (Optional) The configuration options to use for this hash computation.
       *
       * @example
       *
       *     var hasher = CryptoJS.algo.SHA256.create();
       */
      init: function (cfg) {
        // Apply config defaults
        this.cfg = this.cfg.extend(cfg);

        // Set initial values
        this.reset();
      },
      /**
       * Resets this hasher to its initial state.
       *
       * @example
       *
       *     hasher.reset();
       */
      reset: function () {
        // Reset data buffer
        BufferedBlockAlgorithm.reset.call(this);

        // Perform concrete-hasher logic
        this._doReset();
      },
      /**
       * Updates this hasher with a message.
       *
       * @param {WordArray|string} messageUpdate The message to append.
       *
       * @return {Hasher} This hasher.
       *
       * @example
       *
       *     hasher.update('message');
       *     hasher.update(wordArray);
       */
      update: function (messageUpdate) {
        // Append
        this._append(messageUpdate);

        // Update the hash
        this._process();

        // Chainable
        return this;
      },
      /**
       * Finalizes the hash computation.
       * Note that the finalize operation is effectively a destructive, read-once operation.
       *
       * @param {WordArray|string} messageUpdate (Optional) A final message update.
       *
       * @return {WordArray} The hash.
       *
       * @example
       *
       *     var hash = hasher.finalize();
       *     var hash = hasher.finalize('message');
       *     var hash = hasher.finalize(wordArray);
       */
      finalize: function (messageUpdate) {
        // Final message update
        if (messageUpdate) {
          this._append(messageUpdate);
        }

        // Perform concrete-hasher logic
        var hash = this._doFinalize();
        return hash;
      },
      blockSize: 512 / 32,
      /**
       * Creates a shortcut function to a hasher's object interface.
       *
       * @param {Hasher} hasher The hasher to create a helper for.
       *
       * @return {Function} The shortcut function.
       *
       * @static
       *
       * @example
       *
       *     var SHA256 = CryptoJS.lib.Hasher._createHelper(CryptoJS.algo.SHA256);
       */
      _createHelper: function (hasher) {
        return function (message, cfg) {
          return new hasher.init(cfg).finalize(message);
        };
      },
      /**
       * Creates a shortcut function to the HMAC's object interface.
       *
       * @param {Hasher} hasher The hasher to use in this HMAC helper.
       *
       * @return {Function} The shortcut function.
       *
       * @static
       *
       * @example
       *
       *     var HmacSHA256 = CryptoJS.lib.Hasher._createHmacHelper(CryptoJS.algo.SHA256);
       */
      _createHmacHelper: function (hasher) {
        return function (message, key) {
          return new C_algo.HMAC.init(hasher, key).finalize(message);
        };
      }
    });

    /**
     * Algorithm namespace.
     */
    var C_algo = C.algo = {};
    return C;
  }(Math);
  return CryptoJS;
});

/***/ }),

/***/ "./node_modules/crypto-js/enc-base64.js":
/*!**********************************************!*\
  !*** ./node_modules/crypto-js/enc-base64.js ***!
  \**********************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var WordArray = C_lib.WordArray;
    var C_enc = C.enc;

    /**
     * Base64 encoding strategy.
     */
    var Base64 = C_enc.Base64 = {
      /**
       * Converts a word array to a Base64 string.
       *
       * @param {WordArray} wordArray The word array.
       *
       * @return {string} The Base64 string.
       *
       * @static
       *
       * @example
       *
       *     var base64String = CryptoJS.enc.Base64.stringify(wordArray);
       */
      stringify: function (wordArray) {
        // Shortcuts
        var words = wordArray.words;
        var sigBytes = wordArray.sigBytes;
        var map = this._map;

        // Clamp excess bits
        wordArray.clamp();

        // Convert
        var base64Chars = [];
        for (var i = 0; i < sigBytes; i += 3) {
          var byte1 = words[i >>> 2] >>> 24 - i % 4 * 8 & 0xff;
          var byte2 = words[i + 1 >>> 2] >>> 24 - (i + 1) % 4 * 8 & 0xff;
          var byte3 = words[i + 2 >>> 2] >>> 24 - (i + 2) % 4 * 8 & 0xff;
          var triplet = byte1 << 16 | byte2 << 8 | byte3;
          for (var j = 0; j < 4 && i + j * 0.75 < sigBytes; j++) {
            base64Chars.push(map.charAt(triplet >>> 6 * (3 - j) & 0x3f));
          }
        }

        // Add padding
        var paddingChar = map.charAt(64);
        if (paddingChar) {
          while (base64Chars.length % 4) {
            base64Chars.push(paddingChar);
          }
        }
        return base64Chars.join('');
      },
      /**
       * Converts a Base64 string to a word array.
       *
       * @param {string} base64Str The Base64 string.
       *
       * @return {WordArray} The word array.
       *
       * @static
       *
       * @example
       *
       *     var wordArray = CryptoJS.enc.Base64.parse(base64String);
       */
      parse: function (base64Str) {
        // Shortcuts
        var base64StrLength = base64Str.length;
        var map = this._map;
        var reverseMap = this._reverseMap;
        if (!reverseMap) {
          reverseMap = this._reverseMap = [];
          for (var j = 0; j < map.length; j++) {
            reverseMap[map.charCodeAt(j)] = j;
          }
        }

        // Ignore padding
        var paddingChar = map.charAt(64);
        if (paddingChar) {
          var paddingIndex = base64Str.indexOf(paddingChar);
          if (paddingIndex !== -1) {
            base64StrLength = paddingIndex;
          }
        }

        // Convert
        return parseLoop(base64Str, base64StrLength, reverseMap);
      },
      _map: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/='
    };
    function parseLoop(base64Str, base64StrLength, reverseMap) {
      var words = [];
      var nBytes = 0;
      for (var i = 0; i < base64StrLength; i++) {
        if (i % 4) {
          var bits1 = reverseMap[base64Str.charCodeAt(i - 1)] << i % 4 * 2;
          var bits2 = reverseMap[base64Str.charCodeAt(i)] >>> 6 - i % 4 * 2;
          var bitsCombined = bits1 | bits2;
          words[nBytes >>> 2] |= bitsCombined << 24 - nBytes % 4 * 8;
          nBytes++;
        }
      }
      return WordArray.create(words, nBytes);
    }
  })();
  return CryptoJS.enc.Base64;
});

/***/ }),

/***/ "./node_modules/crypto-js/enc-base64url.js":
/*!*************************************************!*\
  !*** ./node_modules/crypto-js/enc-base64url.js ***!
  \*************************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var WordArray = C_lib.WordArray;
    var C_enc = C.enc;

    /**
     * Base64url encoding strategy.
     */
    var Base64url = C_enc.Base64url = {
      /**
       * Converts a word array to a Base64url string.
       *
       * @param {WordArray} wordArray The word array.
       *
       * @param {boolean} urlSafe Whether to use url safe
       *
       * @return {string} The Base64url string.
       *
       * @static
       *
       * @example
       *
       *     var base64String = CryptoJS.enc.Base64url.stringify(wordArray);
       */
      stringify: function (wordArray, urlSafe = true) {
        // Shortcuts
        var words = wordArray.words;
        var sigBytes = wordArray.sigBytes;
        var map = urlSafe ? this._safe_map : this._map;

        // Clamp excess bits
        wordArray.clamp();

        // Convert
        var base64Chars = [];
        for (var i = 0; i < sigBytes; i += 3) {
          var byte1 = words[i >>> 2] >>> 24 - i % 4 * 8 & 0xff;
          var byte2 = words[i + 1 >>> 2] >>> 24 - (i + 1) % 4 * 8 & 0xff;
          var byte3 = words[i + 2 >>> 2] >>> 24 - (i + 2) % 4 * 8 & 0xff;
          var triplet = byte1 << 16 | byte2 << 8 | byte3;
          for (var j = 0; j < 4 && i + j * 0.75 < sigBytes; j++) {
            base64Chars.push(map.charAt(triplet >>> 6 * (3 - j) & 0x3f));
          }
        }

        // Add padding
        var paddingChar = map.charAt(64);
        if (paddingChar) {
          while (base64Chars.length % 4) {
            base64Chars.push(paddingChar);
          }
        }
        return base64Chars.join('');
      },
      /**
       * Converts a Base64url string to a word array.
       *
       * @param {string} base64Str The Base64url string.
       *
       * @param {boolean} urlSafe Whether to use url safe
       *
       * @return {WordArray} The word array.
       *
       * @static
       *
       * @example
       *
       *     var wordArray = CryptoJS.enc.Base64url.parse(base64String);
       */
      parse: function (base64Str, urlSafe = true) {
        // Shortcuts
        var base64StrLength = base64Str.length;
        var map = urlSafe ? this._safe_map : this._map;
        var reverseMap = this._reverseMap;
        if (!reverseMap) {
          reverseMap = this._reverseMap = [];
          for (var j = 0; j < map.length; j++) {
            reverseMap[map.charCodeAt(j)] = j;
          }
        }

        // Ignore padding
        var paddingChar = map.charAt(64);
        if (paddingChar) {
          var paddingIndex = base64Str.indexOf(paddingChar);
          if (paddingIndex !== -1) {
            base64StrLength = paddingIndex;
          }
        }

        // Convert
        return parseLoop(base64Str, base64StrLength, reverseMap);
      },
      _map: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
      _safe_map: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_'
    };
    function parseLoop(base64Str, base64StrLength, reverseMap) {
      var words = [];
      var nBytes = 0;
      for (var i = 0; i < base64StrLength; i++) {
        if (i % 4) {
          var bits1 = reverseMap[base64Str.charCodeAt(i - 1)] << i % 4 * 2;
          var bits2 = reverseMap[base64Str.charCodeAt(i)] >>> 6 - i % 4 * 2;
          var bitsCombined = bits1 | bits2;
          words[nBytes >>> 2] |= bitsCombined << 24 - nBytes % 4 * 8;
          nBytes++;
        }
      }
      return WordArray.create(words, nBytes);
    }
  })();
  return CryptoJS.enc.Base64url;
});

/***/ }),

/***/ "./node_modules/crypto-js/enc-utf16.js":
/*!*********************************************!*\
  !*** ./node_modules/crypto-js/enc-utf16.js ***!
  \*********************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var WordArray = C_lib.WordArray;
    var C_enc = C.enc;

    /**
     * UTF-16 BE encoding strategy.
     */
    var Utf16BE = C_enc.Utf16 = C_enc.Utf16BE = {
      /**
       * Converts a word array to a UTF-16 BE string.
       *
       * @param {WordArray} wordArray The word array.
       *
       * @return {string} The UTF-16 BE string.
       *
       * @static
       *
       * @example
       *
       *     var utf16String = CryptoJS.enc.Utf16.stringify(wordArray);
       */
      stringify: function (wordArray) {
        // Shortcuts
        var words = wordArray.words;
        var sigBytes = wordArray.sigBytes;

        // Convert
        var utf16Chars = [];
        for (var i = 0; i < sigBytes; i += 2) {
          var codePoint = words[i >>> 2] >>> 16 - i % 4 * 8 & 0xffff;
          utf16Chars.push(String.fromCharCode(codePoint));
        }
        return utf16Chars.join('');
      },
      /**
       * Converts a UTF-16 BE string to a word array.
       *
       * @param {string} utf16Str The UTF-16 BE string.
       *
       * @return {WordArray} The word array.
       *
       * @static
       *
       * @example
       *
       *     var wordArray = CryptoJS.enc.Utf16.parse(utf16String);
       */
      parse: function (utf16Str) {
        // Shortcut
        var utf16StrLength = utf16Str.length;

        // Convert
        var words = [];
        for (var i = 0; i < utf16StrLength; i++) {
          words[i >>> 1] |= utf16Str.charCodeAt(i) << 16 - i % 2 * 16;
        }
        return WordArray.create(words, utf16StrLength * 2);
      }
    };

    /**
     * UTF-16 LE encoding strategy.
     */
    C_enc.Utf16LE = {
      /**
       * Converts a word array to a UTF-16 LE string.
       *
       * @param {WordArray} wordArray The word array.
       *
       * @return {string} The UTF-16 LE string.
       *
       * @static
       *
       * @example
       *
       *     var utf16Str = CryptoJS.enc.Utf16LE.stringify(wordArray);
       */
      stringify: function (wordArray) {
        // Shortcuts
        var words = wordArray.words;
        var sigBytes = wordArray.sigBytes;

        // Convert
        var utf16Chars = [];
        for (var i = 0; i < sigBytes; i += 2) {
          var codePoint = swapEndian(words[i >>> 2] >>> 16 - i % 4 * 8 & 0xffff);
          utf16Chars.push(String.fromCharCode(codePoint));
        }
        return utf16Chars.join('');
      },
      /**
       * Converts a UTF-16 LE string to a word array.
       *
       * @param {string} utf16Str The UTF-16 LE string.
       *
       * @return {WordArray} The word array.
       *
       * @static
       *
       * @example
       *
       *     var wordArray = CryptoJS.enc.Utf16LE.parse(utf16Str);
       */
      parse: function (utf16Str) {
        // Shortcut
        var utf16StrLength = utf16Str.length;

        // Convert
        var words = [];
        for (var i = 0; i < utf16StrLength; i++) {
          words[i >>> 1] |= swapEndian(utf16Str.charCodeAt(i) << 16 - i % 2 * 16);
        }
        return WordArray.create(words, utf16StrLength * 2);
      }
    };
    function swapEndian(word) {
      return word << 8 & 0xff00ff00 | word >>> 8 & 0x00ff00ff;
    }
  })();
  return CryptoJS.enc.Utf16;
});

/***/ }),

/***/ "./node_modules/crypto-js/evpkdf.js":
/*!******************************************!*\
  !*** ./node_modules/crypto-js/evpkdf.js ***!
  \******************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./sha1 */ "./node_modules/crypto-js/sha1.js"), __webpack_require__(/*! ./hmac */ "./node_modules/crypto-js/hmac.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var Base = C_lib.Base;
    var WordArray = C_lib.WordArray;
    var C_algo = C.algo;
    var MD5 = C_algo.MD5;

    /**
     * This key derivation function is meant to conform with EVP_BytesToKey.
     * www.openssl.org/docs/crypto/EVP_BytesToKey.html
     */
    var EvpKDF = C_algo.EvpKDF = Base.extend({
      /**
       * Configuration options.
       *
       * @property {number} keySize The key size in words to generate. Default: 4 (128 bits)
       * @property {Hasher} hasher The hash algorithm to use. Default: MD5
       * @property {number} iterations The number of iterations to perform. Default: 1
       */
      cfg: Base.extend({
        keySize: 128 / 32,
        hasher: MD5,
        iterations: 1
      }),
      /**
       * Initializes a newly created key derivation function.
       *
       * @param {Object} cfg (Optional) The configuration options to use for the derivation.
       *
       * @example
       *
       *     var kdf = CryptoJS.algo.EvpKDF.create();
       *     var kdf = CryptoJS.algo.EvpKDF.create({ keySize: 8 });
       *     var kdf = CryptoJS.algo.EvpKDF.create({ keySize: 8, iterations: 1000 });
       */
      init: function (cfg) {
        this.cfg = this.cfg.extend(cfg);
      },
      /**
       * Derives a key from a password.
       *
       * @param {WordArray|string} password The password.
       * @param {WordArray|string} salt A salt.
       *
       * @return {WordArray} The derived key.
       *
       * @example
       *
       *     var key = kdf.compute(password, salt);
       */
      compute: function (password, salt) {
        var block;

        // Shortcut
        var cfg = this.cfg;

        // Init hasher
        var hasher = cfg.hasher.create();

        // Initial values
        var derivedKey = WordArray.create();

        // Shortcuts
        var derivedKeyWords = derivedKey.words;
        var keySize = cfg.keySize;
        var iterations = cfg.iterations;

        // Generate key
        while (derivedKeyWords.length < keySize) {
          if (block) {
            hasher.update(block);
          }
          block = hasher.update(password).finalize(salt);
          hasher.reset();

          // Iterations
          for (var i = 1; i < iterations; i++) {
            block = hasher.finalize(block);
            hasher.reset();
          }
          derivedKey.concat(block);
        }
        derivedKey.sigBytes = keySize * 4;
        return derivedKey;
      }
    });

    /**
     * Derives a key from a password.
     *
     * @param {WordArray|string} password The password.
     * @param {WordArray|string} salt A salt.
     * @param {Object} cfg (Optional) The configuration options to use for this computation.
     *
     * @return {WordArray} The derived key.
     *
     * @static
     *
     * @example
     *
     *     var key = CryptoJS.EvpKDF(password, salt);
     *     var key = CryptoJS.EvpKDF(password, salt, { keySize: 8 });
     *     var key = CryptoJS.EvpKDF(password, salt, { keySize: 8, iterations: 1000 });
     */
    C.EvpKDF = function (password, salt, cfg) {
      return EvpKDF.create(cfg).compute(password, salt);
    };
  })();
  return CryptoJS.EvpKDF;
});

/***/ }),

/***/ "./node_modules/crypto-js/format-hex.js":
/*!**********************************************!*\
  !*** ./node_modules/crypto-js/format-hex.js ***!
  \**********************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function (undefined) {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var CipherParams = C_lib.CipherParams;
    var C_enc = C.enc;
    var Hex = C_enc.Hex;
    var C_format = C.format;
    var HexFormatter = C_format.Hex = {
      /**
       * Converts the ciphertext of a cipher params object to a hexadecimally encoded string.
       *
       * @param {CipherParams} cipherParams The cipher params object.
       *
       * @return {string} The hexadecimally encoded string.
       *
       * @static
       *
       * @example
       *
       *     var hexString = CryptoJS.format.Hex.stringify(cipherParams);
       */
      stringify: function (cipherParams) {
        return cipherParams.ciphertext.toString(Hex);
      },
      /**
       * Converts a hexadecimally encoded ciphertext string to a cipher params object.
       *
       * @param {string} input The hexadecimally encoded string.
       *
       * @return {CipherParams} The cipher params object.
       *
       * @static
       *
       * @example
       *
       *     var cipherParams = CryptoJS.format.Hex.parse(hexString);
       */
      parse: function (input) {
        var ciphertext = Hex.parse(input);
        return CipherParams.create({
          ciphertext: ciphertext
        });
      }
    };
  })();
  return CryptoJS.format.Hex;
});

/***/ }),

/***/ "./node_modules/crypto-js/hmac.js":
/*!****************************************!*\
  !*** ./node_modules/crypto-js/hmac.js ***!
  \****************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var Base = C_lib.Base;
    var C_enc = C.enc;
    var Utf8 = C_enc.Utf8;
    var C_algo = C.algo;

    /**
     * HMAC algorithm.
     */
    var HMAC = C_algo.HMAC = Base.extend({
      /**
       * Initializes a newly created HMAC.
       *
       * @param {Hasher} hasher The hash algorithm to use.
       * @param {WordArray|string} key The secret key.
       *
       * @example
       *
       *     var hmacHasher = CryptoJS.algo.HMAC.create(CryptoJS.algo.SHA256, key);
       */
      init: function (hasher, key) {
        // Init hasher
        hasher = this._hasher = new hasher.init();

        // Convert string to WordArray, else assume WordArray already
        if (typeof key == 'string') {
          key = Utf8.parse(key);
        }

        // Shortcuts
        var hasherBlockSize = hasher.blockSize;
        var hasherBlockSizeBytes = hasherBlockSize * 4;

        // Allow arbitrary length keys
        if (key.sigBytes > hasherBlockSizeBytes) {
          key = hasher.finalize(key);
        }

        // Clamp excess bits
        key.clamp();

        // Clone key for inner and outer pads
        var oKey = this._oKey = key.clone();
        var iKey = this._iKey = key.clone();

        // Shortcuts
        var oKeyWords = oKey.words;
        var iKeyWords = iKey.words;

        // XOR keys with pad constants
        for (var i = 0; i < hasherBlockSize; i++) {
          oKeyWords[i] ^= 0x5c5c5c5c;
          iKeyWords[i] ^= 0x36363636;
        }
        oKey.sigBytes = iKey.sigBytes = hasherBlockSizeBytes;

        // Set initial values
        this.reset();
      },
      /**
       * Resets this HMAC to its initial state.
       *
       * @example
       *
       *     hmacHasher.reset();
       */
      reset: function () {
        // Shortcut
        var hasher = this._hasher;

        // Reset
        hasher.reset();
        hasher.update(this._iKey);
      },
      /**
       * Updates this HMAC with a message.
       *
       * @param {WordArray|string} messageUpdate The message to append.
       *
       * @return {HMAC} This HMAC instance.
       *
       * @example
       *
       *     hmacHasher.update('message');
       *     hmacHasher.update(wordArray);
       */
      update: function (messageUpdate) {
        this._hasher.update(messageUpdate);

        // Chainable
        return this;
      },
      /**
       * Finalizes the HMAC computation.
       * Note that the finalize operation is effectively a destructive, read-once operation.
       *
       * @param {WordArray|string} messageUpdate (Optional) A final message update.
       *
       * @return {WordArray} The HMAC.
       *
       * @example
       *
       *     var hmac = hmacHasher.finalize();
       *     var hmac = hmacHasher.finalize('message');
       *     var hmac = hmacHasher.finalize(wordArray);
       */
      finalize: function (messageUpdate) {
        // Shortcut
        var hasher = this._hasher;

        // Compute HMAC
        var innerHash = hasher.finalize(messageUpdate);
        hasher.reset();
        var hmac = hasher.finalize(this._oKey.clone().concat(innerHash));
        return hmac;
      }
    });
  })();
});

/***/ }),

/***/ "./node_modules/crypto-js/index.js":
/*!*****************************************!*\
  !*** ./node_modules/crypto-js/index.js ***!
  \*****************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./x64-core */ "./node_modules/crypto-js/x64-core.js"), __webpack_require__(/*! ./lib-typedarrays */ "./node_modules/crypto-js/lib-typedarrays.js"), __webpack_require__(/*! ./enc-utf16 */ "./node_modules/crypto-js/enc-utf16.js"), __webpack_require__(/*! ./enc-base64 */ "./node_modules/crypto-js/enc-base64.js"), __webpack_require__(/*! ./enc-base64url */ "./node_modules/crypto-js/enc-base64url.js"), __webpack_require__(/*! ./md5 */ "./node_modules/crypto-js/md5.js"), __webpack_require__(/*! ./sha1 */ "./node_modules/crypto-js/sha1.js"), __webpack_require__(/*! ./sha256 */ "./node_modules/crypto-js/sha256.js"), __webpack_require__(/*! ./sha224 */ "./node_modules/crypto-js/sha224.js"), __webpack_require__(/*! ./sha512 */ "./node_modules/crypto-js/sha512.js"), __webpack_require__(/*! ./sha384 */ "./node_modules/crypto-js/sha384.js"), __webpack_require__(/*! ./sha3 */ "./node_modules/crypto-js/sha3.js"), __webpack_require__(/*! ./ripemd160 */ "./node_modules/crypto-js/ripemd160.js"), __webpack_require__(/*! ./hmac */ "./node_modules/crypto-js/hmac.js"), __webpack_require__(/*! ./pbkdf2 */ "./node_modules/crypto-js/pbkdf2.js"), __webpack_require__(/*! ./evpkdf */ "./node_modules/crypto-js/evpkdf.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"), __webpack_require__(/*! ./mode-cfb */ "./node_modules/crypto-js/mode-cfb.js"), __webpack_require__(/*! ./mode-ctr */ "./node_modules/crypto-js/mode-ctr.js"), __webpack_require__(/*! ./mode-ctr-gladman */ "./node_modules/crypto-js/mode-ctr-gladman.js"), __webpack_require__(/*! ./mode-ofb */ "./node_modules/crypto-js/mode-ofb.js"), __webpack_require__(/*! ./mode-ecb */ "./node_modules/crypto-js/mode-ecb.js"), __webpack_require__(/*! ./pad-ansix923 */ "./node_modules/crypto-js/pad-ansix923.js"), __webpack_require__(/*! ./pad-iso10126 */ "./node_modules/crypto-js/pad-iso10126.js"), __webpack_require__(/*! ./pad-iso97971 */ "./node_modules/crypto-js/pad-iso97971.js"), __webpack_require__(/*! ./pad-zeropadding */ "./node_modules/crypto-js/pad-zeropadding.js"), __webpack_require__(/*! ./pad-nopadding */ "./node_modules/crypto-js/pad-nopadding.js"), __webpack_require__(/*! ./format-hex */ "./node_modules/crypto-js/format-hex.js"), __webpack_require__(/*! ./aes */ "./node_modules/crypto-js/aes.js"), __webpack_require__(/*! ./tripledes */ "./node_modules/crypto-js/tripledes.js"), __webpack_require__(/*! ./rc4 */ "./node_modules/crypto-js/rc4.js"), __webpack_require__(/*! ./rabbit */ "./node_modules/crypto-js/rabbit.js"), __webpack_require__(/*! ./rabbit-legacy */ "./node_modules/crypto-js/rabbit-legacy.js"));
  } else {}
})(this, function (CryptoJS) {
  return CryptoJS;
});

/***/ }),

/***/ "./node_modules/crypto-js/lib-typedarrays.js":
/*!***************************************************!*\
  !*** ./node_modules/crypto-js/lib-typedarrays.js ***!
  \***************************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Check if typed arrays are supported
    if (typeof ArrayBuffer != 'function') {
      return;
    }

    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var WordArray = C_lib.WordArray;

    // Reference original init
    var superInit = WordArray.init;

    // Augment WordArray.init to handle typed arrays
    var subInit = WordArray.init = function (typedArray) {
      // Convert buffers to uint8
      if (typedArray instanceof ArrayBuffer) {
        typedArray = new Uint8Array(typedArray);
      }

      // Convert other array views to uint8
      if (typedArray instanceof Int8Array || typeof Uint8ClampedArray !== "undefined" && typedArray instanceof Uint8ClampedArray || typedArray instanceof Int16Array || typedArray instanceof Uint16Array || typedArray instanceof Int32Array || typedArray instanceof Uint32Array || typedArray instanceof Float32Array || typedArray instanceof Float64Array) {
        typedArray = new Uint8Array(typedArray.buffer, typedArray.byteOffset, typedArray.byteLength);
      }

      // Handle Uint8Array
      if (typedArray instanceof Uint8Array) {
        // Shortcut
        var typedArrayByteLength = typedArray.byteLength;

        // Extract bytes
        var words = [];
        for (var i = 0; i < typedArrayByteLength; i++) {
          words[i >>> 2] |= typedArray[i] << 24 - i % 4 * 8;
        }

        // Initialize this word array
        superInit.call(this, words, typedArrayByteLength);
      } else {
        // Else call normal init
        superInit.apply(this, arguments);
      }
    };
    subInit.prototype = WordArray;
  })();
  return CryptoJS.lib.WordArray;
});

/***/ }),

/***/ "./node_modules/crypto-js/md5.js":
/*!***************************************!*\
  !*** ./node_modules/crypto-js/md5.js ***!
  \***************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function (Math) {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var WordArray = C_lib.WordArray;
    var Hasher = C_lib.Hasher;
    var C_algo = C.algo;

    // Constants table
    var T = [];

    // Compute constants
    (function () {
      for (var i = 0; i < 64; i++) {
        T[i] = Math.abs(Math.sin(i + 1)) * 0x100000000 | 0;
      }
    })();

    /**
     * MD5 hash algorithm.
     */
    var MD5 = C_algo.MD5 = Hasher.extend({
      _doReset: function () {
        this._hash = new WordArray.init([0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476]);
      },
      _doProcessBlock: function (M, offset) {
        // Swap endian
        for (var i = 0; i < 16; i++) {
          // Shortcuts
          var offset_i = offset + i;
          var M_offset_i = M[offset_i];
          M[offset_i] = (M_offset_i << 8 | M_offset_i >>> 24) & 0x00ff00ff | (M_offset_i << 24 | M_offset_i >>> 8) & 0xff00ff00;
        }

        // Shortcuts
        var H = this._hash.words;
        var M_offset_0 = M[offset + 0];
        var M_offset_1 = M[offset + 1];
        var M_offset_2 = M[offset + 2];
        var M_offset_3 = M[offset + 3];
        var M_offset_4 = M[offset + 4];
        var M_offset_5 = M[offset + 5];
        var M_offset_6 = M[offset + 6];
        var M_offset_7 = M[offset + 7];
        var M_offset_8 = M[offset + 8];
        var M_offset_9 = M[offset + 9];
        var M_offset_10 = M[offset + 10];
        var M_offset_11 = M[offset + 11];
        var M_offset_12 = M[offset + 12];
        var M_offset_13 = M[offset + 13];
        var M_offset_14 = M[offset + 14];
        var M_offset_15 = M[offset + 15];

        // Working varialbes
        var a = H[0];
        var b = H[1];
        var c = H[2];
        var d = H[3];

        // Computation
        a = FF(a, b, c, d, M_offset_0, 7, T[0]);
        d = FF(d, a, b, c, M_offset_1, 12, T[1]);
        c = FF(c, d, a, b, M_offset_2, 17, T[2]);
        b = FF(b, c, d, a, M_offset_3, 22, T[3]);
        a = FF(a, b, c, d, M_offset_4, 7, T[4]);
        d = FF(d, a, b, c, M_offset_5, 12, T[5]);
        c = FF(c, d, a, b, M_offset_6, 17, T[6]);
        b = FF(b, c, d, a, M_offset_7, 22, T[7]);
        a = FF(a, b, c, d, M_offset_8, 7, T[8]);
        d = FF(d, a, b, c, M_offset_9, 12, T[9]);
        c = FF(c, d, a, b, M_offset_10, 17, T[10]);
        b = FF(b, c, d, a, M_offset_11, 22, T[11]);
        a = FF(a, b, c, d, M_offset_12, 7, T[12]);
        d = FF(d, a, b, c, M_offset_13, 12, T[13]);
        c = FF(c, d, a, b, M_offset_14, 17, T[14]);
        b = FF(b, c, d, a, M_offset_15, 22, T[15]);
        a = GG(a, b, c, d, M_offset_1, 5, T[16]);
        d = GG(d, a, b, c, M_offset_6, 9, T[17]);
        c = GG(c, d, a, b, M_offset_11, 14, T[18]);
        b = GG(b, c, d, a, M_offset_0, 20, T[19]);
        a = GG(a, b, c, d, M_offset_5, 5, T[20]);
        d = GG(d, a, b, c, M_offset_10, 9, T[21]);
        c = GG(c, d, a, b, M_offset_15, 14, T[22]);
        b = GG(b, c, d, a, M_offset_4, 20, T[23]);
        a = GG(a, b, c, d, M_offset_9, 5, T[24]);
        d = GG(d, a, b, c, M_offset_14, 9, T[25]);
        c = GG(c, d, a, b, M_offset_3, 14, T[26]);
        b = GG(b, c, d, a, M_offset_8, 20, T[27]);
        a = GG(a, b, c, d, M_offset_13, 5, T[28]);
        d = GG(d, a, b, c, M_offset_2, 9, T[29]);
        c = GG(c, d, a, b, M_offset_7, 14, T[30]);
        b = GG(b, c, d, a, M_offset_12, 20, T[31]);
        a = HH(a, b, c, d, M_offset_5, 4, T[32]);
        d = HH(d, a, b, c, M_offset_8, 11, T[33]);
        c = HH(c, d, a, b, M_offset_11, 16, T[34]);
        b = HH(b, c, d, a, M_offset_14, 23, T[35]);
        a = HH(a, b, c, d, M_offset_1, 4, T[36]);
        d = HH(d, a, b, c, M_offset_4, 11, T[37]);
        c = HH(c, d, a, b, M_offset_7, 16, T[38]);
        b = HH(b, c, d, a, M_offset_10, 23, T[39]);
        a = HH(a, b, c, d, M_offset_13, 4, T[40]);
        d = HH(d, a, b, c, M_offset_0, 11, T[41]);
        c = HH(c, d, a, b, M_offset_3, 16, T[42]);
        b = HH(b, c, d, a, M_offset_6, 23, T[43]);
        a = HH(a, b, c, d, M_offset_9, 4, T[44]);
        d = HH(d, a, b, c, M_offset_12, 11, T[45]);
        c = HH(c, d, a, b, M_offset_15, 16, T[46]);
        b = HH(b, c, d, a, M_offset_2, 23, T[47]);
        a = II(a, b, c, d, M_offset_0, 6, T[48]);
        d = II(d, a, b, c, M_offset_7, 10, T[49]);
        c = II(c, d, a, b, M_offset_14, 15, T[50]);
        b = II(b, c, d, a, M_offset_5, 21, T[51]);
        a = II(a, b, c, d, M_offset_12, 6, T[52]);
        d = II(d, a, b, c, M_offset_3, 10, T[53]);
        c = II(c, d, a, b, M_offset_10, 15, T[54]);
        b = II(b, c, d, a, M_offset_1, 21, T[55]);
        a = II(a, b, c, d, M_offset_8, 6, T[56]);
        d = II(d, a, b, c, M_offset_15, 10, T[57]);
        c = II(c, d, a, b, M_offset_6, 15, T[58]);
        b = II(b, c, d, a, M_offset_13, 21, T[59]);
        a = II(a, b, c, d, M_offset_4, 6, T[60]);
        d = II(d, a, b, c, M_offset_11, 10, T[61]);
        c = II(c, d, a, b, M_offset_2, 15, T[62]);
        b = II(b, c, d, a, M_offset_9, 21, T[63]);

        // Intermediate hash value
        H[0] = H[0] + a | 0;
        H[1] = H[1] + b | 0;
        H[2] = H[2] + c | 0;
        H[3] = H[3] + d | 0;
      },
      _doFinalize: function () {
        // Shortcuts
        var data = this._data;
        var dataWords = data.words;
        var nBitsTotal = this._nDataBytes * 8;
        var nBitsLeft = data.sigBytes * 8;

        // Add padding
        dataWords[nBitsLeft >>> 5] |= 0x80 << 24 - nBitsLeft % 32;
        var nBitsTotalH = Math.floor(nBitsTotal / 0x100000000);
        var nBitsTotalL = nBitsTotal;
        dataWords[(nBitsLeft + 64 >>> 9 << 4) + 15] = (nBitsTotalH << 8 | nBitsTotalH >>> 24) & 0x00ff00ff | (nBitsTotalH << 24 | nBitsTotalH >>> 8) & 0xff00ff00;
        dataWords[(nBitsLeft + 64 >>> 9 << 4) + 14] = (nBitsTotalL << 8 | nBitsTotalL >>> 24) & 0x00ff00ff | (nBitsTotalL << 24 | nBitsTotalL >>> 8) & 0xff00ff00;
        data.sigBytes = (dataWords.length + 1) * 4;

        // Hash final blocks
        this._process();

        // Shortcuts
        var hash = this._hash;
        var H = hash.words;

        // Swap endian
        for (var i = 0; i < 4; i++) {
          // Shortcut
          var H_i = H[i];
          H[i] = (H_i << 8 | H_i >>> 24) & 0x00ff00ff | (H_i << 24 | H_i >>> 8) & 0xff00ff00;
        }

        // Return final computed hash
        return hash;
      },
      clone: function () {
        var clone = Hasher.clone.call(this);
        clone._hash = this._hash.clone();
        return clone;
      }
    });
    function FF(a, b, c, d, x, s, t) {
      var n = a + (b & c | ~b & d) + x + t;
      return (n << s | n >>> 32 - s) + b;
    }
    function GG(a, b, c, d, x, s, t) {
      var n = a + (b & d | c & ~d) + x + t;
      return (n << s | n >>> 32 - s) + b;
    }
    function HH(a, b, c, d, x, s, t) {
      var n = a + (b ^ c ^ d) + x + t;
      return (n << s | n >>> 32 - s) + b;
    }
    function II(a, b, c, d, x, s, t) {
      var n = a + (c ^ (b | ~d)) + x + t;
      return (n << s | n >>> 32 - s) + b;
    }

    /**
     * Shortcut function to the hasher's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     *
     * @return {WordArray} The hash.
     *
     * @static
     *
     * @example
     *
     *     var hash = CryptoJS.MD5('message');
     *     var hash = CryptoJS.MD5(wordArray);
     */
    C.MD5 = Hasher._createHelper(MD5);

    /**
     * Shortcut function to the HMAC's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     * @param {WordArray|string} key The secret key.
     *
     * @return {WordArray} The HMAC.
     *
     * @static
     *
     * @example
     *
     *     var hmac = CryptoJS.HmacMD5(message, key);
     */
    C.HmacMD5 = Hasher._createHmacHelper(MD5);
  })(Math);
  return CryptoJS.MD5;
});

/***/ }),

/***/ "./node_modules/crypto-js/mode-cfb.js":
/*!********************************************!*\
  !*** ./node_modules/crypto-js/mode-cfb.js ***!
  \********************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  /**
   * Cipher Feedback block mode.
   */
  CryptoJS.mode.CFB = function () {
    var CFB = CryptoJS.lib.BlockCipherMode.extend();
    CFB.Encryptor = CFB.extend({
      processBlock: function (words, offset) {
        // Shortcuts
        var cipher = this._cipher;
        var blockSize = cipher.blockSize;
        generateKeystreamAndEncrypt.call(this, words, offset, blockSize, cipher);

        // Remember this block to use with next block
        this._prevBlock = words.slice(offset, offset + blockSize);
      }
    });
    CFB.Decryptor = CFB.extend({
      processBlock: function (words, offset) {
        // Shortcuts
        var cipher = this._cipher;
        var blockSize = cipher.blockSize;

        // Remember this block to use with next block
        var thisBlock = words.slice(offset, offset + blockSize);
        generateKeystreamAndEncrypt.call(this, words, offset, blockSize, cipher);

        // This block becomes the previous block
        this._prevBlock = thisBlock;
      }
    });
    function generateKeystreamAndEncrypt(words, offset, blockSize, cipher) {
      var keystream;

      // Shortcut
      var iv = this._iv;

      // Generate keystream
      if (iv) {
        keystream = iv.slice(0);

        // Remove IV for subsequent blocks
        this._iv = undefined;
      } else {
        keystream = this._prevBlock;
      }
      cipher.encryptBlock(keystream, 0);

      // Encrypt
      for (var i = 0; i < blockSize; i++) {
        words[offset + i] ^= keystream[i];
      }
    }
    return CFB;
  }();
  return CryptoJS.mode.CFB;
});

/***/ }),

/***/ "./node_modules/crypto-js/mode-ctr-gladman.js":
/*!****************************************************!*\
  !*** ./node_modules/crypto-js/mode-ctr-gladman.js ***!
  \****************************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  /** @preserve
   * Counter block mode compatible with  Dr Brian Gladman fileenc.c
   * derived from CryptoJS.mode.CTR
   * Jan Hruby jhruby.web@gmail.com
   */
  CryptoJS.mode.CTRGladman = function () {
    var CTRGladman = CryptoJS.lib.BlockCipherMode.extend();
    function incWord(word) {
      if ((word >> 24 & 0xff) === 0xff) {
        //overflow
        var b1 = word >> 16 & 0xff;
        var b2 = word >> 8 & 0xff;
        var b3 = word & 0xff;
        if (b1 === 0xff)
          // overflow b1
          {
            b1 = 0;
            if (b2 === 0xff) {
              b2 = 0;
              if (b3 === 0xff) {
                b3 = 0;
              } else {
                ++b3;
              }
            } else {
              ++b2;
            }
          } else {
          ++b1;
        }
        word = 0;
        word += b1 << 16;
        word += b2 << 8;
        word += b3;
      } else {
        word += 0x01 << 24;
      }
      return word;
    }
    function incCounter(counter) {
      if ((counter[0] = incWord(counter[0])) === 0) {
        // encr_data in fileenc.c from  Dr Brian Gladman's counts only with DWORD j < 8
        counter[1] = incWord(counter[1]);
      }
      return counter;
    }
    var Encryptor = CTRGladman.Encryptor = CTRGladman.extend({
      processBlock: function (words, offset) {
        // Shortcuts
        var cipher = this._cipher;
        var blockSize = cipher.blockSize;
        var iv = this._iv;
        var counter = this._counter;

        // Generate keystream
        if (iv) {
          counter = this._counter = iv.slice(0);

          // Remove IV for subsequent blocks
          this._iv = undefined;
        }
        incCounter(counter);
        var keystream = counter.slice(0);
        cipher.encryptBlock(keystream, 0);

        // Encrypt
        for (var i = 0; i < blockSize; i++) {
          words[offset + i] ^= keystream[i];
        }
      }
    });
    CTRGladman.Decryptor = Encryptor;
    return CTRGladman;
  }();
  return CryptoJS.mode.CTRGladman;
});

/***/ }),

/***/ "./node_modules/crypto-js/mode-ctr.js":
/*!********************************************!*\
  !*** ./node_modules/crypto-js/mode-ctr.js ***!
  \********************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  /**
   * Counter block mode.
   */
  CryptoJS.mode.CTR = function () {
    var CTR = CryptoJS.lib.BlockCipherMode.extend();
    var Encryptor = CTR.Encryptor = CTR.extend({
      processBlock: function (words, offset) {
        // Shortcuts
        var cipher = this._cipher;
        var blockSize = cipher.blockSize;
        var iv = this._iv;
        var counter = this._counter;

        // Generate keystream
        if (iv) {
          counter = this._counter = iv.slice(0);

          // Remove IV for subsequent blocks
          this._iv = undefined;
        }
        var keystream = counter.slice(0);
        cipher.encryptBlock(keystream, 0);

        // Increment counter
        counter[blockSize - 1] = counter[blockSize - 1] + 1 | 0;

        // Encrypt
        for (var i = 0; i < blockSize; i++) {
          words[offset + i] ^= keystream[i];
        }
      }
    });
    CTR.Decryptor = Encryptor;
    return CTR;
  }();
  return CryptoJS.mode.CTR;
});

/***/ }),

/***/ "./node_modules/crypto-js/mode-ecb.js":
/*!********************************************!*\
  !*** ./node_modules/crypto-js/mode-ecb.js ***!
  \********************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  /**
   * Electronic Codebook block mode.
   */
  CryptoJS.mode.ECB = function () {
    var ECB = CryptoJS.lib.BlockCipherMode.extend();
    ECB.Encryptor = ECB.extend({
      processBlock: function (words, offset) {
        this._cipher.encryptBlock(words, offset);
      }
    });
    ECB.Decryptor = ECB.extend({
      processBlock: function (words, offset) {
        this._cipher.decryptBlock(words, offset);
      }
    });
    return ECB;
  }();
  return CryptoJS.mode.ECB;
});

/***/ }),

/***/ "./node_modules/crypto-js/mode-ofb.js":
/*!********************************************!*\
  !*** ./node_modules/crypto-js/mode-ofb.js ***!
  \********************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  /**
   * Output Feedback block mode.
   */
  CryptoJS.mode.OFB = function () {
    var OFB = CryptoJS.lib.BlockCipherMode.extend();
    var Encryptor = OFB.Encryptor = OFB.extend({
      processBlock: function (words, offset) {
        // Shortcuts
        var cipher = this._cipher;
        var blockSize = cipher.blockSize;
        var iv = this._iv;
        var keystream = this._keystream;

        // Generate keystream
        if (iv) {
          keystream = this._keystream = iv.slice(0);

          // Remove IV for subsequent blocks
          this._iv = undefined;
        }
        cipher.encryptBlock(keystream, 0);

        // Encrypt
        for (var i = 0; i < blockSize; i++) {
          words[offset + i] ^= keystream[i];
        }
      }
    });
    OFB.Decryptor = Encryptor;
    return OFB;
  }();
  return CryptoJS.mode.OFB;
});

/***/ }),

/***/ "./node_modules/crypto-js/pad-ansix923.js":
/*!************************************************!*\
  !*** ./node_modules/crypto-js/pad-ansix923.js ***!
  \************************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  /**
   * ANSI X.923 padding strategy.
   */
  CryptoJS.pad.AnsiX923 = {
    pad: function (data, blockSize) {
      // Shortcuts
      var dataSigBytes = data.sigBytes;
      var blockSizeBytes = blockSize * 4;

      // Count padding bytes
      var nPaddingBytes = blockSizeBytes - dataSigBytes % blockSizeBytes;

      // Compute last byte position
      var lastBytePos = dataSigBytes + nPaddingBytes - 1;

      // Pad
      data.clamp();
      data.words[lastBytePos >>> 2] |= nPaddingBytes << 24 - lastBytePos % 4 * 8;
      data.sigBytes += nPaddingBytes;
    },
    unpad: function (data) {
      // Get number of padding bytes from last byte
      var nPaddingBytes = data.words[data.sigBytes - 1 >>> 2] & 0xff;

      // Remove padding
      data.sigBytes -= nPaddingBytes;
    }
  };
  return CryptoJS.pad.Ansix923;
});

/***/ }),

/***/ "./node_modules/crypto-js/pad-iso10126.js":
/*!************************************************!*\
  !*** ./node_modules/crypto-js/pad-iso10126.js ***!
  \************************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  /**
   * ISO 10126 padding strategy.
   */
  CryptoJS.pad.Iso10126 = {
    pad: function (data, blockSize) {
      // Shortcut
      var blockSizeBytes = blockSize * 4;

      // Count padding bytes
      var nPaddingBytes = blockSizeBytes - data.sigBytes % blockSizeBytes;

      // Pad
      data.concat(CryptoJS.lib.WordArray.random(nPaddingBytes - 1)).concat(CryptoJS.lib.WordArray.create([nPaddingBytes << 24], 1));
    },
    unpad: function (data) {
      // Get number of padding bytes from last byte
      var nPaddingBytes = data.words[data.sigBytes - 1 >>> 2] & 0xff;

      // Remove padding
      data.sigBytes -= nPaddingBytes;
    }
  };
  return CryptoJS.pad.Iso10126;
});

/***/ }),

/***/ "./node_modules/crypto-js/pad-iso97971.js":
/*!************************************************!*\
  !*** ./node_modules/crypto-js/pad-iso97971.js ***!
  \************************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  /**
   * ISO/IEC 9797-1 Padding Method 2.
   */
  CryptoJS.pad.Iso97971 = {
    pad: function (data, blockSize) {
      // Add 0x80 byte
      data.concat(CryptoJS.lib.WordArray.create([0x80000000], 1));

      // Zero pad the rest
      CryptoJS.pad.ZeroPadding.pad(data, blockSize);
    },
    unpad: function (data) {
      // Remove zero padding
      CryptoJS.pad.ZeroPadding.unpad(data);

      // Remove one more byte -- the 0x80 byte
      data.sigBytes--;
    }
  };
  return CryptoJS.pad.Iso97971;
});

/***/ }),

/***/ "./node_modules/crypto-js/pad-nopadding.js":
/*!*************************************************!*\
  !*** ./node_modules/crypto-js/pad-nopadding.js ***!
  \*************************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  /**
   * A noop padding strategy.
   */
  CryptoJS.pad.NoPadding = {
    pad: function () {},
    unpad: function () {}
  };
  return CryptoJS.pad.NoPadding;
});

/***/ }),

/***/ "./node_modules/crypto-js/pad-zeropadding.js":
/*!***************************************************!*\
  !*** ./node_modules/crypto-js/pad-zeropadding.js ***!
  \***************************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  /**
   * Zero padding strategy.
   */
  CryptoJS.pad.ZeroPadding = {
    pad: function (data, blockSize) {
      // Shortcut
      var blockSizeBytes = blockSize * 4;

      // Pad
      data.clamp();
      data.sigBytes += blockSizeBytes - (data.sigBytes % blockSizeBytes || blockSizeBytes);
    },
    unpad: function (data) {
      // Shortcut
      var dataWords = data.words;

      // Unpad
      var i = data.sigBytes - 1;
      for (var i = data.sigBytes - 1; i >= 0; i--) {
        if (dataWords[i >>> 2] >>> 24 - i % 4 * 8 & 0xff) {
          data.sigBytes = i + 1;
          break;
        }
      }
    }
  };
  return CryptoJS.pad.ZeroPadding;
});

/***/ }),

/***/ "./node_modules/crypto-js/pbkdf2.js":
/*!******************************************!*\
  !*** ./node_modules/crypto-js/pbkdf2.js ***!
  \******************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./sha1 */ "./node_modules/crypto-js/sha1.js"), __webpack_require__(/*! ./hmac */ "./node_modules/crypto-js/hmac.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var Base = C_lib.Base;
    var WordArray = C_lib.WordArray;
    var C_algo = C.algo;
    var SHA1 = C_algo.SHA1;
    var HMAC = C_algo.HMAC;

    /**
     * Password-Based Key Derivation Function 2 algorithm.
     */
    var PBKDF2 = C_algo.PBKDF2 = Base.extend({
      /**
       * Configuration options.
       *
       * @property {number} keySize The key size in words to generate. Default: 4 (128 bits)
       * @property {Hasher} hasher The hasher to use. Default: SHA1
       * @property {number} iterations The number of iterations to perform. Default: 1
       */
      cfg: Base.extend({
        keySize: 128 / 32,
        hasher: SHA1,
        iterations: 1
      }),
      /**
       * Initializes a newly created key derivation function.
       *
       * @param {Object} cfg (Optional) The configuration options to use for the derivation.
       *
       * @example
       *
       *     var kdf = CryptoJS.algo.PBKDF2.create();
       *     var kdf = CryptoJS.algo.PBKDF2.create({ keySize: 8 });
       *     var kdf = CryptoJS.algo.PBKDF2.create({ keySize: 8, iterations: 1000 });
       */
      init: function (cfg) {
        this.cfg = this.cfg.extend(cfg);
      },
      /**
       * Computes the Password-Based Key Derivation Function 2.
       *
       * @param {WordArray|string} password The password.
       * @param {WordArray|string} salt A salt.
       *
       * @return {WordArray} The derived key.
       *
       * @example
       *
       *     var key = kdf.compute(password, salt);
       */
      compute: function (password, salt) {
        // Shortcut
        var cfg = this.cfg;

        // Init HMAC
        var hmac = HMAC.create(cfg.hasher, password);

        // Initial values
        var derivedKey = WordArray.create();
        var blockIndex = WordArray.create([0x00000001]);

        // Shortcuts
        var derivedKeyWords = derivedKey.words;
        var blockIndexWords = blockIndex.words;
        var keySize = cfg.keySize;
        var iterations = cfg.iterations;

        // Generate key
        while (derivedKeyWords.length < keySize) {
          var block = hmac.update(salt).finalize(blockIndex);
          hmac.reset();

          // Shortcuts
          var blockWords = block.words;
          var blockWordsLength = blockWords.length;

          // Iterations
          var intermediate = block;
          for (var i = 1; i < iterations; i++) {
            intermediate = hmac.finalize(intermediate);
            hmac.reset();

            // Shortcut
            var intermediateWords = intermediate.words;

            // XOR intermediate with block
            for (var j = 0; j < blockWordsLength; j++) {
              blockWords[j] ^= intermediateWords[j];
            }
          }
          derivedKey.concat(block);
          blockIndexWords[0]++;
        }
        derivedKey.sigBytes = keySize * 4;
        return derivedKey;
      }
    });

    /**
     * Computes the Password-Based Key Derivation Function 2.
     *
     * @param {WordArray|string} password The password.
     * @param {WordArray|string} salt A salt.
     * @param {Object} cfg (Optional) The configuration options to use for this computation.
     *
     * @return {WordArray} The derived key.
     *
     * @static
     *
     * @example
     *
     *     var key = CryptoJS.PBKDF2(password, salt);
     *     var key = CryptoJS.PBKDF2(password, salt, { keySize: 8 });
     *     var key = CryptoJS.PBKDF2(password, salt, { keySize: 8, iterations: 1000 });
     */
    C.PBKDF2 = function (password, salt, cfg) {
      return PBKDF2.create(cfg).compute(password, salt);
    };
  })();
  return CryptoJS.PBKDF2;
});

/***/ }),

/***/ "./node_modules/crypto-js/rabbit-legacy.js":
/*!*************************************************!*\
  !*** ./node_modules/crypto-js/rabbit-legacy.js ***!
  \*************************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./enc-base64 */ "./node_modules/crypto-js/enc-base64.js"), __webpack_require__(/*! ./md5 */ "./node_modules/crypto-js/md5.js"), __webpack_require__(/*! ./evpkdf */ "./node_modules/crypto-js/evpkdf.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var StreamCipher = C_lib.StreamCipher;
    var C_algo = C.algo;

    // Reusable objects
    var S = [];
    var C_ = [];
    var G = [];

    /**
     * Rabbit stream cipher algorithm.
     *
     * This is a legacy version that neglected to convert the key to little-endian.
     * This error doesn't affect the cipher's security,
     * but it does affect its compatibility with other implementations.
     */
    var RabbitLegacy = C_algo.RabbitLegacy = StreamCipher.extend({
      _doReset: function () {
        // Shortcuts
        var K = this._key.words;
        var iv = this.cfg.iv;

        // Generate initial state values
        var X = this._X = [K[0], K[3] << 16 | K[2] >>> 16, K[1], K[0] << 16 | K[3] >>> 16, K[2], K[1] << 16 | K[0] >>> 16, K[3], K[2] << 16 | K[1] >>> 16];

        // Generate initial counter values
        var C = this._C = [K[2] << 16 | K[2] >>> 16, K[0] & 0xffff0000 | K[1] & 0x0000ffff, K[3] << 16 | K[3] >>> 16, K[1] & 0xffff0000 | K[2] & 0x0000ffff, K[0] << 16 | K[0] >>> 16, K[2] & 0xffff0000 | K[3] & 0x0000ffff, K[1] << 16 | K[1] >>> 16, K[3] & 0xffff0000 | K[0] & 0x0000ffff];

        // Carry bit
        this._b = 0;

        // Iterate the system four times
        for (var i = 0; i < 4; i++) {
          nextState.call(this);
        }

        // Modify the counters
        for (var i = 0; i < 8; i++) {
          C[i] ^= X[i + 4 & 7];
        }

        // IV setup
        if (iv) {
          // Shortcuts
          var IV = iv.words;
          var IV_0 = IV[0];
          var IV_1 = IV[1];

          // Generate four subvectors
          var i0 = (IV_0 << 8 | IV_0 >>> 24) & 0x00ff00ff | (IV_0 << 24 | IV_0 >>> 8) & 0xff00ff00;
          var i2 = (IV_1 << 8 | IV_1 >>> 24) & 0x00ff00ff | (IV_1 << 24 | IV_1 >>> 8) & 0xff00ff00;
          var i1 = i0 >>> 16 | i2 & 0xffff0000;
          var i3 = i2 << 16 | i0 & 0x0000ffff;

          // Modify counter values
          C[0] ^= i0;
          C[1] ^= i1;
          C[2] ^= i2;
          C[3] ^= i3;
          C[4] ^= i0;
          C[5] ^= i1;
          C[6] ^= i2;
          C[7] ^= i3;

          // Iterate the system four times
          for (var i = 0; i < 4; i++) {
            nextState.call(this);
          }
        }
      },
      _doProcessBlock: function (M, offset) {
        // Shortcut
        var X = this._X;

        // Iterate the system
        nextState.call(this);

        // Generate four keystream words
        S[0] = X[0] ^ X[5] >>> 16 ^ X[3] << 16;
        S[1] = X[2] ^ X[7] >>> 16 ^ X[5] << 16;
        S[2] = X[4] ^ X[1] >>> 16 ^ X[7] << 16;
        S[3] = X[6] ^ X[3] >>> 16 ^ X[1] << 16;
        for (var i = 0; i < 4; i++) {
          // Swap endian
          S[i] = (S[i] << 8 | S[i] >>> 24) & 0x00ff00ff | (S[i] << 24 | S[i] >>> 8) & 0xff00ff00;

          // Encrypt
          M[offset + i] ^= S[i];
        }
      },
      blockSize: 128 / 32,
      ivSize: 64 / 32
    });
    function nextState() {
      // Shortcuts
      var X = this._X;
      var C = this._C;

      // Save old counter values
      for (var i = 0; i < 8; i++) {
        C_[i] = C[i];
      }

      // Calculate new counter values
      C[0] = C[0] + 0x4d34d34d + this._b | 0;
      C[1] = C[1] + 0xd34d34d3 + (C[0] >>> 0 < C_[0] >>> 0 ? 1 : 0) | 0;
      C[2] = C[2] + 0x34d34d34 + (C[1] >>> 0 < C_[1] >>> 0 ? 1 : 0) | 0;
      C[3] = C[3] + 0x4d34d34d + (C[2] >>> 0 < C_[2] >>> 0 ? 1 : 0) | 0;
      C[4] = C[4] + 0xd34d34d3 + (C[3] >>> 0 < C_[3] >>> 0 ? 1 : 0) | 0;
      C[5] = C[5] + 0x34d34d34 + (C[4] >>> 0 < C_[4] >>> 0 ? 1 : 0) | 0;
      C[6] = C[6] + 0x4d34d34d + (C[5] >>> 0 < C_[5] >>> 0 ? 1 : 0) | 0;
      C[7] = C[7] + 0xd34d34d3 + (C[6] >>> 0 < C_[6] >>> 0 ? 1 : 0) | 0;
      this._b = C[7] >>> 0 < C_[7] >>> 0 ? 1 : 0;

      // Calculate the g-values
      for (var i = 0; i < 8; i++) {
        var gx = X[i] + C[i];

        // Construct high and low argument for squaring
        var ga = gx & 0xffff;
        var gb = gx >>> 16;

        // Calculate high and low result of squaring
        var gh = ((ga * ga >>> 17) + ga * gb >>> 15) + gb * gb;
        var gl = ((gx & 0xffff0000) * gx | 0) + ((gx & 0x0000ffff) * gx | 0);

        // High XOR low
        G[i] = gh ^ gl;
      }

      // Calculate new state values
      X[0] = G[0] + (G[7] << 16 | G[7] >>> 16) + (G[6] << 16 | G[6] >>> 16) | 0;
      X[1] = G[1] + (G[0] << 8 | G[0] >>> 24) + G[7] | 0;
      X[2] = G[2] + (G[1] << 16 | G[1] >>> 16) + (G[0] << 16 | G[0] >>> 16) | 0;
      X[3] = G[3] + (G[2] << 8 | G[2] >>> 24) + G[1] | 0;
      X[4] = G[4] + (G[3] << 16 | G[3] >>> 16) + (G[2] << 16 | G[2] >>> 16) | 0;
      X[5] = G[5] + (G[4] << 8 | G[4] >>> 24) + G[3] | 0;
      X[6] = G[6] + (G[5] << 16 | G[5] >>> 16) + (G[4] << 16 | G[4] >>> 16) | 0;
      X[7] = G[7] + (G[6] << 8 | G[6] >>> 24) + G[5] | 0;
    }

    /**
     * Shortcut functions to the cipher's object interface.
     *
     * @example
     *
     *     var ciphertext = CryptoJS.RabbitLegacy.encrypt(message, key, cfg);
     *     var plaintext  = CryptoJS.RabbitLegacy.decrypt(ciphertext, key, cfg);
     */
    C.RabbitLegacy = StreamCipher._createHelper(RabbitLegacy);
  })();
  return CryptoJS.RabbitLegacy;
});

/***/ }),

/***/ "./node_modules/crypto-js/rabbit.js":
/*!******************************************!*\
  !*** ./node_modules/crypto-js/rabbit.js ***!
  \******************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./enc-base64 */ "./node_modules/crypto-js/enc-base64.js"), __webpack_require__(/*! ./md5 */ "./node_modules/crypto-js/md5.js"), __webpack_require__(/*! ./evpkdf */ "./node_modules/crypto-js/evpkdf.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var StreamCipher = C_lib.StreamCipher;
    var C_algo = C.algo;

    // Reusable objects
    var S = [];
    var C_ = [];
    var G = [];

    /**
     * Rabbit stream cipher algorithm
     */
    var Rabbit = C_algo.Rabbit = StreamCipher.extend({
      _doReset: function () {
        // Shortcuts
        var K = this._key.words;
        var iv = this.cfg.iv;

        // Swap endian
        for (var i = 0; i < 4; i++) {
          K[i] = (K[i] << 8 | K[i] >>> 24) & 0x00ff00ff | (K[i] << 24 | K[i] >>> 8) & 0xff00ff00;
        }

        // Generate initial state values
        var X = this._X = [K[0], K[3] << 16 | K[2] >>> 16, K[1], K[0] << 16 | K[3] >>> 16, K[2], K[1] << 16 | K[0] >>> 16, K[3], K[2] << 16 | K[1] >>> 16];

        // Generate initial counter values
        var C = this._C = [K[2] << 16 | K[2] >>> 16, K[0] & 0xffff0000 | K[1] & 0x0000ffff, K[3] << 16 | K[3] >>> 16, K[1] & 0xffff0000 | K[2] & 0x0000ffff, K[0] << 16 | K[0] >>> 16, K[2] & 0xffff0000 | K[3] & 0x0000ffff, K[1] << 16 | K[1] >>> 16, K[3] & 0xffff0000 | K[0] & 0x0000ffff];

        // Carry bit
        this._b = 0;

        // Iterate the system four times
        for (var i = 0; i < 4; i++) {
          nextState.call(this);
        }

        // Modify the counters
        for (var i = 0; i < 8; i++) {
          C[i] ^= X[i + 4 & 7];
        }

        // IV setup
        if (iv) {
          // Shortcuts
          var IV = iv.words;
          var IV_0 = IV[0];
          var IV_1 = IV[1];

          // Generate four subvectors
          var i0 = (IV_0 << 8 | IV_0 >>> 24) & 0x00ff00ff | (IV_0 << 24 | IV_0 >>> 8) & 0xff00ff00;
          var i2 = (IV_1 << 8 | IV_1 >>> 24) & 0x00ff00ff | (IV_1 << 24 | IV_1 >>> 8) & 0xff00ff00;
          var i1 = i0 >>> 16 | i2 & 0xffff0000;
          var i3 = i2 << 16 | i0 & 0x0000ffff;

          // Modify counter values
          C[0] ^= i0;
          C[1] ^= i1;
          C[2] ^= i2;
          C[3] ^= i3;
          C[4] ^= i0;
          C[5] ^= i1;
          C[6] ^= i2;
          C[7] ^= i3;

          // Iterate the system four times
          for (var i = 0; i < 4; i++) {
            nextState.call(this);
          }
        }
      },
      _doProcessBlock: function (M, offset) {
        // Shortcut
        var X = this._X;

        // Iterate the system
        nextState.call(this);

        // Generate four keystream words
        S[0] = X[0] ^ X[5] >>> 16 ^ X[3] << 16;
        S[1] = X[2] ^ X[7] >>> 16 ^ X[5] << 16;
        S[2] = X[4] ^ X[1] >>> 16 ^ X[7] << 16;
        S[3] = X[6] ^ X[3] >>> 16 ^ X[1] << 16;
        for (var i = 0; i < 4; i++) {
          // Swap endian
          S[i] = (S[i] << 8 | S[i] >>> 24) & 0x00ff00ff | (S[i] << 24 | S[i] >>> 8) & 0xff00ff00;

          // Encrypt
          M[offset + i] ^= S[i];
        }
      },
      blockSize: 128 / 32,
      ivSize: 64 / 32
    });
    function nextState() {
      // Shortcuts
      var X = this._X;
      var C = this._C;

      // Save old counter values
      for (var i = 0; i < 8; i++) {
        C_[i] = C[i];
      }

      // Calculate new counter values
      C[0] = C[0] + 0x4d34d34d + this._b | 0;
      C[1] = C[1] + 0xd34d34d3 + (C[0] >>> 0 < C_[0] >>> 0 ? 1 : 0) | 0;
      C[2] = C[2] + 0x34d34d34 + (C[1] >>> 0 < C_[1] >>> 0 ? 1 : 0) | 0;
      C[3] = C[3] + 0x4d34d34d + (C[2] >>> 0 < C_[2] >>> 0 ? 1 : 0) | 0;
      C[4] = C[4] + 0xd34d34d3 + (C[3] >>> 0 < C_[3] >>> 0 ? 1 : 0) | 0;
      C[5] = C[5] + 0x34d34d34 + (C[4] >>> 0 < C_[4] >>> 0 ? 1 : 0) | 0;
      C[6] = C[6] + 0x4d34d34d + (C[5] >>> 0 < C_[5] >>> 0 ? 1 : 0) | 0;
      C[7] = C[7] + 0xd34d34d3 + (C[6] >>> 0 < C_[6] >>> 0 ? 1 : 0) | 0;
      this._b = C[7] >>> 0 < C_[7] >>> 0 ? 1 : 0;

      // Calculate the g-values
      for (var i = 0; i < 8; i++) {
        var gx = X[i] + C[i];

        // Construct high and low argument for squaring
        var ga = gx & 0xffff;
        var gb = gx >>> 16;

        // Calculate high and low result of squaring
        var gh = ((ga * ga >>> 17) + ga * gb >>> 15) + gb * gb;
        var gl = ((gx & 0xffff0000) * gx | 0) + ((gx & 0x0000ffff) * gx | 0);

        // High XOR low
        G[i] = gh ^ gl;
      }

      // Calculate new state values
      X[0] = G[0] + (G[7] << 16 | G[7] >>> 16) + (G[6] << 16 | G[6] >>> 16) | 0;
      X[1] = G[1] + (G[0] << 8 | G[0] >>> 24) + G[7] | 0;
      X[2] = G[2] + (G[1] << 16 | G[1] >>> 16) + (G[0] << 16 | G[0] >>> 16) | 0;
      X[3] = G[3] + (G[2] << 8 | G[2] >>> 24) + G[1] | 0;
      X[4] = G[4] + (G[3] << 16 | G[3] >>> 16) + (G[2] << 16 | G[2] >>> 16) | 0;
      X[5] = G[5] + (G[4] << 8 | G[4] >>> 24) + G[3] | 0;
      X[6] = G[6] + (G[5] << 16 | G[5] >>> 16) + (G[4] << 16 | G[4] >>> 16) | 0;
      X[7] = G[7] + (G[6] << 8 | G[6] >>> 24) + G[5] | 0;
    }

    /**
     * Shortcut functions to the cipher's object interface.
     *
     * @example
     *
     *     var ciphertext = CryptoJS.Rabbit.encrypt(message, key, cfg);
     *     var plaintext  = CryptoJS.Rabbit.decrypt(ciphertext, key, cfg);
     */
    C.Rabbit = StreamCipher._createHelper(Rabbit);
  })();
  return CryptoJS.Rabbit;
});

/***/ }),

/***/ "./node_modules/crypto-js/rc4.js":
/*!***************************************!*\
  !*** ./node_modules/crypto-js/rc4.js ***!
  \***************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./enc-base64 */ "./node_modules/crypto-js/enc-base64.js"), __webpack_require__(/*! ./md5 */ "./node_modules/crypto-js/md5.js"), __webpack_require__(/*! ./evpkdf */ "./node_modules/crypto-js/evpkdf.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var StreamCipher = C_lib.StreamCipher;
    var C_algo = C.algo;

    /**
     * RC4 stream cipher algorithm.
     */
    var RC4 = C_algo.RC4 = StreamCipher.extend({
      _doReset: function () {
        // Shortcuts
        var key = this._key;
        var keyWords = key.words;
        var keySigBytes = key.sigBytes;

        // Init sbox
        var S = this._S = [];
        for (var i = 0; i < 256; i++) {
          S[i] = i;
        }

        // Key setup
        for (var i = 0, j = 0; i < 256; i++) {
          var keyByteIndex = i % keySigBytes;
          var keyByte = keyWords[keyByteIndex >>> 2] >>> 24 - keyByteIndex % 4 * 8 & 0xff;
          j = (j + S[i] + keyByte) % 256;

          // Swap
          var t = S[i];
          S[i] = S[j];
          S[j] = t;
        }

        // Counters
        this._i = this._j = 0;
      },
      _doProcessBlock: function (M, offset) {
        M[offset] ^= generateKeystreamWord.call(this);
      },
      keySize: 256 / 32,
      ivSize: 0
    });
    function generateKeystreamWord() {
      // Shortcuts
      var S = this._S;
      var i = this._i;
      var j = this._j;

      // Generate keystream word
      var keystreamWord = 0;
      for (var n = 0; n < 4; n++) {
        i = (i + 1) % 256;
        j = (j + S[i]) % 256;

        // Swap
        var t = S[i];
        S[i] = S[j];
        S[j] = t;
        keystreamWord |= S[(S[i] + S[j]) % 256] << 24 - n * 8;
      }

      // Update counters
      this._i = i;
      this._j = j;
      return keystreamWord;
    }

    /**
     * Shortcut functions to the cipher's object interface.
     *
     * @example
     *
     *     var ciphertext = CryptoJS.RC4.encrypt(message, key, cfg);
     *     var plaintext  = CryptoJS.RC4.decrypt(ciphertext, key, cfg);
     */
    C.RC4 = StreamCipher._createHelper(RC4);

    /**
     * Modified RC4 stream cipher algorithm.
     */
    var RC4Drop = C_algo.RC4Drop = RC4.extend({
      /**
       * Configuration options.
       *
       * @property {number} drop The number of keystream words to drop. Default 192
       */
      cfg: RC4.cfg.extend({
        drop: 192
      }),
      _doReset: function () {
        RC4._doReset.call(this);

        // Drop
        for (var i = this.cfg.drop; i > 0; i--) {
          generateKeystreamWord.call(this);
        }
      }
    });

    /**
     * Shortcut functions to the cipher's object interface.
     *
     * @example
     *
     *     var ciphertext = CryptoJS.RC4Drop.encrypt(message, key, cfg);
     *     var plaintext  = CryptoJS.RC4Drop.decrypt(ciphertext, key, cfg);
     */
    C.RC4Drop = StreamCipher._createHelper(RC4Drop);
  })();
  return CryptoJS.RC4;
});

/***/ }),

/***/ "./node_modules/crypto-js/ripemd160.js":
/*!*********************************************!*\
  !*** ./node_modules/crypto-js/ripemd160.js ***!
  \*********************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"));
  } else {}
})(this, function (CryptoJS) {
  /** @preserve
  (c) 2012 by Cédric Mesnil. All rights reserved.
  	Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
  	    - Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
      - Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
  	THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */

  (function (Math) {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var WordArray = C_lib.WordArray;
    var Hasher = C_lib.Hasher;
    var C_algo = C.algo;

    // Constants table
    var _zl = WordArray.create([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 7, 4, 13, 1, 10, 6, 15, 3, 12, 0, 9, 5, 2, 14, 11, 8, 3, 10, 14, 4, 9, 15, 8, 1, 2, 7, 0, 6, 13, 11, 5, 12, 1, 9, 11, 10, 0, 8, 12, 4, 13, 3, 7, 15, 14, 5, 6, 2, 4, 0, 5, 9, 7, 12, 2, 10, 14, 1, 3, 8, 11, 6, 15, 13]);
    var _zr = WordArray.create([5, 14, 7, 0, 9, 2, 11, 4, 13, 6, 15, 8, 1, 10, 3, 12, 6, 11, 3, 7, 0, 13, 5, 10, 14, 15, 8, 12, 4, 9, 1, 2, 15, 5, 1, 3, 7, 14, 6, 9, 11, 8, 12, 2, 10, 0, 4, 13, 8, 6, 4, 1, 3, 11, 15, 0, 5, 12, 2, 13, 9, 7, 10, 14, 12, 15, 10, 4, 1, 5, 8, 7, 6, 2, 13, 14, 0, 3, 9, 11]);
    var _sl = WordArray.create([11, 14, 15, 12, 5, 8, 7, 9, 11, 13, 14, 15, 6, 7, 9, 8, 7, 6, 8, 13, 11, 9, 7, 15, 7, 12, 15, 9, 11, 7, 13, 12, 11, 13, 6, 7, 14, 9, 13, 15, 14, 8, 13, 6, 5, 12, 7, 5, 11, 12, 14, 15, 14, 15, 9, 8, 9, 14, 5, 6, 8, 6, 5, 12, 9, 15, 5, 11, 6, 8, 13, 12, 5, 12, 13, 14, 11, 8, 5, 6]);
    var _sr = WordArray.create([8, 9, 9, 11, 13, 15, 15, 5, 7, 7, 8, 11, 14, 14, 12, 6, 9, 13, 15, 7, 12, 8, 9, 11, 7, 7, 12, 7, 6, 15, 13, 11, 9, 7, 15, 11, 8, 6, 6, 14, 12, 13, 5, 14, 13, 13, 7, 5, 15, 5, 8, 11, 14, 14, 6, 14, 6, 9, 12, 9, 12, 5, 15, 8, 8, 5, 12, 9, 12, 5, 14, 6, 8, 13, 6, 5, 15, 13, 11, 11]);
    var _hl = WordArray.create([0x00000000, 0x5A827999, 0x6ED9EBA1, 0x8F1BBCDC, 0xA953FD4E]);
    var _hr = WordArray.create([0x50A28BE6, 0x5C4DD124, 0x6D703EF3, 0x7A6D76E9, 0x00000000]);

    /**
     * RIPEMD160 hash algorithm.
     */
    var RIPEMD160 = C_algo.RIPEMD160 = Hasher.extend({
      _doReset: function () {
        this._hash = WordArray.create([0x67452301, 0xEFCDAB89, 0x98BADCFE, 0x10325476, 0xC3D2E1F0]);
      },
      _doProcessBlock: function (M, offset) {
        // Swap endian
        for (var i = 0; i < 16; i++) {
          // Shortcuts
          var offset_i = offset + i;
          var M_offset_i = M[offset_i];

          // Swap
          M[offset_i] = (M_offset_i << 8 | M_offset_i >>> 24) & 0x00ff00ff | (M_offset_i << 24 | M_offset_i >>> 8) & 0xff00ff00;
        }
        // Shortcut
        var H = this._hash.words;
        var hl = _hl.words;
        var hr = _hr.words;
        var zl = _zl.words;
        var zr = _zr.words;
        var sl = _sl.words;
        var sr = _sr.words;

        // Working variables
        var al, bl, cl, dl, el;
        var ar, br, cr, dr, er;
        ar = al = H[0];
        br = bl = H[1];
        cr = cl = H[2];
        dr = dl = H[3];
        er = el = H[4];
        // Computation
        var t;
        for (var i = 0; i < 80; i += 1) {
          t = al + M[offset + zl[i]] | 0;
          if (i < 16) {
            t += f1(bl, cl, dl) + hl[0];
          } else if (i < 32) {
            t += f2(bl, cl, dl) + hl[1];
          } else if (i < 48) {
            t += f3(bl, cl, dl) + hl[2];
          } else if (i < 64) {
            t += f4(bl, cl, dl) + hl[3];
          } else {
            // if (i<80) {
            t += f5(bl, cl, dl) + hl[4];
          }
          t = t | 0;
          t = rotl(t, sl[i]);
          t = t + el | 0;
          al = el;
          el = dl;
          dl = rotl(cl, 10);
          cl = bl;
          bl = t;
          t = ar + M[offset + zr[i]] | 0;
          if (i < 16) {
            t += f5(br, cr, dr) + hr[0];
          } else if (i < 32) {
            t += f4(br, cr, dr) + hr[1];
          } else if (i < 48) {
            t += f3(br, cr, dr) + hr[2];
          } else if (i < 64) {
            t += f2(br, cr, dr) + hr[3];
          } else {
            // if (i<80) {
            t += f1(br, cr, dr) + hr[4];
          }
          t = t | 0;
          t = rotl(t, sr[i]);
          t = t + er | 0;
          ar = er;
          er = dr;
          dr = rotl(cr, 10);
          cr = br;
          br = t;
        }
        // Intermediate hash value
        t = H[1] + cl + dr | 0;
        H[1] = H[2] + dl + er | 0;
        H[2] = H[3] + el + ar | 0;
        H[3] = H[4] + al + br | 0;
        H[4] = H[0] + bl + cr | 0;
        H[0] = t;
      },
      _doFinalize: function () {
        // Shortcuts
        var data = this._data;
        var dataWords = data.words;
        var nBitsTotal = this._nDataBytes * 8;
        var nBitsLeft = data.sigBytes * 8;

        // Add padding
        dataWords[nBitsLeft >>> 5] |= 0x80 << 24 - nBitsLeft % 32;
        dataWords[(nBitsLeft + 64 >>> 9 << 4) + 14] = (nBitsTotal << 8 | nBitsTotal >>> 24) & 0x00ff00ff | (nBitsTotal << 24 | nBitsTotal >>> 8) & 0xff00ff00;
        data.sigBytes = (dataWords.length + 1) * 4;

        // Hash final blocks
        this._process();

        // Shortcuts
        var hash = this._hash;
        var H = hash.words;

        // Swap endian
        for (var i = 0; i < 5; i++) {
          // Shortcut
          var H_i = H[i];

          // Swap
          H[i] = (H_i << 8 | H_i >>> 24) & 0x00ff00ff | (H_i << 24 | H_i >>> 8) & 0xff00ff00;
        }

        // Return final computed hash
        return hash;
      },
      clone: function () {
        var clone = Hasher.clone.call(this);
        clone._hash = this._hash.clone();
        return clone;
      }
    });
    function f1(x, y, z) {
      return x ^ y ^ z;
    }
    function f2(x, y, z) {
      return x & y | ~x & z;
    }
    function f3(x, y, z) {
      return (x | ~y) ^ z;
    }
    function f4(x, y, z) {
      return x & z | y & ~z;
    }
    function f5(x, y, z) {
      return x ^ (y | ~z);
    }
    function rotl(x, n) {
      return x << n | x >>> 32 - n;
    }

    /**
     * Shortcut function to the hasher's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     *
     * @return {WordArray} The hash.
     *
     * @static
     *
     * @example
     *
     *     var hash = CryptoJS.RIPEMD160('message');
     *     var hash = CryptoJS.RIPEMD160(wordArray);
     */
    C.RIPEMD160 = Hasher._createHelper(RIPEMD160);

    /**
     * Shortcut function to the HMAC's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     * @param {WordArray|string} key The secret key.
     *
     * @return {WordArray} The HMAC.
     *
     * @static
     *
     * @example
     *
     *     var hmac = CryptoJS.HmacRIPEMD160(message, key);
     */
    C.HmacRIPEMD160 = Hasher._createHmacHelper(RIPEMD160);
  })(Math);
  return CryptoJS.RIPEMD160;
});

/***/ }),

/***/ "./node_modules/crypto-js/sha1.js":
/*!****************************************!*\
  !*** ./node_modules/crypto-js/sha1.js ***!
  \****************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var WordArray = C_lib.WordArray;
    var Hasher = C_lib.Hasher;
    var C_algo = C.algo;

    // Reusable object
    var W = [];

    /**
     * SHA-1 hash algorithm.
     */
    var SHA1 = C_algo.SHA1 = Hasher.extend({
      _doReset: function () {
        this._hash = new WordArray.init([0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0]);
      },
      _doProcessBlock: function (M, offset) {
        // Shortcut
        var H = this._hash.words;

        // Working variables
        var a = H[0];
        var b = H[1];
        var c = H[2];
        var d = H[3];
        var e = H[4];

        // Computation
        for (var i = 0; i < 80; i++) {
          if (i < 16) {
            W[i] = M[offset + i] | 0;
          } else {
            var n = W[i - 3] ^ W[i - 8] ^ W[i - 14] ^ W[i - 16];
            W[i] = n << 1 | n >>> 31;
          }
          var t = (a << 5 | a >>> 27) + e + W[i];
          if (i < 20) {
            t += (b & c | ~b & d) + 0x5a827999;
          } else if (i < 40) {
            t += (b ^ c ^ d) + 0x6ed9eba1;
          } else if (i < 60) {
            t += (b & c | b & d | c & d) - 0x70e44324;
          } else /* if (i < 80) */{
              t += (b ^ c ^ d) - 0x359d3e2a;
            }
          e = d;
          d = c;
          c = b << 30 | b >>> 2;
          b = a;
          a = t;
        }

        // Intermediate hash value
        H[0] = H[0] + a | 0;
        H[1] = H[1] + b | 0;
        H[2] = H[2] + c | 0;
        H[3] = H[3] + d | 0;
        H[4] = H[4] + e | 0;
      },
      _doFinalize: function () {
        // Shortcuts
        var data = this._data;
        var dataWords = data.words;
        var nBitsTotal = this._nDataBytes * 8;
        var nBitsLeft = data.sigBytes * 8;

        // Add padding
        dataWords[nBitsLeft >>> 5] |= 0x80 << 24 - nBitsLeft % 32;
        dataWords[(nBitsLeft + 64 >>> 9 << 4) + 14] = Math.floor(nBitsTotal / 0x100000000);
        dataWords[(nBitsLeft + 64 >>> 9 << 4) + 15] = nBitsTotal;
        data.sigBytes = dataWords.length * 4;

        // Hash final blocks
        this._process();

        // Return final computed hash
        return this._hash;
      },
      clone: function () {
        var clone = Hasher.clone.call(this);
        clone._hash = this._hash.clone();
        return clone;
      }
    });

    /**
     * Shortcut function to the hasher's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     *
     * @return {WordArray} The hash.
     *
     * @static
     *
     * @example
     *
     *     var hash = CryptoJS.SHA1('message');
     *     var hash = CryptoJS.SHA1(wordArray);
     */
    C.SHA1 = Hasher._createHelper(SHA1);

    /**
     * Shortcut function to the HMAC's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     * @param {WordArray|string} key The secret key.
     *
     * @return {WordArray} The HMAC.
     *
     * @static
     *
     * @example
     *
     *     var hmac = CryptoJS.HmacSHA1(message, key);
     */
    C.HmacSHA1 = Hasher._createHmacHelper(SHA1);
  })();
  return CryptoJS.SHA1;
});

/***/ }),

/***/ "./node_modules/crypto-js/sha224.js":
/*!******************************************!*\
  !*** ./node_modules/crypto-js/sha224.js ***!
  \******************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./sha256 */ "./node_modules/crypto-js/sha256.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var WordArray = C_lib.WordArray;
    var C_algo = C.algo;
    var SHA256 = C_algo.SHA256;

    /**
     * SHA-224 hash algorithm.
     */
    var SHA224 = C_algo.SHA224 = SHA256.extend({
      _doReset: function () {
        this._hash = new WordArray.init([0xc1059ed8, 0x367cd507, 0x3070dd17, 0xf70e5939, 0xffc00b31, 0x68581511, 0x64f98fa7, 0xbefa4fa4]);
      },
      _doFinalize: function () {
        var hash = SHA256._doFinalize.call(this);
        hash.sigBytes -= 4;
        return hash;
      }
    });

    /**
     * Shortcut function to the hasher's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     *
     * @return {WordArray} The hash.
     *
     * @static
     *
     * @example
     *
     *     var hash = CryptoJS.SHA224('message');
     *     var hash = CryptoJS.SHA224(wordArray);
     */
    C.SHA224 = SHA256._createHelper(SHA224);

    /**
     * Shortcut function to the HMAC's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     * @param {WordArray|string} key The secret key.
     *
     * @return {WordArray} The HMAC.
     *
     * @static
     *
     * @example
     *
     *     var hmac = CryptoJS.HmacSHA224(message, key);
     */
    C.HmacSHA224 = SHA256._createHmacHelper(SHA224);
  })();
  return CryptoJS.SHA224;
});

/***/ }),

/***/ "./node_modules/crypto-js/sha256.js":
/*!******************************************!*\
  !*** ./node_modules/crypto-js/sha256.js ***!
  \******************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function (Math) {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var WordArray = C_lib.WordArray;
    var Hasher = C_lib.Hasher;
    var C_algo = C.algo;

    // Initialization and round constants tables
    var H = [];
    var K = [];

    // Compute constants
    (function () {
      function isPrime(n) {
        var sqrtN = Math.sqrt(n);
        for (var factor = 2; factor <= sqrtN; factor++) {
          if (!(n % factor)) {
            return false;
          }
        }
        return true;
      }
      function getFractionalBits(n) {
        return (n - (n | 0)) * 0x100000000 | 0;
      }
      var n = 2;
      var nPrime = 0;
      while (nPrime < 64) {
        if (isPrime(n)) {
          if (nPrime < 8) {
            H[nPrime] = getFractionalBits(Math.pow(n, 1 / 2));
          }
          K[nPrime] = getFractionalBits(Math.pow(n, 1 / 3));
          nPrime++;
        }
        n++;
      }
    })();

    // Reusable object
    var W = [];

    /**
     * SHA-256 hash algorithm.
     */
    var SHA256 = C_algo.SHA256 = Hasher.extend({
      _doReset: function () {
        this._hash = new WordArray.init(H.slice(0));
      },
      _doProcessBlock: function (M, offset) {
        // Shortcut
        var H = this._hash.words;

        // Working variables
        var a = H[0];
        var b = H[1];
        var c = H[2];
        var d = H[3];
        var e = H[4];
        var f = H[5];
        var g = H[6];
        var h = H[7];

        // Computation
        for (var i = 0; i < 64; i++) {
          if (i < 16) {
            W[i] = M[offset + i] | 0;
          } else {
            var gamma0x = W[i - 15];
            var gamma0 = (gamma0x << 25 | gamma0x >>> 7) ^ (gamma0x << 14 | gamma0x >>> 18) ^ gamma0x >>> 3;
            var gamma1x = W[i - 2];
            var gamma1 = (gamma1x << 15 | gamma1x >>> 17) ^ (gamma1x << 13 | gamma1x >>> 19) ^ gamma1x >>> 10;
            W[i] = gamma0 + W[i - 7] + gamma1 + W[i - 16];
          }
          var ch = e & f ^ ~e & g;
          var maj = a & b ^ a & c ^ b & c;
          var sigma0 = (a << 30 | a >>> 2) ^ (a << 19 | a >>> 13) ^ (a << 10 | a >>> 22);
          var sigma1 = (e << 26 | e >>> 6) ^ (e << 21 | e >>> 11) ^ (e << 7 | e >>> 25);
          var t1 = h + sigma1 + ch + K[i] + W[i];
          var t2 = sigma0 + maj;
          h = g;
          g = f;
          f = e;
          e = d + t1 | 0;
          d = c;
          c = b;
          b = a;
          a = t1 + t2 | 0;
        }

        // Intermediate hash value
        H[0] = H[0] + a | 0;
        H[1] = H[1] + b | 0;
        H[2] = H[2] + c | 0;
        H[3] = H[3] + d | 0;
        H[4] = H[4] + e | 0;
        H[5] = H[5] + f | 0;
        H[6] = H[6] + g | 0;
        H[7] = H[7] + h | 0;
      },
      _doFinalize: function () {
        // Shortcuts
        var data = this._data;
        var dataWords = data.words;
        var nBitsTotal = this._nDataBytes * 8;
        var nBitsLeft = data.sigBytes * 8;

        // Add padding
        dataWords[nBitsLeft >>> 5] |= 0x80 << 24 - nBitsLeft % 32;
        dataWords[(nBitsLeft + 64 >>> 9 << 4) + 14] = Math.floor(nBitsTotal / 0x100000000);
        dataWords[(nBitsLeft + 64 >>> 9 << 4) + 15] = nBitsTotal;
        data.sigBytes = dataWords.length * 4;

        // Hash final blocks
        this._process();

        // Return final computed hash
        return this._hash;
      },
      clone: function () {
        var clone = Hasher.clone.call(this);
        clone._hash = this._hash.clone();
        return clone;
      }
    });

    /**
     * Shortcut function to the hasher's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     *
     * @return {WordArray} The hash.
     *
     * @static
     *
     * @example
     *
     *     var hash = CryptoJS.SHA256('message');
     *     var hash = CryptoJS.SHA256(wordArray);
     */
    C.SHA256 = Hasher._createHelper(SHA256);

    /**
     * Shortcut function to the HMAC's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     * @param {WordArray|string} key The secret key.
     *
     * @return {WordArray} The HMAC.
     *
     * @static
     *
     * @example
     *
     *     var hmac = CryptoJS.HmacSHA256(message, key);
     */
    C.HmacSHA256 = Hasher._createHmacHelper(SHA256);
  })(Math);
  return CryptoJS.SHA256;
});

/***/ }),

/***/ "./node_modules/crypto-js/sha3.js":
/*!****************************************!*\
  !*** ./node_modules/crypto-js/sha3.js ***!
  \****************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./x64-core */ "./node_modules/crypto-js/x64-core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function (Math) {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var WordArray = C_lib.WordArray;
    var Hasher = C_lib.Hasher;
    var C_x64 = C.x64;
    var X64Word = C_x64.Word;
    var C_algo = C.algo;

    // Constants tables
    var RHO_OFFSETS = [];
    var PI_INDEXES = [];
    var ROUND_CONSTANTS = [];

    // Compute Constants
    (function () {
      // Compute rho offset constants
      var x = 1,
        y = 0;
      for (var t = 0; t < 24; t++) {
        RHO_OFFSETS[x + 5 * y] = (t + 1) * (t + 2) / 2 % 64;
        var newX = y % 5;
        var newY = (2 * x + 3 * y) % 5;
        x = newX;
        y = newY;
      }

      // Compute pi index constants
      for (var x = 0; x < 5; x++) {
        for (var y = 0; y < 5; y++) {
          PI_INDEXES[x + 5 * y] = y + (2 * x + 3 * y) % 5 * 5;
        }
      }

      // Compute round constants
      var LFSR = 0x01;
      for (var i = 0; i < 24; i++) {
        var roundConstantMsw = 0;
        var roundConstantLsw = 0;
        for (var j = 0; j < 7; j++) {
          if (LFSR & 0x01) {
            var bitPosition = (1 << j) - 1;
            if (bitPosition < 32) {
              roundConstantLsw ^= 1 << bitPosition;
            } else /* if (bitPosition >= 32) */{
                roundConstantMsw ^= 1 << bitPosition - 32;
              }
          }

          // Compute next LFSR
          if (LFSR & 0x80) {
            // Primitive polynomial over GF(2): x^8 + x^6 + x^5 + x^4 + 1
            LFSR = LFSR << 1 ^ 0x71;
          } else {
            LFSR <<= 1;
          }
        }
        ROUND_CONSTANTS[i] = X64Word.create(roundConstantMsw, roundConstantLsw);
      }
    })();

    // Reusable objects for temporary values
    var T = [];
    (function () {
      for (var i = 0; i < 25; i++) {
        T[i] = X64Word.create();
      }
    })();

    /**
     * SHA-3 hash algorithm.
     */
    var SHA3 = C_algo.SHA3 = Hasher.extend({
      /**
       * Configuration options.
       *
       * @property {number} outputLength
       *   The desired number of bits in the output hash.
       *   Only values permitted are: 224, 256, 384, 512.
       *   Default: 512
       */
      cfg: Hasher.cfg.extend({
        outputLength: 512
      }),
      _doReset: function () {
        var state = this._state = [];
        for (var i = 0; i < 25; i++) {
          state[i] = new X64Word.init();
        }
        this.blockSize = (1600 - 2 * this.cfg.outputLength) / 32;
      },
      _doProcessBlock: function (M, offset) {
        // Shortcuts
        var state = this._state;
        var nBlockSizeLanes = this.blockSize / 2;

        // Absorb
        for (var i = 0; i < nBlockSizeLanes; i++) {
          // Shortcuts
          var M2i = M[offset + 2 * i];
          var M2i1 = M[offset + 2 * i + 1];

          // Swap endian
          M2i = (M2i << 8 | M2i >>> 24) & 0x00ff00ff | (M2i << 24 | M2i >>> 8) & 0xff00ff00;
          M2i1 = (M2i1 << 8 | M2i1 >>> 24) & 0x00ff00ff | (M2i1 << 24 | M2i1 >>> 8) & 0xff00ff00;

          // Absorb message into state
          var lane = state[i];
          lane.high ^= M2i1;
          lane.low ^= M2i;
        }

        // Rounds
        for (var round = 0; round < 24; round++) {
          // Theta
          for (var x = 0; x < 5; x++) {
            // Mix column lanes
            var tMsw = 0,
              tLsw = 0;
            for (var y = 0; y < 5; y++) {
              var lane = state[x + 5 * y];
              tMsw ^= lane.high;
              tLsw ^= lane.low;
            }

            // Temporary values
            var Tx = T[x];
            Tx.high = tMsw;
            Tx.low = tLsw;
          }
          for (var x = 0; x < 5; x++) {
            // Shortcuts
            var Tx4 = T[(x + 4) % 5];
            var Tx1 = T[(x + 1) % 5];
            var Tx1Msw = Tx1.high;
            var Tx1Lsw = Tx1.low;

            // Mix surrounding columns
            var tMsw = Tx4.high ^ (Tx1Msw << 1 | Tx1Lsw >>> 31);
            var tLsw = Tx4.low ^ (Tx1Lsw << 1 | Tx1Msw >>> 31);
            for (var y = 0; y < 5; y++) {
              var lane = state[x + 5 * y];
              lane.high ^= tMsw;
              lane.low ^= tLsw;
            }
          }

          // Rho Pi
          for (var laneIndex = 1; laneIndex < 25; laneIndex++) {
            var tMsw;
            var tLsw;

            // Shortcuts
            var lane = state[laneIndex];
            var laneMsw = lane.high;
            var laneLsw = lane.low;
            var rhoOffset = RHO_OFFSETS[laneIndex];

            // Rotate lanes
            if (rhoOffset < 32) {
              tMsw = laneMsw << rhoOffset | laneLsw >>> 32 - rhoOffset;
              tLsw = laneLsw << rhoOffset | laneMsw >>> 32 - rhoOffset;
            } else /* if (rhoOffset >= 32) */{
                tMsw = laneLsw << rhoOffset - 32 | laneMsw >>> 64 - rhoOffset;
                tLsw = laneMsw << rhoOffset - 32 | laneLsw >>> 64 - rhoOffset;
              }

            // Transpose lanes
            var TPiLane = T[PI_INDEXES[laneIndex]];
            TPiLane.high = tMsw;
            TPiLane.low = tLsw;
          }

          // Rho pi at x = y = 0
          var T0 = T[0];
          var state0 = state[0];
          T0.high = state0.high;
          T0.low = state0.low;

          // Chi
          for (var x = 0; x < 5; x++) {
            for (var y = 0; y < 5; y++) {
              // Shortcuts
              var laneIndex = x + 5 * y;
              var lane = state[laneIndex];
              var TLane = T[laneIndex];
              var Tx1Lane = T[(x + 1) % 5 + 5 * y];
              var Tx2Lane = T[(x + 2) % 5 + 5 * y];

              // Mix rows
              lane.high = TLane.high ^ ~Tx1Lane.high & Tx2Lane.high;
              lane.low = TLane.low ^ ~Tx1Lane.low & Tx2Lane.low;
            }
          }

          // Iota
          var lane = state[0];
          var roundConstant = ROUND_CONSTANTS[round];
          lane.high ^= roundConstant.high;
          lane.low ^= roundConstant.low;
        }
      },
      _doFinalize: function () {
        // Shortcuts
        var data = this._data;
        var dataWords = data.words;
        var nBitsTotal = this._nDataBytes * 8;
        var nBitsLeft = data.sigBytes * 8;
        var blockSizeBits = this.blockSize * 32;

        // Add padding
        dataWords[nBitsLeft >>> 5] |= 0x1 << 24 - nBitsLeft % 32;
        dataWords[(Math.ceil((nBitsLeft + 1) / blockSizeBits) * blockSizeBits >>> 5) - 1] |= 0x80;
        data.sigBytes = dataWords.length * 4;

        // Hash final blocks
        this._process();

        // Shortcuts
        var state = this._state;
        var outputLengthBytes = this.cfg.outputLength / 8;
        var outputLengthLanes = outputLengthBytes / 8;

        // Squeeze
        var hashWords = [];
        for (var i = 0; i < outputLengthLanes; i++) {
          // Shortcuts
          var lane = state[i];
          var laneMsw = lane.high;
          var laneLsw = lane.low;

          // Swap endian
          laneMsw = (laneMsw << 8 | laneMsw >>> 24) & 0x00ff00ff | (laneMsw << 24 | laneMsw >>> 8) & 0xff00ff00;
          laneLsw = (laneLsw << 8 | laneLsw >>> 24) & 0x00ff00ff | (laneLsw << 24 | laneLsw >>> 8) & 0xff00ff00;

          // Squeeze state to retrieve hash
          hashWords.push(laneLsw);
          hashWords.push(laneMsw);
        }

        // Return final computed hash
        return new WordArray.init(hashWords, outputLengthBytes);
      },
      clone: function () {
        var clone = Hasher.clone.call(this);
        var state = clone._state = this._state.slice(0);
        for (var i = 0; i < 25; i++) {
          state[i] = state[i].clone();
        }
        return clone;
      }
    });

    /**
     * Shortcut function to the hasher's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     *
     * @return {WordArray} The hash.
     *
     * @static
     *
     * @example
     *
     *     var hash = CryptoJS.SHA3('message');
     *     var hash = CryptoJS.SHA3(wordArray);
     */
    C.SHA3 = Hasher._createHelper(SHA3);

    /**
     * Shortcut function to the HMAC's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     * @param {WordArray|string} key The secret key.
     *
     * @return {WordArray} The HMAC.
     *
     * @static
     *
     * @example
     *
     *     var hmac = CryptoJS.HmacSHA3(message, key);
     */
    C.HmacSHA3 = Hasher._createHmacHelper(SHA3);
  })(Math);
  return CryptoJS.SHA3;
});

/***/ }),

/***/ "./node_modules/crypto-js/sha384.js":
/*!******************************************!*\
  !*** ./node_modules/crypto-js/sha384.js ***!
  \******************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./x64-core */ "./node_modules/crypto-js/x64-core.js"), __webpack_require__(/*! ./sha512 */ "./node_modules/crypto-js/sha512.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_x64 = C.x64;
    var X64Word = C_x64.Word;
    var X64WordArray = C_x64.WordArray;
    var C_algo = C.algo;
    var SHA512 = C_algo.SHA512;

    /**
     * SHA-384 hash algorithm.
     */
    var SHA384 = C_algo.SHA384 = SHA512.extend({
      _doReset: function () {
        this._hash = new X64WordArray.init([new X64Word.init(0xcbbb9d5d, 0xc1059ed8), new X64Word.init(0x629a292a, 0x367cd507), new X64Word.init(0x9159015a, 0x3070dd17), new X64Word.init(0x152fecd8, 0xf70e5939), new X64Word.init(0x67332667, 0xffc00b31), new X64Word.init(0x8eb44a87, 0x68581511), new X64Word.init(0xdb0c2e0d, 0x64f98fa7), new X64Word.init(0x47b5481d, 0xbefa4fa4)]);
      },
      _doFinalize: function () {
        var hash = SHA512._doFinalize.call(this);
        hash.sigBytes -= 16;
        return hash;
      }
    });

    /**
     * Shortcut function to the hasher's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     *
     * @return {WordArray} The hash.
     *
     * @static
     *
     * @example
     *
     *     var hash = CryptoJS.SHA384('message');
     *     var hash = CryptoJS.SHA384(wordArray);
     */
    C.SHA384 = SHA512._createHelper(SHA384);

    /**
     * Shortcut function to the HMAC's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     * @param {WordArray|string} key The secret key.
     *
     * @return {WordArray} The HMAC.
     *
     * @static
     *
     * @example
     *
     *     var hmac = CryptoJS.HmacSHA384(message, key);
     */
    C.HmacSHA384 = SHA512._createHmacHelper(SHA384);
  })();
  return CryptoJS.SHA384;
});

/***/ }),

/***/ "./node_modules/crypto-js/sha512.js":
/*!******************************************!*\
  !*** ./node_modules/crypto-js/sha512.js ***!
  \******************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./x64-core */ "./node_modules/crypto-js/x64-core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var Hasher = C_lib.Hasher;
    var C_x64 = C.x64;
    var X64Word = C_x64.Word;
    var X64WordArray = C_x64.WordArray;
    var C_algo = C.algo;
    function X64Word_create() {
      return X64Word.create.apply(X64Word, arguments);
    }

    // Constants
    var K = [X64Word_create(0x428a2f98, 0xd728ae22), X64Word_create(0x71374491, 0x23ef65cd), X64Word_create(0xb5c0fbcf, 0xec4d3b2f), X64Word_create(0xe9b5dba5, 0x8189dbbc), X64Word_create(0x3956c25b, 0xf348b538), X64Word_create(0x59f111f1, 0xb605d019), X64Word_create(0x923f82a4, 0xaf194f9b), X64Word_create(0xab1c5ed5, 0xda6d8118), X64Word_create(0xd807aa98, 0xa3030242), X64Word_create(0x12835b01, 0x45706fbe), X64Word_create(0x243185be, 0x4ee4b28c), X64Word_create(0x550c7dc3, 0xd5ffb4e2), X64Word_create(0x72be5d74, 0xf27b896f), X64Word_create(0x80deb1fe, 0x3b1696b1), X64Word_create(0x9bdc06a7, 0x25c71235), X64Word_create(0xc19bf174, 0xcf692694), X64Word_create(0xe49b69c1, 0x9ef14ad2), X64Word_create(0xefbe4786, 0x384f25e3), X64Word_create(0x0fc19dc6, 0x8b8cd5b5), X64Word_create(0x240ca1cc, 0x77ac9c65), X64Word_create(0x2de92c6f, 0x592b0275), X64Word_create(0x4a7484aa, 0x6ea6e483), X64Word_create(0x5cb0a9dc, 0xbd41fbd4), X64Word_create(0x76f988da, 0x831153b5), X64Word_create(0x983e5152, 0xee66dfab), X64Word_create(0xa831c66d, 0x2db43210), X64Word_create(0xb00327c8, 0x98fb213f), X64Word_create(0xbf597fc7, 0xbeef0ee4), X64Word_create(0xc6e00bf3, 0x3da88fc2), X64Word_create(0xd5a79147, 0x930aa725), X64Word_create(0x06ca6351, 0xe003826f), X64Word_create(0x14292967, 0x0a0e6e70), X64Word_create(0x27b70a85, 0x46d22ffc), X64Word_create(0x2e1b2138, 0x5c26c926), X64Word_create(0x4d2c6dfc, 0x5ac42aed), X64Word_create(0x53380d13, 0x9d95b3df), X64Word_create(0x650a7354, 0x8baf63de), X64Word_create(0x766a0abb, 0x3c77b2a8), X64Word_create(0x81c2c92e, 0x47edaee6), X64Word_create(0x92722c85, 0x1482353b), X64Word_create(0xa2bfe8a1, 0x4cf10364), X64Word_create(0xa81a664b, 0xbc423001), X64Word_create(0xc24b8b70, 0xd0f89791), X64Word_create(0xc76c51a3, 0x0654be30), X64Word_create(0xd192e819, 0xd6ef5218), X64Word_create(0xd6990624, 0x5565a910), X64Word_create(0xf40e3585, 0x5771202a), X64Word_create(0x106aa070, 0x32bbd1b8), X64Word_create(0x19a4c116, 0xb8d2d0c8), X64Word_create(0x1e376c08, 0x5141ab53), X64Word_create(0x2748774c, 0xdf8eeb99), X64Word_create(0x34b0bcb5, 0xe19b48a8), X64Word_create(0x391c0cb3, 0xc5c95a63), X64Word_create(0x4ed8aa4a, 0xe3418acb), X64Word_create(0x5b9cca4f, 0x7763e373), X64Word_create(0x682e6ff3, 0xd6b2b8a3), X64Word_create(0x748f82ee, 0x5defb2fc), X64Word_create(0x78a5636f, 0x43172f60), X64Word_create(0x84c87814, 0xa1f0ab72), X64Word_create(0x8cc70208, 0x1a6439ec), X64Word_create(0x90befffa, 0x23631e28), X64Word_create(0xa4506ceb, 0xde82bde9), X64Word_create(0xbef9a3f7, 0xb2c67915), X64Word_create(0xc67178f2, 0xe372532b), X64Word_create(0xca273ece, 0xea26619c), X64Word_create(0xd186b8c7, 0x21c0c207), X64Word_create(0xeada7dd6, 0xcde0eb1e), X64Word_create(0xf57d4f7f, 0xee6ed178), X64Word_create(0x06f067aa, 0x72176fba), X64Word_create(0x0a637dc5, 0xa2c898a6), X64Word_create(0x113f9804, 0xbef90dae), X64Word_create(0x1b710b35, 0x131c471b), X64Word_create(0x28db77f5, 0x23047d84), X64Word_create(0x32caab7b, 0x40c72493), X64Word_create(0x3c9ebe0a, 0x15c9bebc), X64Word_create(0x431d67c4, 0x9c100d4c), X64Word_create(0x4cc5d4be, 0xcb3e42b6), X64Word_create(0x597f299c, 0xfc657e2a), X64Word_create(0x5fcb6fab, 0x3ad6faec), X64Word_create(0x6c44198c, 0x4a475817)];

    // Reusable objects
    var W = [];
    (function () {
      for (var i = 0; i < 80; i++) {
        W[i] = X64Word_create();
      }
    })();

    /**
     * SHA-512 hash algorithm.
     */
    var SHA512 = C_algo.SHA512 = Hasher.extend({
      _doReset: function () {
        this._hash = new X64WordArray.init([new X64Word.init(0x6a09e667, 0xf3bcc908), new X64Word.init(0xbb67ae85, 0x84caa73b), new X64Word.init(0x3c6ef372, 0xfe94f82b), new X64Word.init(0xa54ff53a, 0x5f1d36f1), new X64Word.init(0x510e527f, 0xade682d1), new X64Word.init(0x9b05688c, 0x2b3e6c1f), new X64Word.init(0x1f83d9ab, 0xfb41bd6b), new X64Word.init(0x5be0cd19, 0x137e2179)]);
      },
      _doProcessBlock: function (M, offset) {
        // Shortcuts
        var H = this._hash.words;
        var H0 = H[0];
        var H1 = H[1];
        var H2 = H[2];
        var H3 = H[3];
        var H4 = H[4];
        var H5 = H[5];
        var H6 = H[6];
        var H7 = H[7];
        var H0h = H0.high;
        var H0l = H0.low;
        var H1h = H1.high;
        var H1l = H1.low;
        var H2h = H2.high;
        var H2l = H2.low;
        var H3h = H3.high;
        var H3l = H3.low;
        var H4h = H4.high;
        var H4l = H4.low;
        var H5h = H5.high;
        var H5l = H5.low;
        var H6h = H6.high;
        var H6l = H6.low;
        var H7h = H7.high;
        var H7l = H7.low;

        // Working variables
        var ah = H0h;
        var al = H0l;
        var bh = H1h;
        var bl = H1l;
        var ch = H2h;
        var cl = H2l;
        var dh = H3h;
        var dl = H3l;
        var eh = H4h;
        var el = H4l;
        var fh = H5h;
        var fl = H5l;
        var gh = H6h;
        var gl = H6l;
        var hh = H7h;
        var hl = H7l;

        // Rounds
        for (var i = 0; i < 80; i++) {
          var Wil;
          var Wih;

          // Shortcut
          var Wi = W[i];

          // Extend message
          if (i < 16) {
            Wih = Wi.high = M[offset + i * 2] | 0;
            Wil = Wi.low = M[offset + i * 2 + 1] | 0;
          } else {
            // Gamma0
            var gamma0x = W[i - 15];
            var gamma0xh = gamma0x.high;
            var gamma0xl = gamma0x.low;
            var gamma0h = (gamma0xh >>> 1 | gamma0xl << 31) ^ (gamma0xh >>> 8 | gamma0xl << 24) ^ gamma0xh >>> 7;
            var gamma0l = (gamma0xl >>> 1 | gamma0xh << 31) ^ (gamma0xl >>> 8 | gamma0xh << 24) ^ (gamma0xl >>> 7 | gamma0xh << 25);

            // Gamma1
            var gamma1x = W[i - 2];
            var gamma1xh = gamma1x.high;
            var gamma1xl = gamma1x.low;
            var gamma1h = (gamma1xh >>> 19 | gamma1xl << 13) ^ (gamma1xh << 3 | gamma1xl >>> 29) ^ gamma1xh >>> 6;
            var gamma1l = (gamma1xl >>> 19 | gamma1xh << 13) ^ (gamma1xl << 3 | gamma1xh >>> 29) ^ (gamma1xl >>> 6 | gamma1xh << 26);

            // W[i] = gamma0 + W[i - 7] + gamma1 + W[i - 16]
            var Wi7 = W[i - 7];
            var Wi7h = Wi7.high;
            var Wi7l = Wi7.low;
            var Wi16 = W[i - 16];
            var Wi16h = Wi16.high;
            var Wi16l = Wi16.low;
            Wil = gamma0l + Wi7l;
            Wih = gamma0h + Wi7h + (Wil >>> 0 < gamma0l >>> 0 ? 1 : 0);
            Wil = Wil + gamma1l;
            Wih = Wih + gamma1h + (Wil >>> 0 < gamma1l >>> 0 ? 1 : 0);
            Wil = Wil + Wi16l;
            Wih = Wih + Wi16h + (Wil >>> 0 < Wi16l >>> 0 ? 1 : 0);
            Wi.high = Wih;
            Wi.low = Wil;
          }
          var chh = eh & fh ^ ~eh & gh;
          var chl = el & fl ^ ~el & gl;
          var majh = ah & bh ^ ah & ch ^ bh & ch;
          var majl = al & bl ^ al & cl ^ bl & cl;
          var sigma0h = (ah >>> 28 | al << 4) ^ (ah << 30 | al >>> 2) ^ (ah << 25 | al >>> 7);
          var sigma0l = (al >>> 28 | ah << 4) ^ (al << 30 | ah >>> 2) ^ (al << 25 | ah >>> 7);
          var sigma1h = (eh >>> 14 | el << 18) ^ (eh >>> 18 | el << 14) ^ (eh << 23 | el >>> 9);
          var sigma1l = (el >>> 14 | eh << 18) ^ (el >>> 18 | eh << 14) ^ (el << 23 | eh >>> 9);

          // t1 = h + sigma1 + ch + K[i] + W[i]
          var Ki = K[i];
          var Kih = Ki.high;
          var Kil = Ki.low;
          var t1l = hl + sigma1l;
          var t1h = hh + sigma1h + (t1l >>> 0 < hl >>> 0 ? 1 : 0);
          var t1l = t1l + chl;
          var t1h = t1h + chh + (t1l >>> 0 < chl >>> 0 ? 1 : 0);
          var t1l = t1l + Kil;
          var t1h = t1h + Kih + (t1l >>> 0 < Kil >>> 0 ? 1 : 0);
          var t1l = t1l + Wil;
          var t1h = t1h + Wih + (t1l >>> 0 < Wil >>> 0 ? 1 : 0);

          // t2 = sigma0 + maj
          var t2l = sigma0l + majl;
          var t2h = sigma0h + majh + (t2l >>> 0 < sigma0l >>> 0 ? 1 : 0);

          // Update working variables
          hh = gh;
          hl = gl;
          gh = fh;
          gl = fl;
          fh = eh;
          fl = el;
          el = dl + t1l | 0;
          eh = dh + t1h + (el >>> 0 < dl >>> 0 ? 1 : 0) | 0;
          dh = ch;
          dl = cl;
          ch = bh;
          cl = bl;
          bh = ah;
          bl = al;
          al = t1l + t2l | 0;
          ah = t1h + t2h + (al >>> 0 < t1l >>> 0 ? 1 : 0) | 0;
        }

        // Intermediate hash value
        H0l = H0.low = H0l + al;
        H0.high = H0h + ah + (H0l >>> 0 < al >>> 0 ? 1 : 0);
        H1l = H1.low = H1l + bl;
        H1.high = H1h + bh + (H1l >>> 0 < bl >>> 0 ? 1 : 0);
        H2l = H2.low = H2l + cl;
        H2.high = H2h + ch + (H2l >>> 0 < cl >>> 0 ? 1 : 0);
        H3l = H3.low = H3l + dl;
        H3.high = H3h + dh + (H3l >>> 0 < dl >>> 0 ? 1 : 0);
        H4l = H4.low = H4l + el;
        H4.high = H4h + eh + (H4l >>> 0 < el >>> 0 ? 1 : 0);
        H5l = H5.low = H5l + fl;
        H5.high = H5h + fh + (H5l >>> 0 < fl >>> 0 ? 1 : 0);
        H6l = H6.low = H6l + gl;
        H6.high = H6h + gh + (H6l >>> 0 < gl >>> 0 ? 1 : 0);
        H7l = H7.low = H7l + hl;
        H7.high = H7h + hh + (H7l >>> 0 < hl >>> 0 ? 1 : 0);
      },
      _doFinalize: function () {
        // Shortcuts
        var data = this._data;
        var dataWords = data.words;
        var nBitsTotal = this._nDataBytes * 8;
        var nBitsLeft = data.sigBytes * 8;

        // Add padding
        dataWords[nBitsLeft >>> 5] |= 0x80 << 24 - nBitsLeft % 32;
        dataWords[(nBitsLeft + 128 >>> 10 << 5) + 30] = Math.floor(nBitsTotal / 0x100000000);
        dataWords[(nBitsLeft + 128 >>> 10 << 5) + 31] = nBitsTotal;
        data.sigBytes = dataWords.length * 4;

        // Hash final blocks
        this._process();

        // Convert hash to 32-bit word array before returning
        var hash = this._hash.toX32();

        // Return final computed hash
        return hash;
      },
      clone: function () {
        var clone = Hasher.clone.call(this);
        clone._hash = this._hash.clone();
        return clone;
      },
      blockSize: 1024 / 32
    });

    /**
     * Shortcut function to the hasher's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     *
     * @return {WordArray} The hash.
     *
     * @static
     *
     * @example
     *
     *     var hash = CryptoJS.SHA512('message');
     *     var hash = CryptoJS.SHA512(wordArray);
     */
    C.SHA512 = Hasher._createHelper(SHA512);

    /**
     * Shortcut function to the HMAC's object interface.
     *
     * @param {WordArray|string} message The message to hash.
     * @param {WordArray|string} key The secret key.
     *
     * @return {WordArray} The HMAC.
     *
     * @static
     *
     * @example
     *
     *     var hmac = CryptoJS.HmacSHA512(message, key);
     */
    C.HmacSHA512 = Hasher._createHmacHelper(SHA512);
  })();
  return CryptoJS.SHA512;
});

/***/ }),

/***/ "./node_modules/crypto-js/tripledes.js":
/*!*********************************************!*\
  !*** ./node_modules/crypto-js/tripledes.js ***!
  \*********************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory, undef) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"), __webpack_require__(/*! ./enc-base64 */ "./node_modules/crypto-js/enc-base64.js"), __webpack_require__(/*! ./md5 */ "./node_modules/crypto-js/md5.js"), __webpack_require__(/*! ./evpkdf */ "./node_modules/crypto-js/evpkdf.js"), __webpack_require__(/*! ./cipher-core */ "./node_modules/crypto-js/cipher-core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function () {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var WordArray = C_lib.WordArray;
    var BlockCipher = C_lib.BlockCipher;
    var C_algo = C.algo;

    // Permuted Choice 1 constants
    var PC1 = [57, 49, 41, 33, 25, 17, 9, 1, 58, 50, 42, 34, 26, 18, 10, 2, 59, 51, 43, 35, 27, 19, 11, 3, 60, 52, 44, 36, 63, 55, 47, 39, 31, 23, 15, 7, 62, 54, 46, 38, 30, 22, 14, 6, 61, 53, 45, 37, 29, 21, 13, 5, 28, 20, 12, 4];

    // Permuted Choice 2 constants
    var PC2 = [14, 17, 11, 24, 1, 5, 3, 28, 15, 6, 21, 10, 23, 19, 12, 4, 26, 8, 16, 7, 27, 20, 13, 2, 41, 52, 31, 37, 47, 55, 30, 40, 51, 45, 33, 48, 44, 49, 39, 56, 34, 53, 46, 42, 50, 36, 29, 32];

    // Cumulative bit shift constants
    var BIT_SHIFTS = [1, 2, 4, 6, 8, 10, 12, 14, 15, 17, 19, 21, 23, 25, 27, 28];

    // SBOXes and round permutation constants
    var SBOX_P = [{
      0x0: 0x808200,
      0x10000000: 0x8000,
      0x20000000: 0x808002,
      0x30000000: 0x2,
      0x40000000: 0x200,
      0x50000000: 0x808202,
      0x60000000: 0x800202,
      0x70000000: 0x800000,
      0x80000000: 0x202,
      0x90000000: 0x800200,
      0xa0000000: 0x8200,
      0xb0000000: 0x808000,
      0xc0000000: 0x8002,
      0xd0000000: 0x800002,
      0xe0000000: 0x0,
      0xf0000000: 0x8202,
      0x8000000: 0x0,
      0x18000000: 0x808202,
      0x28000000: 0x8202,
      0x38000000: 0x8000,
      0x48000000: 0x808200,
      0x58000000: 0x200,
      0x68000000: 0x808002,
      0x78000000: 0x2,
      0x88000000: 0x800200,
      0x98000000: 0x8200,
      0xa8000000: 0x808000,
      0xb8000000: 0x800202,
      0xc8000000: 0x800002,
      0xd8000000: 0x8002,
      0xe8000000: 0x202,
      0xf8000000: 0x800000,
      0x1: 0x8000,
      0x10000001: 0x2,
      0x20000001: 0x808200,
      0x30000001: 0x800000,
      0x40000001: 0x808002,
      0x50000001: 0x8200,
      0x60000001: 0x200,
      0x70000001: 0x800202,
      0x80000001: 0x808202,
      0x90000001: 0x808000,
      0xa0000001: 0x800002,
      0xb0000001: 0x8202,
      0xc0000001: 0x202,
      0xd0000001: 0x800200,
      0xe0000001: 0x8002,
      0xf0000001: 0x0,
      0x8000001: 0x808202,
      0x18000001: 0x808000,
      0x28000001: 0x800000,
      0x38000001: 0x200,
      0x48000001: 0x8000,
      0x58000001: 0x800002,
      0x68000001: 0x2,
      0x78000001: 0x8202,
      0x88000001: 0x8002,
      0x98000001: 0x800202,
      0xa8000001: 0x202,
      0xb8000001: 0x808200,
      0xc8000001: 0x800200,
      0xd8000001: 0x0,
      0xe8000001: 0x8200,
      0xf8000001: 0x808002
    }, {
      0x0: 0x40084010,
      0x1000000: 0x4000,
      0x2000000: 0x80000,
      0x3000000: 0x40080010,
      0x4000000: 0x40000010,
      0x5000000: 0x40084000,
      0x6000000: 0x40004000,
      0x7000000: 0x10,
      0x8000000: 0x84000,
      0x9000000: 0x40004010,
      0xa000000: 0x40000000,
      0xb000000: 0x84010,
      0xc000000: 0x80010,
      0xd000000: 0x0,
      0xe000000: 0x4010,
      0xf000000: 0x40080000,
      0x800000: 0x40004000,
      0x1800000: 0x84010,
      0x2800000: 0x10,
      0x3800000: 0x40004010,
      0x4800000: 0x40084010,
      0x5800000: 0x40000000,
      0x6800000: 0x80000,
      0x7800000: 0x40080010,
      0x8800000: 0x80010,
      0x9800000: 0x0,
      0xa800000: 0x4000,
      0xb800000: 0x40080000,
      0xc800000: 0x40000010,
      0xd800000: 0x84000,
      0xe800000: 0x40084000,
      0xf800000: 0x4010,
      0x10000000: 0x0,
      0x11000000: 0x40080010,
      0x12000000: 0x40004010,
      0x13000000: 0x40084000,
      0x14000000: 0x40080000,
      0x15000000: 0x10,
      0x16000000: 0x84010,
      0x17000000: 0x4000,
      0x18000000: 0x4010,
      0x19000000: 0x80000,
      0x1a000000: 0x80010,
      0x1b000000: 0x40000010,
      0x1c000000: 0x84000,
      0x1d000000: 0x40004000,
      0x1e000000: 0x40000000,
      0x1f000000: 0x40084010,
      0x10800000: 0x84010,
      0x11800000: 0x80000,
      0x12800000: 0x40080000,
      0x13800000: 0x4000,
      0x14800000: 0x40004000,
      0x15800000: 0x40084010,
      0x16800000: 0x10,
      0x17800000: 0x40000000,
      0x18800000: 0x40084000,
      0x19800000: 0x40000010,
      0x1a800000: 0x40004010,
      0x1b800000: 0x80010,
      0x1c800000: 0x0,
      0x1d800000: 0x4010,
      0x1e800000: 0x40080010,
      0x1f800000: 0x84000
    }, {
      0x0: 0x104,
      0x100000: 0x0,
      0x200000: 0x4000100,
      0x300000: 0x10104,
      0x400000: 0x10004,
      0x500000: 0x4000004,
      0x600000: 0x4010104,
      0x700000: 0x4010000,
      0x800000: 0x4000000,
      0x900000: 0x4010100,
      0xa00000: 0x10100,
      0xb00000: 0x4010004,
      0xc00000: 0x4000104,
      0xd00000: 0x10000,
      0xe00000: 0x4,
      0xf00000: 0x100,
      0x80000: 0x4010100,
      0x180000: 0x4010004,
      0x280000: 0x0,
      0x380000: 0x4000100,
      0x480000: 0x4000004,
      0x580000: 0x10000,
      0x680000: 0x10004,
      0x780000: 0x104,
      0x880000: 0x4,
      0x980000: 0x100,
      0xa80000: 0x4010000,
      0xb80000: 0x10104,
      0xc80000: 0x10100,
      0xd80000: 0x4000104,
      0xe80000: 0x4010104,
      0xf80000: 0x4000000,
      0x1000000: 0x4010100,
      0x1100000: 0x10004,
      0x1200000: 0x10000,
      0x1300000: 0x4000100,
      0x1400000: 0x100,
      0x1500000: 0x4010104,
      0x1600000: 0x4000004,
      0x1700000: 0x0,
      0x1800000: 0x4000104,
      0x1900000: 0x4000000,
      0x1a00000: 0x4,
      0x1b00000: 0x10100,
      0x1c00000: 0x4010000,
      0x1d00000: 0x104,
      0x1e00000: 0x10104,
      0x1f00000: 0x4010004,
      0x1080000: 0x4000000,
      0x1180000: 0x104,
      0x1280000: 0x4010100,
      0x1380000: 0x0,
      0x1480000: 0x10004,
      0x1580000: 0x4000100,
      0x1680000: 0x100,
      0x1780000: 0x4010004,
      0x1880000: 0x10000,
      0x1980000: 0x4010104,
      0x1a80000: 0x10104,
      0x1b80000: 0x4000004,
      0x1c80000: 0x4000104,
      0x1d80000: 0x4010000,
      0x1e80000: 0x4,
      0x1f80000: 0x10100
    }, {
      0x0: 0x80401000,
      0x10000: 0x80001040,
      0x20000: 0x401040,
      0x30000: 0x80400000,
      0x40000: 0x0,
      0x50000: 0x401000,
      0x60000: 0x80000040,
      0x70000: 0x400040,
      0x80000: 0x80000000,
      0x90000: 0x400000,
      0xa0000: 0x40,
      0xb0000: 0x80001000,
      0xc0000: 0x80400040,
      0xd0000: 0x1040,
      0xe0000: 0x1000,
      0xf0000: 0x80401040,
      0x8000: 0x80001040,
      0x18000: 0x40,
      0x28000: 0x80400040,
      0x38000: 0x80001000,
      0x48000: 0x401000,
      0x58000: 0x80401040,
      0x68000: 0x0,
      0x78000: 0x80400000,
      0x88000: 0x1000,
      0x98000: 0x80401000,
      0xa8000: 0x400000,
      0xb8000: 0x1040,
      0xc8000: 0x80000000,
      0xd8000: 0x400040,
      0xe8000: 0x401040,
      0xf8000: 0x80000040,
      0x100000: 0x400040,
      0x110000: 0x401000,
      0x120000: 0x80000040,
      0x130000: 0x0,
      0x140000: 0x1040,
      0x150000: 0x80400040,
      0x160000: 0x80401000,
      0x170000: 0x80001040,
      0x180000: 0x80401040,
      0x190000: 0x80000000,
      0x1a0000: 0x80400000,
      0x1b0000: 0x401040,
      0x1c0000: 0x80001000,
      0x1d0000: 0x400000,
      0x1e0000: 0x40,
      0x1f0000: 0x1000,
      0x108000: 0x80400000,
      0x118000: 0x80401040,
      0x128000: 0x0,
      0x138000: 0x401000,
      0x148000: 0x400040,
      0x158000: 0x80000000,
      0x168000: 0x80001040,
      0x178000: 0x40,
      0x188000: 0x80000040,
      0x198000: 0x1000,
      0x1a8000: 0x80001000,
      0x1b8000: 0x80400040,
      0x1c8000: 0x1040,
      0x1d8000: 0x80401000,
      0x1e8000: 0x400000,
      0x1f8000: 0x401040
    }, {
      0x0: 0x80,
      0x1000: 0x1040000,
      0x2000: 0x40000,
      0x3000: 0x20000000,
      0x4000: 0x20040080,
      0x5000: 0x1000080,
      0x6000: 0x21000080,
      0x7000: 0x40080,
      0x8000: 0x1000000,
      0x9000: 0x20040000,
      0xa000: 0x20000080,
      0xb000: 0x21040080,
      0xc000: 0x21040000,
      0xd000: 0x0,
      0xe000: 0x1040080,
      0xf000: 0x21000000,
      0x800: 0x1040080,
      0x1800: 0x21000080,
      0x2800: 0x80,
      0x3800: 0x1040000,
      0x4800: 0x40000,
      0x5800: 0x20040080,
      0x6800: 0x21040000,
      0x7800: 0x20000000,
      0x8800: 0x20040000,
      0x9800: 0x0,
      0xa800: 0x21040080,
      0xb800: 0x1000080,
      0xc800: 0x20000080,
      0xd800: 0x21000000,
      0xe800: 0x1000000,
      0xf800: 0x40080,
      0x10000: 0x40000,
      0x11000: 0x80,
      0x12000: 0x20000000,
      0x13000: 0x21000080,
      0x14000: 0x1000080,
      0x15000: 0x21040000,
      0x16000: 0x20040080,
      0x17000: 0x1000000,
      0x18000: 0x21040080,
      0x19000: 0x21000000,
      0x1a000: 0x1040000,
      0x1b000: 0x20040000,
      0x1c000: 0x40080,
      0x1d000: 0x20000080,
      0x1e000: 0x0,
      0x1f000: 0x1040080,
      0x10800: 0x21000080,
      0x11800: 0x1000000,
      0x12800: 0x1040000,
      0x13800: 0x20040080,
      0x14800: 0x20000000,
      0x15800: 0x1040080,
      0x16800: 0x80,
      0x17800: 0x21040000,
      0x18800: 0x40080,
      0x19800: 0x21040080,
      0x1a800: 0x0,
      0x1b800: 0x21000000,
      0x1c800: 0x1000080,
      0x1d800: 0x40000,
      0x1e800: 0x20040000,
      0x1f800: 0x20000080
    }, {
      0x0: 0x10000008,
      0x100: 0x2000,
      0x200: 0x10200000,
      0x300: 0x10202008,
      0x400: 0x10002000,
      0x500: 0x200000,
      0x600: 0x200008,
      0x700: 0x10000000,
      0x800: 0x0,
      0x900: 0x10002008,
      0xa00: 0x202000,
      0xb00: 0x8,
      0xc00: 0x10200008,
      0xd00: 0x202008,
      0xe00: 0x2008,
      0xf00: 0x10202000,
      0x80: 0x10200000,
      0x180: 0x10202008,
      0x280: 0x8,
      0x380: 0x200000,
      0x480: 0x202008,
      0x580: 0x10000008,
      0x680: 0x10002000,
      0x780: 0x2008,
      0x880: 0x200008,
      0x980: 0x2000,
      0xa80: 0x10002008,
      0xb80: 0x10200008,
      0xc80: 0x0,
      0xd80: 0x10202000,
      0xe80: 0x202000,
      0xf80: 0x10000000,
      0x1000: 0x10002000,
      0x1100: 0x10200008,
      0x1200: 0x10202008,
      0x1300: 0x2008,
      0x1400: 0x200000,
      0x1500: 0x10000000,
      0x1600: 0x10000008,
      0x1700: 0x202000,
      0x1800: 0x202008,
      0x1900: 0x0,
      0x1a00: 0x8,
      0x1b00: 0x10200000,
      0x1c00: 0x2000,
      0x1d00: 0x10002008,
      0x1e00: 0x10202000,
      0x1f00: 0x200008,
      0x1080: 0x8,
      0x1180: 0x202000,
      0x1280: 0x200000,
      0x1380: 0x10000008,
      0x1480: 0x10002000,
      0x1580: 0x2008,
      0x1680: 0x10202008,
      0x1780: 0x10200000,
      0x1880: 0x10202000,
      0x1980: 0x10200008,
      0x1a80: 0x2000,
      0x1b80: 0x202008,
      0x1c80: 0x200008,
      0x1d80: 0x0,
      0x1e80: 0x10000000,
      0x1f80: 0x10002008
    }, {
      0x0: 0x100000,
      0x10: 0x2000401,
      0x20: 0x400,
      0x30: 0x100401,
      0x40: 0x2100401,
      0x50: 0x0,
      0x60: 0x1,
      0x70: 0x2100001,
      0x80: 0x2000400,
      0x90: 0x100001,
      0xa0: 0x2000001,
      0xb0: 0x2100400,
      0xc0: 0x2100000,
      0xd0: 0x401,
      0xe0: 0x100400,
      0xf0: 0x2000000,
      0x8: 0x2100001,
      0x18: 0x0,
      0x28: 0x2000401,
      0x38: 0x2100400,
      0x48: 0x100000,
      0x58: 0x2000001,
      0x68: 0x2000000,
      0x78: 0x401,
      0x88: 0x100401,
      0x98: 0x2000400,
      0xa8: 0x2100000,
      0xb8: 0x100001,
      0xc8: 0x400,
      0xd8: 0x2100401,
      0xe8: 0x1,
      0xf8: 0x100400,
      0x100: 0x2000000,
      0x110: 0x100000,
      0x120: 0x2000401,
      0x130: 0x2100001,
      0x140: 0x100001,
      0x150: 0x2000400,
      0x160: 0x2100400,
      0x170: 0x100401,
      0x180: 0x401,
      0x190: 0x2100401,
      0x1a0: 0x100400,
      0x1b0: 0x1,
      0x1c0: 0x0,
      0x1d0: 0x2100000,
      0x1e0: 0x2000001,
      0x1f0: 0x400,
      0x108: 0x100400,
      0x118: 0x2000401,
      0x128: 0x2100001,
      0x138: 0x1,
      0x148: 0x2000000,
      0x158: 0x100000,
      0x168: 0x401,
      0x178: 0x2100400,
      0x188: 0x2000001,
      0x198: 0x2100000,
      0x1a8: 0x0,
      0x1b8: 0x2100401,
      0x1c8: 0x100401,
      0x1d8: 0x400,
      0x1e8: 0x2000400,
      0x1f8: 0x100001
    }, {
      0x0: 0x8000820,
      0x1: 0x20000,
      0x2: 0x8000000,
      0x3: 0x20,
      0x4: 0x20020,
      0x5: 0x8020820,
      0x6: 0x8020800,
      0x7: 0x800,
      0x8: 0x8020000,
      0x9: 0x8000800,
      0xa: 0x20800,
      0xb: 0x8020020,
      0xc: 0x820,
      0xd: 0x0,
      0xe: 0x8000020,
      0xf: 0x20820,
      0x80000000: 0x800,
      0x80000001: 0x8020820,
      0x80000002: 0x8000820,
      0x80000003: 0x8000000,
      0x80000004: 0x8020000,
      0x80000005: 0x20800,
      0x80000006: 0x20820,
      0x80000007: 0x20,
      0x80000008: 0x8000020,
      0x80000009: 0x820,
      0x8000000a: 0x20020,
      0x8000000b: 0x8020800,
      0x8000000c: 0x0,
      0x8000000d: 0x8020020,
      0x8000000e: 0x8000800,
      0x8000000f: 0x20000,
      0x10: 0x20820,
      0x11: 0x8020800,
      0x12: 0x20,
      0x13: 0x800,
      0x14: 0x8000800,
      0x15: 0x8000020,
      0x16: 0x8020020,
      0x17: 0x20000,
      0x18: 0x0,
      0x19: 0x20020,
      0x1a: 0x8020000,
      0x1b: 0x8000820,
      0x1c: 0x8020820,
      0x1d: 0x20800,
      0x1e: 0x820,
      0x1f: 0x8000000,
      0x80000010: 0x20000,
      0x80000011: 0x800,
      0x80000012: 0x8020020,
      0x80000013: 0x20820,
      0x80000014: 0x20,
      0x80000015: 0x8020000,
      0x80000016: 0x8000000,
      0x80000017: 0x8000820,
      0x80000018: 0x8020820,
      0x80000019: 0x8000020,
      0x8000001a: 0x8000800,
      0x8000001b: 0x0,
      0x8000001c: 0x20800,
      0x8000001d: 0x820,
      0x8000001e: 0x20020,
      0x8000001f: 0x8020800
    }];

    // Masks that select the SBOX input
    var SBOX_MASK = [0xf8000001, 0x1f800000, 0x01f80000, 0x001f8000, 0x0001f800, 0x00001f80, 0x000001f8, 0x8000001f];

    /**
     * DES block cipher algorithm.
     */
    var DES = C_algo.DES = BlockCipher.extend({
      _doReset: function () {
        // Shortcuts
        var key = this._key;
        var keyWords = key.words;

        // Select 56 bits according to PC1
        var keyBits = [];
        for (var i = 0; i < 56; i++) {
          var keyBitPos = PC1[i] - 1;
          keyBits[i] = keyWords[keyBitPos >>> 5] >>> 31 - keyBitPos % 32 & 1;
        }

        // Assemble 16 subkeys
        var subKeys = this._subKeys = [];
        for (var nSubKey = 0; nSubKey < 16; nSubKey++) {
          // Create subkey
          var subKey = subKeys[nSubKey] = [];

          // Shortcut
          var bitShift = BIT_SHIFTS[nSubKey];

          // Select 48 bits according to PC2
          for (var i = 0; i < 24; i++) {
            // Select from the left 28 key bits
            subKey[i / 6 | 0] |= keyBits[(PC2[i] - 1 + bitShift) % 28] << 31 - i % 6;

            // Select from the right 28 key bits
            subKey[4 + (i / 6 | 0)] |= keyBits[28 + (PC2[i + 24] - 1 + bitShift) % 28] << 31 - i % 6;
          }

          // Since each subkey is applied to an expanded 32-bit input,
          // the subkey can be broken into 8 values scaled to 32-bits,
          // which allows the key to be used without expansion
          subKey[0] = subKey[0] << 1 | subKey[0] >>> 31;
          for (var i = 1; i < 7; i++) {
            subKey[i] = subKey[i] >>> (i - 1) * 4 + 3;
          }
          subKey[7] = subKey[7] << 5 | subKey[7] >>> 27;
        }

        // Compute inverse subkeys
        var invSubKeys = this._invSubKeys = [];
        for (var i = 0; i < 16; i++) {
          invSubKeys[i] = subKeys[15 - i];
        }
      },
      encryptBlock: function (M, offset) {
        this._doCryptBlock(M, offset, this._subKeys);
      },
      decryptBlock: function (M, offset) {
        this._doCryptBlock(M, offset, this._invSubKeys);
      },
      _doCryptBlock: function (M, offset, subKeys) {
        // Get input
        this._lBlock = M[offset];
        this._rBlock = M[offset + 1];

        // Initial permutation
        exchangeLR.call(this, 4, 0x0f0f0f0f);
        exchangeLR.call(this, 16, 0x0000ffff);
        exchangeRL.call(this, 2, 0x33333333);
        exchangeRL.call(this, 8, 0x00ff00ff);
        exchangeLR.call(this, 1, 0x55555555);

        // Rounds
        for (var round = 0; round < 16; round++) {
          // Shortcuts
          var subKey = subKeys[round];
          var lBlock = this._lBlock;
          var rBlock = this._rBlock;

          // Feistel function
          var f = 0;
          for (var i = 0; i < 8; i++) {
            f |= SBOX_P[i][((rBlock ^ subKey[i]) & SBOX_MASK[i]) >>> 0];
          }
          this._lBlock = rBlock;
          this._rBlock = lBlock ^ f;
        }

        // Undo swap from last round
        var t = this._lBlock;
        this._lBlock = this._rBlock;
        this._rBlock = t;

        // Final permutation
        exchangeLR.call(this, 1, 0x55555555);
        exchangeRL.call(this, 8, 0x00ff00ff);
        exchangeRL.call(this, 2, 0x33333333);
        exchangeLR.call(this, 16, 0x0000ffff);
        exchangeLR.call(this, 4, 0x0f0f0f0f);

        // Set output
        M[offset] = this._lBlock;
        M[offset + 1] = this._rBlock;
      },
      keySize: 64 / 32,
      ivSize: 64 / 32,
      blockSize: 64 / 32
    });

    // Swap bits across the left and right words
    function exchangeLR(offset, mask) {
      var t = (this._lBlock >>> offset ^ this._rBlock) & mask;
      this._rBlock ^= t;
      this._lBlock ^= t << offset;
    }
    function exchangeRL(offset, mask) {
      var t = (this._rBlock >>> offset ^ this._lBlock) & mask;
      this._lBlock ^= t;
      this._rBlock ^= t << offset;
    }

    /**
     * Shortcut functions to the cipher's object interface.
     *
     * @example
     *
     *     var ciphertext = CryptoJS.DES.encrypt(message, key, cfg);
     *     var plaintext  = CryptoJS.DES.decrypt(ciphertext, key, cfg);
     */
    C.DES = BlockCipher._createHelper(DES);

    /**
     * Triple-DES block cipher algorithm.
     */
    var TripleDES = C_algo.TripleDES = BlockCipher.extend({
      _doReset: function () {
        // Shortcuts
        var key = this._key;
        var keyWords = key.words;
        // Make sure the key length is valid (64, 128 or >= 192 bit)
        if (keyWords.length !== 2 && keyWords.length !== 4 && keyWords.length < 6) {
          throw new Error('Invalid key length - 3DES requires the key length to be 64, 128, 192 or >192.');
        }

        // Extend the key according to the keying options defined in 3DES standard
        var key1 = keyWords.slice(0, 2);
        var key2 = keyWords.length < 4 ? keyWords.slice(0, 2) : keyWords.slice(2, 4);
        var key3 = keyWords.length < 6 ? keyWords.slice(0, 2) : keyWords.slice(4, 6);

        // Create DES instances
        this._des1 = DES.createEncryptor(WordArray.create(key1));
        this._des2 = DES.createEncryptor(WordArray.create(key2));
        this._des3 = DES.createEncryptor(WordArray.create(key3));
      },
      encryptBlock: function (M, offset) {
        this._des1.encryptBlock(M, offset);
        this._des2.decryptBlock(M, offset);
        this._des3.encryptBlock(M, offset);
      },
      decryptBlock: function (M, offset) {
        this._des3.decryptBlock(M, offset);
        this._des2.encryptBlock(M, offset);
        this._des1.decryptBlock(M, offset);
      },
      keySize: 192 / 32,
      ivSize: 64 / 32,
      blockSize: 64 / 32
    });

    /**
     * Shortcut functions to the cipher's object interface.
     *
     * @example
     *
     *     var ciphertext = CryptoJS.TripleDES.encrypt(message, key, cfg);
     *     var plaintext  = CryptoJS.TripleDES.decrypt(ciphertext, key, cfg);
     */
    C.TripleDES = BlockCipher._createHelper(TripleDES);
  })();
  return CryptoJS.TripleDES;
});

/***/ }),

/***/ "./node_modules/crypto-js/x64-core.js":
/*!********************************************!*\
  !*** ./node_modules/crypto-js/x64-core.js ***!
  \********************************************/
/***/ (function(module, exports, __webpack_require__) {

;
(function (root, factory) {
  if (true) {
    // CommonJS
    module.exports = exports = factory(__webpack_require__(/*! ./core */ "./node_modules/crypto-js/core.js"));
  } else {}
})(this, function (CryptoJS) {
  (function (undefined) {
    // Shortcuts
    var C = CryptoJS;
    var C_lib = C.lib;
    var Base = C_lib.Base;
    var X32WordArray = C_lib.WordArray;

    /**
     * x64 namespace.
     */
    var C_x64 = C.x64 = {};

    /**
     * A 64-bit word.
     */
    var X64Word = C_x64.Word = Base.extend({
      /**
       * Initializes a newly created 64-bit word.
       *
       * @param {number} high The high 32 bits.
       * @param {number} low The low 32 bits.
       *
       * @example
       *
       *     var x64Word = CryptoJS.x64.Word.create(0x00010203, 0x04050607);
       */
      init: function (high, low) {
        this.high = high;
        this.low = low;
      }

      /**
       * Bitwise NOTs this word.
       *
       * @return {X64Word} A new x64-Word object after negating.
       *
       * @example
       *
       *     var negated = x64Word.not();
       */
      // not: function () {
      // var high = ~this.high;
      // var low = ~this.low;

      // return X64Word.create(high, low);
      // },

      /**
       * Bitwise ANDs this word with the passed word.
       *
       * @param {X64Word} word The x64-Word to AND with this word.
       *
       * @return {X64Word} A new x64-Word object after ANDing.
       *
       * @example
       *
       *     var anded = x64Word.and(anotherX64Word);
       */
      // and: function (word) {
      // var high = this.high & word.high;
      // var low = this.low & word.low;

      // return X64Word.create(high, low);
      // },

      /**
       * Bitwise ORs this word with the passed word.
       *
       * @param {X64Word} word The x64-Word to OR with this word.
       *
       * @return {X64Word} A new x64-Word object after ORing.
       *
       * @example
       *
       *     var ored = x64Word.or(anotherX64Word);
       */
      // or: function (word) {
      // var high = this.high | word.high;
      // var low = this.low | word.low;

      // return X64Word.create(high, low);
      // },

      /**
       * Bitwise XORs this word with the passed word.
       *
       * @param {X64Word} word The x64-Word to XOR with this word.
       *
       * @return {X64Word} A new x64-Word object after XORing.
       *
       * @example
       *
       *     var xored = x64Word.xor(anotherX64Word);
       */
      // xor: function (word) {
      // var high = this.high ^ word.high;
      // var low = this.low ^ word.low;

      // return X64Word.create(high, low);
      // },

      /**
       * Shifts this word n bits to the left.
       *
       * @param {number} n The number of bits to shift.
       *
       * @return {X64Word} A new x64-Word object after shifting.
       *
       * @example
       *
       *     var shifted = x64Word.shiftL(25);
       */
      // shiftL: function (n) {
      // if (n < 32) {
      // var high = (this.high << n) | (this.low >>> (32 - n));
      // var low = this.low << n;
      // } else {
      // var high = this.low << (n - 32);
      // var low = 0;
      // }

      // return X64Word.create(high, low);
      // },

      /**
       * Shifts this word n bits to the right.
       *
       * @param {number} n The number of bits to shift.
       *
       * @return {X64Word} A new x64-Word object after shifting.
       *
       * @example
       *
       *     var shifted = x64Word.shiftR(7);
       */
      // shiftR: function (n) {
      // if (n < 32) {
      // var low = (this.low >>> n) | (this.high << (32 - n));
      // var high = this.high >>> n;
      // } else {
      // var low = this.high >>> (n - 32);
      // var high = 0;
      // }

      // return X64Word.create(high, low);
      // },

      /**
       * Rotates this word n bits to the left.
       *
       * @param {number} n The number of bits to rotate.
       *
       * @return {X64Word} A new x64-Word object after rotating.
       *
       * @example
       *
       *     var rotated = x64Word.rotL(25);
       */
      // rotL: function (n) {
      // return this.shiftL(n).or(this.shiftR(64 - n));
      // },

      /**
       * Rotates this word n bits to the right.
       *
       * @param {number} n The number of bits to rotate.
       *
       * @return {X64Word} A new x64-Word object after rotating.
       *
       * @example
       *
       *     var rotated = x64Word.rotR(7);
       */
      // rotR: function (n) {
      // return this.shiftR(n).or(this.shiftL(64 - n));
      // },

      /**
       * Adds this word with the passed word.
       *
       * @param {X64Word} word The x64-Word to add with this word.
       *
       * @return {X64Word} A new x64-Word object after adding.
       *
       * @example
       *
       *     var added = x64Word.add(anotherX64Word);
       */
      // add: function (word) {
      // var low = (this.low + word.low) | 0;
      // var carry = (low >>> 0) < (this.low >>> 0) ? 1 : 0;
      // var high = (this.high + word.high + carry) | 0;

      // return X64Word.create(high, low);
      // }
    });

    /**
     * An array of 64-bit words.
     *
     * @property {Array} words The array of CryptoJS.x64.Word objects.
     * @property {number} sigBytes The number of significant bytes in this word array.
     */
    var X64WordArray = C_x64.WordArray = Base.extend({
      /**
       * Initializes a newly created word array.
       *
       * @param {Array} words (Optional) An array of CryptoJS.x64.Word objects.
       * @param {number} sigBytes (Optional) The number of significant bytes in the words.
       *
       * @example
       *
       *     var wordArray = CryptoJS.x64.WordArray.create();
       *
       *     var wordArray = CryptoJS.x64.WordArray.create([
       *         CryptoJS.x64.Word.create(0x00010203, 0x04050607),
       *         CryptoJS.x64.Word.create(0x18191a1b, 0x1c1d1e1f)
       *     ]);
       *
       *     var wordArray = CryptoJS.x64.WordArray.create([
       *         CryptoJS.x64.Word.create(0x00010203, 0x04050607),
       *         CryptoJS.x64.Word.create(0x18191a1b, 0x1c1d1e1f)
       *     ], 10);
       */
      init: function (words, sigBytes) {
        words = this.words = words || [];
        if (sigBytes != undefined) {
          this.sigBytes = sigBytes;
        } else {
          this.sigBytes = words.length * 8;
        }
      },
      /**
       * Converts this 64-bit word array to a 32-bit word array.
       *
       * @return {CryptoJS.lib.WordArray} This word array's data as a 32-bit word array.
       *
       * @example
       *
       *     var x32WordArray = x64WordArray.toX32();
       */
      toX32: function () {
        // Shortcuts
        var x64Words = this.words;
        var x64WordsLength = x64Words.length;

        // Convert
        var x32Words = [];
        for (var i = 0; i < x64WordsLength; i++) {
          var x64Word = x64Words[i];
          x32Words.push(x64Word.high);
          x32Words.push(x64Word.low);
        }
        return X32WordArray.create(x32Words, this.sigBytes);
      },
      /**
       * Creates a copy of this word array.
       *
       * @return {X64WordArray} The clone.
       *
       * @example
       *
       *     var clone = x64WordArray.clone();
       */
      clone: function () {
        var clone = Base.clone.call(this);

        // Clone "words" array
        var words = clone.words = this.words.slice(0);

        // Clone each X64Word object
        var wordsLength = words.length;
        for (var i = 0; i < wordsLength; i++) {
          words[i] = words[i].clone();
        }
        return clone;
      }
    });
  })();
  return CryptoJS;
});

/***/ }),

/***/ "./node_modules/form-data/lib/browser.js":
/*!***********************************************!*\
  !*** ./node_modules/form-data/lib/browser.js ***!
  \***********************************************/
/***/ ((module) => {

/* eslint-env browser */
module.exports = typeof self == 'object' ? self.FormData : window.FormData;

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ActivityReceivedEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ActivityReceivedEventArgs),
/* harmony export */   AudioConfig: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioConfig),
/* harmony export */   AudioFormatTag: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioFormatTag),
/* harmony export */   AudioInputStream: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioInputStream),
/* harmony export */   AudioOutputStream: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioOutputStream),
/* harmony export */   AudioStreamFormat: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamFormat),
/* harmony export */   AutoDetectSourceLanguageConfig: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AutoDetectSourceLanguageConfig),
/* harmony export */   AutoDetectSourceLanguageResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AutoDetectSourceLanguageResult),
/* harmony export */   BaseAudioPlayer: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.BaseAudioPlayer),
/* harmony export */   BotFrameworkConfig: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.BotFrameworkConfig),
/* harmony export */   CancellationDetails: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationDetails),
/* harmony export */   CancellationDetailsBase: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationDetailsBase),
/* harmony export */   CancellationErrorCode: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode),
/* harmony export */   CancellationReason: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationReason),
/* harmony export */   Connection: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.Connection),
/* harmony export */   ConnectionEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionEventArgs),
/* harmony export */   ConnectionMessage: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionMessage),
/* harmony export */   ConnectionMessageEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionMessageEventArgs),
/* harmony export */   Conversation: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.Conversation),
/* harmony export */   ConversationExpirationEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationExpirationEventArgs),
/* harmony export */   ConversationParticipantsChangedEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationParticipantsChangedEventArgs),
/* harmony export */   ConversationTranscriber: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranscriber),
/* harmony export */   ConversationTranscriptionCanceledEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranscriptionCanceledEventArgs),
/* harmony export */   ConversationTranscriptionEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranscriptionEventArgs),
/* harmony export */   ConversationTranslationCanceledEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranslationCanceledEventArgs),
/* harmony export */   ConversationTranslationEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranslationEventArgs),
/* harmony export */   ConversationTranslationResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranslationResult),
/* harmony export */   ConversationTranslator: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranslator),
/* harmony export */   CustomCommandsConfig: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CustomCommandsConfig),
/* harmony export */   Diagnostics: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.Diagnostics),
/* harmony export */   DialogServiceConfig: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.DialogServiceConfig),
/* harmony export */   DialogServiceConnector: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.DialogServiceConnector),
/* harmony export */   IntentRecognitionCanceledEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.IntentRecognitionCanceledEventArgs),
/* harmony export */   IntentRecognitionEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.IntentRecognitionEventArgs),
/* harmony export */   IntentRecognitionResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.IntentRecognitionResult),
/* harmony export */   IntentRecognizer: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.IntentRecognizer),
/* harmony export */   KeywordRecognitionModel: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.KeywordRecognitionModel),
/* harmony export */   LanguageIdMode: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.LanguageIdMode),
/* harmony export */   LanguageUnderstandingModel: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.LanguageUnderstandingModel),
/* harmony export */   LogLevel: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.LogLevel),
/* harmony export */   NoMatchDetails: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.NoMatchDetails),
/* harmony export */   NoMatchReason: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.NoMatchReason),
/* harmony export */   OutputFormat: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.OutputFormat),
/* harmony export */   Participant: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.Participant),
/* harmony export */   ParticipantChangedReason: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ParticipantChangedReason),
/* harmony export */   PhraseListGrammar: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PhraseListGrammar),
/* harmony export */   ProfanityOption: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ProfanityOption),
/* harmony export */   PronunciationAssessmentConfig: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PronunciationAssessmentConfig),
/* harmony export */   PronunciationAssessmentGradingSystem: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PronunciationAssessmentGradingSystem),
/* harmony export */   PronunciationAssessmentGranularity: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PronunciationAssessmentGranularity),
/* harmony export */   PronunciationAssessmentResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PronunciationAssessmentResult),
/* harmony export */   PropertyCollection: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection),
/* harmony export */   PropertyId: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId),
/* harmony export */   PullAudioInputStream: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PullAudioInputStream),
/* harmony export */   PullAudioInputStreamCallback: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PullAudioInputStreamCallback),
/* harmony export */   PullAudioOutputStream: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PullAudioOutputStream),
/* harmony export */   PushAudioInputStream: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PushAudioInputStream),
/* harmony export */   PushAudioOutputStream: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PushAudioOutputStream),
/* harmony export */   PushAudioOutputStreamCallback: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PushAudioOutputStreamCallback),
/* harmony export */   RecognitionEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionEventArgs),
/* harmony export */   RecognitionResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionResult),
/* harmony export */   Recognizer: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.Recognizer),
/* harmony export */   ResultReason: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ResultReason),
/* harmony export */   ServiceEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ServiceEventArgs),
/* harmony export */   ServicePropertyChannel: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ServicePropertyChannel),
/* harmony export */   SessionEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SessionEventArgs),
/* harmony export */   SourceLanguageConfig: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SourceLanguageConfig),
/* harmony export */   SpeakerAudioDestination: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerAudioDestination),
/* harmony export */   SpeakerIdentificationModel: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerIdentificationModel),
/* harmony export */   SpeakerRecognitionCancellationDetails: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerRecognitionCancellationDetails),
/* harmony export */   SpeakerRecognitionResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerRecognitionResult),
/* harmony export */   SpeakerRecognitionResultType: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerRecognitionResultType),
/* harmony export */   SpeakerRecognizer: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerRecognizer),
/* harmony export */   SpeakerVerificationModel: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerVerificationModel),
/* harmony export */   SpeechConfig: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechConfig),
/* harmony export */   SpeechConfigImpl: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechConfigImpl),
/* harmony export */   SpeechRecognitionCanceledEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechRecognitionCanceledEventArgs),
/* harmony export */   SpeechRecognitionEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechRecognitionEventArgs),
/* harmony export */   SpeechRecognitionResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechRecognitionResult),
/* harmony export */   SpeechRecognizer: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechRecognizer),
/* harmony export */   SpeechSynthesisBookmarkEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisBookmarkEventArgs),
/* harmony export */   SpeechSynthesisBoundaryType: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisBoundaryType),
/* harmony export */   SpeechSynthesisEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisEventArgs),
/* harmony export */   SpeechSynthesisOutputFormat: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisOutputFormat),
/* harmony export */   SpeechSynthesisResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisResult),
/* harmony export */   SpeechSynthesisVisemeEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisVisemeEventArgs),
/* harmony export */   SpeechSynthesisWordBoundaryEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisWordBoundaryEventArgs),
/* harmony export */   SpeechSynthesizer: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesizer),
/* harmony export */   SpeechTranslationConfig: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechTranslationConfig),
/* harmony export */   SpeechTranslationConfigImpl: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechTranslationConfigImpl),
/* harmony export */   SynthesisResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SynthesisResult),
/* harmony export */   SynthesisVoicesResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SynthesisVoicesResult),
/* harmony export */   TranslationRecognitionCanceledEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationRecognitionCanceledEventArgs),
/* harmony export */   TranslationRecognitionEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationRecognitionEventArgs),
/* harmony export */   TranslationRecognitionResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationRecognitionResult),
/* harmony export */   TranslationRecognizer: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationRecognizer),
/* harmony export */   TranslationSynthesisEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationSynthesisEventArgs),
/* harmony export */   TranslationSynthesisResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationSynthesisResult),
/* harmony export */   Translations: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.Translations),
/* harmony export */   TurnStatusReceivedEventArgs: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TurnStatusReceivedEventArgs),
/* harmony export */   User: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.User),
/* harmony export */   VoiceInfo: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceInfo),
/* harmony export */   VoiceProfile: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfile),
/* harmony export */   VoiceProfileCancellationDetails: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfileCancellationDetails),
/* harmony export */   VoiceProfileClient: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfileClient),
/* harmony export */   VoiceProfileEnrollmentCancellationDetails: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfileEnrollmentCancellationDetails),
/* harmony export */   VoiceProfileEnrollmentResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfileEnrollmentResult),
/* harmony export */   VoiceProfilePhraseResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfilePhraseResult),
/* harmony export */   VoiceProfileResult: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfileResult),
/* harmony export */   VoiceProfileType: () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfileType)
/* harmony export */ });
/* harmony import */ var _src_common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./src/common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js");
/* harmony import */ var _src_common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js");
/* harmony import */ var _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./src/sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


// Common.Storage.SetLocalStorage(new Common.Browser.LocalStorage());
// Common.Storage.SetSessionStorage(new Common.Browser.SessionStorage());
_src_common_Exports__WEBPACK_IMPORTED_MODULE_0__.Events.instance.attachConsoleListener(new _src_common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.ConsoleLoggingListener());
// Speech SDK API


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConsoleLoggingListener: () => (/* binding */ ConsoleLoggingListener)
/* harmony export */ });
/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ "?0825");
/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/LogLevel */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js");
/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* eslint-disable @typescript-eslint/no-unsafe-assignment */
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



class ConsoleLoggingListener {
  constructor(logLevelFilter = _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__.EventType.None) {
    this.privLogPath = undefined;
    this.privEnableConsoleOutput = true;
    this.privLogLevelFilter = logLevelFilter;
  }
  set logPath(path) {
    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(fs__WEBPACK_IMPORTED_MODULE_0__.openSync, "\nFile System access not available");
    this.privLogPath = path;
  }
  set enableConsoleOutput(enableOutput) {
    this.privEnableConsoleOutput = enableOutput;
  }
  onEvent(event) {
    if (event.eventType >= this.privLogLevelFilter) {
      const log = this.toString(event);
      if (!!this.privLogPath) {
        fs__WEBPACK_IMPORTED_MODULE_0__.writeFileSync(this.privLogPath, log + "\n", {
          flag: "a+"
        });
      }
      if (this.privEnableConsoleOutput) {
        switch (event.eventType) {
          case _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__.EventType.Debug:
            // eslint-disable-next-line no-console
            console.debug(log);
            break;
          case _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__.EventType.Info:
            // eslint-disable-next-line no-console
            console.info(log);
            break;
          case _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__.EventType.Warning:
            // eslint-disable-next-line no-console
            console.warn(log);
            break;
          case _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__.EventType.Error:
            // eslint-disable-next-line no-console
            console.error(log);
            break;
          default:
            // eslint-disable-next-line no-console
            console.log(log);
            break;
        }
      }
    }
  }
  toString(event) {
    const logFragments = [`${event.eventTime}`, `${event.name}`];
    const e = event;
    for (const prop in e) {
      if (prop && event.hasOwnProperty(prop) && prop !== "eventTime" && prop !== "eventType" && prop !== "eventId" && prop !== "name" && prop !== "constructor") {
        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access
        const value = e[prop];
        let valueToLog = "<NULL>";
        if (value !== undefined && value !== null) {
          if (typeof value === "number" || typeof value === "string") {
            valueToLog = value.toString();
          } else {
            valueToLog = JSON.stringify(value);
          }
        }
        logFragments.push(`${prop}: ${valueToLog}`);
      }
    }
    return logFragments.join(" | ");
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   FileAudioSource: () => (/* binding */ FileAudioSource)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js");
/* harmony import */ var _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};



class FileAudioSource {
  constructor(file, filename, audioSourceId) {
    this.privStreams = {};
    this.privHeaderEnd = 44;
    this.privId = audioSourceId ? audioSourceId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();
    this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();
    this.privSource = file;
    if (typeof window !== "undefined" && typeof Blob !== "undefined" && this.privSource instanceof Blob) {
      this.privFilename = file.name;
    } else {
      this.privFilename = filename || "unknown.wav";
    }
    // Read the header.
    this.privAudioFormatPromise = this.readHeader();
  }
  get format() {
    return this.privAudioFormatPromise;
  }
  turnOn() {
    if (this.privFilename.lastIndexOf(".wav") !== this.privFilename.length - 4) {
      const errorMsg = this.privFilename + " is not supported. Only WAVE files are allowed at the moment.";
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioSourceErrorEvent(errorMsg, ""));
      return Promise.reject(errorMsg);
    }
    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioSourceInitializingEvent(this.privId)); // no stream id
    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioSourceReadyEvent(this.privId));
    return;
  }
  id() {
    return this.privId;
  }
  attach(audioNodeId) {
    return __awaiter(this, void 0, void 0, function* () {
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));
      const stream = yield this.upload(audioNodeId);
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));
      return Promise.resolve({
        detach: () => __awaiter(this, void 0, void 0, function* () {
          stream.readEnded();
          delete this.privStreams[audioNodeId];
          this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
          yield this.turnOff();
        }),
        id: () => audioNodeId,
        read: () => stream.read()
      });
    });
  }
  detach(audioNodeId) {
    if (audioNodeId && this.privStreams[audioNodeId]) {
      this.privStreams[audioNodeId].close();
      delete this.privStreams[audioNodeId];
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
    }
  }
  turnOff() {
    for (const streamId in this.privStreams) {
      if (streamId) {
        const stream = this.privStreams[streamId];
        if (stream && !stream.isClosed) {
          stream.close();
        }
      }
    }
    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioSourceOffEvent(this.privId)); // no stream now
    return Promise.resolve();
  }
  get events() {
    return this.privEvents;
  }
  get deviceInfo() {
    return this.privAudioFormatPromise.then(result => Promise.resolve({
      bitspersample: result.bitsPerSample,
      channelcount: result.channels,
      connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.connectivity.Unknown,
      manufacturer: "Speech SDK",
      model: "File",
      samplerate: result.samplesPerSec,
      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.type.File
    }));
  }
  readHeader() {
    // Read the wave header.
    const maxHeaderSize = 4296;
    const header = this.privSource.slice(0, maxHeaderSize);
    const headerResult = new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.Deferred();
    const processHeader = header => {
      const view = new DataView(header);
      const getWord = index => String.fromCharCode(view.getUint8(index), view.getUint8(index + 1), view.getUint8(index + 2), view.getUint8(index + 3));
      // RIFF 4 bytes.
      if ("RIFF" !== getWord(0)) {
        headerResult.reject("Invalid WAV header in file, RIFF was not found");
        return;
      }
      // length, 4 bytes
      // RIFF Type & fmt 8 bytes
      if ("WAVE" !== getWord(8) || "fmt " !== getWord(12)) {
        headerResult.reject("Invalid WAV header in file, WAVEfmt was not found");
        return;
      }
      const formatSize = view.getInt32(16, true);
      const channelCount = view.getUint16(22, true);
      const sampleRate = view.getUint32(24, true);
      const bitsPerSample = view.getUint16(34, true);
      // Confirm if header is 44 bytes long.
      let pos = 36 + Math.max(formatSize - 16, 0);
      for (; getWord(pos) !== "data"; pos += 2) {
        if (pos > maxHeaderSize - 8) {
          headerResult.reject("Invalid WAV header in file, data block was not found");
          return;
        }
      }
      this.privHeaderEnd = pos + 8;
      headerResult.resolve(_sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_5__.AudioStreamFormat.getWaveFormatPCM(sampleRate, bitsPerSample, channelCount));
    };
    if (typeof window !== "undefined" && typeof Blob !== "undefined" && header instanceof Blob) {
      const reader = new FileReader();
      reader.onload = event => {
        const header = event.target.result;
        processHeader(header);
      };
      reader.readAsArrayBuffer(header);
    } else {
      const h = header;
      processHeader(h.buffer.slice(h.byteOffset, h.byteOffset + h.byteLength));
    }
    return headerResult.promise;
  }
  upload(audioNodeId) {
    return __awaiter(this, void 0, void 0, function* () {
      const onerror = error => {
        const errorMsg = `Error occurred while processing '${this.privFilename}'. ${error}`;
        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeErrorEvent(this.privId, audioNodeId, errorMsg));
        throw new Error(errorMsg);
      };
      try {
        yield this.turnOn();
        const format = yield this.privAudioFormatPromise;
        const stream = new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.ChunkedArrayBufferStream(format.avgBytesPerSec / 10, audioNodeId);
        this.privStreams[audioNodeId] = stream;
        const chunk = this.privSource.slice(this.privHeaderEnd);
        const processFile = buff => {
          if (stream.isClosed) {
            return; // output stream was closed (somebody called TurnOff). We're done here.
          }

          stream.writeStreamChunk({
            buffer: buff,
            isEnd: false,
            timeReceived: Date.now()
          });
          stream.close();
        };
        if (typeof window !== "undefined" && typeof Blob !== "undefined" && chunk instanceof Blob) {
          const reader = new FileReader();
          reader.onerror = ev => onerror(ev.toString());
          reader.onload = event => {
            const fileBuffer = event.target.result;
            processFile(fileBuffer);
          };
          reader.readAsArrayBuffer(chunk);
        } else {
          const c = chunk;
          processFile(c.buffer.slice(c.byteOffset, c.byteOffset + c.byteLength));
        }
        return stream;
      } catch (e) {
        onerror(e);
      }
    });
  }
  onEvent(event) {
    this.privEvents.onEvent(event);
    _common_Exports__WEBPACK_IMPORTED_MODULE_7__.Events.instance.onEvent(event);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AudioWorkletSourceURLPropertyName: () => (/* binding */ AudioWorkletSourceURLPropertyName),
/* harmony export */   MicAudioSource: () => (/* binding */ MicAudioSource)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js");
/* harmony import */ var _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};



const AudioWorkletSourceURLPropertyName = "MICROPHONE-WorkletSourceUrl";
class MicAudioSource {
  constructor(privRecorder, deviceId, audioSourceId, mediaStream) {
    this.privRecorder = privRecorder;
    this.deviceId = deviceId;
    this.privStreams = {};
    this.privOutputChunkSize = MicAudioSource.AUDIOFORMAT.avgBytesPerSec / 10;
    this.privId = audioSourceId ? audioSourceId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();
    this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();
    this.privMediaStream = mediaStream || null;
    this.privIsClosing = false;
  }
  get format() {
    return Promise.resolve(MicAudioSource.AUDIOFORMAT);
  }
  turnOn() {
    if (this.privInitializeDeferral) {
      return this.privInitializeDeferral.promise;
    }
    this.privInitializeDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.Deferred();
    try {
      this.createAudioContext();
    } catch (error) {
      if (error instanceof Error) {
        const typedError = error;
        this.privInitializeDeferral.reject(typedError.name + ": " + typedError.message);
      } else {
        this.privInitializeDeferral.reject(error);
      }
      return this.privInitializeDeferral.promise;
    }
    const nav = window.navigator;
    let getUserMedia =
    // eslint-disable-next-line
    nav.getUserMedia || nav.webkitGetUserMedia || nav.mozGetUserMedia || nav.msGetUserMedia;
    if (!!nav.mediaDevices) {
      getUserMedia = (constraints, successCallback, errorCallback) => {
        nav.mediaDevices.getUserMedia(constraints).then(successCallback).catch(errorCallback);
      };
    }
    if (!getUserMedia) {
      const errorMsg = "Browser does not support getUserMedia.";
      this.privInitializeDeferral.reject(errorMsg);
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceErrorEvent(errorMsg, "")); // mic initialized error - no streamid at this point
    } else {
      const next = () => {
        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceInitializingEvent(this.privId)); // no stream id
        if (this.privMediaStream && this.privMediaStream.active) {
          this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceReadyEvent(this.privId));
          this.privInitializeDeferral.resolve();
        } else {
          getUserMedia({
            audio: this.deviceId ? {
              deviceId: this.deviceId
            } : true,
            video: false
          }, mediaStream => {
            this.privMediaStream = mediaStream;
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceReadyEvent(this.privId));
            this.privInitializeDeferral.resolve();
          }, error => {
            const errorMsg = `Error occurred during microphone initialization: ${error}`;
            this.privInitializeDeferral.reject(errorMsg);
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceErrorEvent(this.privId, errorMsg));
          });
        }
      };
      if (this.privContext.state === "suspended") {
        // NOTE: On iOS, the Web Audio API requires sounds to be triggered from an explicit user action.
        // https://github.com/WebAudio/web-audio-api/issues/790
        this.privContext.resume().then(next).catch(reason => {
          this.privInitializeDeferral.reject(`Failed to initialize audio context: ${reason}`);
        });
      } else {
        next();
      }
    }
    return this.privInitializeDeferral.promise;
  }
  id() {
    return this.privId;
  }
  attach(audioNodeId) {
    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));
    return this.listen(audioNodeId).then(stream => {
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));
      return {
        detach: () => __awaiter(this, void 0, void 0, function* () {
          stream.readEnded();
          delete this.privStreams[audioNodeId];
          this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
          return this.turnOff();
        }),
        id: () => audioNodeId,
        read: () => stream.read()
      };
    });
  }
  detach(audioNodeId) {
    if (audioNodeId && this.privStreams[audioNodeId]) {
      this.privStreams[audioNodeId].close();
      delete this.privStreams[audioNodeId];
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
    }
  }
  turnOff() {
    return __awaiter(this, void 0, void 0, function* () {
      for (const streamId in this.privStreams) {
        if (streamId) {
          const stream = this.privStreams[streamId];
          if (stream) {
            stream.close();
          }
        }
      }
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceOffEvent(this.privId)); // no stream now
      if (this.privInitializeDeferral) {
        // Correctly handle when browser forces mic off before turnOn() completes
        // eslint-disable-next-line @typescript-eslint/await-thenable
        yield this.privInitializeDeferral;
        this.privInitializeDeferral = null;
      }
      yield this.destroyAudioContext();
      return;
    });
  }
  get events() {
    return this.privEvents;
  }
  get deviceInfo() {
    return this.getMicrophoneLabel().then(label => ({
      bitspersample: MicAudioSource.AUDIOFORMAT.bitsPerSample,
      channelcount: MicAudioSource.AUDIOFORMAT.channels,
      connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.connectivity.Unknown,
      manufacturer: "Speech SDK",
      model: label,
      samplerate: MicAudioSource.AUDIOFORMAT.samplesPerSec,
      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.type.Microphones
    }));
  }
  setProperty(name, value) {
    if (name === AudioWorkletSourceURLPropertyName) {
      this.privRecorder.setWorkletUrl(value);
    } else {
      throw new Error("Property '" + name + "' is not supported on Microphone.");
    }
  }
  getMicrophoneLabel() {
    const defaultMicrophoneName = "microphone";
    // If we did this already, return the value.
    if (this.privMicrophoneLabel !== undefined) {
      return Promise.resolve(this.privMicrophoneLabel);
    }
    // If the stream isn't currently running, we can't query devices because security.
    if (this.privMediaStream === undefined || !this.privMediaStream.active) {
      return Promise.resolve(defaultMicrophoneName);
    }
    // Setup a default
    this.privMicrophoneLabel = defaultMicrophoneName;
    // Get the id of the device running the audio track.
    const microphoneDeviceId = this.privMediaStream.getTracks()[0].getSettings().deviceId;
    // If the browser doesn't support getting the device ID, set a default and return.
    if (undefined === microphoneDeviceId) {
      return Promise.resolve(this.privMicrophoneLabel);
    }
    const deferred = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.Deferred();
    // Enumerate the media devices.
    navigator.mediaDevices.enumerateDevices().then(devices => {
      for (const device of devices) {
        if (device.deviceId === microphoneDeviceId) {
          // Found the device
          this.privMicrophoneLabel = device.label;
          break;
        }
      }
      deferred.resolve(this.privMicrophoneLabel);
    }, () => deferred.resolve(this.privMicrophoneLabel));
    return deferred.promise;
  }
  listen(audioNodeId) {
    return __awaiter(this, void 0, void 0, function* () {
      yield this.turnOn();
      const stream = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.ChunkedArrayBufferStream(this.privOutputChunkSize, audioNodeId);
      this.privStreams[audioNodeId] = stream;
      try {
        this.privRecorder.record(this.privContext, this.privMediaStream, stream);
      } catch (error) {
        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeErrorEvent(this.privId, audioNodeId, error));
        throw error;
      }
      const result = stream;
      return result;
    });
  }
  onEvent(event) {
    this.privEvents.onEvent(event);
    _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Events.instance.onEvent(event);
  }
  createAudioContext() {
    if (!!this.privContext) {
      return;
    }
    this.privContext = _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_7__.AudioStreamFormatImpl.getAudioContext(MicAudioSource.AUDIOFORMAT.samplesPerSec);
  }
  destroyAudioContext() {
    return __awaiter(this, void 0, void 0, function* () {
      if (!this.privContext) {
        return;
      }
      this.privRecorder.releaseMediaResources(this.privContext);
      // This pattern brought to you by a bug in the TypeScript compiler where it
      // confuses the ("close" in this.privContext) with this.privContext always being null as the alternate.
      // https://github.com/Microsoft/TypeScript/issues/11498
      let hasClose = false;
      if ("close" in this.privContext) {
        hasClose = true;
      }
      if (hasClose) {
        if (!this.privIsClosing) {
          // The audio context close may take enough time that the close is called twice
          this.privIsClosing = true;
          yield this.privContext.close();
          this.privContext = null;
          this.privIsClosing = false;
        }
      } else if (null !== this.privContext && this.privContext.state === "running") {
        // Suspend actually takes a callback, but analogous to the
        // resume method, it'll be only fired if suspend is called
        // in a direct response to a user action. The later is not always
        // the case, as TurnOff is also called, when we receive an
        // end-of-speech message from the service. So, doing a best effort
        // fire-and-forget here.
        yield this.privContext.suspend();
      }
    });
  }
}
MicAudioSource.AUDIOFORMAT = _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_7__.AudioStreamFormat.getDefaultInputFormat();

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   PcmRecorder: () => (/* binding */ PcmRecorder)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class PcmRecorder {
  constructor(stopInputOnRelease) {
    this.privStopInputOnRelease = stopInputOnRelease;
  }
  record(context, mediaStream, outputStream) {
    const desiredSampleRate = 16000;
    const waveStreamEncoder = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.RiffPcmEncoder(context.sampleRate, desiredSampleRate);
    const micInput = context.createMediaStreamSource(mediaStream);
    const attachScriptProcessor = () => {
      // eslint-disable-next-line @typescript-eslint/explicit-function-return-type
      const scriptNode = (() => {
        let bufferSize = 0;
        try {
          return context.createScriptProcessor(bufferSize, 1, 1);
        } catch (error) {
          // Webkit (<= version 31) requires a valid bufferSize.
          bufferSize = 2048;
          let audioSampleRate = context.sampleRate;
          while (bufferSize < 16384 && audioSampleRate >= 2 * desiredSampleRate) {
            bufferSize <<= 1;
            audioSampleRate >>= 1;
          }
          return context.createScriptProcessor(bufferSize, 1, 1);
        }
      })();
      scriptNode.onaudioprocess = event => {
        const inputFrame = event.inputBuffer.getChannelData(0);
        if (outputStream && !outputStream.isClosed) {
          const waveFrame = waveStreamEncoder.encode(inputFrame);
          if (!!waveFrame) {
            outputStream.writeStreamChunk({
              buffer: waveFrame,
              isEnd: false,
              timeReceived: Date.now()
            });
          }
        }
      };
      micInput.connect(scriptNode);
      scriptNode.connect(context.destination);
      this.privMediaResources = {
        scriptProcessorNode: scriptNode,
        source: micInput,
        stream: mediaStream
      };
    };
    // https://webaudio.github.io/web-audio-api/#audioworklet
    // Using AudioWorklet to improve audio quality and avoid audio glitches due to blocking the UI thread
    if (!!context.audioWorklet) {
      if (!this.privSpeechProcessorScript) {
        const workletScript = `class SP extends AudioWorkletProcessor {
                    constructor(options) {
                      super(options);
                    }
                    process(inputs, outputs) {
                      const input = inputs[0];
                      const output = [];
                      for (let channel = 0; channel < input.length; channel += 1) {
                        output[channel] = input[channel];
                      }
                      this.port.postMessage(output[0]);
                      return true;
                    }
                  }
                  registerProcessor('speech-processor', SP);`;
        const blob = new Blob([workletScript], {
          type: "application/javascript; charset=utf-8"
        });
        this.privSpeechProcessorScript = URL.createObjectURL(blob);
      }
      context.audioWorklet.addModule(this.privSpeechProcessorScript).then(() => {
        const workletNode = new AudioWorkletNode(context, "speech-processor");
        workletNode.port.onmessage = ev => {
          const inputFrame = ev.data;
          if (outputStream && !outputStream.isClosed) {
            const waveFrame = waveStreamEncoder.encode(inputFrame);
            if (!!waveFrame) {
              outputStream.writeStreamChunk({
                buffer: waveFrame,
                isEnd: false,
                timeReceived: Date.now()
              });
            }
          }
        };
        micInput.connect(workletNode);
        workletNode.connect(context.destination);
        this.privMediaResources = {
          scriptProcessorNode: workletNode,
          source: micInput,
          stream: mediaStream
        };
      }).catch(() => {
        attachScriptProcessor();
      });
    } else {
      try {
        attachScriptProcessor();
      } catch (err) {
        throw new Error(`Unable to start audio worklet node for PCMRecorder: ${err}`);
      }
    }
  }
  releaseMediaResources(context) {
    if (this.privMediaResources) {
      if (this.privMediaResources.scriptProcessorNode) {
        this.privMediaResources.scriptProcessorNode.disconnect(context.destination);
        this.privMediaResources.scriptProcessorNode = null;
      }
      if (this.privMediaResources.source) {
        this.privMediaResources.source.disconnect();
        if (this.privStopInputOnRelease) {
          this.privMediaResources.stream.getTracks().forEach(track => track.stop());
        }
        this.privMediaResources.source = null;
      }
    }
  }
  setWorkletUrl(url) {
    this.privSpeechProcessorScript = url;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ProxyInfo: () => (/* binding */ ProxyInfo)
/* harmony export */ });
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class ProxyInfo {
  constructor(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
    this.privProxyHostName = proxyHostName;
    this.privProxyPort = proxyPort;
    this.privProxyUserName = proxyUserName;
    this.privProxyPassword = proxyPassword;
  }
  static fromParameters(parameters) {
    return new ProxyInfo(parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_ProxyHostName), parseInt(parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_ProxyPort), 10), parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_ProxyUserName), parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_ProxyPassword));
  }
  static fromRecognizerConfig(config) {
    return this.fromParameters(config.parameters);
  }
  get HostName() {
    return this.privProxyHostName;
  }
  get Port() {
    return this.privProxyPort;
  }
  get UserName() {
    return this.privProxyUserName;
  }
  get Password() {
    return this.privProxyPassword;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ReplayableAudioNode: () => (/* binding */ ReplayableAudioNode)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class ReplayableAudioNode {
  constructor(audioSource, bytesPerSecond) {
    this.privBuffers = [];
    this.privReplayOffset = 0;
    this.privLastShrinkOffset = 0;
    this.privBufferStartOffset = 0;
    this.privBufferSerial = 0;
    this.privBufferedBytes = 0;
    this.privReplay = false;
    this.privLastChunkAcquiredTime = 0;
    this.privAudioNode = audioSource;
    this.privBytesPerSecond = bytesPerSecond;
  }
  id() {
    return this.privAudioNode.id();
  }
  // Reads and returns the next chunk of audio buffer.
  // If replay of existing buffers are needed, read() will first seek and replay
  // existing content, and upoin completion it will read new content from the underlying
  // audio node, saving that content into the replayable buffers.
  read() {
    // if there is a replay request to honor.
    if (!!this.privReplay && this.privBuffers.length !== 0) {
      // Find the start point in the buffers.
      // Offsets are in 100ns increments.
      // So how many bytes do we need to seek to get the right offset?
      const offsetToSeek = this.privReplayOffset - this.privBufferStartOffset;
      let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);
      if (0 !== bytesToSeek % 2) {
        bytesToSeek++;
      }
      let i = 0;
      while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {
        bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;
      }
      if (i < this.privBuffers.length) {
        const retVal = this.privBuffers[i].chunk.buffer.slice(bytesToSeek);
        this.privReplayOffset += retVal.byteLength / this.privBytesPerSecond * 1e+7;
        // If we've reached the end of the buffers, stop replaying.
        if (i === this.privBuffers.length - 1) {
          this.privReplay = false;
        }
        return Promise.resolve({
          buffer: retVal,
          isEnd: false,
          timeReceived: this.privBuffers[i].chunk.timeReceived
        });
      }
    }
    return this.privAudioNode.read().then(result => {
      if (result && result.buffer) {
        this.privBuffers.push(new BufferEntry(result, this.privBufferSerial++, this.privBufferedBytes));
        this.privBufferedBytes += result.buffer.byteLength;
      }
      return result;
    });
  }
  detach() {
    this.privBuffers = undefined;
    return this.privAudioNode.detach();
  }
  replay() {
    if (this.privBuffers && 0 !== this.privBuffers.length) {
      this.privReplay = true;
      this.privReplayOffset = this.privLastShrinkOffset;
    }
  }
  // Shrinks the existing audio buffers to start at the new offset, or at the
  // beginning of the buffer closest to the requested offset.
  // A replay request will start from the last shrink point.
  shrinkBuffers(offset) {
    if (this.privBuffers === undefined || this.privBuffers.length === 0) {
      return;
    }
    this.privLastShrinkOffset = offset;
    // Find the start point in the buffers.
    // Offsets are in 100ns increments.
    // So how many bytes do we need to seek to get the right offset?
    const offsetToSeek = offset - this.privBufferStartOffset;
    let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);
    let i = 0;
    while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {
      bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;
    }
    this.privBufferStartOffset = Math.round(offset - bytesToSeek / this.privBytesPerSecond * 1e+7);
    this.privBuffers = this.privBuffers.slice(i);
  }
  // Finds the time a buffer of audio was first seen by offset.
  findTimeAtOffset(offset) {
    if (offset < this.privBufferStartOffset || this.privBuffers === undefined) {
      return 0;
    }
    for (const value of this.privBuffers) {
      const startOffset = value.byteOffset / this.privBytesPerSecond * 1e7;
      const endOffset = startOffset + value.chunk.buffer.byteLength / this.privBytesPerSecond * 1e7;
      if (offset >= startOffset && offset <= endOffset) {
        return value.chunk.timeReceived;
      }
    }
    return 0;
  }
}
// Primary use of this class is to help debugging problems with the replay
// code. If the memory cost of alloc / dealloc gets too much, drop it and just use
// the ArrayBuffer directly.
class BufferEntry {
  constructor(chunk, serial, byteOffset) {
    this.chunk = chunk;
    this.serial = serial;
    this.byteOffset = byteOffset;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   RestConfigBase: () => (/* binding */ RestConfigBase)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class RestConfigBase {
  static get requestOptions() {
    return RestConfigBase.privDefaultRequestOptions;
  }
  static get configParams() {
    return RestConfigBase.privDefaultParams;
  }
  static get restErrors() {
    return RestConfigBase.privRestErrors;
  }
}
RestConfigBase.privDefaultRequestOptions = {
  headers: {
    Accept: "application/json"
  },
  ignoreCache: false,
  timeout: 10000
};
RestConfigBase.privRestErrors = {
  authInvalidSubscriptionKey: "You must specify either an authentication token to use, or a Cognitive Speech subscription key.",
  authInvalidSubscriptionRegion: "You must specify the Cognitive Speech region to use.",
  invalidArgs: "Required input not found: {arg}.",
  invalidCreateJoinConversationResponse: "Creating/Joining conversation failed with HTTP {status}.",
  invalidParticipantRequest: "The requested participant was not found.",
  permissionDeniedConnect: "Required credentials not found.",
  permissionDeniedConversation: "Invalid operation: only the host can {command} the conversation.",
  permissionDeniedParticipant: "Invalid operation: only the host can {command} a participant.",
  permissionDeniedSend: "Invalid operation: the conversation is not in a connected state.",
  permissionDeniedStart: "Invalid operation: there is already an active conversation."
};
RestConfigBase.privDefaultParams = {
  apiVersion: "api-version",
  authorization: "Authorization",
  clientAppId: "X-ClientAppId",
  contentTypeKey: "Content-Type",
  correlationId: "X-CorrelationId",
  languageCode: "language",
  nickname: "nickname",
  profanity: "profanity",
  requestId: "X-RequestId",
  roomId: "roomid",
  sessionToken: "token",
  subscriptionKey: "Ocp-Apim-Subscription-Key",
  subscriptionRegion: "Ocp-Apim-Subscription-Region",
  token: "X-CapitoToken"
};

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   RestMessageAdapter: () => (/* binding */ RestMessageAdapter),
/* harmony export */   RestRequestType: () => (/* binding */ RestRequestType)
/* harmony export */ });
/* harmony import */ var bent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! bent */ "./node_modules/bent/src/browser.js");
/* harmony import */ var bent__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(bent__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};


var RestRequestType;
(function (RestRequestType) {
  RestRequestType["Get"] = "GET";
  RestRequestType["Post"] = "POST";
  RestRequestType["Delete"] = "DELETE";
  RestRequestType["File"] = "file";
})(RestRequestType || (RestRequestType = {}));
// accept rest operations via request method and return abstracted objects from server response
class RestMessageAdapter {
  constructor(configParams) {
    if (!configParams) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ArgumentNullError("configParams");
    }
    this.privHeaders = configParams.headers;
    this.privIgnoreCache = configParams.ignoreCache;
  }
  static extractHeaderValue(headerKey, headers) {
    let headerValue = "";
    try {
      const arr = headers.trim().split(/[\r\n]+/);
      const headerMap = {};
      arr.forEach(line => {
        const parts = line.split(": ");
        const header = parts.shift().toLowerCase();
        const value = parts.join(": ");
        headerMap[header] = value;
      });
      headerValue = headerMap[headerKey.toLowerCase()];
    } catch (e) {
      // ignore the error
    }
    return headerValue;
  }
  set options(configParams) {
    this.privHeaders = configParams.headers;
    this.privIgnoreCache = configParams.ignoreCache;
  }
  setHeaders(key, value) {
    this.privHeaders[key] = value;
  }
  request(method, uri, queryParams = {}, body = null) {
    const responseReceivedDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.Deferred();
    const requestCommand = method === RestRequestType.File ? "POST" : method;
    const handleRestResponse = (data, j = {}) => {
      const d = data;
      return {
        data: JSON.stringify(j),
        headers: JSON.stringify(data.headers),
        json: j,
        ok: data.statusCode >= 200 && data.statusCode < 300,
        status: data.statusCode,
        statusText: j.error ? j.error.message : d.statusText ? d.statusText : d.statusMessage
      };
    };
    const send = postData => {
      const sendRequest = bent__WEBPACK_IMPORTED_MODULE_0___default()(uri, requestCommand, this.privHeaders, 200, 201, 202, 204, 400, 401, 402, 403, 404);
      const params = this.queryParams(queryParams) === "" ? "" : `?${this.queryParams(queryParams)}`;
      sendRequest(params, postData).then(data => __awaiter(this, void 0, void 0, function* () {
        if (method === RestRequestType.Delete || data.statusCode === 204) {
          // No JSON from Delete and reset (204) operations
          responseReceivedDeferral.resolve(handleRestResponse(data));
        } else {
          try {
            const j = yield data.json();
            responseReceivedDeferral.resolve(handleRestResponse(data, j));
          } catch (_a) {
            responseReceivedDeferral.resolve(handleRestResponse(data));
          }
        }
      })).catch(error => {
        responseReceivedDeferral.reject(error);
      });
    };
    if (this.privIgnoreCache) {
      this.privHeaders["Cache-Control"] = "no-cache";
    }
    if (method === RestRequestType.Post && body) {
      this.privHeaders["content-type"] = "application/json";
      this.privHeaders["Content-Type"] = "application/json";
    }
    send(body);
    return responseReceivedDeferral.promise;
  }
  queryParams(params = {}) {
    return Object.keys(params).map(k => encodeURIComponent(k) + "=" + encodeURIComponent(params[k])).join("&");
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   WebsocketConnection: () => (/* binding */ WebsocketConnection)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./WebsocketMessageAdapter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};


class WebsocketConnection {
  constructor(uri, queryParameters, headers, messageFormatter, proxyInfo, enableCompression = false, connectionId) {
    this.privIsDisposed = false;
    if (!uri) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("uri");
    }
    if (!messageFormatter) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("messageFormatter");
    }
    this.privMessageFormatter = messageFormatter;
    let queryParams = "";
    let i = 0;
    if (queryParameters) {
      for (const paramName in queryParameters) {
        if (paramName) {
          queryParams += i === 0 && uri.indexOf("?") === -1 ? "?" : "&";
          const key = encodeURIComponent(paramName);
          queryParams += key;
          let val = queryParameters[paramName];
          if (val) {
            val = encodeURIComponent(val);
            queryParams += `=${val}`;
          }
          i++;
        }
      }
    }
    if (headers) {
      for (const headerName in headers) {
        if (headerName) {
          queryParams += i === 0 && uri.indexOf("?") === -1 ? "?" : "&";
          const val = encodeURIComponent(headers[headerName]);
          queryParams += `${headerName}=${val}`;
          i++;
        }
      }
    }
    this.privUri = uri + queryParams;
    this.privId = connectionId ? connectionId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_1__.createNoDashGuid)();
    this.privConnectionMessageAdapter = new _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_2__.WebsocketMessageAdapter(this.privUri, this.id, this.privMessageFormatter, proxyInfo, headers, enableCompression);
  }
  dispose() {
    return __awaiter(this, void 0, void 0, function* () {
      this.privIsDisposed = true;
      if (this.privConnectionMessageAdapter) {
        yield this.privConnectionMessageAdapter.close();
      }
    });
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  get id() {
    return this.privId;
  }
  get uri() {
    return this.privUri;
  }
  state() {
    return this.privConnectionMessageAdapter.state;
  }
  open() {
    return this.privConnectionMessageAdapter.open();
  }
  send(message) {
    return this.privConnectionMessageAdapter.send(message);
  }
  read() {
    return this.privConnectionMessageAdapter.read();
  }
  get events() {
    return this.privConnectionMessageAdapter.events;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   WebsocketMessageAdapter: () => (/* binding */ WebsocketMessageAdapter)
/* harmony export */ });
/* harmony import */ var net__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! net */ "?a1bf");
/* harmony import */ var net__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(net__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var tls__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tls */ "?14d6");
/* harmony import */ var tls__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(tls__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var agent_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! agent-base */ "?6483");
/* harmony import */ var agent_base__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(agent_base__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var https_proxy_agent__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! https-proxy-agent */ "?72ad");
/* harmony import */ var https_proxy_agent__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(https_proxy_agent__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var ws__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ws */ "?e42a");
/* harmony import */ var ws__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(ws__WEBPACK_IMPORTED_MODULE_4__);
/* harmony import */ var _common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../common.speech/HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};







class WebsocketMessageAdapter {
  constructor(uri, connectionId, messageFormatter, proxyInfo, headers, enableCompression) {
    if (!uri) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.ArgumentNullError("uri");
    }
    if (!messageFormatter) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.ArgumentNullError("messageFormatter");
    }
    this.proxyInfo = proxyInfo;
    this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.EventSource();
    this.privConnectionId = connectionId;
    this.privMessageFormatter = messageFormatter;
    this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_7__.ConnectionState.None;
    this.privUri = uri;
    this.privHeaders = headers;
    this.privEnableCompression = enableCompression;
    // Add the connection ID to the headers
    this.privHeaders[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_8__.HeaderNames.ConnectionId] = this.privConnectionId;
    this.privLastErrorReceived = "";
  }
  get state() {
    return this.privConnectionState;
  }
  open() {
    if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_7__.ConnectionState.Disconnected) {
      return Promise.reject(`Cannot open a connection that is in ${this.privConnectionState} state`);
    }
    if (this.privConnectionEstablishDeferral) {
      return this.privConnectionEstablishDeferral.promise;
    }
    this.privConnectionEstablishDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_9__.Deferred();
    this.privCertificateValidatedDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_9__.Deferred();
    this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_7__.ConnectionState.Connecting;
    try {
      if (typeof WebSocket !== "undefined" && !WebsocketMessageAdapter.forceNpmWebSocket) {
        // Browser handles cert checks.
        this.privCertificateValidatedDeferral.resolve();
        this.privWebsocketClient = new WebSocket(this.privUri);
      } else {
        const options = {
          headers: this.privHeaders,
          perMessageDeflate: this.privEnableCompression
        };
        // The ocsp library will handle validation for us and fail the connection if needed.
        this.privCertificateValidatedDeferral.resolve();
        options.agent = this.getAgent();
        // Workaround for https://github.com/microsoft/cognitive-services-speech-sdk-js/issues/465
        // Which is root caused by https://github.com/TooTallNate/node-agent-base/issues/61
        const uri = new URL(this.privUri);
        let protocol = uri.protocol;
        if ((protocol === null || protocol === void 0 ? void 0 : protocol.toLocaleLowerCase()) === "wss:") {
          protocol = "https:";
        } else if ((protocol === null || protocol === void 0 ? void 0 : protocol.toLocaleLowerCase()) === "ws:") {
          protocol = "http:";
        }
        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access
        options.agent.protocol = protocol;
        this.privWebsocketClient = new (ws__WEBPACK_IMPORTED_MODULE_4___default())(this.privUri, options);
      }
      this.privWebsocketClient.binaryType = "arraybuffer";
      this.privReceivingMessageQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_10__.Queue();
      this.privDisconnectDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_9__.Deferred();
      this.privSendMessageQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_10__.Queue();
      this.processSendQueue().catch(reason => {
        _common_Exports__WEBPACK_IMPORTED_MODULE_11__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_12__.BackgroundEvent(reason));
      });
    } catch (error) {
      this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_13__.ConnectionOpenResponse(500, error));
      return this.privConnectionEstablishDeferral.promise;
    }
    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_14__.ConnectionStartEvent(this.privConnectionId, this.privUri));
    this.privWebsocketClient.onopen = () => {
      this.privCertificateValidatedDeferral.promise.then(() => {
        this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_7__.ConnectionState.Connected;
        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_14__.ConnectionEstablishedEvent(this.privConnectionId));
        this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_13__.ConnectionOpenResponse(200, ""));
      }, error => {
        this.privConnectionEstablishDeferral.reject(error);
      });
    };
    this.privWebsocketClient.onerror = e => {
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_14__.ConnectionErrorEvent(this.privConnectionId, e.message, e.type));
      this.privLastErrorReceived = e.message;
    };
    this.privWebsocketClient.onclose = e => {
      if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_7__.ConnectionState.Connecting) {
        this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_7__.ConnectionState.Disconnected;
        // this.onEvent(new ConnectionEstablishErrorEvent(this.connectionId, e.code, e.reason));
        this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_13__.ConnectionOpenResponse(e.code, e.reason + " " + this.privLastErrorReceived));
      } else {
        this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_7__.ConnectionState.Disconnected;
        this.privWebsocketClient = null;
        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_14__.ConnectionClosedEvent(this.privConnectionId, e.code, e.reason));
      }
      this.onClose(e.code, e.reason).catch(reason => {
        _common_Exports__WEBPACK_IMPORTED_MODULE_11__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_12__.BackgroundEvent(reason));
      });
    };
    this.privWebsocketClient.onmessage = e => {
      const networkReceivedTime = new Date().toISOString();
      if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_7__.ConnectionState.Connected) {
        const deferred = new _common_Exports__WEBPACK_IMPORTED_MODULE_9__.Deferred();
        // let id = ++this.idCounter;
        this.privReceivingMessageQueue.enqueueFromPromise(deferred.promise);
        if (e.data instanceof ArrayBuffer) {
          const rawMessage = new _common_Exports__WEBPACK_IMPORTED_MODULE_15__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_16__.MessageType.Binary, e.data);
          this.privMessageFormatter.toConnectionMessage(rawMessage).then(connectionMessage => {
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_14__.ConnectionMessageReceivedEvent(this.privConnectionId, networkReceivedTime, connectionMessage));
            deferred.resolve(connectionMessage);
          }, error => {
            // TODO: Events for these ?
            deferred.reject(`Invalid binary message format. Error: ${error}`);
          });
        } else {
          const rawMessage = new _common_Exports__WEBPACK_IMPORTED_MODULE_15__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_16__.MessageType.Text, e.data);
          this.privMessageFormatter.toConnectionMessage(rawMessage).then(connectionMessage => {
            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_14__.ConnectionMessageReceivedEvent(this.privConnectionId, networkReceivedTime, connectionMessage));
            deferred.resolve(connectionMessage);
          }, error => {
            // TODO: Events for these ?
            deferred.reject(`Invalid text message format. Error: ${error}`);
          });
        }
      }
    };
    return this.privConnectionEstablishDeferral.promise;
  }
  send(message) {
    if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_7__.ConnectionState.Connected) {
      return Promise.reject(`Cannot send on connection that is in ${_common_Exports__WEBPACK_IMPORTED_MODULE_7__.ConnectionState[this.privConnectionState]} state`);
    }
    const messageSendStatusDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_9__.Deferred();
    const messageSendDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_9__.Deferred();
    this.privSendMessageQueue.enqueueFromPromise(messageSendDeferral.promise);
    this.privMessageFormatter.fromConnectionMessage(message).then(rawMessage => {
      messageSendDeferral.resolve({
        Message: message,
        RawWebsocketMessage: rawMessage,
        sendStatusDeferral: messageSendStatusDeferral
      });
    }, error => {
      messageSendDeferral.reject(`Error formatting the message. ${error}`);
    });
    return messageSendStatusDeferral.promise;
  }
  read() {
    if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_7__.ConnectionState.Connected) {
      return Promise.reject(`Cannot read on connection that is in ${this.privConnectionState} state`);
    }
    return this.privReceivingMessageQueue.dequeue();
  }
  close(reason) {
    if (this.privWebsocketClient) {
      if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_7__.ConnectionState.Disconnected) {
        this.privWebsocketClient.close(1000, reason ? reason : "Normal closure by client");
      }
    } else {
      return Promise.resolve();
    }
    return this.privDisconnectDeferral.promise;
  }
  get events() {
    return this.privConnectionEvents;
  }
  sendRawMessage(sendItem) {
    try {
      // indicates we are draining the queue and it came with no message;
      if (!sendItem) {
        return Promise.resolve();
      }
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_14__.ConnectionMessageSentEvent(this.privConnectionId, new Date().toISOString(), sendItem.Message));
      // add a check for the ws readystate in order to stop the red console error 'WebSocket is already in CLOSING or CLOSED state' appearing
      if (this.isWebsocketOpen) {
        // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
        this.privWebsocketClient.send(sendItem.RawWebsocketMessage.payload);
      } else {
        return Promise.reject("websocket send error: Websocket not ready " + this.privConnectionId + " " + sendItem.Message.id + " " + new Error().stack);
      }
      return Promise.resolve();
    } catch (e) {
      return Promise.reject(`websocket send error: ${e}`);
    }
  }
  onClose(code, reason) {
    return __awaiter(this, void 0, void 0, function* () {
      const closeReason = `Connection closed. ${code}: ${reason}`;
      this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_7__.ConnectionState.Disconnected;
      this.privDisconnectDeferral.resolve();
      yield this.privReceivingMessageQueue.drainAndDispose(() => {
        // TODO: Events for these ?
        // Logger.instance.onEvent(new LoggingEvent(LogType.Warning, null, `Failed to process received message. Reason: ${closeReason}, Message: ${JSON.stringify(pendingReceiveItem)}`));
      }, closeReason);
      yield this.privSendMessageQueue.drainAndDispose(pendingSendItem => {
        pendingSendItem.sendStatusDeferral.reject(closeReason);
      }, closeReason);
    });
  }
  processSendQueue() {
    return __awaiter(this, void 0, void 0, function* () {
      while (true) {
        const itemToSend = this.privSendMessageQueue.dequeue();
        const sendItem = yield itemToSend;
        // indicates we are draining the queue and it came with no message;
        if (!sendItem) {
          return;
        }
        try {
          yield this.sendRawMessage(sendItem);
          sendItem.sendStatusDeferral.resolve();
        } catch (sendError) {
          sendItem.sendStatusDeferral.reject(sendError);
        }
      }
    });
  }
  onEvent(event) {
    this.privConnectionEvents.onEvent(event);
    _common_Exports__WEBPACK_IMPORTED_MODULE_11__.Events.instance.onEvent(event);
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  getAgent() {
    // eslint-disable-next-line @typescript-eslint/unbound-method
    const agent = new (agent_base__WEBPACK_IMPORTED_MODULE_2___default().Agent)(this.createConnection);
    if (this.proxyInfo !== undefined && this.proxyInfo.HostName !== undefined && this.proxyInfo.Port > 0) {
      agent.proxyInfo = this.proxyInfo;
    }
    return agent;
  }
  static GetProxyAgent(proxyInfo) {
    const httpProxyOptions = {
      host: proxyInfo.HostName,
      port: proxyInfo.Port
    };
    if (!!proxyInfo.UserName) {
      httpProxyOptions.headers = {
        "Proxy-Authentication": "Basic " + new Buffer(`${proxyInfo.UserName}:${proxyInfo.Password === undefined ? "" : proxyInfo.Password}`).toString("base64")
      };
    } else {
      httpProxyOptions.headers = {};
    }
    httpProxyOptions.headers.requestOCSP = "true";
    const httpProxyAgent = new (https_proxy_agent__WEBPACK_IMPORTED_MODULE_3___default())(httpProxyOptions);
    return httpProxyAgent;
  }
  createConnection(request, options) {
    let socketPromise;
    options = Object.assign(Object.assign({}, options), {
      requestOCSP: true,
      servername: options.host
    });
    if (!!this.proxyInfo) {
      const httpProxyAgent = WebsocketMessageAdapter.GetProxyAgent(this.proxyInfo);
      const baseAgent = httpProxyAgent;
      socketPromise = new Promise((resolve, reject) => {
        baseAgent.callback(request, options, (error, socket) => {
          if (!!error) {
            reject(error);
          } else {
            resolve(socket);
          }
        });
      });
    } else {
      if (!!options.secureEndpoint) {
        socketPromise = Promise.resolve(tls__WEBPACK_IMPORTED_MODULE_1__.connect(options));
      } else {
        socketPromise = Promise.resolve(net__WEBPACK_IMPORTED_MODULE_0__.connect(options));
      }
    }
    return socketPromise;
  }
  get isWebsocketOpen() {
    return this.privWebsocketClient && this.privWebsocketClient.readyState === this.privWebsocketClient.OPEN;
  }
}
WebsocketMessageAdapter.forceNpmWebSocket = false;

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AddedLmIntent: () => (/* binding */ AddedLmIntent)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * @class AddedLmIntent
 */
// eslint-disable-next-line max-classes-per-file
class AddedLmIntent {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param modelImpl - The model.
   * @param intentName - The intent name.
   */
  constructor(modelImpl, intentName) {
    this.modelImpl = modelImpl;
    this.intentName = intentName;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AgentConfig: () => (/* binding */ AgentConfig)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Represents the JSON used in the agent.config message sent to the speech service.
 */
class AgentConfig {
  toJsonString() {
    return JSON.stringify(this.iPrivConfig);
  }
  get() {
    return this.iPrivConfig;
  }
  /**
   * Setter for the agent.config object.
   * @param value a JSON serializable object.
   */
  set(value) {
    this.iPrivConfig = value;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js":
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js ***!
  \****************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CognitiveSubscriptionKeyAuthentication: () => (/* binding */ CognitiveSubscriptionKeyAuthentication)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./IAuthentication */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



/**
 * @class
 */
class CognitiveSubscriptionKeyAuthentication {
  /**
   * Creates and initializes an instance of the CognitiveSubscriptionKeyAuthentication class.
   * @constructor
   * @param {string} subscriptionKey - The subscription key
   */
  constructor(subscriptionKey) {
    if (!subscriptionKey) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("subscriptionKey");
    }
    this.privAuthInfo = new _IAuthentication__WEBPACK_IMPORTED_MODULE_1__.AuthInfo(_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.AuthKey, subscriptionKey);
  }
  /**
   * Fetches the subscription key.
   * @member
   * @function
   * @public
   * @param {string} authFetchEventId - The id to fetch.
   */
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  fetch(authFetchEventId) {
    return Promise.resolve(this.privAuthInfo);
  }
  /**
   * Fetches the subscription key.
   * @member
   * @function
   * @public
   * @param {string} authFetchEventId - The id to fetch.
   */
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  fetchOnExpiry(authFetchEventId) {
    return Promise.resolve(this.privAuthInfo);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CognitiveTokenAuthentication: () => (/* binding */ CognitiveTokenAuthentication)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./IAuthentication */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



class CognitiveTokenAuthentication {
  constructor(fetchCallback, fetchOnExpiryCallback) {
    if (!fetchCallback) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("fetchCallback");
    }
    if (!fetchOnExpiryCallback) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("fetchOnExpiryCallback");
    }
    this.privFetchCallback = fetchCallback;
    this.privFetchOnExpiryCallback = fetchOnExpiryCallback;
  }
  fetch(authFetchEventId) {
    return this.privFetchCallback(authFetchEventId).then(token => new _IAuthentication__WEBPACK_IMPORTED_MODULE_1__.AuthInfo(_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.Authorization, token === undefined ? undefined : CognitiveTokenAuthentication.privTokenPrefix + token));
  }
  fetchOnExpiry(authFetchEventId) {
    return this.privFetchOnExpiryCallback(authFetchEventId).then(token => new _IAuthentication__WEBPACK_IMPORTED_MODULE_1__.AuthInfo(_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.Authorization, token === undefined ? undefined : CognitiveTokenAuthentication.privTokenPrefix + token));
  }
}
CognitiveTokenAuthentication.privTokenPrefix = "bearer ";

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConnectionFactoryBase: () => (/* binding */ ConnectionFactoryBase)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./QueryParameterNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



class ConnectionFactoryBase {
  static getHostSuffix(region) {
    if (!!region) {
      if (region.toLowerCase().startsWith("china")) {
        return ".azure.cn";
      }
      if (region.toLowerCase().startsWith("usgov")) {
        return ".azure.us";
      }
    }
    return ".microsoft.com";
  }
  setCommonUrlParams(config, queryParams, endpoint) {
    const propertyIdToParameterMap = new Map([[_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.Speech_SegmentationSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.SegmentationSilenceTimeoutMs], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_EnableAudioLogging, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.EnableAudioLogging], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.EndSilenceTimeoutMs], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.InitialSilenceTimeoutMs], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_PostProcessingOption, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.Postprocessing], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_ProfanityOption, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.Profanity], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.EnableWordLevelTimestamps], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_StablePartialResultThreshold, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.StableIntermediateThreshold]]);
    propertyIdToParameterMap.forEach((parameterName, propertyId) => {
      this.setUrlParameter(propertyId, parameterName, config, queryParams, endpoint);
    });
    const serviceProperties = JSON.parse(config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.ServicePropertiesPropertyName, "{}"));
    Object.keys(serviceProperties).forEach(value => {
      queryParams[value] = serviceProperties[value];
    });
  }
  setUrlParameter(propId, parameterName, config, queryParams, endpoint) {
    const value = config.parameters.getProperty(propId, undefined);
    // FIXME: The .search() check will incorrectly match parameter name anywhere in the string
    //        including e.g. the path portion, or even as a substring of other query parameters
    if (value && (!endpoint || endpoint.search(parameterName) === -1)) {
      queryParams[parameterName] = value.toLocaleLowerCase();
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConversationServiceRecognizer.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConversationServiceRecognizer.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationServiceRecognizer: () => (/* binding */ ConversationServiceRecognizer)
/* harmony export */ });
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js");
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};


class ConversationServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);
    this.handleSpeechPhraseMessage = textBody => __awaiter(this, void 0, void 0, function* () {
      return this.handleSpeechPhrase(textBody);
    });
    this.handleSpeechHypothesisMessage = textBody => this.handleSpeechHypothesis(textBody);
  }
  processTypeSpecificMessages(connectionMessage) {
    void connectionMessage;
    return;
  }
  handleRecognizedCallback(result, offset, sessionId) {
    void result;
    void offset;
    void sessionId;
    return;
  }
  handleRecognizingCallback(result, duration, sessionId) {
    void result;
    void duration;
    void sessionId;
    return;
  }
  processSpeechMessages(connectionMessage) {
    return __awaiter(this, void 0, void 0, function* () {
      let processed = false;
      switch (connectionMessage.path.toLowerCase()) {
        case "speech.hypothesis":
        case "speech.fragment":
          if (!!this.handleSpeechHypothesisMessage) {
            this.handleSpeechHypothesisMessage(connectionMessage.textBody);
          }
          processed = true;
          break;
        case "speech.phrase":
          if (!!this.handleSpeechPhraseMessage) {
            yield this.handleSpeechPhraseMessage(connectionMessage.textBody);
          }
          processed = true;
          break;
        default:
          break;
      }
      return processed;
    });
  }
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    // Implementing to allow inheritance
    void sessionId;
    void requestId;
    void cancellationReason;
    void errorCode;
    void error;
  }
  handleSpeechPhrase(textBody) {
    return __awaiter(this, void 0, void 0, function* () {
      const simple = _Exports__WEBPACK_IMPORTED_MODULE_1__.SimpleSpeechPhrase.fromJSON(textBody);
      const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_2__.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);
      let result;
      const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyCollection();
      resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceResponse_JsonResult, textBody);
      const simpleOffset = simple.Offset + this.privRequestSession.currentTurnAudioOffset;
      let offset = simpleOffset;
      this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);
      if (_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled === resultReason) {
        const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_2__.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);
        const cancellationErrorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);
        yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, _Exports__WEBPACK_IMPORTED_MODULE_2__.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));
      } else {
        if (!(this.privRequestSession.isSpeechEnded && resultReason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.NoMatch && simple.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_6__.RecognitionStatus.InitialSilenceTimeout)) {
          if (this.privRecognizerConfig.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_7__.OutputFormatPropertyName) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat.Simple]) {
            result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simpleOffset, simple.Language, simple.LanguageDetectionConfidence, simple.SpeakerId, undefined, textBody, resultProps);
          } else {
            const detailed = _Exports__WEBPACK_IMPORTED_MODULE_10__.DetailedSpeechPhrase.fromJSON(textBody);
            const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;
            const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);
            result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, detailed.Text, detailed.Duration, totalOffset, detailed.Language, detailed.LanguageDetectionConfidence, detailed.SpeakerId, undefined, offsetCorrectedJson, resultProps);
            offset = result.offset;
          }
          this.handleRecognizedCallback(result, offset, this.privRequestSession.sessionId);
        }
      }
    });
  }
  handleSpeechHypothesis(textBody) {
    const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_11__.SpeechHypothesis.fromJSON(textBody);
    const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;
    const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyCollection();
    resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceResponse_JsonResult, textBody);
    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechRecognitionResult(this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, hypothesis.SpeakerId, undefined, textBody, resultProps);
    this.privRequestSession.onHypothesis(offset);
    this.handleRecognizingCallback(result, hypothesis.Duration, this.privRequestSession.sessionId);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   DialogConnectionFactory: () => (/* binding */ DialogConnectionFactory)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js");
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./QueryParameterNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */







class DialogConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {
  create(config, authInfo, connectionId) {
    const applicationId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.Conversation_ApplicationId, "");
    const dialogType = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.Conversation_DialogType);
    const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region);
    const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage, "en-US");
    const requestTurnStatus = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.Conversation_Request_Bot_Status_Messages, "true");
    const queryParams = {};
    queryParams[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ConnectionId] = connectionId;
    queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.Format] = config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormatPropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Simple]).toLowerCase();
    queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.Language] = language;
    queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.RequestBotStatusMessages] = requestTurnStatus;
    if (applicationId) {
      queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.BotId] = applicationId;
      if (dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.DialogServiceConfig.DialogTypes.CustomCommands) {
        queryParams[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.CustomCommandsAppId] = applicationId;
      }
    }
    const resourceInfix = dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.DialogServiceConfig.DialogTypes.CustomCommands ? "commands/" : "";
    const version = dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.DialogServiceConfig.DialogTypes.CustomCommands ? "v1" : dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.DialogServiceConfig.DialogTypes.BotFramework ? "v3" : "v0";
    const headers = {};
    if (authInfo.token != null && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    // The URL used for connection is chosen in a priority order of specification:
    //  1. If a custom endpoint is provided, that URL is used verbatim.
    //  2. If a custom host is provided (e.g. "wss://my.custom.endpoint.com:1123"), a URL is constructed from it.
    //  3. If no custom connection details are provided, a URL is constructed from default values.
    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint, "");
    if (!endpoint) {
      const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);
      const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, `wss://${region}.${DialogConnectionFactory.BaseUrl}${hostSuffix}`);
      const standardizedHost = host.endsWith("/") ? host : host + "/";
      endpoint = `${standardizedHost}${resourceInfix}${DialogConnectionFactory.ApiKey}/${version}`;
    }
    this.setCommonUrlParams(config, queryParams, endpoint);
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_8__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
}
DialogConnectionFactory.ApiKey = "api";
DialogConnectionFactory.BaseUrl = "convai.speech";

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   DialogServiceAdapter: () => (/* binding */ DialogServiceAdapter)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js");
/* harmony import */ var _common_DialogEvents__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ../common/DialogEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js");
/* harmony import */ var _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js");
/* harmony import */ var _DialogServiceTurnStateManager__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./DialogServiceTurnStateManager */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js");
/* harmony import */ var _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js");
/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};









class DialogServiceAdapter extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector);
    this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();
    this.privDialogServiceConnector = dialogServiceConnector;
    this.receiveMessageOverride = () => this.receiveDialogMessageOverride();
    this.privTurnStateManager = new _DialogServiceTurnStateManager__WEBPACK_IMPORTED_MODULE_2__.DialogServiceTurnStateManager();
    this.recognizeOverride = (recoMode, successCallback, errorCallback) => this.listenOnce(recoMode, successCallback, errorCallback);
    this.postConnectImplOverride = connection => this.dialogConnectImpl(connection);
    this.configConnectionOverride = connection => this.configConnection(connection);
    this.disconnectOverride = () => this.privDisconnect();
    this.privDialogAudioSource = audioSource;
    this.agentConfigSent = false;
    this.privLastResult = null;
    this.connectionEvents.attach(connectionEvent => {
      if (connectionEvent.name === "ConnectionClosedEvent") {
        this.terminateMessageLoop = true;
      }
    });
  }
  sendMessage(message) {
    return __awaiter(this, void 0, void 0, function* () {
      const interactionGuid = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.createGuid)();
      const requestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.createNoDashGuid)();
      const agentMessage = {
        context: {
          interactionId: interactionGuid
        },
        // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
        messagePayload: JSON.parse(message),
        version: 0.5
      };
      const agentMessageJson = JSON.stringify(agentMessage);
      const connection = yield this.fetchConnection();
      yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_5__.MessageType.Text, "agent", requestId, "application/json", agentMessageJson));
    });
  }
  privDisconnect() {
    return __awaiter(this, void 0, void 0, function* () {
      yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode.NoError, "Disconnecting");
      this.terminateMessageLoop = true;
      this.agentConfigSent = false;
      return;
    });
  }
  processTypeSpecificMessages(connectionMessage) {
    const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.PropertyCollection();
    if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_5__.MessageType.Text) {
      resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
    }
    let result;
    let processed;
    switch (connectionMessage.path.toLowerCase()) {
      case "speech.phrase":
        const speechPhrase = _Exports__WEBPACK_IMPORTED_MODULE_10__.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);
        this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + speechPhrase.Offset + speechPhrase.Duration);
        if (speechPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_11__.RecognitionStatus.TooManyRequests && speechPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_11__.RecognitionStatus.Error) {
          const args = this.fireEventForResult(speechPhrase, resultProps);
          this.privLastResult = args.result;
          if (!!this.privDialogServiceConnector.recognized) {
            try {
              this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, args);
              /* eslint-disable no-empty */
            } catch (error) {
              // Not going to let errors in the event handler
              // trip things up.
            }
          }
        }
        processed = true;
        break;
      case "speech.hypothesis":
        const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_12__.SpeechHypothesis.fromJSON(connectionMessage.textBody);
        const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;
        result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult(this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined, undefined, connectionMessage.textBody, resultProps);
        this.privRequestSession.onHypothesis(offset);
        const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechRecognitionEventArgs(result, hypothesis.Duration, this.privRequestSession.sessionId);
        if (!!this.privDialogServiceConnector.recognizing) {
          try {
            this.privDialogServiceConnector.recognizing(this.privDialogServiceConnector, ev);
            /* eslint-disable no-empty */
          } catch (error) {
            // Not going to let errors in the event handler
            // trip things up.
          }
        }
        processed = true;
        break;
      case "speech.keyword":
        const keyword = _Exports__WEBPACK_IMPORTED_MODULE_16__.SpeechKeyword.fromJSON(connectionMessage.textBody);
        result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult(this.privRequestSession.requestId, keyword.Status === "Accepted" ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.ResultReason.RecognizedKeyword : _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.ResultReason.NoMatch, keyword.Text, keyword.Duration, keyword.Offset, undefined, undefined, undefined, undefined, connectionMessage.textBody, resultProps);
        if (keyword.Status !== "Accepted") {
          this.privLastResult = result;
        }
        const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechRecognitionEventArgs(result, result.duration, result.resultId);
        if (!!this.privDialogServiceConnector.recognized) {
          try {
            this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, event);
            /* eslint-disable no-empty */
          } catch (error) {
            // Not going to let errors in the event handler
            // trip things up.
          }
        }
        processed = true;
        break;
      case "audio":
        {
          const audioRequestId = connectionMessage.requestId.toUpperCase();
          const turn = this.privTurnStateManager.GetTurn(audioRequestId);
          try {
            // Empty binary message signals end of stream.
            if (!connectionMessage.binaryBody) {
              turn.endAudioStream();
            } else {
              turn.audioStream.write(connectionMessage.binaryBody);
            }
          } catch (error) {
            // Not going to let errors in the event handler
            // trip things up.
          }
        }
        processed = true;
        break;
      case "response":
        {
          this.handleResponseMessage(connectionMessage);
        }
        processed = true;
        break;
      default:
        break;
    }
    const defferal = new _common_Exports__WEBPACK_IMPORTED_MODULE_17__.Deferred();
    defferal.resolve(processed);
    return defferal.promise;
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    return __awaiter(this, void 0, void 0, function* () {
      this.terminateMessageLoop = true;
      if (!!this.privRequestSession.isRecognizing) {
        yield this.privRequestSession.onStopRecognizing();
      }
      if (!!this.privDialogServiceConnector.canceled) {
        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.PropertyCollection();
        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_18__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode[errorCode]);
        const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_19__.SpeechRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);
        try {
          this.privDialogServiceConnector.canceled(this.privDialogServiceConnector, cancelEvent);
          /* eslint-disable no-empty */
        } catch (_a) {}
        if (!!this.privSuccessCallback) {
          const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult(undefined,
          // ResultId
          _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.ResultReason.Canceled, undefined,
          // Text
          undefined,
          // Duration
          undefined,
          // Offset
          undefined,
          // Language
          undefined,
          // Language Detection Confidence
          undefined,
          // Speaker Id
          error, undefined,
          // Json
          properties);
          try {
            this.privSuccessCallback(result);
            this.privSuccessCallback = undefined;
            /* eslint-disable no-empty */
          } catch (_b) {}
        }
      }
    });
  }
  listenOnce(recoMode, successCallback, errorCallback) {
    return __awaiter(this, void 0, void 0, function* () {
      this.privRecognizerConfig.recognitionMode = recoMode;
      this.privSuccessCallback = successCallback;
      this.privErrorCallback = errorCallback;
      this.privRequestSession.startNewRecognition();
      this.privRequestSession.listenForServiceTelemetry(this.privDialogAudioSource.events);
      this.privRecognizerConfig.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.Speech_SessionId, this.privRequestSession.sessionId);
      // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().
      const conPromise = this.connectImpl();
      const preAudioPromise = this.sendPreAudioMessages();
      const node = yield this.privDialogAudioSource.attach(this.privRequestSession.audioNodeId);
      const format = yield this.privDialogAudioSource.format;
      const deviceInfo = yield this.privDialogAudioSource.deviceInfo;
      const audioNode = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_20__.ReplayableAudioNode(node, format.avgBytesPerSec);
      yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);
      this.privRecognizerConfig.SpeechServiceConfig.Context.audio = {
        source: deviceInfo
      };
      try {
        yield conPromise;
        yield preAudioPromise;
      } catch (error) {
        yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode.ConnectionFailure, error);
        return Promise.resolve();
      }
      const sessionStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_21__.SessionEventArgs(this.privRequestSession.sessionId);
      if (!!this.privRecognizer.sessionStarted) {
        this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);
      }
      const audioSendPromise = this.sendAudio(audioNode);
      // /* eslint-disable no-empty */
      audioSendPromise.then(() => {}, error => __awaiter(this, void 0, void 0, function* () {
        yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode.RuntimeError, error);
      }));
    });
  }
  // Establishes a websocket connection to the end point.
  dialogConnectImpl(connection) {
    this.privConnectionLoop = this.startMessageLoop();
    return connection;
  }
  receiveDialogMessageOverride() {
    // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages
    const communicationCustodian = new _common_Exports__WEBPACK_IMPORTED_MODULE_17__.Deferred();
    const loop = () => __awaiter(this, void 0, void 0, function* () {
      try {
        const isDisposed = this.isDisposed();
        const terminateMessageLoop = !this.isDisposed() && this.terminateMessageLoop;
        if (isDisposed || terminateMessageLoop) {
          // We're done.
          communicationCustodian.resolve(undefined);
          return;
        }
        const connection = yield this.fetchConnection();
        const message = yield connection.read();
        if (!message) {
          return loop();
        }
        const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__.SpeechConnectionMessage.fromConnectionMessage(message);
        switch (connectionMessage.path.toLowerCase()) {
          case "turn.start":
            {
              const turnRequestId = connectionMessage.requestId.toUpperCase();
              const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();
              // turn started by the service
              if (turnRequestId !== audioSessionReqId) {
                this.privTurnStateManager.StartTurn(turnRequestId);
              } else {
                this.privRequestSession.onServiceTurnStartResponse();
              }
            }
            break;
          case "speech.startdetected":
            const speechStartDetected = _Exports__WEBPACK_IMPORTED_MODULE_22__.SpeechDetected.fromJSON(connectionMessage.textBody);
            const speechStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_23__.RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);
            if (!!this.privRecognizer.speechStartDetected) {
              this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);
            }
            break;
          case "speech.enddetected":
            let json;
            if (connectionMessage.textBody.length > 0) {
              json = connectionMessage.textBody;
            } else {
              // If the request was empty, the JSON returned is empty.
              json = "{ Offset: 0 }";
            }
            const speechStopDetected = _Exports__WEBPACK_IMPORTED_MODULE_22__.SpeechDetected.fromJSON(json);
            this.privRequestSession.onServiceRecognized(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset);
            const speechStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_23__.RecognitionEventArgs(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);
            if (!!this.privRecognizer.speechEndDetected) {
              this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);
            }
            break;
          case "turn.end":
            {
              const turnEndRequestId = connectionMessage.requestId.toUpperCase();
              const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();
              // turn started by the service
              if (turnEndRequestId !== audioSessionReqId) {
                this.privTurnStateManager.CompleteTurn(turnEndRequestId);
              } else {
                // Audio session turn
                const sessionStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_21__.SessionEventArgs(this.privRequestSession.sessionId);
                yield this.privRequestSession.onServiceTurnEndResponse(false);
                if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {
                  if (!!this.privRecognizer.sessionStopped) {
                    this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);
                  }
                }
                // report result to promise.
                if (!!this.privSuccessCallback && this.privLastResult) {
                  try {
                    this.privSuccessCallback(this.privLastResult);
                    this.privLastResult = null;
                  } catch (e) {
                    if (!!this.privErrorCallback) {
                      this.privErrorCallback(e);
                    }
                  }
                  // Only invoke the call back once.
                  // and if it's successful don't invoke the
                  // error after that.
                  this.privSuccessCallback = undefined;
                  this.privErrorCallback = undefined;
                }
              }
            }
            break;
          default:
            try {
              const processed = yield this.processTypeSpecificMessages(connectionMessage);
              if (!processed) {
                if (!!this.serviceEvents) {
                  this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_24__.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));
                }
              }
            } catch (e) {
              //
            }
        }
        const ret = loop();
        return ret;
      } catch (error) {
        this.terminateMessageLoop = true;
        communicationCustodian.resolve();
      }
    });
    loop().catch(reason => {
      _common_Exports__WEBPACK_IMPORTED_MODULE_25__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_26__.BackgroundEvent(reason));
    });
    return communicationCustodian.promise;
  }
  startMessageLoop() {
    return __awaiter(this, void 0, void 0, function* () {
      this.terminateMessageLoop = false;
      try {
        yield this.receiveDialogMessageOverride();
      } catch (error) {
        yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode.RuntimeError, error);
      }
      return Promise.resolve();
    });
  }
  // Takes an established websocket connection to the endpoint and sends speech configuration information.
  configConnection(connection) {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.terminateMessageLoop) {
        this.terminateMessageLoop = false;
        return Promise.reject("Connection to service terminated.");
      }
      yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());
      yield this.sendAgentConfig(connection);
      return connection;
    });
  }
  sendPreAudioMessages() {
    return __awaiter(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      this.addKeywordContextData();
      yield this.sendSpeechContext(connection, true);
      yield this.sendAgentContext(connection);
      yield this.sendWaveHeader(connection);
    });
  }
  sendAgentConfig(connection) {
    if (this.agentConfig && !this.agentConfigSent) {
      if (this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.Conversation_DialogType) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_27__.DialogServiceConfig.DialogTypes.CustomCommands) {
        const config = this.agentConfig.get();
        config.botInfo.commandsCulture = this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.SpeechServiceConnection_RecoLanguage, "en-us");
        this.agentConfig.set(config);
      }
      this.onEvent(new _common_DialogEvents__WEBPACK_IMPORTED_MODULE_28__.SendingAgentContextMessageEvent(this.agentConfig));
      const agentConfigJson = this.agentConfig.toJsonString();
      // guard against sending this multiple times on one connection
      this.agentConfigSent = true;
      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_5__.MessageType.Text, "agent.config", this.privRequestSession.requestId, "application/json", agentConfigJson));
    }
    return;
  }
  sendAgentContext(connection) {
    const guid = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.createGuid)();
    const speechActivityTemplate = this.privDialogServiceConnector.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.Conversation_Speech_Activity_Template);
    const agentContext = {
      channelData: "",
      context: {
        interactionId: guid
      },
      messagePayload: typeof speechActivityTemplate === undefined ? undefined : speechActivityTemplate,
      version: 0.5
    };
    const agentContextJson = JSON.stringify(agentContext);
    return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_5__.MessageType.Text, "speech.agent.context", this.privRequestSession.requestId, "application/json", agentContextJson));
  }
  fireEventForResult(serviceResult, properties) {
    const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_29__.EnumTranslation.implTranslateRecognitionResult(serviceResult.RecognitionStatus);
    const offset = serviceResult.Offset + this.privRequestSession.currentTurnAudioOffset;
    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, serviceResult.DisplayText, serviceResult.Duration, offset, serviceResult.Language, serviceResult.LanguageDetectionConfidence, undefined, undefined, JSON.stringify(serviceResult), properties);
    const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechRecognitionEventArgs(result, offset, this.privRequestSession.sessionId);
    return ev;
  }
  handleResponseMessage(responseMessage) {
    // "response" messages can contain either "message" (activity) or "MessageStatus" data. Fire the appropriate
    // event according to the message type that's specified.
    const responsePayload = JSON.parse(responseMessage.textBody);
    switch (responsePayload.messageType.toLowerCase()) {
      case "message":
        const responseRequestId = responseMessage.requestId.toUpperCase();
        const activityPayload = _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_30__.ActivityPayloadResponse.fromJSON(responseMessage.textBody);
        const turn = this.privTurnStateManager.GetTurn(responseRequestId);
        // update the conversation Id
        if (activityPayload.conversationId) {
          const updateAgentConfig = this.agentConfig.get();
          updateAgentConfig.botInfo.conversationId = activityPayload.conversationId;
          this.agentConfig.set(updateAgentConfig);
        }
        const pullAudioOutputStream = turn.processActivityPayload(activityPayload, _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_31__.AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(this.privDialogServiceConnector.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)));
        const activity = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_32__.ActivityReceivedEventArgs(activityPayload.messagePayload, pullAudioOutputStream);
        if (!!this.privDialogServiceConnector.activityReceived) {
          try {
            this.privDialogServiceConnector.activityReceived(this.privDialogServiceConnector, activity);
            /* eslint-disable-next-line no-empty */
          } catch (error) {
            // Not going to let errors in the event handler
            // trip things up.
          }
        }
        break;
      case "messagestatus":
        if (!!this.privDialogServiceConnector.turnStatusReceived) {
          try {
            this.privDialogServiceConnector.turnStatusReceived(this.privDialogServiceConnector, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_33__.TurnStatusReceivedEventArgs(responseMessage.textBody));
            /* eslint-disable-next-line no-empty */
          } catch (error) {
            // Not going to let errors in the event handler
            // trip things up.
          }
        }
        break;
      default:
        _common_Exports__WEBPACK_IMPORTED_MODULE_25__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_26__.BackgroundEvent(`Unexpected response of type ${responsePayload.messageType}. Ignoring.`));
        break;
    }
  }
  onEvent(event) {
    this.privEvents.onEvent(event);
    _common_Exports__WEBPACK_IMPORTED_MODULE_25__.Events.instance.onEvent(event);
  }
  addKeywordContextData() {
    const keywordPropertyValue = this.privRecognizerConfig.parameters.getProperty("SPEECH-KeywordsToDetect");
    if (keywordPropertyValue === undefined) {
      return;
    }
    const keywordOffsetPropertyValue = this.privRecognizerConfig.parameters.getProperty("SPEECH-KeywordsToDetect-Offsets");
    const keywordDurationPropertyValue = this.privRecognizerConfig.parameters.getProperty("SPEECH-KeywordsToDetect-Durations");
    const keywords = keywordPropertyValue.split(";");
    const keywordOffsets = keywordOffsetPropertyValue === undefined ? [] : keywordOffsetPropertyValue.split(";");
    const keywordDurations = keywordDurationPropertyValue === undefined ? [] : keywordDurationPropertyValue.split(";");
    const keywordDefinitionArray = [];
    for (let i = 0; i < keywords.length; i++) {
      const definition = {};
      definition.text = keywords[i];
      if (i < keywordOffsets.length) {
        definition.offset = Number(keywordOffsets[i]);
      }
      if (i < keywordDurations.length) {
        definition.duration = Number(keywordDurations[i]);
      }
      keywordDefinitionArray.push(definition);
    }
    this.speechContext.setSection("invocationSource", "VoiceActivationWithKeyword");
    this.speechContext.setSection("keywordDetection", [{
      clientDetectedKeywords: keywordDefinitionArray,
      onReject: {
        action: "EndOfTurn"
      },
      type: "startTrigger"
    }]);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   DialogServiceTurnState: () => (/* binding */ DialogServiceTurnState)
/* harmony export */ });
/* harmony import */ var _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js");
/* harmony import */ var _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js");
/* harmony import */ var _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



class DialogServiceTurnState {
  constructor(manager, requestId) {
    this.privRequestId = requestId;
    this.privIsCompleted = false;
    this.privAudioStream = null;
    this.privTurnManager = manager;
    this.resetTurnEndTimeout();
  }
  get audioStream() {
    // Called when is needed to stream.
    this.resetTurnEndTimeout();
    return this.privAudioStream;
  }
  processActivityPayload(payload, audioFormat) {
    if (payload.messageDataStreamType === _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_0__.MessageDataStreamType.TextToSpeechAudio) {
      this.privAudioStream = _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__.AudioOutputStream.createPullStream();
      this.privAudioStream.format = audioFormat !== undefined ? audioFormat : _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__.AudioOutputFormatImpl.getDefaultOutputFormat();
    }
    return this.privAudioStream;
  }
  endAudioStream() {
    if (this.privAudioStream !== null && !this.privAudioStream.isClosed) {
      this.privAudioStream.close();
    }
  }
  complete() {
    if (this.privTimeoutToken !== undefined) {
      // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
      clearTimeout(this.privTimeoutToken);
    }
    this.endAudioStream();
  }
  resetTurnEndTimeout() {
    if (this.privTimeoutToken !== undefined) {
      // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
      clearTimeout(this.privTimeoutToken);
    }
    this.privTimeoutToken = setTimeout(() => {
      this.privTurnManager.CompleteTurn(this.privRequestId);
      return;
    }, 2000);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   DialogServiceTurnStateManager: () => (/* binding */ DialogServiceTurnStateManager)
/* harmony export */ });
/* harmony import */ var _common_Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _DialogServiceTurnState__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DialogServiceTurnState */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


class DialogServiceTurnStateManager {
  constructor() {
    this.privTurnMap = new Map();
    return;
  }
  StartTurn(id) {
    if (this.privTurnMap.has(id)) {
      throw new _common_Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError("Service error: There is already a turn with id:" + id);
    }
    const turnState = new _DialogServiceTurnState__WEBPACK_IMPORTED_MODULE_1__.DialogServiceTurnState(this, id);
    this.privTurnMap.set(id, turnState);
    return this.privTurnMap.get(id);
  }
  GetTurn(id) {
    return this.privTurnMap.get(id);
  }
  CompleteTurn(id) {
    if (!this.privTurnMap.has(id)) {
      throw new _common_Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError("Service error: Received turn end for an unknown turn id:" + id);
    }
    const turnState = this.privTurnMap.get(id);
    turnState.complete();
    this.privTurnMap.delete(id);
    return turnState;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   DynamicGrammarBuilder: () => (/* binding */ DynamicGrammarBuilder)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Responsible for building the object to be sent to the speech service to support dynamic grammars.
 * @class DynamicGrammarBuilder
 */
class DynamicGrammarBuilder {
  // Adds one more reference phrases to the dynamic grammar to send.
  // All added phrases are generic phrases.
  addPhrase(phrase) {
    if (!this.privPhrases) {
      this.privPhrases = [];
    }
    if (phrase instanceof Array) {
      this.privPhrases = this.privPhrases.concat(phrase);
    } else {
      this.privPhrases.push(phrase);
    }
  }
  // Clears all phrases stored in the current object.
  clearPhrases() {
    this.privPhrases = undefined;
  }
  // Adds one or more reference grammars to the current grammar.
  addReferenceGrammar(grammar) {
    if (!this.privGrammars) {
      this.privGrammars = [];
    }
    if (grammar instanceof Array) {
      this.privGrammars = this.privGrammars.concat(grammar);
    } else {
      this.privGrammars.push(grammar);
    }
  }
  // clears all grammars stored on the recognizer.
  clearGrammars() {
    this.privGrammars = undefined;
  }
  // Generates an object that represents the dynamic grammar used by the Speech Service.
  // This is done by building an object with the correct layout based on the phrases and reference grammars added to this instance
  // of a DynamicGrammarBuilder
  generateGrammarObject() {
    if (this.privGrammars === undefined && this.privPhrases === undefined) {
      return undefined;
    }
    const retObj = {};
    retObj.ReferenceGrammars = this.privGrammars;
    if (undefined !== this.privPhrases && 0 !== this.privPhrases.length) {
      const retPhrases = [];
      this.privPhrases.forEach(value => {
        retPhrases.push({
          Text: value
        });
      });
      retObj.Groups = [{
        Type: "Generic",
        Items: retPhrases
      }];
    }
    return retObj;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js ***!
  \**************************************************************************************************************************/
/***/ (() => {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   EnumTranslation: () => (/* binding */ EnumTranslation)
/* harmony export */ });
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


class EnumTranslation {
  static implTranslateRecognitionResult(recognitionStatus) {
    let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.Canceled;
    switch (recognitionStatus) {
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Success:
        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.RecognizedSpeech;
        break;
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.NoMatch:
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.InitialSilenceTimeout:
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BabbleTimeout:
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.EndOfDictation:
        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.NoMatch;
        break;
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Error:
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BadRequest:
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Forbidden:
      default:
        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.Canceled;
        break;
    }
    return reason;
  }
  static implTranslateCancelResult(recognitionStatus) {
    let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationReason.EndOfStream;
    switch (recognitionStatus) {
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Success:
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.EndOfDictation:
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.NoMatch:
        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationReason.EndOfStream;
        break;
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.InitialSilenceTimeout:
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BabbleTimeout:
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Error:
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BadRequest:
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Forbidden:
      default:
        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationReason.Error;
        break;
    }
    return reason;
  }
  static implTranslateCancelErrorCode(recognitionStatus) {
    let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.NoError;
    switch (recognitionStatus) {
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Error:
        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.ServiceError;
        break;
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.TooManyRequests:
        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.TooManyRequests;
        break;
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BadRequest:
        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.BadRequestParameters;
        break;
      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Forbidden:
        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.Forbidden;
        break;
      default:
        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.NoError;
        break;
    }
    return reason;
  }
  static implTranslateErrorDetails(cancellationErrorCode) {
    let errorDetails = "The speech service encountered an internal error and could not continue.";
    switch (cancellationErrorCode) {
      case _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.Forbidden:
        errorDetails = "The recognizer is using a free subscription that ran out of quota.";
        break;
      case _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.BadRequestParameters:
        errorDetails = "Invalid parameter or unsupported audio format in the request.";
        break;
      case _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.TooManyRequests:
        errorDetails = "The number of parallel requests exceeded the number of allowed concurrent transcriptions.";
        break;
      default:
        break;
    }
    return errorDetails;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AddedLmIntent: () => (/* reexport safe */ _AddedLmIntent__WEBPACK_IMPORTED_MODULE_30__.AddedLmIntent),
/* harmony export */   AgentConfig: () => (/* reexport safe */ _AgentConfig__WEBPACK_IMPORTED_MODULE_39__.AgentConfig),
/* harmony export */   AuthInfo: () => (/* reexport safe */ _IAuthentication__WEBPACK_IMPORTED_MODULE_2__.AuthInfo),
/* harmony export */   AutoDetectSourceLanguagesOpenRangeOptionName: () => (/* binding */ AutoDetectSourceLanguagesOpenRangeOptionName),
/* harmony export */   CancellationErrorCodePropertyName: () => (/* binding */ CancellationErrorCodePropertyName),
/* harmony export */   CognitiveSubscriptionKeyAuthentication: () => (/* reexport safe */ _CognitiveSubscriptionKeyAuthentication__WEBPACK_IMPORTED_MODULE_0__.CognitiveSubscriptionKeyAuthentication),
/* harmony export */   CognitiveTokenAuthentication: () => (/* reexport safe */ _CognitiveTokenAuthentication__WEBPACK_IMPORTED_MODULE_1__.CognitiveTokenAuthentication),
/* harmony export */   ConnectingToServiceEvent: () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_7__.ConnectingToServiceEvent),
/* harmony export */   Context: () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_10__.Context),
/* harmony export */   ConversationConnectionConfig: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__.ConversationConnectionConfig),
/* harmony export */   ConversationManager: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__.ConversationManager),
/* harmony export */   ConversationReceivedTranslationEventArgs: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__.ConversationReceivedTranslationEventArgs),
/* harmony export */   ConversationRecognizerFactory: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__.ConversationRecognizerFactory),
/* harmony export */   ConversationServiceRecognizer: () => (/* reexport safe */ _ConversationServiceRecognizer__WEBPACK_IMPORTED_MODULE_9__.ConversationServiceRecognizer),
/* harmony export */   ConversationTranslatorCommandTypes: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__.ConversationTranslatorCommandTypes),
/* harmony export */   ConversationTranslatorMessageTypes: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__.ConversationTranslatorMessageTypes),
/* harmony export */   DetailedSpeechPhrase: () => (/* reexport safe */ _ServiceMessages_DetailedSpeechPhrase__WEBPACK_IMPORTED_MODULE_28__.DetailedSpeechPhrase),
/* harmony export */   Device: () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_10__.Device),
/* harmony export */   DialogServiceAdapter: () => (/* reexport safe */ _DialogServiceAdapter__WEBPACK_IMPORTED_MODULE_38__.DialogServiceAdapter),
/* harmony export */   DynamicGrammarBuilder: () => (/* reexport safe */ _DynamicGrammarBuilder__WEBPACK_IMPORTED_MODULE_36__.DynamicGrammarBuilder),
/* harmony export */   EnumTranslation: () => (/* reexport safe */ _EnumTranslation__WEBPACK_IMPORTED_MODULE_17__.EnumTranslation),
/* harmony export */   ForceDictationPropertyName: () => (/* binding */ ForceDictationPropertyName),
/* harmony export */   IntentConnectionFactory: () => (/* reexport safe */ _IntentConnectionFactory__WEBPACK_IMPORTED_MODULE_5__.IntentConnectionFactory),
/* harmony export */   IntentResponse: () => (/* reexport safe */ _ServiceMessages_IntentResponse__WEBPACK_IMPORTED_MODULE_32__.IntentResponse),
/* harmony export */   IntentServiceRecognizer: () => (/* reexport safe */ _IntentServiceRecognizer__WEBPACK_IMPORTED_MODULE_31__.IntentServiceRecognizer),
/* harmony export */   InternalParticipants: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__.InternalParticipants),
/* harmony export */   ListeningStartedEvent: () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_7__.ListeningStartedEvent),
/* harmony export */   LockRoomEventArgs: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__.LockRoomEventArgs),
/* harmony export */   MetadataType: () => (/* reexport safe */ _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_41__.MetadataType),
/* harmony export */   MuteAllEventArgs: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__.MuteAllEventArgs),
/* harmony export */   OS: () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_10__.OS),
/* harmony export */   OutputFormatPropertyName: () => (/* binding */ OutputFormatPropertyName),
/* harmony export */   ParticipantAttributeEventArgs: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__.ParticipantAttributeEventArgs),
/* harmony export */   ParticipantEventArgs: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__.ParticipantEventArgs),
/* harmony export */   ParticipantsListEventArgs: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__.ParticipantsListEventArgs),
/* harmony export */   RecognitionCompletionStatus: () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_7__.RecognitionCompletionStatus),
/* harmony export */   RecognitionEndedEvent: () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_7__.RecognitionEndedEvent),
/* harmony export */   RecognitionMode: () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_10__.RecognitionMode),
/* harmony export */   RecognitionStartedEvent: () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_7__.RecognitionStartedEvent),
/* harmony export */   RecognitionStatus: () => (/* reexport safe */ _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_18__.RecognitionStatus),
/* harmony export */   RecognitionTriggeredEvent: () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_7__.RecognitionTriggeredEvent),
/* harmony export */   RecognizerConfig: () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_10__.RecognizerConfig),
/* harmony export */   RequestSession: () => (/* reexport safe */ _RequestSession__WEBPACK_IMPORTED_MODULE_34__.RequestSession),
/* harmony export */   ServicePropertiesPropertyName: () => (/* binding */ ServicePropertiesPropertyName),
/* harmony export */   ServiceRecognizerBase: () => (/* reexport safe */ _ServiceRecognizerBase__WEBPACK_IMPORTED_MODULE_8__.ServiceRecognizerBase),
/* harmony export */   SimpleSpeechPhrase: () => (/* reexport safe */ _ServiceMessages_SimpleSpeechPhrase__WEBPACK_IMPORTED_MODULE_29__.SimpleSpeechPhrase),
/* harmony export */   SpeakerRecognitionConfig: () => (/* reexport safe */ _SpeakerRecognitionConfig__WEBPACK_IMPORTED_MODULE_47__.SpeakerRecognitionConfig),
/* harmony export */   SpeakerRecognitionConnectionFactory: () => (/* reexport safe */ _SpeakerRecognitionConnectionFactory__WEBPACK_IMPORTED_MODULE_6__.SpeakerRecognitionConnectionFactory),
/* harmony export */   SpeakerServiceRecognizer: () => (/* reexport safe */ _SpeakerServiceRecognizer__WEBPACK_IMPORTED_MODULE_48__.SpeakerServiceRecognizer),
/* harmony export */   SpeechConnectionFactory: () => (/* reexport safe */ _SpeechConnectionFactory__WEBPACK_IMPORTED_MODULE_13__.SpeechConnectionFactory),
/* harmony export */   SpeechContext: () => (/* reexport safe */ _SpeechContext__WEBPACK_IMPORTED_MODULE_35__.SpeechContext),
/* harmony export */   SpeechDetected: () => (/* reexport safe */ _ServiceMessages_SpeechDetected__WEBPACK_IMPORTED_MODULE_23__.SpeechDetected),
/* harmony export */   SpeechHypothesis: () => (/* reexport safe */ _ServiceMessages_SpeechHypothesis__WEBPACK_IMPORTED_MODULE_24__.SpeechHypothesis),
/* harmony export */   SpeechKeyword: () => (/* reexport safe */ _ServiceMessages_SpeechKeyword__WEBPACK_IMPORTED_MODULE_25__.SpeechKeyword),
/* harmony export */   SpeechRecognitionEvent: () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_7__.SpeechRecognitionEvent),
/* harmony export */   SpeechResultFormat: () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_10__.SpeechResultFormat),
/* harmony export */   SpeechServiceConfig: () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_10__.SpeechServiceConfig),
/* harmony export */   SpeechServiceRecognizer: () => (/* reexport safe */ _SpeechServiceRecognizer__WEBPACK_IMPORTED_MODULE_26__.SpeechServiceRecognizer),
/* harmony export */   SpeechSynthesisConnectionFactory: () => (/* reexport safe */ _SpeechSynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_16__.SpeechSynthesisConnectionFactory),
/* harmony export */   SynthesisAdapterBase: () => (/* reexport safe */ _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_43__.SynthesisAdapterBase),
/* harmony export */   SynthesisAudioMetadata: () => (/* reexport safe */ _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_41__.SynthesisAudioMetadata),
/* harmony export */   SynthesisContext: () => (/* reexport safe */ _SynthesisContext__WEBPACK_IMPORTED_MODULE_46__.SynthesisContext),
/* harmony export */   SynthesisRestAdapter: () => (/* reexport safe */ _SynthesisRestAdapter__WEBPACK_IMPORTED_MODULE_44__.SynthesisRestAdapter),
/* harmony export */   SynthesisServiceType: () => (/* reexport safe */ _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_45__.SynthesisServiceType),
/* harmony export */   SynthesisStatus: () => (/* reexport safe */ _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_18__.SynthesisStatus),
/* harmony export */   SynthesisTurn: () => (/* reexport safe */ _SynthesisTurn__WEBPACK_IMPORTED_MODULE_42__.SynthesisTurn),
/* harmony export */   SynthesizerConfig: () => (/* reexport safe */ _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_45__.SynthesizerConfig),
/* harmony export */   System: () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_10__.System),
/* harmony export */   TranscriberConnectionFactory: () => (/* reexport safe */ _TranscriberConnectionFactory__WEBPACK_IMPORTED_MODULE_14__.TranscriberConnectionFactory),
/* harmony export */   TranscriberRecognizer: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__.TranscriberRecognizer),
/* harmony export */   TranscriptionServiceRecognizer: () => (/* reexport safe */ _TranscriptionServiceRecognizer__WEBPACK_IMPORTED_MODULE_27__.TranscriptionServiceRecognizer),
/* harmony export */   TranslationConnectionFactory: () => (/* reexport safe */ _TranslationConnectionFactory__WEBPACK_IMPORTED_MODULE_15__.TranslationConnectionFactory),
/* harmony export */   TranslationHypothesis: () => (/* reexport safe */ _ServiceMessages_TranslationHypothesis__WEBPACK_IMPORTED_MODULE_20__.TranslationHypothesis),
/* harmony export */   TranslationPhrase: () => (/* reexport safe */ _ServiceMessages_TranslationPhrase__WEBPACK_IMPORTED_MODULE_21__.TranslationPhrase),
/* harmony export */   TranslationServiceRecognizer: () => (/* reexport safe */ _TranslationServiceRecognizer__WEBPACK_IMPORTED_MODULE_22__.TranslationServiceRecognizer),
/* harmony export */   TranslationSynthesisEnd: () => (/* reexport safe */ _ServiceMessages_TranslationSynthesisEnd__WEBPACK_IMPORTED_MODULE_19__.TranslationSynthesisEnd),
/* harmony export */   VoiceProfileConnectionFactory: () => (/* reexport safe */ _SpeakerRecognitionConnectionFactory__WEBPACK_IMPORTED_MODULE_6__.VoiceProfileConnectionFactory),
/* harmony export */   VoiceServiceRecognizer: () => (/* reexport safe */ _VoiceServiceRecognizer__WEBPACK_IMPORTED_MODULE_49__.VoiceServiceRecognizer),
/* harmony export */   WebsocketMessageFormatter: () => (/* reexport safe */ _WebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_12__.WebsocketMessageFormatter),
/* harmony export */   connectivity: () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_10__.connectivity),
/* harmony export */   type: () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_10__.type)
/* harmony export */ });
/* harmony import */ var _CognitiveSubscriptionKeyAuthentication__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CognitiveSubscriptionKeyAuthentication */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js");
/* harmony import */ var _CognitiveTokenAuthentication__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./CognitiveTokenAuthentication */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js");
/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./IAuthentication */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js");
/* harmony import */ var _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./IConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js");
/* harmony import */ var _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__);
/* harmony reexport (unknown) */ var __WEBPACK_REEXPORT_OBJECT__ = {};
/* harmony reexport (unknown) */ for(const __WEBPACK_IMPORT_KEY__ in _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__) if(["default","OutputFormatPropertyName","CancellationErrorCodePropertyName","ServicePropertiesPropertyName","ForceDictationPropertyName","AutoDetectSourceLanguagesOpenRangeOptionName","CognitiveSubscriptionKeyAuthentication","CognitiveTokenAuthentication","AuthInfo"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) __WEBPACK_REEXPORT_OBJECT__[__WEBPACK_IMPORT_KEY__] = () => _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__[__WEBPACK_IMPORT_KEY__]
/* harmony reexport (unknown) */ __webpack_require__.d(__webpack_exports__, __WEBPACK_REEXPORT_OBJECT__);
/* harmony import */ var _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ISynthesisConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js");
/* harmony import */ var _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__);
/* harmony reexport (unknown) */ var __WEBPACK_REEXPORT_OBJECT__ = {};
/* harmony reexport (unknown) */ for(const __WEBPACK_IMPORT_KEY__ in _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__) if(["default","OutputFormatPropertyName","CancellationErrorCodePropertyName","ServicePropertiesPropertyName","ForceDictationPropertyName","AutoDetectSourceLanguagesOpenRangeOptionName","CognitiveSubscriptionKeyAuthentication","CognitiveTokenAuthentication","AuthInfo"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) __WEBPACK_REEXPORT_OBJECT__[__WEBPACK_IMPORT_KEY__] = () => _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__[__WEBPACK_IMPORT_KEY__]
/* harmony reexport (unknown) */ __webpack_require__.d(__webpack_exports__, __WEBPACK_REEXPORT_OBJECT__);
/* harmony import */ var _IntentConnectionFactory__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./IntentConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js");
/* harmony import */ var _SpeakerRecognitionConnectionFactory__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./SpeakerRecognitionConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConnectionFactory.js");
/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./RecognitionEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js");
/* harmony import */ var _ServiceRecognizerBase__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./ServiceRecognizerBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js");
/* harmony import */ var _ConversationServiceRecognizer__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./ConversationServiceRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConversationServiceRecognizer.js");
/* harmony import */ var _RecognizerConfig__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./RecognizerConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./SpeechServiceInterfaces */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js");
/* harmony import */ var _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_11___default = /*#__PURE__*/__webpack_require__.n(_SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_11__);
/* harmony reexport (unknown) */ var __WEBPACK_REEXPORT_OBJECT__ = {};
/* harmony reexport (unknown) */ for(const __WEBPACK_IMPORT_KEY__ in _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_11__) if(["default","OutputFormatPropertyName","CancellationErrorCodePropertyName","ServicePropertiesPropertyName","ForceDictationPropertyName","AutoDetectSourceLanguagesOpenRangeOptionName","CognitiveSubscriptionKeyAuthentication","CognitiveTokenAuthentication","AuthInfo","IntentConnectionFactory","SpeakerRecognitionConnectionFactory","VoiceProfileConnectionFactory","ConnectingToServiceEvent","ListeningStartedEvent","RecognitionCompletionStatus","RecognitionEndedEvent","RecognitionStartedEvent","RecognitionTriggeredEvent","SpeechRecognitionEvent","ServiceRecognizerBase","ConversationServiceRecognizer","Context","Device","OS","RecognitionMode","RecognizerConfig","SpeechResultFormat","SpeechServiceConfig","System","connectivity","type"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) __WEBPACK_REEXPORT_OBJECT__[__WEBPACK_IMPORT_KEY__] = () => _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_11__[__WEBPACK_IMPORT_KEY__]
/* harmony reexport (unknown) */ __webpack_require__.d(__webpack_exports__, __WEBPACK_REEXPORT_OBJECT__);
/* harmony import */ var _WebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./WebsocketMessageFormatter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js");
/* harmony import */ var _SpeechConnectionFactory__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./SpeechConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js");
/* harmony import */ var _TranscriberConnectionFactory__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./TranscriberConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js");
/* harmony import */ var _TranslationConnectionFactory__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./TranslationConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js");
/* harmony import */ var _SpeechSynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./SpeechSynthesisConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js");
/* harmony import */ var _EnumTranslation__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./EnumTranslation */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js");
/* harmony import */ var _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./ServiceMessages/Enums */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js");
/* harmony import */ var _ServiceMessages_TranslationSynthesisEnd__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./ServiceMessages/TranslationSynthesisEnd */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js");
/* harmony import */ var _ServiceMessages_TranslationHypothesis__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./ServiceMessages/TranslationHypothesis */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js");
/* harmony import */ var _ServiceMessages_TranslationPhrase__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./ServiceMessages/TranslationPhrase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js");
/* harmony import */ var _TranslationServiceRecognizer__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./TranslationServiceRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js");
/* harmony import */ var _ServiceMessages_SpeechDetected__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./ServiceMessages/SpeechDetected */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js");
/* harmony import */ var _ServiceMessages_SpeechHypothesis__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./ServiceMessages/SpeechHypothesis */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js");
/* harmony import */ var _ServiceMessages_SpeechKeyword__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./ServiceMessages/SpeechKeyword */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js");
/* harmony import */ var _SpeechServiceRecognizer__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./SpeechServiceRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js");
/* harmony import */ var _TranscriptionServiceRecognizer__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./TranscriptionServiceRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js");
/* harmony import */ var _ServiceMessages_DetailedSpeechPhrase__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./ServiceMessages/DetailedSpeechPhrase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js");
/* harmony import */ var _ServiceMessages_SimpleSpeechPhrase__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./ServiceMessages/SimpleSpeechPhrase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js");
/* harmony import */ var _AddedLmIntent__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./AddedLmIntent */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js");
/* harmony import */ var _IntentServiceRecognizer__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./IntentServiceRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js");
/* harmony import */ var _ServiceMessages_IntentResponse__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./ServiceMessages/IntentResponse */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js");
/* harmony import */ var _ServiceMessages_SpeakerResponse__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./ServiceMessages/SpeakerResponse */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeakerResponse.js");
/* harmony import */ var _ServiceMessages_SpeakerResponse__WEBPACK_IMPORTED_MODULE_33___default = /*#__PURE__*/__webpack_require__.n(_ServiceMessages_SpeakerResponse__WEBPACK_IMPORTED_MODULE_33__);
/* harmony reexport (unknown) */ var __WEBPACK_REEXPORT_OBJECT__ = {};
/* harmony reexport (unknown) */ for(const __WEBPACK_IMPORT_KEY__ in _ServiceMessages_SpeakerResponse__WEBPACK_IMPORTED_MODULE_33__) if(["default","OutputFormatPropertyName","CancellationErrorCodePropertyName","ServicePropertiesPropertyName","ForceDictationPropertyName","AutoDetectSourceLanguagesOpenRangeOptionName","CognitiveSubscriptionKeyAuthentication","CognitiveTokenAuthentication","AuthInfo","IntentConnectionFactory","SpeakerRecognitionConnectionFactory","VoiceProfileConnectionFactory","ConnectingToServiceEvent","ListeningStartedEvent","RecognitionCompletionStatus","RecognitionEndedEvent","RecognitionStartedEvent","RecognitionTriggeredEvent","SpeechRecognitionEvent","ServiceRecognizerBase","ConversationServiceRecognizer","Context","Device","OS","RecognitionMode","RecognizerConfig","SpeechResultFormat","SpeechServiceConfig","System","connectivity","type","WebsocketMessageFormatter","SpeechConnectionFactory","TranscriberConnectionFactory","TranslationConnectionFactory","SpeechSynthesisConnectionFactory","EnumTranslation","RecognitionStatus","SynthesisStatus","TranslationSynthesisEnd","TranslationHypothesis","TranslationPhrase","TranslationServiceRecognizer","SpeechDetected","SpeechHypothesis","SpeechKeyword","SpeechServiceRecognizer","TranscriptionServiceRecognizer","DetailedSpeechPhrase","SimpleSpeechPhrase","AddedLmIntent","IntentServiceRecognizer","IntentResponse"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) __WEBPACK_REEXPORT_OBJECT__[__WEBPACK_IMPORT_KEY__] = () => _ServiceMessages_SpeakerResponse__WEBPACK_IMPORTED_MODULE_33__[__WEBPACK_IMPORT_KEY__]
/* harmony reexport (unknown) */ __webpack_require__.d(__webpack_exports__, __WEBPACK_REEXPORT_OBJECT__);
/* harmony import */ var _RequestSession__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./RequestSession */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js");
/* harmony import */ var _SpeechContext__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./SpeechContext */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js");
/* harmony import */ var _DynamicGrammarBuilder__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./DynamicGrammarBuilder */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js");
/* harmony import */ var _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./DynamicGrammarInterfaces */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js");
/* harmony import */ var _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_37___default = /*#__PURE__*/__webpack_require__.n(_DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_37__);
/* harmony reexport (unknown) */ var __WEBPACK_REEXPORT_OBJECT__ = {};
/* harmony reexport (unknown) */ for(const __WEBPACK_IMPORT_KEY__ in _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_37__) if(["default","OutputFormatPropertyName","CancellationErrorCodePropertyName","ServicePropertiesPropertyName","ForceDictationPropertyName","AutoDetectSourceLanguagesOpenRangeOptionName","CognitiveSubscriptionKeyAuthentication","CognitiveTokenAuthentication","AuthInfo","IntentConnectionFactory","SpeakerRecognitionConnectionFactory","VoiceProfileConnectionFactory","ConnectingToServiceEvent","ListeningStartedEvent","RecognitionCompletionStatus","RecognitionEndedEvent","RecognitionStartedEvent","RecognitionTriggeredEvent","SpeechRecognitionEvent","ServiceRecognizerBase","ConversationServiceRecognizer","Context","Device","OS","RecognitionMode","RecognizerConfig","SpeechResultFormat","SpeechServiceConfig","System","connectivity","type","WebsocketMessageFormatter","SpeechConnectionFactory","TranscriberConnectionFactory","TranslationConnectionFactory","SpeechSynthesisConnectionFactory","EnumTranslation","RecognitionStatus","SynthesisStatus","TranslationSynthesisEnd","TranslationHypothesis","TranslationPhrase","TranslationServiceRecognizer","SpeechDetected","SpeechHypothesis","SpeechKeyword","SpeechServiceRecognizer","TranscriptionServiceRecognizer","DetailedSpeechPhrase","SimpleSpeechPhrase","AddedLmIntent","IntentServiceRecognizer","IntentResponse","RequestSession","SpeechContext","DynamicGrammarBuilder"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) __WEBPACK_REEXPORT_OBJECT__[__WEBPACK_IMPORT_KEY__] = () => _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_37__[__WEBPACK_IMPORT_KEY__]
/* harmony reexport (unknown) */ __webpack_require__.d(__webpack_exports__, __WEBPACK_REEXPORT_OBJECT__);
/* harmony import */ var _DialogServiceAdapter__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./DialogServiceAdapter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js");
/* harmony import */ var _AgentConfig__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./AgentConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js");
/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./Transcription/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js");
/* harmony import */ var _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./ServiceMessages/SynthesisAudioMetadata */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js");
/* harmony import */ var _SynthesisTurn__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./SynthesisTurn */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js");
/* harmony import */ var _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./SynthesisAdapterBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js");
/* harmony import */ var _SynthesisRestAdapter__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./SynthesisRestAdapter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js");
/* harmony import */ var _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./SynthesizerConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js");
/* harmony import */ var _SynthesisContext__WEBPACK_IMPORTED_MODULE_46__ = __webpack_require__(/*! ./SynthesisContext */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js");
/* harmony import */ var _SpeakerRecognitionConfig__WEBPACK_IMPORTED_MODULE_47__ = __webpack_require__(/*! ./SpeakerRecognitionConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js");
/* harmony import */ var _SpeakerServiceRecognizer__WEBPACK_IMPORTED_MODULE_48__ = __webpack_require__(/*! ./SpeakerServiceRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerServiceRecognizer.js");
/* harmony import */ var _VoiceServiceRecognizer__WEBPACK_IMPORTED_MODULE_49__ = __webpack_require__(/*! ./VoiceServiceRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/VoiceServiceRecognizer.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Make sure not to export internal modules.
//


















































const OutputFormatPropertyName = "OutputFormat";
const CancellationErrorCodePropertyName = "CancellationErrorCode";
const ServicePropertiesPropertyName = "ServiceProperties";
const ForceDictationPropertyName = "ForceDictation";
const AutoDetectSourceLanguagesOpenRangeOptionName = "OpenRange";

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   HeaderNames: () => (/* binding */ HeaderNames)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class HeaderNames {}
HeaderNames.AuthKey = "Ocp-Apim-Subscription-Key";
HeaderNames.Authorization = "Authorization";
HeaderNames.SpIDAuthKey = "Apim-Subscription-Id";
HeaderNames.ConnectionId = "X-ConnectionId";
HeaderNames.ContentType = "Content-Type";
HeaderNames.CustomCommandsAppId = "X-CommandsAppId";
HeaderNames.Path = "Path";
HeaderNames.RequestId = "X-RequestId";
HeaderNames.RequestStreamId = "X-StreamId";
HeaderNames.RequestTimestamp = "X-Timestamp";

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AuthInfo: () => (/* binding */ AuthInfo)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class AuthInfo {
  constructor(headerName, token) {
    this.privHeaderName = headerName;
    this.privToken = token;
  }
  get headerName() {
    return this.privHeaderName;
  }
  get token() {
    return this.privToken;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js ***!
  \********************************************************************************************************************/
/***/ (() => {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js ***!
  \*****************************************************************************************************************************/
/***/ (() => {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   IntentConnectionFactory: () => (/* binding */ IntentConnectionFactory)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js");
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.





class IntentConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {
  create(config, authInfo, connectionId) {
    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint);
    if (!endpoint) {
      const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_IntentRegion);
      const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);
      const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, "wss://" + region + ".sr.speech" + hostSuffix);
      endpoint = host + "/speech/recognition/interactive/cognitiveservices/v1";
    }
    const queryParams = {
      format: "simple",
      language: config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage)
    };
    this.setCommonUrlParams(config, queryParams, endpoint);
    const headers = {};
    if (authInfo.token !== undefined && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ConnectionId] = connectionId;
    config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Url, endpoint);
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_4__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
  getSpeechRegionFromIntentRegion(intentRegion) {
    switch (intentRegion) {
      case "West US":
      case "US West":
      case "westus":
        return "uswest";
      case "West US 2":
      case "US West 2":
      case "westus2":
        return "uswest2";
      case "South Central US":
      case "US South Central":
      case "southcentralus":
        return "ussouthcentral";
      case "West Central US":
      case "US West Central":
      case "westcentralus":
        return "uswestcentral";
      case "East US":
      case "US East":
      case "eastus":
        return "useast";
      case "East US 2":
      case "US East 2":
      case "eastus2":
        return "useast2";
      case "West Europe":
      case "Europe West":
      case "westeurope":
        return "europewest";
      case "North Europe":
      case "Europe North":
      case "northeurope":
        return "europenorth";
      case "Brazil South":
      case "South Brazil":
      case "southbrazil":
        return "brazilsouth";
      case "Australia East":
      case "East Australia":
      case "eastaustralia":
        return "australiaeast";
      case "Southeast Asia":
      case "Asia Southeast":
      case "southeastasia":
        return "asiasoutheast";
      case "East Asia":
      case "Asia East":
      case "eastasia":
        return "asiaeast";
      default:
        return intentRegion;
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   IntentServiceRecognizer: () => (/* binding */ IntentServiceRecognizer)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



// eslint-disable-next-line max-classes-per-file
class IntentServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);
    this.privIntentRecognizer = recognizer;
    this.privIntentDataSent = false;
  }
  setIntents(addedIntents, umbrellaIntent) {
    this.privAddedLmIntents = addedIntents;
    this.privUmbrellaIntent = umbrellaIntent;
    this.privIntentDataSent = true;
  }
  processTypeSpecificMessages(connectionMessage) {
    let result;
    let ev;
    let processed = false;
    const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();
    if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_2__.MessageType.Text) {
      resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
    }
    switch (connectionMessage.path.toLowerCase()) {
      case "speech.hypothesis":
        const speechHypothesis = _Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechHypothesis.fromJSON(connectionMessage.textBody);
        result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(undefined, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ResultReason.RecognizingIntent, speechHypothesis.Text, speechHypothesis.Duration, speechHypothesis.Offset + this.privRequestSession.currentTurnAudioOffset, speechHypothesis.Language, speechHypothesis.LanguageDetectionConfidence, undefined, connectionMessage.textBody, resultProps);
        this.privRequestSession.onHypothesis(result.offset);
        ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentRecognitionEventArgs(result, speechHypothesis.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);
        if (!!this.privIntentRecognizer.recognizing) {
          try {
            this.privIntentRecognizer.recognizing(this.privIntentRecognizer, ev);
            /* eslint-disable no-empty */
          } catch (error) {
            // Not going to let errors in the event handler
            // trip things up.
          }
        }
        processed = true;
        break;
      case "speech.phrase":
        const simple = _Exports__WEBPACK_IMPORTED_MODULE_8__.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);
        result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(undefined, this.privRequestSession.requestId, _Exports__WEBPACK_IMPORTED_MODULE_9__.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus), simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, undefined, connectionMessage.textBody, resultProps);
        ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);
        const sendEvent = () => {
          if (!!this.privIntentRecognizer.recognized) {
            try {
              this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);
              /* eslint-disable no-empty */
            } catch (error) {
              // Not going to let errors in the event handler
              // trip things up.
            }
          }
          // report result to promise.
          if (!!this.privSuccessCallback) {
            try {
              this.privSuccessCallback(result);
            } catch (e) {
              if (!!this.privErrorCallback) {
                this.privErrorCallback(e);
              }
            }
            // Only invoke the call back once.
            // and if it's successful don't invoke the
            // error after that.
            this.privSuccessCallback = undefined;
            this.privErrorCallback = undefined;
          }
        };
        // If intent data was sent, the terminal result for this recognizer is an intent being found.
        // If no intent data was sent, the terminal event is speech recognition being successful.
        if (false === this.privIntentDataSent || _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ResultReason.NoMatch === ev.result.reason) {
          // Advance the buffers.
          this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);
          sendEvent();
        } else {
          // Squirrel away the args, when the response event arrives it will build upon them
          // and then return
          this.privPendingIntentArgs = ev;
        }
        processed = true;
        break;
      case "response":
        // Response from LUIS
        ev = this.privPendingIntentArgs;
        this.privPendingIntentArgs = undefined;
        if (undefined === ev) {
          if ("" === connectionMessage.textBody) {
            // This condition happens if there is nothing but silence in the
            // audio sent to the service.
            return;
          }
          // Odd... Not sure this can happen
          ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentRecognitionEventArgs(new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(), 0, this.privRequestSession.sessionId);
        }
        const intentResponse = _Exports__WEBPACK_IMPORTED_MODULE_10__.IntentResponse.fromJSON(connectionMessage.textBody);
        // If LUIS didn't return anything, send the existing event, else
        // modify it to show the match.
        // See if the intent found is in the list of intents asked for.
        if (null !== intentResponse && !!intentResponse.topScoringIntent && !!intentResponse.topScoringIntent.intent) {
          let addedIntent = this.privAddedLmIntents[intentResponse.topScoringIntent.intent];
          if (this.privUmbrellaIntent !== undefined) {
            addedIntent = this.privUmbrellaIntent;
          }
          if (!!addedIntent) {
            const intentId = addedIntent === undefined || addedIntent.intentName === undefined ? intentResponse.topScoringIntent.intent : addedIntent.intentName;
            let reason = ev.result.reason;
            if (undefined !== intentId) {
              reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ResultReason.RecognizedIntent;
            }
            // make sure, properties is set.
            const properties = undefined !== ev.result.properties ? ev.result.properties : new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();
            properties.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.LanguageUnderstandingServiceResponse_JsonResult, connectionMessage.textBody);
            ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentRecognitionEventArgs(new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(intentId, ev.result.resultId, reason, ev.result.text, ev.result.duration, ev.result.offset, undefined, undefined, ev.result.errorDetails, ev.result.json, properties), ev.offset, ev.sessionId);
          }
        }
        this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);
        if (!!this.privIntentRecognizer.recognized) {
          try {
            this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);
            /* eslint-disable no-empty */
          } catch (error) {
            // Not going to let errors in the event handler
            // trip things up.
          }
        }
        // report result to promise.
        if (!!this.privSuccessCallback) {
          try {
            this.privSuccessCallback(ev.result);
          } catch (e) {
            if (!!this.privErrorCallback) {
              this.privErrorCallback(e);
            }
          }
          // Only invoke the call back once.
          // and if it's successful don't invoke the
          // error after that.
          this.privSuccessCallback = undefined;
          this.privErrorCallback = undefined;
        }
        processed = true;
        break;
      default:
        break;
    }
    const defferal = new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.Deferred();
    defferal.resolve(processed);
    return defferal.promise;
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();
    properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_12__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.CancellationErrorCode[errorCode]);
    if (!!this.privIntentRecognizer.canceled) {
      const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.IntentRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, undefined, sessionId);
      try {
        this.privIntentRecognizer.canceled(this.privIntentRecognizer, cancelEvent);
        /* eslint-disable no-empty */
      } catch (_a) {}
    }
    if (!!this.privSuccessCallback) {
      const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(undefined,
      // Intent Id
      requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ResultReason.Canceled, undefined,
      // Text
      undefined,
      // Duration
      undefined,
      // Offset
      undefined,
      // Language
      undefined,
      // LanguageDetectionConfidence
      error, undefined,
      // Json
      properties);
      try {
        this.privSuccessCallback(result);
        this.privSuccessCallback = undefined;
        /* eslint-disable no-empty */
      } catch (_b) {}
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   QueryParameterNames: () => (/* binding */ QueryParameterNames)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class QueryParameterNames {}
QueryParameterNames.BotId = "botid";
QueryParameterNames.CustomSpeechDeploymentId = "cid";
QueryParameterNames.CustomVoiceDeploymentId = "deploymentId";
QueryParameterNames.EnableAudioLogging = "storeAudio";
QueryParameterNames.EnableLanguageId = "lidEnabled";
QueryParameterNames.EnableWordLevelTimestamps = "wordLevelTimestamps";
QueryParameterNames.EndSilenceTimeoutMs = "endSilenceTimeoutMs";
QueryParameterNames.SegmentationSilenceTimeoutMs = "segmentationSilenceTimeoutMs";
QueryParameterNames.Format = "format";
QueryParameterNames.InitialSilenceTimeoutMs = "initialSilenceTimeoutMs";
QueryParameterNames.Language = "language";
QueryParameterNames.Profanity = "profanity";
QueryParameterNames.RequestBotStatusMessages = "enableBotMessageStatus";
QueryParameterNames.StableIntermediateThreshold = "stableIntermediateThreshold";
QueryParameterNames.StableTranslation = "stableTranslation";
QueryParameterNames.TestHooks = "testhooks";
QueryParameterNames.Postprocessing = "postprocessing";
QueryParameterNames.CtsMeetingId = "meetingId";
QueryParameterNames.CtsDeviceId = "deviceId";
QueryParameterNames.CtsIsParticipant = "isParticipant";

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConnectingToServiceEvent: () => (/* binding */ ConnectingToServiceEvent),
/* harmony export */   ListeningStartedEvent: () => (/* binding */ ListeningStartedEvent),
/* harmony export */   RecognitionCompletionStatus: () => (/* binding */ RecognitionCompletionStatus),
/* harmony export */   RecognitionEndedEvent: () => (/* binding */ RecognitionEndedEvent),
/* harmony export */   RecognitionStartedEvent: () => (/* binding */ RecognitionStartedEvent),
/* harmony export */   RecognitionTriggeredEvent: () => (/* binding */ RecognitionTriggeredEvent),
/* harmony export */   SpeechRecognitionEvent: () => (/* binding */ SpeechRecognitionEvent)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */

class SpeechRecognitionEvent extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {
  constructor(eventName, requestId, sessionId, eventType = _common_Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Info) {
    super(eventName, eventType);
    this.privRequestId = requestId;
    this.privSessionId = sessionId;
  }
  get requestId() {
    return this.privRequestId;
  }
  get sessionId() {
    return this.privSessionId;
  }
}
class RecognitionTriggeredEvent extends SpeechRecognitionEvent {
  constructor(requestId, sessionId, audioSourceId, audioNodeId) {
    super("RecognitionTriggeredEvent", requestId, sessionId);
    this.privAudioSourceId = audioSourceId;
    this.privAudioNodeId = audioNodeId;
  }
  get audioSourceId() {
    return this.privAudioSourceId;
  }
  get audioNodeId() {
    return this.privAudioNodeId;
  }
}
class ListeningStartedEvent extends SpeechRecognitionEvent {
  constructor(requestId, sessionId, audioSourceId, audioNodeId) {
    super("ListeningStartedEvent", requestId, sessionId);
    this.privAudioSourceId = audioSourceId;
    this.privAudioNodeId = audioNodeId;
  }
  get audioSourceId() {
    return this.privAudioSourceId;
  }
  get audioNodeId() {
    return this.privAudioNodeId;
  }
}
class ConnectingToServiceEvent extends SpeechRecognitionEvent {
  constructor(requestId, authFetchEventid, sessionId) {
    super("ConnectingToServiceEvent", requestId, sessionId);
    this.privAuthFetchEventid = authFetchEventid;
  }
  get authFetchEventid() {
    return this.privAuthFetchEventid;
  }
}
class RecognitionStartedEvent extends SpeechRecognitionEvent {
  constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId) {
    super("RecognitionStartedEvent", requestId, sessionId);
    this.privAudioSourceId = audioSourceId;
    this.privAudioNodeId = audioNodeId;
    this.privAuthFetchEventId = authFetchEventId;
  }
  get audioSourceId() {
    return this.privAudioSourceId;
  }
  get audioNodeId() {
    return this.privAudioNodeId;
  }
  get authFetchEventId() {
    return this.privAuthFetchEventId;
  }
}
var RecognitionCompletionStatus;
(function (RecognitionCompletionStatus) {
  RecognitionCompletionStatus[RecognitionCompletionStatus["Success"] = 0] = "Success";
  RecognitionCompletionStatus[RecognitionCompletionStatus["AudioSourceError"] = 1] = "AudioSourceError";
  RecognitionCompletionStatus[RecognitionCompletionStatus["AudioSourceTimeout"] = 2] = "AudioSourceTimeout";
  RecognitionCompletionStatus[RecognitionCompletionStatus["AuthTokenFetchError"] = 3] = "AuthTokenFetchError";
  RecognitionCompletionStatus[RecognitionCompletionStatus["AuthTokenFetchTimeout"] = 4] = "AuthTokenFetchTimeout";
  RecognitionCompletionStatus[RecognitionCompletionStatus["UnAuthorized"] = 5] = "UnAuthorized";
  RecognitionCompletionStatus[RecognitionCompletionStatus["ConnectTimeout"] = 6] = "ConnectTimeout";
  RecognitionCompletionStatus[RecognitionCompletionStatus["ConnectError"] = 7] = "ConnectError";
  RecognitionCompletionStatus[RecognitionCompletionStatus["ClientRecognitionActivityTimeout"] = 8] = "ClientRecognitionActivityTimeout";
  RecognitionCompletionStatus[RecognitionCompletionStatus["UnknownError"] = 9] = "UnknownError";
})(RecognitionCompletionStatus || (RecognitionCompletionStatus = {}));
class RecognitionEndedEvent extends SpeechRecognitionEvent {
  constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId, serviceTag, status, error) {
    super("RecognitionEndedEvent", requestId, sessionId, status === RecognitionCompletionStatus.Success ? _common_Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Info : _common_Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Error);
    this.privAudioSourceId = audioSourceId;
    this.privAudioNodeId = audioNodeId;
    this.privAuthFetchEventId = authFetchEventId;
    this.privStatus = status;
    this.privError = error;
    this.privServiceTag = serviceTag;
  }
  get audioSourceId() {
    return this.privAudioSourceId;
  }
  get audioNodeId() {
    return this.privAudioNodeId;
  }
  get authFetchEventId() {
    return this.privAuthFetchEventId;
  }
  get serviceTag() {
    return this.privServiceTag;
  }
  get status() {
    return this.privStatus;
  }
  get error() {
    return this.privError;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Context: () => (/* binding */ Context),
/* harmony export */   Device: () => (/* binding */ Device),
/* harmony export */   OS: () => (/* binding */ OS),
/* harmony export */   RecognitionMode: () => (/* binding */ RecognitionMode),
/* harmony export */   RecognizerConfig: () => (/* binding */ RecognizerConfig),
/* harmony export */   SpeechResultFormat: () => (/* binding */ SpeechResultFormat),
/* harmony export */   SpeechServiceConfig: () => (/* binding */ SpeechServiceConfig),
/* harmony export */   System: () => (/* binding */ System),
/* harmony export */   connectivity: () => (/* binding */ connectivity),
/* harmony export */   type: () => (/* binding */ type)
/* harmony export */ });
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */

var RecognitionMode;
(function (RecognitionMode) {
  RecognitionMode[RecognitionMode["Interactive"] = 0] = "Interactive";
  RecognitionMode[RecognitionMode["Conversation"] = 1] = "Conversation";
  RecognitionMode[RecognitionMode["Dictation"] = 2] = "Dictation";
})(RecognitionMode || (RecognitionMode = {}));
var SpeechResultFormat;
(function (SpeechResultFormat) {
  SpeechResultFormat[SpeechResultFormat["Simple"] = 0] = "Simple";
  SpeechResultFormat[SpeechResultFormat["Detailed"] = 1] = "Detailed";
})(SpeechResultFormat || (SpeechResultFormat = {}));
class RecognizerConfig {
  constructor(speechServiceConfig, parameters) {
    this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new SpeechServiceConfig(new Context(null));
    this.privParameters = parameters;
    this.privMaxRetryCount = parseInt(parameters.getProperty("SPEECH-Error-MaxRetryCount", "4"), 10);
    this.privLanguageIdMode = parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_LanguageIdMode, undefined);
  }
  get parameters() {
    return this.privParameters;
  }
  get recognitionMode() {
    return this.privRecognitionMode;
  }
  set recognitionMode(value) {
    this.privRecognitionMode = value;
    this.privRecognitionActivityTimeout = value === RecognitionMode.Interactive ? 8000 : 25000;
    this.privSpeechServiceConfig.Recognition = RecognitionMode[value];
  }
  get SpeechServiceConfig() {
    return this.privSpeechServiceConfig;
  }
  get recognitionActivityTimeout() {
    return this.privRecognitionActivityTimeout;
  }
  get isContinuousRecognition() {
    return this.privRecognitionMode !== RecognitionMode.Interactive;
  }
  get languageIdMode() {
    return this.privLanguageIdMode;
  }
  get autoDetectSourceLanguages() {
    return this.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, undefined);
  }
  get recognitionEndpointVersion() {
    return this.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, undefined);
  }
  get sourceLanguageModels() {
    const models = [];
    let modelsExist = false;
    if (this.autoDetectSourceLanguages !== undefined) {
      for (const language of this.autoDetectSourceLanguages.split(",")) {
        const customProperty = language + _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_EndpointId.toString();
        const modelId = this.parameters.getProperty(customProperty, undefined);
        if (modelId !== undefined) {
          models.push({
            language,
            endpoint: modelId
          });
          modelsExist = true;
        } else {
          models.push({
            language,
            endpoint: ""
          });
        }
      }
    }
    return modelsExist ? models : undefined;
  }
  get maxRetryCount() {
    return this.privMaxRetryCount;
  }
}
// The config is serialized and sent as the Speech.Config
class SpeechServiceConfig {
  constructor(context) {
    this.context = context;
  }
  serialize() {
    return JSON.stringify(this, (key, value) => {
      if (value && typeof value === "object") {
        const replacement = {};
        for (const k in value) {
          if (Object.hasOwnProperty.call(value, k)) {
            // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
            replacement[k && k.charAt(0).toLowerCase() + k.substring(1)] = value[k];
          }
        }
        return replacement;
      }
      return value;
    });
  }
  get Context() {
    return this.context;
  }
  get Recognition() {
    return this.recognition;
  }
  set Recognition(value) {
    this.recognition = value.toLowerCase();
  }
}
class Context {
  constructor(os) {
    this.system = new System();
    this.os = os;
  }
}
class System {
  constructor() {
    // Note: below will be patched for official builds.
    const SPEECHSDK_CLIENTSDK_VERSION = "1.29.0";
    this.name = "SpeechSDK";
    this.version = SPEECHSDK_CLIENTSDK_VERSION;
    this.build = "JavaScript";
    this.lang = "JavaScript";
  }
}
class OS {
  constructor(platform, name, version) {
    this.platform = platform;
    this.name = name;
    this.version = version;
  }
}
class Device {
  constructor(manufacturer, model, version) {
    this.manufacturer = manufacturer;
    this.model = model;
    this.version = version;
  }
}
var connectivity;
(function (connectivity) {
  connectivity["Bluetooth"] = "Bluetooth";
  connectivity["Wired"] = "Wired";
  connectivity["WiFi"] = "WiFi";
  connectivity["Cellular"] = "Cellular";
  connectivity["InBuilt"] = "InBuilt";
  connectivity["Unknown"] = "Unknown";
})(connectivity || (connectivity = {}));
var type;
(function (type) {
  type["Phone"] = "Phone";
  type["Speaker"] = "Speaker";
  type["Car"] = "Car";
  type["Headset"] = "Headset";
  type["Thermostat"] = "Thermostat";
  type["Microphones"] = "Microphones";
  type["Deskphone"] = "Deskphone";
  type["RemoteControl"] = "RemoteControl";
  type["Unknown"] = "Unknown";
  type["File"] = "File";
  type["Stream"] = "Stream";
})(type || (type = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   RequestSession: () => (/* binding */ RequestSession)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js");
/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./RecognitionEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js");
/* harmony import */ var _ServiceTelemetryListener_Internal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ServiceTelemetryListener.Internal */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};



class RequestSession {
  constructor(audioSourceId) {
    this.privIsDisposed = false;
    this.privDetachables = new Array();
    this.privIsAudioNodeDetached = false;
    this.privIsRecognizing = false;
    this.privIsSpeechEnded = false;
    this.privTurnStartAudioOffset = 0;
    this.privLastRecoOffset = 0;
    this.privHypothesisReceived = false;
    this.privBytesSent = 0;
    this.privRecogNumber = 0;
    this.privInTurn = false;
    this.privConnectionAttempts = 0;
    this.privAudioSourceId = audioSourceId;
    this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();
    this.privAudioNodeId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();
    this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();
    // We're not in a turn, so resolve.
    this.privTurnDeferral.resolve();
  }
  get sessionId() {
    return this.privSessionId;
  }
  get requestId() {
    return this.privRequestId;
  }
  get audioNodeId() {
    return this.privAudioNodeId;
  }
  get turnCompletionPromise() {
    return this.privTurnDeferral.promise;
  }
  get isSpeechEnded() {
    return this.privIsSpeechEnded;
  }
  get isRecognizing() {
    return this.privIsRecognizing;
  }
  get currentTurnAudioOffset() {
    return this.privTurnStartAudioOffset;
  }
  get recogNumber() {
    return this.privRecogNumber;
  }
  get numConnectionAttempts() {
    return this.privConnectionAttempts;
  }
  // The number of bytes sent for the current connection.
  // Counter is reset to 0 each time a connection is established.
  get bytesSent() {
    return this.privBytesSent;
  }
  listenForServiceTelemetry(eventSource) {
    if (!!this.privServiceTelemetryListener) {
      this.privDetachables.push(eventSource.attachListener(this.privServiceTelemetryListener));
    }
  }
  startNewRecognition() {
    this.privIsSpeechEnded = false;
    this.privIsRecognizing = true;
    this.privTurnStartAudioOffset = 0;
    this.privLastRecoOffset = 0;
    this.privRecogNumber++;
    this.privServiceTelemetryListener = new _ServiceTelemetryListener_Internal__WEBPACK_IMPORTED_MODULE_2__.ServiceTelemetryListener(this.privRequestId, this.privAudioSourceId, this.privAudioNodeId);
    this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__.RecognitionTriggeredEvent(this.requestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));
  }
  onAudioSourceAttachCompleted(audioNode, isError) {
    return __awaiter(this, void 0, void 0, function* () {
      this.privAudioNode = audioNode;
      this.privIsAudioNodeDetached = false;
      if (isError) {
        yield this.onComplete();
      } else {
        this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__.ListeningStartedEvent(this.privRequestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));
      }
    });
  }
  onPreConnectionStart(authFetchEventId, connectionId) {
    this.privAuthFetchEventId = authFetchEventId;
    this.privSessionId = connectionId;
    this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__.ConnectingToServiceEvent(this.privRequestId, this.privAuthFetchEventId, this.privSessionId));
  }
  onAuthCompleted(isError) {
    return __awaiter(this, void 0, void 0, function* () {
      if (isError) {
        yield this.onComplete();
      }
    });
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  onConnectionEstablishCompleted(statusCode, reason) {
    return __awaiter(this, void 0, void 0, function* () {
      if (statusCode === 200) {
        this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__.RecognitionStartedEvent(this.requestId, this.privAudioSourceId, this.privAudioNodeId, this.privAuthFetchEventId, this.privSessionId));
        if (!!this.privAudioNode) {
          this.privAudioNode.replay();
        }
        this.privTurnStartAudioOffset = this.privLastRecoOffset;
        this.privBytesSent = 0;
        return;
      } else if (statusCode === 403) {
        yield this.onComplete();
      }
    });
  }
  onServiceTurnEndResponse(continuousRecognition) {
    return __awaiter(this, void 0, void 0, function* () {
      this.privTurnDeferral.resolve();
      if (!continuousRecognition || this.isSpeechEnded) {
        yield this.onComplete();
        this.privInTurn = false;
      } else {
        // Start a new request set.
        this.privTurnStartAudioOffset = this.privLastRecoOffset;
        this.privAudioNode.replay();
      }
    });
  }
  onSpeechContext() {
    this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();
  }
  onServiceTurnStartResponse() {
    if (!!this.privTurnDeferral && !!this.privInTurn) {
      // What? How are we starting a turn with another not done?
      this.privTurnDeferral.reject("Another turn started before current completed.");
      // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited
      // eslint-disable-next-line @typescript-eslint/no-empty-function
      this.privTurnDeferral.promise.then().catch(() => {});
    }
    this.privInTurn = true;
    this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();
  }
  onHypothesis(offset) {
    if (!this.privHypothesisReceived) {
      this.privHypothesisReceived = true;
      this.privServiceTelemetryListener.hypothesisReceived(this.privAudioNode.findTimeAtOffset(offset));
    }
  }
  onPhraseRecognized(offset) {
    this.privServiceTelemetryListener.phraseReceived(this.privAudioNode.findTimeAtOffset(offset));
    this.onServiceRecognized(offset);
  }
  onServiceRecognized(offset) {
    this.privLastRecoOffset = offset;
    this.privHypothesisReceived = false;
    this.privAudioNode.shrinkBuffers(offset);
    this.privConnectionAttempts = 0;
  }
  onAudioSent(bytesSent) {
    this.privBytesSent += bytesSent;
  }
  onRetryConnection() {
    this.privConnectionAttempts++;
  }
  dispose() {
    return __awaiter(this, void 0, void 0, function* () {
      if (!this.privIsDisposed) {
        // we should have completed by now. If we did not its an unknown error.
        this.privIsDisposed = true;
        for (const detachable of this.privDetachables) {
          yield detachable.detach();
        }
        if (!!this.privServiceTelemetryListener) {
          this.privServiceTelemetryListener.dispose();
        }
        this.privIsRecognizing = false;
      }
    });
  }
  getTelemetry() {
    if (this.privServiceTelemetryListener.hasTelemetry) {
      return this.privServiceTelemetryListener.getTelemetry();
    } else {
      return null;
    }
  }
  onStopRecognizing() {
    return __awaiter(this, void 0, void 0, function* () {
      yield this.onComplete();
    });
  }
  // Should be called with the audioNode for this session has indicated that it is out of speech.
  onSpeechEnded() {
    this.privIsSpeechEnded = true;
  }
  onEvent(event) {
    if (!!this.privServiceTelemetryListener) {
      this.privServiceTelemetryListener.onEvent(event);
    }
    _common_Exports__WEBPACK_IMPORTED_MODULE_4__.Events.instance.onEvent(event);
  }
  onComplete() {
    return __awaiter(this, void 0, void 0, function* () {
      if (!!this.privIsRecognizing) {
        this.privIsRecognizing = false;
        yield this.detachAudioNode();
      }
    });
  }
  detachAudioNode() {
    return __awaiter(this, void 0, void 0, function* () {
      if (!this.privIsAudioNodeDetached) {
        this.privIsAudioNodeDetached = true;
        if (this.privAudioNode) {
          yield this.privAudioNode.detach();
        }
      }
    });
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js":
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js ***!
  \*****************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ActivityPayloadResponse: () => (/* binding */ ActivityPayloadResponse),
/* harmony export */   MessageDataStreamType: () => (/* binding */ MessageDataStreamType)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// response
class ActivityPayloadResponse {
  constructor(json) {
    this.privActivityResponse = JSON.parse(json);
  }
  static fromJSON(json) {
    return new ActivityPayloadResponse(json);
  }
  get conversationId() {
    return this.privActivityResponse.conversationId;
  }
  get messageDataStreamType() {
    return this.privActivityResponse.messageDataStreamType;
  }
  get messagePayload() {
    return this.privActivityResponse.messagePayload;
  }
  get version() {
    return this.privActivityResponse.version;
  }
}
var MessageDataStreamType;
(function (MessageDataStreamType) {
  MessageDataStreamType[MessageDataStreamType["None"] = 0] = "None";
  MessageDataStreamType[MessageDataStreamType["TextToSpeechAudio"] = 1] = "TextToSpeechAudio";
})(MessageDataStreamType || (MessageDataStreamType = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   DetailedSpeechPhrase: () => (/* binding */ DetailedSpeechPhrase)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class DetailedSpeechPhrase {
  constructor(json) {
    this.privDetailedSpeechPhrase = JSON.parse(json);
    this.privDetailedSpeechPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionStatus[this.privDetailedSpeechPhrase.RecognitionStatus];
  }
  static fromJSON(json) {
    return new DetailedSpeechPhrase(json);
  }
  getJsonWithCorrectedOffsets(baseOffset) {
    if (!!this.privDetailedSpeechPhrase.NBest) {
      let firstWordOffset;
      for (const phrase of this.privDetailedSpeechPhrase.NBest) {
        if (!!phrase.Words && !!phrase.Words[0]) {
          firstWordOffset = phrase.Words[0].Offset;
          break;
        }
      }
      if (!!firstWordOffset && firstWordOffset < baseOffset) {
        const offset = baseOffset - firstWordOffset;
        for (const details of this.privDetailedSpeechPhrase.NBest) {
          if (!!details.Words) {
            for (const word of details.Words) {
              word.Offset += offset;
            }
          }
          if (!!details.DisplayWords) {
            for (const word of details.DisplayWords) {
              word.Offset += offset;
            }
          }
        }
      }
    }
    return JSON.stringify(this.privDetailedSpeechPhrase);
  }
  get RecognitionStatus() {
    return this.privDetailedSpeechPhrase.RecognitionStatus;
  }
  get NBest() {
    return this.privDetailedSpeechPhrase.NBest;
  }
  get Duration() {
    return this.privDetailedSpeechPhrase.Duration;
  }
  get Offset() {
    return this.privDetailedSpeechPhrase.Offset;
  }
  get Language() {
    return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Language;
  }
  get LanguageDetectionConfidence() {
    return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Confidence;
  }
  get Text() {
    if (!!this.privDetailedSpeechPhrase.NBest && this.privDetailedSpeechPhrase.NBest[0]) {
      return this.privDetailedSpeechPhrase.NBest[0].Display || this.privDetailedSpeechPhrase.NBest[0].DisplayText;
    }
    return this.privDetailedSpeechPhrase.DisplayText;
  }
  get SpeakerId() {
    return this.privDetailedSpeechPhrase.SpeakerId;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   RecognitionStatus: () => (/* binding */ RecognitionStatus),
/* harmony export */   SynthesisStatus: () => (/* binding */ SynthesisStatus)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * @class SynthesisStatus
 * @private
 */
var SynthesisStatus;
(function (SynthesisStatus) {
  /**
   * The response contains valid audio data.
   * @member SynthesisStatus.Success
   */
  SynthesisStatus[SynthesisStatus["Success"] = 0] = "Success";
  /**
   * Indicates the end of audio data. No valid audio data is included in the message.
   * @member SynthesisStatus.SynthesisEnd
   */
  SynthesisStatus[SynthesisStatus["SynthesisEnd"] = 1] = "SynthesisEnd";
  /**
   * Indicates an error occurred during synthesis data processing.
   * @member SynthesisStatus.Error
   */
  SynthesisStatus[SynthesisStatus["Error"] = 2] = "Error";
})(SynthesisStatus || (SynthesisStatus = {}));
var RecognitionStatus;
(function (RecognitionStatus) {
  RecognitionStatus[RecognitionStatus["Success"] = 0] = "Success";
  RecognitionStatus[RecognitionStatus["NoMatch"] = 1] = "NoMatch";
  RecognitionStatus[RecognitionStatus["InitialSilenceTimeout"] = 2] = "InitialSilenceTimeout";
  RecognitionStatus[RecognitionStatus["BabbleTimeout"] = 3] = "BabbleTimeout";
  RecognitionStatus[RecognitionStatus["Error"] = 4] = "Error";
  RecognitionStatus[RecognitionStatus["EndOfDictation"] = 5] = "EndOfDictation";
  RecognitionStatus[RecognitionStatus["TooManyRequests"] = 6] = "TooManyRequests";
  RecognitionStatus[RecognitionStatus["BadRequest"] = 7] = "BadRequest";
  RecognitionStatus[RecognitionStatus["Forbidden"] = 8] = "Forbidden";
})(RecognitionStatus || (RecognitionStatus = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   IntentResponse: () => (/* binding */ IntentResponse)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// response
class IntentResponse {
  constructor(json) {
    if (json === "") {
      this.privIntentResponse = {};
    } else {
      this.privIntentResponse = JSON.parse(json);
    }
  }
  static fromJSON(json) {
    return new IntentResponse(json);
  }
  get query() {
    return this.privIntentResponse.query;
  }
  get topScoringIntent() {
    return this.privIntentResponse.topScoringIntent;
  }
  get entities() {
    return this.privIntentResponse.entities;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js":
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js ***!
  \************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SimpleSpeechPhrase: () => (/* binding */ SimpleSpeechPhrase)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class SimpleSpeechPhrase {
  constructor(json) {
    this.privSimpleSpeechPhrase = JSON.parse(json);
    this.privSimpleSpeechPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionStatus[this.privSimpleSpeechPhrase.RecognitionStatus];
  }
  static fromJSON(json) {
    return new SimpleSpeechPhrase(json);
  }
  get RecognitionStatus() {
    return this.privSimpleSpeechPhrase.RecognitionStatus;
  }
  get DisplayText() {
    return this.privSimpleSpeechPhrase.DisplayText;
  }
  get Offset() {
    return this.privSimpleSpeechPhrase.Offset;
  }
  get Duration() {
    return this.privSimpleSpeechPhrase.Duration;
  }
  get Language() {
    return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Language;
  }
  get LanguageDetectionConfidence() {
    return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Confidence;
  }
  get SpeakerId() {
    return this.privSimpleSpeechPhrase.SpeakerId;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeakerResponse.js":
/*!*********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeakerResponse.js ***!
  \*********************************************************************************************************************************/
/***/ (() => {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechDetected: () => (/* binding */ SpeechDetected)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class SpeechDetected {
  constructor(json) {
    this.privSpeechStartDetected = JSON.parse(json);
  }
  static fromJSON(json) {
    return new SpeechDetected(json);
  }
  get Offset() {
    return this.privSpeechStartDetected.Offset;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechHypothesis: () => (/* binding */ SpeechHypothesis)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class SpeechHypothesis {
  constructor(json) {
    this.privSpeechHypothesis = JSON.parse(json);
  }
  static fromJSON(json) {
    return new SpeechHypothesis(json);
  }
  get Text() {
    return this.privSpeechHypothesis.Text;
  }
  get Offset() {
    return this.privSpeechHypothesis.Offset;
  }
  get Duration() {
    return this.privSpeechHypothesis.Duration;
  }
  get Language() {
    return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Language;
  }
  get LanguageDetectionConfidence() {
    return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Confidence;
  }
  get SpeakerId() {
    return this.privSpeechHypothesis.SpeakerId;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechKeyword: () => (/* binding */ SpeechKeyword)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class SpeechKeyword {
  constructor(json) {
    this.privSpeechKeyword = JSON.parse(json);
  }
  static fromJSON(json) {
    return new SpeechKeyword(json);
  }
  get Status() {
    return this.privSpeechKeyword.Status;
  }
  get Text() {
    return this.privSpeechKeyword.Text;
  }
  get Offset() {
    return this.privSpeechKeyword.Offset;
  }
  get Duration() {
    return this.privSpeechKeyword.Duration;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js":
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js ***!
  \****************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   MetadataType: () => (/* binding */ MetadataType),
/* harmony export */   SynthesisAudioMetadata: () => (/* binding */ SynthesisAudioMetadata)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var MetadataType;
(function (MetadataType) {
  MetadataType["WordBoundary"] = "WordBoundary";
  MetadataType["Bookmark"] = "Bookmark";
  MetadataType["Viseme"] = "Viseme";
  MetadataType["SentenceBoundary"] = "SentenceBoundary";
  MetadataType["SessionEnd"] = "SessionEnd";
})(MetadataType || (MetadataType = {}));
class SynthesisAudioMetadata {
  constructor(json) {
    this.privSynthesisAudioMetadata = JSON.parse(json);
  }
  static fromJSON(json) {
    return new SynthesisAudioMetadata(json);
  }
  get Metadata() {
    return this.privSynthesisAudioMetadata.Metadata;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js":
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js ***!
  \***************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranslationHypothesis: () => (/* binding */ TranslationHypothesis)
/* harmony export */ });
/* harmony import */ var _TranslationStatus__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../TranslationStatus */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class TranslationHypothesis {
  constructor(json) {
    this.privTranslationHypothesis = JSON.parse(json);
    this.privTranslationHypothesis.Translation.TranslationStatus = _TranslationStatus__WEBPACK_IMPORTED_MODULE_0__.TranslationStatus[this.privTranslationHypothesis.Translation.TranslationStatus];
  }
  static fromJSON(json) {
    return new TranslationHypothesis(json);
  }
  get Duration() {
    return this.privTranslationHypothesis.Duration;
  }
  get Offset() {
    return this.privTranslationHypothesis.Offset;
  }
  get Text() {
    return this.privTranslationHypothesis.Text;
  }
  get Translation() {
    return this.privTranslationHypothesis.Translation;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranslationPhrase: () => (/* binding */ TranslationPhrase)
/* harmony export */ });
/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js");
/* harmony import */ var _TranslationStatus__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../TranslationStatus */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



class TranslationPhrase {
  constructor(phrase) {
    this.privTranslationPhrase = phrase;
    this.privTranslationPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionStatus[this.privTranslationPhrase.RecognitionStatus];
    if (this.privTranslationPhrase.Translation !== undefined) {
      this.privTranslationPhrase.Translation.TranslationStatus = _TranslationStatus__WEBPACK_IMPORTED_MODULE_1__.TranslationStatus[this.privTranslationPhrase.Translation.TranslationStatus];
    }
  }
  static fromJSON(json) {
    return new TranslationPhrase(JSON.parse(json));
  }
  static fromTranslationResponse(translationResponse) {
    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(translationResponse, "translationResponse");
    const phrase = translationResponse.SpeechPhrase;
    translationResponse.SpeechPhrase = undefined;
    phrase.Translation = translationResponse;
    phrase.Text = phrase.DisplayText;
    return new TranslationPhrase(phrase);
  }
  get RecognitionStatus() {
    return this.privTranslationPhrase.RecognitionStatus;
  }
  get Offset() {
    return this.privTranslationPhrase.Offset;
  }
  get Duration() {
    return this.privTranslationPhrase.Duration;
  }
  get Text() {
    return this.privTranslationPhrase.Text;
  }
  get Language() {
    var _a;
    return (_a = this.privTranslationPhrase.PrimaryLanguage) === null || _a === void 0 ? void 0 : _a.Language;
  }
  get Confidence() {
    var _a;
    return (_a = this.privTranslationPhrase.PrimaryLanguage) === null || _a === void 0 ? void 0 : _a.Confidence;
  }
  get Translation() {
    return this.privTranslationPhrase.Translation;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js":
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js ***!
  \*****************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranslationSynthesisEnd: () => (/* binding */ TranslationSynthesisEnd)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class TranslationSynthesisEnd {
  constructor(json) {
    this.privSynthesisEnd = JSON.parse(json);
    if (!!this.privSynthesisEnd.SynthesisStatus) {
      this.privSynthesisEnd.SynthesisStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__.SynthesisStatus[this.privSynthesisEnd.SynthesisStatus];
    }
    if (!!this.privSynthesisEnd.Status) {
      this.privSynthesisEnd.SynthesisStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__.SynthesisStatus[this.privSynthesisEnd.Status];
    }
  }
  static fromJSON(json) {
    return new TranslationSynthesisEnd(json);
  }
  get SynthesisStatus() {
    return this.privSynthesisEnd.SynthesisStatus;
  }
  get FailureReason() {
    return this.privSynthesisEnd.FailureReason;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TurnStatusResponsePayload: () => (/* binding */ TurnStatusResponsePayload)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class TurnStatusResponsePayload {
  constructor(json) {
    this.privMessageStatusResponse = JSON.parse(json);
  }
  static fromJSON(json) {
    return new TurnStatusResponsePayload(json);
  }
  get interactionId() {
    return this.privMessageStatusResponse.interactionId;
  }
  get conversationId() {
    return this.privMessageStatusResponse.conversationId;
  }
  get statusCode() {
    // Payloads may contain a limited set of textual representations or a numeric status
    // code. The textual values are here converted into numeric ones.
    switch (this.privMessageStatusResponse.statusCode) {
      case "Success":
        return 200;
      case "Failed":
        return 400;
      case "TimedOut":
        return 429;
      default:
        // eslint-disable-next-line @typescript-eslint/no-unsafe-return
        return this.privMessageStatusResponse.statusCode;
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ServiceRecognizerBase: () => (/* binding */ ServiceRecognizerBase)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js");
/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};





class ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
    // A promise for a configured connection.
    // Do not consume directly, call fetchConnection instead.
    this.privConnectionConfigurationPromise = undefined;
    // A promise for a connection, but one that has not had the speech context sent yet.
    // Do not consume directly, call fetchConnection instead.
    this.privConnectionPromise = undefined;
    this.privSetTimeout = setTimeout;
    this.privIsLiveAudio = false;
    this.recognizeOverride = undefined;
    this.recognizeSpeaker = undefined;
    this.disconnectOverride = undefined;
    this.receiveMessageOverride = undefined;
    this.sendPrePayloadJSONOverride = undefined;
    this.postConnectImplOverride = undefined;
    this.configConnectionOverride = undefined;
    this.handleSpeechPhraseMessage = undefined;
    this.handleSpeechHypothesisMessage = undefined;
    if (!authentication) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("authentication");
    }
    if (!connectionFactory) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("connectionFactory");
    }
    if (!audioSource) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("audioSource");
    }
    if (!recognizerConfig) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("recognizerConfig");
    }
    this.privMustReportEndOfStream = false;
    this.privAuthentication = authentication;
    this.privConnectionFactory = connectionFactory;
    this.privAudioSource = audioSource;
    this.privRecognizerConfig = recognizerConfig;
    this.privIsDisposed = false;
    this.privRecognizer = recognizer;
    this.privRequestSession = new _Exports__WEBPACK_IMPORTED_MODULE_1__.RequestSession(this.privAudioSource.id());
    this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();
    this.privServiceEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();
    this.privDynamicGrammar = new _Exports__WEBPACK_IMPORTED_MODULE_3__.DynamicGrammarBuilder();
    this.privSpeechContext = new _Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechContext(this.privDynamicGrammar);
    this.privAgentConfig = new _Exports__WEBPACK_IMPORTED_MODULE_5__.AgentConfig();
    if (typeof Blob !== "undefined" && typeof Worker !== "undefined") {
      this.privSetTimeout = _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Timeout.setTimeout;
    }
    this.connectionEvents.attach(connectionEvent => {
      if (connectionEvent.name === "ConnectionClosedEvent") {
        const connectionClosedEvent = connectionEvent;
        if (connectionClosedEvent.statusCode === 1003 || connectionClosedEvent.statusCode === 1007 || connectionClosedEvent.statusCode === 1002 || connectionClosedEvent.statusCode === 4000 || this.privRequestSession.numConnectionAttempts > this.privRecognizerConfig.maxRetryCount) {
          void this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.Error, connectionClosedEvent.statusCode === 1007 ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.BadRequestParameters : _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);
        }
      }
    });
    const phraseDetection = {};
    if (recognizerConfig.autoDetectSourceLanguages !== undefined) {
      const sourceLanguages = recognizerConfig.autoDetectSourceLanguages.split(",");
      let speechContextLidMode;
      if (recognizerConfig.languageIdMode === "Continuous") {
        speechContextLidMode = "DetectContinuous";
      } else {
        // recognizerConfig.languageIdMode === "AtStart"
        speechContextLidMode = "DetectAtAudioStart";
      }
      this.privSpeechContext.setSection("languageId", {
        Priority: "PrioritizeLatency",
        languages: sourceLanguages,
        mode: speechContextLidMode,
        onSuccess: {
          action: "Recognize"
        },
        onUnknown: {
          action: "None"
        }
      });
      this.privSpeechContext.setSection("phraseOutput", {
        interimResults: {
          resultType: "Auto"
        },
        phraseResults: {
          resultType: "Always"
        }
      });
      const customModels = recognizerConfig.sourceLanguageModels;
      if (customModels !== undefined) {
        phraseDetection.customModels = customModels;
        phraseDetection.onInterim = {
          action: "None"
        };
        phraseDetection.onSuccess = {
          action: "None"
        };
      }
    }
    const isEmpty = obj => {
      // eslint-disable-next-line guard-for-in, brace-style
      for (const x in obj) {
        return false;
      }
      return true;
    };
    if (!isEmpty(phraseDetection)) {
      this.privSpeechContext.setSection("phraseDetection", phraseDetection);
    }
  }
  setSpeechSegmentationTimeout() {
    const speechSegmentationTimeout = this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.Speech_SegmentationSilenceTimeoutMs, undefined);
    if (speechSegmentationTimeout !== undefined) {
      const mode = this.recognitionMode === _Exports__WEBPACK_IMPORTED_MODULE_10__.RecognitionMode.Conversation ? "CONVERSATION" : this.recognitionMode === _Exports__WEBPACK_IMPORTED_MODULE_10__.RecognitionMode.Dictation ? "DICTATION" : "INTERACTIVE";
      const segmentationSilenceTimeoutMs = parseInt(speechSegmentationTimeout, 10);
      const phraseDetection = this.privSpeechContext.getSection("phraseDetection");
      phraseDetection.mode = mode;
      phraseDetection[mode] = {
        segmentation: {
          mode: "Custom",
          segmentationSilenceTimeoutMs
        }
      };
      this.privSpeechContext.setSection("phraseDetection", phraseDetection);
    }
  }
  get audioSource() {
    return this.privAudioSource;
  }
  get speechContext() {
    return this.privSpeechContext;
  }
  get dynamicGrammar() {
    return this.privDynamicGrammar;
  }
  get agentConfig() {
    return this.privAgentConfig;
  }
  set conversationTranslatorToken(token) {
    this.privRecognizerConfig.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.ConversationTranslator_Token, token);
  }
  set voiceProfileType(type) {
    this.privRecognizerConfig.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.SpeechServiceConnection_SpeakerIdMode, type);
  }
  set authentication(auth) {
    this.privAuthentication = this.authentication;
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  dispose(reason) {
    return __awaiter(this, void 0, void 0, function* () {
      this.privIsDisposed = true;
      if (this.privConnectionConfigurationPromise !== undefined) {
        try {
          const connection = yield this.privConnectionConfigurationPromise;
          yield connection.dispose(reason);
        } catch (error) {
          // The connection is in a bad state. But we're trying to kill it, so...
          return;
        }
      }
    });
  }
  get connectionEvents() {
    return this.privConnectionEvents;
  }
  get serviceEvents() {
    return this.privServiceEvents;
  }
  get recognitionMode() {
    return this.privRecognizerConfig.recognitionMode;
  }
  recognize(recoMode, successCallback, errorCallBack) {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.recognizeOverride !== undefined) {
        yield this.recognizeOverride(recoMode, successCallback, errorCallBack);
        return;
      }
      // Clear the existing configuration promise to force a re-transmission of config and context.
      this.privConnectionConfigurationPromise = undefined;
      this.privRecognizerConfig.recognitionMode = recoMode;
      this.setSpeechSegmentationTimeout();
      this.privSuccessCallback = successCallback;
      this.privErrorCallback = errorCallBack;
      this.privRequestSession.startNewRecognition();
      this.privRequestSession.listenForServiceTelemetry(this.privAudioSource.events);
      // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().
      const conPromise = this.connectImpl();
      let audioNode;
      try {
        const audioStreamNode = yield this.audioSource.attach(this.privRequestSession.audioNodeId);
        const format = yield this.audioSource.format;
        const deviceInfo = yield this.audioSource.deviceInfo;
        this.privIsLiveAudio = deviceInfo.type && deviceInfo.type === _Exports__WEBPACK_IMPORTED_MODULE_10__.type.Microphones;
        audioNode = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_11__.ReplayableAudioNode(audioStreamNode, format.avgBytesPerSec);
        yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);
        this.privRecognizerConfig.SpeechServiceConfig.Context.audio = {
          source: deviceInfo
        };
      } catch (error) {
        yield this.privRequestSession.onStopRecognizing();
        throw error;
      }
      try {
        yield conPromise;
      } catch (error) {
        yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.ConnectionFailure, error);
        return;
      }
      const sessionStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.SessionEventArgs(this.privRequestSession.sessionId);
      if (!!this.privRecognizer.sessionStarted) {
        this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);
      }
      void this.receiveMessage();
      const audioSendPromise = this.sendAudio(audioNode);
      audioSendPromise.catch(error => __awaiter(this, void 0, void 0, function* () {
        yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.RuntimeError, error);
      }));
      return;
    });
  }
  stopRecognizing() {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privRequestSession.isRecognizing) {
        try {
          yield this.audioSource.turnOff();
          yield this.sendFinalAudio();
          yield this.privRequestSession.onStopRecognizing();
          yield this.privRequestSession.turnCompletionPromise;
        } finally {
          yield this.privRequestSession.dispose();
        }
      }
      return;
    });
  }
  connect() {
    return __awaiter(this, void 0, void 0, function* () {
      yield this.connectImpl();
      return Promise.resolve();
    });
  }
  connectAsync(cb, err) {
    this.connectImpl().then(() => {
      try {
        if (!!cb) {
          cb();
        }
      } catch (e) {
        if (!!err) {
          err(e);
        }
      }
    }, reason => {
      try {
        if (!!err) {
          err(reason);
        }
        /* eslint-disable no-empty */
      } catch (error) {}
    });
  }
  disconnect() {
    return __awaiter(this, void 0, void 0, function* () {
      yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.NoError, "Disconnecting");
      if (this.disconnectOverride !== undefined) {
        yield this.disconnectOverride();
      }
      if (this.privConnectionPromise !== undefined) {
        try {
          yield (yield this.privConnectionPromise).dispose();
        } catch (error) {}
      }
      this.privConnectionPromise = undefined;
    });
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  sendMessage(message) {
    return;
  }
  sendNetworkMessage(path, payload) {
    return __awaiter(this, void 0, void 0, function* () {
      const type = typeof payload === "string" ? _common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text : _common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary;
      const contentType = typeof payload === "string" ? "application/json" : "";
      const connection = yield this.fetchConnection();
      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(type, path, this.privRequestSession.requestId, contentType, payload));
    });
  }
  set activityTemplate(messagePayload) {
    this.privActivityTemplate = messagePayload;
  }
  get activityTemplate() {
    return this.privActivityTemplate;
  }
  sendTelemetryData() {
    return __awaiter(this, void 0, void 0, function* () {
      const telemetryData = this.privRequestSession.getTelemetry();
      if (ServiceRecognizerBase.telemetryDataEnabled !== true || this.privIsDisposed || null === telemetryData) {
        return;
      }
      if (!!ServiceRecognizerBase.telemetryData) {
        try {
          ServiceRecognizerBase.telemetryData(telemetryData);
          /* eslint-disable no-empty */
        } catch (_a) {}
      }
      const connection = yield this.fetchConnection();
      yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text, "telemetry", this.privRequestSession.requestId, "application/json", telemetryData));
    });
  }
  // Cancels recognition.
  cancelRecognitionLocal(cancellationReason, errorCode, error) {
    return __awaiter(this, void 0, void 0, function* () {
      if (!!this.privRequestSession.isRecognizing) {
        yield this.privRequestSession.onStopRecognizing();
        this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, cancellationReason, errorCode, error);
      }
    });
  }
  receiveMessage() {
    return __awaiter(this, void 0, void 0, function* () {
      try {
        if (this.privIsDisposed) {
          // We're done.
          return;
        }
        let connection = yield this.fetchConnection();
        const message = yield connection.read();
        if (this.receiveMessageOverride !== undefined) {
          return this.receiveMessageOverride();
        }
        // indicates we are draining the queue and it came with no message;
        if (!message) {
          if (!this.privRequestSession.isRecognizing) {
            return;
          } else {
            return this.receiveMessage();
          }
        }
        this.privServiceHasSentMessage = true;
        const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage.fromConnectionMessage(message);
        if (connectionMessage.requestId.toLowerCase() === this.privRequestSession.requestId.toLowerCase()) {
          switch (connectionMessage.path.toLowerCase()) {
            case "turn.start":
              this.privMustReportEndOfStream = true;
              this.privRequestSession.onServiceTurnStartResponse();
              break;
            case "speech.startdetected":
              const speechStartDetected = _Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechDetected.fromJSON(connectionMessage.textBody);
              const speechStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);
              if (!!this.privRecognizer.speechStartDetected) {
                this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);
              }
              break;
            case "speech.enddetected":
              let json;
              if (connectionMessage.textBody.length > 0) {
                json = connectionMessage.textBody;
              } else {
                // If the request was empty, the JSON returned is empty.
                json = "{ Offset: 0 }";
              }
              const speechStopDetected = _Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechDetected.fromJSON(json);
              const speechStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.RecognitionEventArgs(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);
              if (!!this.privRecognizer.speechEndDetected) {
                this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);
              }
              break;
            case "turn.end":
              yield this.sendTelemetryData();
              if (this.privRequestSession.isSpeechEnded && this.privMustReportEndOfStream) {
                this.privMustReportEndOfStream = false;
                yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.EndOfStream, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.NoError, undefined);
              }
              const sessionStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.SessionEventArgs(this.privRequestSession.sessionId);
              yield this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition);
              if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {
                if (!!this.privRecognizer.sessionStopped) {
                  this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);
                }
                return;
              } else {
                connection = yield this.fetchConnection();
                yield this.sendPrePayloadJSON(connection);
              }
              break;
            default:
              if (!(yield this.processTypeSpecificMessages(connectionMessage))) {
                // here are some messages that the derived class has not processed, dispatch them to connect class
                if (!!this.privServiceEvents) {
                  this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_17__.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));
                }
              }
          }
        }
        return this.receiveMessage();
      } catch (error) {
        return null;
      }
    });
  }
  sendSpeechContext(connection, generateNewRequestId) {
    const speechContextJson = this.speechContext.toJSON();
    if (generateNewRequestId) {
      this.privRequestSession.onSpeechContext();
    }
    if (speechContextJson) {
      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text, "speech.context", this.privRequestSession.requestId, "application/json", speechContextJson));
    }
    return;
  }
  noOp() {
    // operation not supported
    return;
  }
  // Encapsulated for derived service recognizers that need to send additional JSON
  sendPrePayloadJSON(connection, generateNewRequestId = true) {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.sendPrePayloadJSONOverride !== undefined) {
        return this.sendPrePayloadJSONOverride(connection);
      }
      yield this.sendSpeechContext(connection, generateNewRequestId);
      yield this.sendWaveHeader(connection);
      return;
    });
  }
  sendWaveHeader(connection) {
    return __awaiter(this, void 0, void 0, function* () {
      const format = yield this.audioSource.format;
      // this.writeBufferToConsole(format.header);
      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary, "audio", this.privRequestSession.requestId, "audio/x-wav", format.header));
    });
  }
  // Establishes a websocket connection to the end point.
  connectImpl() {
    if (this.privConnectionPromise !== undefined) {
      return this.privConnectionPromise.then(connection => {
        if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_18__.ConnectionState.Disconnected) {
          this.privConnectionId = null;
          this.privConnectionPromise = undefined;
          this.privServiceHasSentMessage = false;
          return this.connectImpl();
        }
        return this.privConnectionPromise;
      }, () => {
        this.privConnectionId = null;
        this.privConnectionPromise = undefined;
        this.privServiceHasSentMessage = false;
        return this.connectImpl();
      });
    }
    this.privConnectionPromise = this.retryableConnect();
    // Attach an empty handler to allow the promise to run in the background while
    // other startup events happen. It'll eventually be awaited on.
    // eslint-disable-next-line @typescript-eslint/no-empty-function
    this.privConnectionPromise.catch(() => {});
    if (this.postConnectImplOverride !== undefined) {
      return this.postConnectImplOverride(this.privConnectionPromise);
    }
    return this.privConnectionPromise;
  }
  sendSpeechServiceConfig(connection, requestSession, SpeechServiceConfigJson) {
    requestSession.onSpeechContext();
    // filter out anything that is not required for the service to work.
    if (ServiceRecognizerBase.telemetryDataEnabled !== true) {
      const withTelemetry = JSON.parse(SpeechServiceConfigJson);
      const replacement = {
        context: {
          system: withTelemetry.context.system
        }
      };
      SpeechServiceConfigJson = JSON.stringify(replacement);
    }
    if (this.privRecognizerConfig.parameters.getProperty("f0f5debc-f8c9-4892-ac4b-90a7ab359fd2", "false").toLowerCase() === "true") {
      const json = JSON.parse(SpeechServiceConfigJson);
      json.context.DisableReferenceChannel = "True";
      json.context.MicSpec = "1_0_0";
      SpeechServiceConfigJson = JSON.stringify(json);
    }
    if (SpeechServiceConfigJson) {
      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text, "speech.config", requestSession.requestId, "application/json", SpeechServiceConfigJson));
    }
    return;
  }
  fetchConnection() {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privConnectionConfigurationPromise !== undefined) {
        return this.privConnectionConfigurationPromise.then(connection => {
          if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_18__.ConnectionState.Disconnected) {
            this.privConnectionId = null;
            this.privConnectionConfigurationPromise = undefined;
            this.privServiceHasSentMessage = false;
            return this.fetchConnection();
          }
          return this.privConnectionConfigurationPromise;
        }, () => {
          this.privConnectionId = null;
          this.privConnectionConfigurationPromise = undefined;
          this.privServiceHasSentMessage = false;
          return this.fetchConnection();
        });
      }
      this.privConnectionConfigurationPromise = this.configureConnection();
      return yield this.privConnectionConfigurationPromise;
    });
  }
  sendAudio(audioStreamNode) {
    return __awaiter(this, void 0, void 0, function* () {
      const audioFormat = yield this.audioSource.format;
      // The time we last sent data to the service.
      let nextSendTime = Date.now();
      // Max amount to send before we start to throttle
      const fastLaneSizeMs = this.privRecognizerConfig.parameters.getProperty("SPEECH-TransmitLengthBeforThrottleMs", "5000");
      const maxSendUnthrottledBytes = audioFormat.avgBytesPerSec / 1000 * parseInt(fastLaneSizeMs, 10);
      const startRecogNumber = this.privRequestSession.recogNumber;
      const readAndUploadCycle = () => __awaiter(this, void 0, void 0, function* () {
        // If speech is done, stop sending audio.
        if (!this.privIsDisposed && !this.privRequestSession.isSpeechEnded && this.privRequestSession.isRecognizing && this.privRequestSession.recogNumber === startRecogNumber) {
          const connection = yield this.fetchConnection();
          const audioStreamChunk = yield audioStreamNode.read();
          // we have a new audio chunk to upload.
          if (this.privRequestSession.isSpeechEnded) {
            // If service already recognized audio end then don't send any more audio
            return;
          }
          let payload;
          let sendDelay;
          if (!audioStreamChunk || audioStreamChunk.isEnd) {
            payload = null;
            sendDelay = 0;
          } else {
            payload = audioStreamChunk.buffer;
            this.privRequestSession.onAudioSent(payload.byteLength);
            if (maxSendUnthrottledBytes >= this.privRequestSession.bytesSent) {
              sendDelay = 0;
            } else {
              sendDelay = Math.max(0, nextSendTime - Date.now());
            }
          }
          if (0 !== sendDelay) {
            yield this.delay(sendDelay);
          }
          if (payload !== null) {
            nextSendTime = Date.now() + payload.byteLength * 1000 / (audioFormat.avgBytesPerSec * 2);
          }
          // Are we still alive?
          if (!this.privIsDisposed && !this.privRequestSession.isSpeechEnded && this.privRequestSession.isRecognizing && this.privRequestSession.recogNumber === startRecogNumber) {
            connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary, "audio", this.privRequestSession.requestId, null, payload)).catch(() => {
              // eslint-disable-next-line @typescript-eslint/no-empty-function
              this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition).catch(() => {});
            });
            if (!(audioStreamChunk === null || audioStreamChunk === void 0 ? void 0 : audioStreamChunk.isEnd)) {
              // this.writeBufferToConsole(payload);
              // Regardless of success or failure, schedule the next upload.
              // If the underlying connection was broken, the next cycle will
              // get a new connection and re-transmit missing audio automatically.
              return readAndUploadCycle();
            } else {
              // the audio stream has been closed, no need to schedule next
              // read-upload cycle.
              if (!this.privIsLiveAudio) {
                this.privRequestSession.onSpeechEnded();
              }
            }
          }
        }
      });
      return readAndUploadCycle();
    });
  }
  retryableConnect() {
    return __awaiter(this, void 0, void 0, function* () {
      let isUnAuthorized = false;
      this.privAuthFetchEventId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_19__.createNoDashGuid)();
      const sessionId = this.privRequestSession.sessionId;
      this.privConnectionId = sessionId !== undefined ? sessionId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_19__.createNoDashGuid)();
      this.privRequestSession.onPreConnectionStart(this.privAuthFetchEventId, this.privConnectionId);
      let lastStatusCode = 0;
      let lastReason = "";
      while (this.privRequestSession.numConnectionAttempts <= this.privRecognizerConfig.maxRetryCount) {
        // Get the auth information for the connection. This is a bit of overkill for the current API surface, but leaving the plumbing in place to be able to raise a developer-customer
        // facing event when a connection fails to let them try and provide new auth information.
        const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);
        const auth = yield authPromise;
        yield this.privRequestSession.onAuthCompleted(false);
        // Create the connection
        const connection = this.privConnectionFactory.create(this.privRecognizerConfig, auth, this.privConnectionId);
        // Attach the telemetry handlers.
        this.privRequestSession.listenForServiceTelemetry(connection.events);
        // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,
        // it'll stop sending events.
        connection.events.attach(event => {
          this.connectionEvents.onEvent(event);
        });
        const response = yield connection.open();
        // 200 == everything is fine.
        if (response.statusCode === 200) {
          yield this.privRequestSession.onConnectionEstablishCompleted(response.statusCode);
          return Promise.resolve(connection);
        } else if (response.statusCode === 1006) {
          isUnAuthorized = true;
        }
        lastStatusCode = response.statusCode;
        lastReason = response.reason;
        this.privRequestSession.onRetryConnection();
      }
      yield this.privRequestSession.onConnectionEstablishCompleted(lastStatusCode, lastReason);
      return Promise.reject(`Unable to contact server. StatusCode: ${lastStatusCode}, ${this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.SpeechServiceConnection_Endpoint)} Reason: ${lastReason}`);
    });
  }
  delay(delayMs) {
    return new Promise(resolve => this.privSetTimeout(resolve, delayMs));
  }
  writeBufferToConsole(buffer) {
    let out = "Buffer Size: ";
    if (null === buffer) {
      out += "null";
    } else {
      const readView = new Uint8Array(buffer);
      out += `${buffer.byteLength}\r\n`;
      for (let i = 0; i < buffer.byteLength; i++) {
        out += readView[i].toString(16).padStart(2, "0") + " ";
        if ((i + 1) % 16 === 0) {
          // eslint-disable-next-line no-console
          console.info(out);
          out = "";
        }
      }
    }
    // eslint-disable-next-line no-console
    console.info(out);
  }
  sendFinalAudio() {
    return __awaiter(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary, "audio", this.privRequestSession.requestId, null, null));
      return;
    });
  }
  // Takes an established websocket connection to the endpoint and sends speech configuration information.
  configureConnection() {
    return __awaiter(this, void 0, void 0, function* () {
      const connection = yield this.connectImpl();
      if (this.configConnectionOverride !== undefined) {
        return this.configConnectionOverride(connection);
      }
      yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());
      yield this.sendPrePayloadJSON(connection, false);
      return connection;
    });
  }
}
ServiceRecognizerBase.telemetryDataEnabled = true;

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ServiceTelemetryListener: () => (/* binding */ ServiceTelemetryListener)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js");
/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./RecognitionEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */


class ServiceTelemetryListener {
  constructor(requestId, audioSourceId, audioNodeId) {
    this.privIsDisposed = false;
    this.privListeningTriggerMetric = null;
    this.privMicMetric = null;
    this.privConnectionEstablishMetric = null;
    this.privRequestId = requestId;
    this.privAudioSourceId = audioSourceId;
    this.privAudioNodeId = audioNodeId;
    this.privReceivedMessages = {};
    this.privPhraseLatencies = [];
    this.privHypothesisLatencies = [];
  }
  phraseReceived(audioReceivedTime) {
    if (audioReceivedTime > 0) {
      // 0 indicates the time is unknown. Drop it.
      this.privPhraseLatencies.push(Date.now() - audioReceivedTime);
    }
  }
  hypothesisReceived(audioReceivedTime) {
    if (audioReceivedTime > 0) {
      // 0 indicates the time is unknown. Drop it.
      this.privHypothesisLatencies.push(Date.now() - audioReceivedTime);
    }
  }
  onEvent(e) {
    if (this.privIsDisposed) {
      return;
    }
    if (e instanceof _RecognitionEvents__WEBPACK_IMPORTED_MODULE_0__.RecognitionTriggeredEvent && e.requestId === this.privRequestId) {
      this.privListeningTriggerMetric = {
        End: e.eventTime,
        Name: "ListeningTrigger",
        Start: e.eventTime
      };
    }
    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioStreamNodeAttachingEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
      this.privMicStartTime = e.eventTime;
    }
    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioStreamNodeAttachedEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
      this.privMicStartTime = e.eventTime;
    }
    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioSourceErrorEvent && e.audioSourceId === this.privAudioSourceId) {
      if (!this.privMicMetric) {
        this.privMicMetric = {
          End: e.eventTime,
          Error: e.error,
          Name: "Microphone",
          Start: this.privMicStartTime
        };
      }
    }
    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioStreamNodeErrorEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
      if (!this.privMicMetric) {
        this.privMicMetric = {
          End: e.eventTime,
          Error: e.error,
          Name: "Microphone",
          Start: this.privMicStartTime
        };
      }
    }
    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioStreamNodeDetachedEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
      if (!this.privMicMetric) {
        this.privMicMetric = {
          End: e.eventTime,
          Name: "Microphone",
          Start: this.privMicStartTime
        };
      }
    }
    if (e instanceof _RecognitionEvents__WEBPACK_IMPORTED_MODULE_0__.ConnectingToServiceEvent && e.requestId === this.privRequestId) {
      this.privConnectionId = e.sessionId;
    }
    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionStartEvent && e.connectionId === this.privConnectionId) {
      this.privConnectionStartTime = e.eventTime;
    }
    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionEstablishedEvent && e.connectionId === this.privConnectionId) {
      if (!this.privConnectionEstablishMetric) {
        this.privConnectionEstablishMetric = {
          End: e.eventTime,
          Id: this.privConnectionId,
          Name: "Connection",
          Start: this.privConnectionStartTime
        };
      }
    }
    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionEstablishErrorEvent && e.connectionId === this.privConnectionId) {
      if (!this.privConnectionEstablishMetric) {
        this.privConnectionEstablishMetric = {
          End: e.eventTime,
          Error: this.getConnectionError(e.statusCode),
          Id: this.privConnectionId,
          Name: "Connection",
          Start: this.privConnectionStartTime
        };
      }
    }
    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionMessageReceivedEvent && e.connectionId === this.privConnectionId) {
      if (e.message && e.message.headers && e.message.headers.path) {
        if (!this.privReceivedMessages[e.message.headers.path]) {
          this.privReceivedMessages[e.message.headers.path] = new Array();
        }
        const maxMessagesToSend = 50;
        if (this.privReceivedMessages[e.message.headers.path].length < maxMessagesToSend) {
          this.privReceivedMessages[e.message.headers.path].push(e.networkReceivedTime);
        }
      }
    }
  }
  getTelemetry() {
    const metrics = new Array();
    if (this.privListeningTriggerMetric) {
      metrics.push(this.privListeningTriggerMetric);
    }
    if (this.privMicMetric) {
      metrics.push(this.privMicMetric);
    }
    if (this.privConnectionEstablishMetric) {
      metrics.push(this.privConnectionEstablishMetric);
    }
    if (this.privPhraseLatencies.length > 0) {
      metrics.push({
        PhraseLatencyMs: this.privPhraseLatencies
      });
    }
    if (this.privHypothesisLatencies.length > 0) {
      metrics.push({
        FirstHypothesisLatencyMs: this.privHypothesisLatencies
      });
    }
    const telemetry = {
      Metrics: metrics,
      ReceivedMessages: this.privReceivedMessages
    };
    const json = JSON.stringify(telemetry);
    // We dont want to send the same telemetry again. So clean those out.
    this.privReceivedMessages = {};
    this.privListeningTriggerMetric = null;
    this.privMicMetric = null;
    this.privConnectionEstablishMetric = null;
    this.privPhraseLatencies = [];
    this.privHypothesisLatencies = [];
    return json;
  }
  // Determines if there are any telemetry events to send to the service.
  get hasTelemetry() {
    return Object.keys(this.privReceivedMessages).length !== 0 || this.privListeningTriggerMetric !== null || this.privMicMetric !== null || this.privConnectionEstablishMetric !== null || this.privPhraseLatencies.length !== 0 || this.privHypothesisLatencies.length !== 0;
  }
  dispose() {
    this.privIsDisposed = true;
  }
  getConnectionError(statusCode) {
    /*
    -- Websocket status codes --
    NormalClosure = 1000,
    EndpointUnavailable = 1001,
    ProtocolError = 1002,
    InvalidMessageType = 1003,
    Empty = 1005,
    InvalidPayloadData = 1007,
    PolicyViolation = 1008,
    MessageTooBig = 1009,
    MandatoryExtension = 1010,
    InternalServerError = 1011
    */
    switch (statusCode) {
      case 400:
      case 1002:
      case 1003:
      case 1005:
      case 1007:
      case 1008:
      case 1009:
        return "BadRequest";
      case 401:
        return "Unauthorized";
      case 403:
        return "Forbidden";
      case 503:
      case 1001:
        return "ServerUnavailable";
      case 500:
      case 1011:
        return "ServerError";
      case 408:
      case 504:
        return "Timeout";
      default:
        return "statuscode:" + statusCode.toString();
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeakerRecognitionConfig: () => (/* binding */ SpeakerRecognitionConfig)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class SpeakerRecognitionConfig {
  constructor(context, parameters) {
    this.privContext = context ? context : new _Exports__WEBPACK_IMPORTED_MODULE_0__.Context(null);
    this.privParameters = parameters;
  }
  get parameters() {
    return this.privParameters;
  }
  get Context() {
    return this.privContext;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConnectionFactory.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConnectionFactory.js ***!
  \*************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeakerRecognitionConnectionFactory: () => (/* binding */ SpeakerRecognitionConnectionFactory),
/* harmony export */   VoiceProfileConnectionFactory: () => (/* binding */ VoiceProfileConnectionFactory)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js");
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */





class SpeakerRecognitionConnectionFactoryBase extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {
  create(config, authInfo, endpointPath, connectionId) {
    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint);
    if (!endpoint) {
      const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region);
      const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);
      const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, `wss://${region}.spr-frontend.speech${hostSuffix}`);
      const scenario = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SpeakerIdMode, "TextIndependentIdentification");
      endpoint = `${host}/speaker/ws/${this.scenarioToPath(scenario)}/${endpointPath}`;
    }
    const queryParams = {
      format: "simple",
      language: config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage)
    };
    this.setCommonUrlParams(config, queryParams, endpoint);
    const headers = {};
    if (authInfo.token !== undefined && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ConnectionId] = connectionId;
    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.SpIDAuthKey] = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Key);
    config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Url, endpoint);
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_4__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
  scenarioToPath(mode) {
    switch (mode) {
      case "TextIndependentVerification":
      case "2":
        return "verification/text-independent";
      case "TextDependentVerification":
      case "1":
        return "verification/text-dependent";
      default:
        return "identification/text-independent";
    }
  }
}
class SpeakerRecognitionConnectionFactory extends SpeakerRecognitionConnectionFactoryBase {
  create(config, authInfo, connectionId) {
    return super.create(config, authInfo, "recognition", connectionId);
  }
}
class VoiceProfileConnectionFactory extends SpeakerRecognitionConnectionFactoryBase {
  create(config, authInfo, connectionId) {
    return super.create(config, authInfo, "profile", connectionId);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerServiceRecognizer.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerServiceRecognizer.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeakerServiceRecognizer: () => (/* binding */ SpeakerServiceRecognizer)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};





// eslint-disable-next-line max-classes-per-file
class SpeakerServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);
    this.privSpeakerRecognizer = recognizer;
    this.privSpeakerAudioSource = audioSource;
    this.recognizeSpeaker = model => this.recognizeSpeakerOnce(model);
    this.sendPrePayloadJSONOverride = () => this.noOp();
  }
  processTypeSpecificMessages(connectionMessage) {
    let processed = false;
    const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();
    if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_2__.MessageType.Text) {
      resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
    }
    switch (connectionMessage.path.toLowerCase()) {
      case "speaker.response":
        const response = JSON.parse(connectionMessage.textBody);
        let result;
        if (response.status.statusCode.toLowerCase() !== "success") {
          result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeakerRecognitionResult(response, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.ServiceError, response.status.reason);
        } else {
          result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeakerRecognitionResult(response, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.RecognizedSpeaker);
        }
        if (!!this.privResultDeferral) {
          this.privResultDeferral.resolve(result);
        }
        processed = true;
        break;
      default:
        break;
    }
    const defferal = new _common_Exports__WEBPACK_IMPORTED_MODULE_7__.Deferred();
    defferal.resolve(processed);
    return defferal.promise;
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();
    properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode[errorCode]);
    if (!!this.privResultDeferral) {
      const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeakerRecognitionResult({
        scenario: this.privSpeakerModel.scenario,
        status: {
          statusCode: error,
          reason: error
        }
      }, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled, errorCode, error);
      try {
        this.privResultDeferral.resolve(result);
      } catch (error) {
        this.privResultDeferral.reject(error);
      }
    }
  }
  recognizeSpeakerOnce(model) {
    return __awaiter(this, void 0, void 0, function* () {
      this.privSpeakerModel = model;
      this.voiceProfileType = model.scenario;
      if (!this.privResultDeferral) {
        this.privResultDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_7__.Deferred();
      }
      this.privRequestSession.startNewRecognition();
      this.privRequestSession.listenForServiceTelemetry(this.privSpeakerAudioSource.events);
      this.privRecognizerConfig.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.Speech_SessionId, this.privRequestSession.sessionId);
      // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().
      const conPromise = this.connectImpl();
      const preAudioPromise = this.sendPreAudioMessages(this.extractSpeakerContext(model));
      const node = yield this.privSpeakerAudioSource.attach(this.privRequestSession.audioNodeId);
      const format = yield this.privSpeakerAudioSource.format;
      const deviceInfo = yield this.privSpeakerAudioSource.deviceInfo;
      const audioNode = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__.ReplayableAudioNode(node, format.avgBytesPerSec);
      yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);
      this.privRecognizerConfig.SpeechServiceConfig.Context.audio = {
        source: deviceInfo
      };
      try {
        yield conPromise;
        yield preAudioPromise;
      } catch (err) {
        this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.ConnectionFailure, err);
      }
      const sessionStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.SessionEventArgs(this.privRequestSession.sessionId);
      if (!!this.privRecognizer.sessionStarted) {
        this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);
      }
      void this.receiveMessage();
      const audioSendPromise = this.sendAudio(audioNode);
      // /* eslint-disable no-empty */
      audioSendPromise.then(() => {}, error => {
        this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.RuntimeError, error);
      });
      return this.privResultDeferral.promise;
    });
  }
  sendPreAudioMessages(context) {
    return __awaiter(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      yield this.sendSpeakerRecognition(connection, context);
      // await this.sendWaveHeader(connection);
    });
  }

  sendSpeakerRecognition(connection, context) {
    return __awaiter(this, void 0, void 0, function* () {
      const speakerContextJson = JSON.stringify(context);
      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_12__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_2__.MessageType.Text, "speaker.context", this.privRequestSession.requestId, "application/json; charset=utf-8", speakerContextJson));
    });
  }
  extractSpeakerContext(model) {
    return {
      features: {
        interimResult: "enabled",
        progressiveDetection: "disabled"
      },
      profileIds: model.profileIds,
      scenario: model.scenario
    };
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechConnectionFactory: () => (/* binding */ SpeechConnectionFactory)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js");
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./QueryParameterNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.







class SpeechConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {
  constructor() {
    super(...arguments);
    this.interactiveRelativeUri = "/speech/recognition/interactive/cognitiveservices/v1";
    this.conversationRelativeUri = "/speech/recognition/conversation/cognitiveservices/v1";
    this.dictationRelativeUri = "/speech/recognition/dictation/cognitiveservices/v1";
    this.universalUri = "/speech/universal/v";
  }
  create(config, authInfo, connectionId) {
    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint, undefined);
    const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region, undefined);
    const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);
    const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, "wss://" + region + ".stt.speech" + hostSuffix);
    const queryParams = {};
    const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId, undefined);
    const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage, undefined);
    if (endpointId) {
      if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.CustomSpeechDeploymentId) === -1) {
        queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.CustomSpeechDeploymentId] = endpointId;
      }
    } else if (language) {
      if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Language) === -1) {
        queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Language] = language;
      }
    }
    if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Format) === -1) {
      queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Format] = config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.OutputFormatPropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat.Simple]).toLowerCase();
    }
    if (config.autoDetectSourceLanguages !== undefined) {
      queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.EnableLanguageId] = "true";
    }
    this.setCommonUrlParams(config, queryParams, endpoint);
    if (!endpoint) {
      switch (config.recognitionMode) {
        case _Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation:
          if (config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.ForceDictationPropertyName, "false") === "true") {
            endpoint = host + this.dictationRelativeUri;
          } else {
            if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {
              endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;
            } else {
              endpoint = host + this.conversationRelativeUri;
            }
          }
          break;
        case _Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Dictation:
          endpoint = host + this.dictationRelativeUri;
          break;
        default:
          if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {
            endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;
          } else {
            endpoint = host + this.interactiveRelativeUri; // default is interactive
          }

          break;
      }
    }
    const headers = {};
    if (authInfo.token !== undefined && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_6__.HeaderNames.ConnectionId] = connectionId;
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    const webSocketConnection = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_8__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
    // Set the value of SpeechServiceConnection_Url to webSocketConnection.uri (and not to `endpoint`), since this value is the final
    // URI that was used to make the connection (including query parameters).
    const uri = webSocketConnection.uri;
    config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Url, uri);
    return webSocketConnection;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechConnectionMessage: () => (/* binding */ SpeechConnectionMessage)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


class SpeechConnectionMessage extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ConnectionMessage {
  constructor(messageType, path, requestId, contentType, body, streamId, additionalHeaders, id) {
    if (!path) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ArgumentNullError("path");
    }
    if (!requestId) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ArgumentNullError("requestId");
    }
    const headers = {};
    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.Path] = path;
    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestId] = requestId;
    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestTimestamp] = new Date().toISOString();
    if (contentType) {
      headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ContentType] = contentType;
    }
    if (streamId) {
      headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestStreamId] = streamId;
    }
    if (additionalHeaders) {
      for (const headerName in additionalHeaders) {
        if (headerName) {
          headers[headerName] = additionalHeaders[headerName];
        }
      }
    }
    if (id) {
      super(messageType, body, headers, id);
    } else {
      super(messageType, body, headers);
    }
    this.privPath = path;
    this.privRequestId = requestId;
    this.privContentType = contentType;
    this.privStreamId = streamId;
    this.privAdditionalHeaders = additionalHeaders;
  }
  get path() {
    return this.privPath;
  }
  get requestId() {
    return this.privRequestId;
  }
  get contentType() {
    return this.privContentType;
  }
  get streamId() {
    return this.privStreamId;
  }
  get additionalHeaders() {
    return this.privAdditionalHeaders;
  }
  static fromConnectionMessage(message) {
    let path = null;
    let requestId = null;
    let contentType = null;
    // let requestTimestamp = null;
    let streamId = null;
    const additionalHeaders = {};
    if (message.headers) {
      for (const headerName in message.headers) {
        if (headerName) {
          if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.Path.toLowerCase()) {
            path = message.headers[headerName];
          } else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestId.toLowerCase()) {
            requestId = message.headers[headerName];
            // } else if (headerName.toLowerCase() === HeaderNames.RequestTimestamp.toLowerCase()) {
            //  requestTimestamp = message.headers[headerName];
          } else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ContentType.toLowerCase()) {
            contentType = message.headers[headerName];
          } else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestStreamId.toLowerCase()) {
            streamId = message.headers[headerName];
          } else {
            additionalHeaders[headerName] = message.headers[headerName];
          }
        }
      }
    }
    return new SpeechConnectionMessage(message.messageType, path, requestId, contentType, message.body, streamId, additionalHeaders, message.id);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechContext: () => (/* binding */ SpeechContext)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Represents the JSON used in the speech.context message sent to the speech service.
 * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.
 */
class SpeechContext {
  constructor(dynamicGrammar) {
    this.privContext = {};
    this.privDynamicGrammar = dynamicGrammar;
  }
  /**
   * Gets a section of the speech.context object.
   * @param sectionName Name of the section to get.
   * @return string or Context JSON serializable object that represents the value.
   */
  getSection(sectionName) {
    return this.privContext[sectionName] || {};
  }
  /**
   * Adds a section to the speech.context object.
   * @param sectionName Name of the section to add.
   * @param value JSON serializable object that represents the value.
   */
  setSection(sectionName, value) {
    this.privContext[sectionName] = value;
  }
  /**
   * @Internal
   * This is only used by pronunciation assessment config.
   * Do not use externally, object returned will change without warning or notice.
   */
  setPronunciationAssessmentParams(params) {
    if (this.privContext.phraseDetection === undefined) {
      this.privContext.phraseDetection = {
        enrichment: {
          pronunciationAssessment: {}
        }
      };
    }
    this.privContext.phraseDetection.enrichment.pronunciationAssessment = JSON.parse(params);
    this.setWordLevelTimings();
    this.privContext.phraseOutput.detailed.options.push("PronunciationAssessment");
    if (this.privContext.phraseOutput.detailed.options.indexOf("SNR") === -1) {
      this.privContext.phraseOutput.detailed.options.push("SNR");
    }
  }
  setWordLevelTimings() {
    if (this.privContext.phraseOutput === undefined) {
      this.privContext.phraseOutput = {
        detailed: {
          options: []
        },
        format: {}
      };
    }
    if (this.privContext.phraseOutput.detailed === undefined) {
      this.privContext.phraseOutput.detailed = {
        options: []
      };
    }
    this.privContext.phraseOutput.format = "Detailed";
    if (this.privContext.phraseOutput.detailed.options.indexOf("WordTimings") === -1) {
      this.privContext.phraseOutput.detailed.options.push("WordTimings");
    }
  }
  toJSON() {
    const dgi = this.privDynamicGrammar.generateGrammarObject();
    this.setSection("dgi", dgi);
    const ret = JSON.stringify(this.privContext);
    return ret;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js ***!
  \*************************************************************************************************************************/
/***/ (() => {

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechServiceRecognizer: () => (/* binding */ SpeechServiceRecognizer)
/* harmony export */ });
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};


// eslint-disable-next-line max-classes-per-file
class SpeechServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer);
    this.privSpeechRecognizer = speechRecognizer;
  }
  processTypeSpecificMessages(connectionMessage) {
    return __awaiter(this, void 0, void 0, function* () {
      let result;
      const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();
      resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
      let processed = false;
      switch (connectionMessage.path.toLowerCase()) {
        case "speech.hypothesis":
        case "speech.fragment":
          const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_3__.SpeechHypothesis.fromJSON(connectionMessage.textBody);
          const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;
          result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined,
          // Speaker Id
          undefined, connectionMessage.textBody, resultProps);
          this.privRequestSession.onHypothesis(offset);
          const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechRecognitionEventArgs(result, hypothesis.Duration, this.privRequestSession.sessionId);
          if (!!this.privSpeechRecognizer.recognizing) {
            try {
              this.privSpeechRecognizer.recognizing(this.privSpeechRecognizer, ev);
              /* eslint-disable no-empty */
            } catch (error) {
              // Not going to let errors in the event handler
              // trip things up.
            }
          }
          processed = true;
          break;
        case "speech.phrase":
          const simple = _Exports__WEBPACK_IMPORTED_MODULE_7__.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);
          const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);
          this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);
          if (_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled === resultReason) {
            const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);
            const cancellationErrorCode = _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);
            yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));
          } else {
            if (!(this.privRequestSession.isSpeechEnded && resultReason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.NoMatch && simple.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_9__.RecognitionStatus.InitialSilenceTimeout)) {
              if (this.privRecognizerConfig.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.OutputFormatPropertyName) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.OutputFormat.Simple]) {
                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, undefined,
                // Speaker Id
                undefined, connectionMessage.textBody, resultProps);
              } else {
                const detailed = _Exports__WEBPACK_IMPORTED_MODULE_12__.DetailedSpeechPhrase.fromJSON(connectionMessage.textBody);
                const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;
                const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);
                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, detailed.RecognitionStatus === _Exports__WEBPACK_IMPORTED_MODULE_9__.RecognitionStatus.Success ? detailed.NBest[0].Display : undefined, detailed.Duration, totalOffset, detailed.Language, detailed.LanguageDetectionConfidence, undefined,
                // Speaker Id
                undefined, offsetCorrectedJson, resultProps);
              }
              const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);
              if (!!this.privSpeechRecognizer.recognized) {
                try {
                  this.privSpeechRecognizer.recognized(this.privSpeechRecognizer, event);
                  /* eslint-disable no-empty */
                } catch (error) {
                  // Not going to let errors in the event handler
                  // trip things up.
                }
              }
            }
            if (!!this.privSuccessCallback) {
              try {
                this.privSuccessCallback(result);
              } catch (e) {
                if (!!this.privErrorCallback) {
                  this.privErrorCallback(e);
                }
              }
              // Only invoke the call back once.
              // and if it's successful don't invoke the
              // error after that.
              this.privSuccessCallback = undefined;
              this.privErrorCallback = undefined;
            }
          }
          processed = true;
          break;
        default:
          break;
      }
      return processed;
    });
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();
    properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.CancellationErrorCode[errorCode]);
    if (!!this.privSpeechRecognizer.canceled) {
      const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.SpeechRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);
      try {
        this.privSpeechRecognizer.canceled(this.privSpeechRecognizer, cancelEvent);
        /* eslint-disable no-empty */
      } catch (_a) {}
    }
    if (!!this.privSuccessCallback) {
      const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled, undefined,
      // Text
      undefined,
      // Duration
      undefined,
      // Offset
      undefined,
      // Language
      undefined,
      // Language Detection Confidence
      undefined,
      // Speaker Id
      error, undefined,
      // Json
      properties);
      try {
        this.privSuccessCallback(result);
        this.privSuccessCallback = undefined;
        /* eslint-disable no-empty */
      } catch (_b) {}
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechSynthesisConnectionFactory: () => (/* binding */ SpeechSynthesisConnectionFactory)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js");
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./QueryParameterNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.






class SpeechSynthesisConnectionFactory {
  constructor() {
    this.synthesisUri = "/cognitiveservices/websocket/v1";
  }
  create(config, authInfo, connectionId) {
    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Endpoint, undefined);
    const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Region, undefined);
    const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__.ConnectionFactoryBase.getHostSuffix(region);
    const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_EndpointId, undefined);
    const hostPrefix = endpointId === undefined ? "tts" : "voice";
    const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Host, "wss://" + region + "." + hostPrefix + ".speech" + hostSuffix);
    const queryParams = {};
    if (!endpoint) {
      endpoint = host + this.synthesisUri;
    }
    const headers = {};
    if (authInfo.token !== undefined && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ConnectionId] = connectionId;
    if (endpointId !== undefined) {
      headers[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.CustomVoiceDeploymentId] = endpointId;
    }
    config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Url, endpoint);
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_4__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_5__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_6__.ProxyInfo.fromParameters(config.parameters), enableCompression, connectionId);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SynthesisAdapterBase: () => (/* binding */ SynthesisAdapterBase)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js");
/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};




class SynthesisAdapterBase {
  constructor(authentication, connectionFactory, synthesizerConfig, speechSynthesizer, audioDestination) {
    this.speakOverride = undefined;
    this.receiveMessageOverride = undefined;
    this.connectImplOverride = undefined;
    this.configConnectionOverride = undefined;
    // A promise for a configured connection.
    // Do not consume directly, call fetchConnection instead.
    this.privConnectionConfigurationPromise = undefined;
    if (!authentication) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("authentication");
    }
    if (!connectionFactory) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("connectionFactory");
    }
    if (!synthesizerConfig) {
      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("synthesizerConfig");
    }
    this.privAuthentication = authentication;
    this.privConnectionFactory = connectionFactory;
    this.privSynthesizerConfig = synthesizerConfig;
    this.privIsDisposed = false;
    this.privSpeechSynthesizer = speechSynthesizer;
    this.privSessionAudioDestination = audioDestination;
    this.privSynthesisTurn = new _Exports__WEBPACK_IMPORTED_MODULE_1__.SynthesisTurn();
    this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();
    this.privServiceEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();
    this.privSynthesisContext = new _Exports__WEBPACK_IMPORTED_MODULE_3__.SynthesisContext(this.privSpeechSynthesizer);
    this.privAgentConfig = new _Exports__WEBPACK_IMPORTED_MODULE_4__.AgentConfig();
    this.connectionEvents.attach(connectionEvent => {
      if (connectionEvent.name === "ConnectionClosedEvent") {
        const connectionClosedEvent = connectionEvent;
        if (connectionClosedEvent.statusCode !== 1000) {
          this.cancelSynthesisLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error, connectionClosedEvent.statusCode === 1007 ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.BadRequestParameters : _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);
        }
      }
    });
  }
  get synthesisContext() {
    return this.privSynthesisContext;
  }
  get agentConfig() {
    return this.privAgentConfig;
  }
  get connectionEvents() {
    return this.privConnectionEvents;
  }
  get serviceEvents() {
    return this.privServiceEvents;
  }
  set activityTemplate(messagePayload) {
    this.privActivityTemplate = messagePayload;
  }
  get activityTemplate() {
    return this.privActivityTemplate;
  }
  set audioOutputFormat(format) {
    this.privAudioOutputFormat = format;
    this.privSynthesisTurn.audioOutputFormat = format;
    if (this.privSessionAudioDestination !== undefined) {
      this.privSessionAudioDestination.format = format;
    }
    if (this.synthesisContext !== undefined) {
      this.synthesisContext.audioOutputFormat = format;
    }
  }
  static addHeader(audio, format) {
    if (!format.hasHeader) {
      return audio;
    }
    format.updateHeader(audio.byteLength);
    const tmp = new Uint8Array(audio.byteLength + format.header.byteLength);
    tmp.set(new Uint8Array(format.header), 0);
    tmp.set(new Uint8Array(audio), format.header.byteLength);
    return tmp.buffer;
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  dispose(reason) {
    return __awaiter(this, void 0, void 0, function* () {
      this.privIsDisposed = true;
      if (this.privSessionAudioDestination !== undefined) {
        this.privSessionAudioDestination.close();
      }
      if (this.privConnectionConfigurationPromise !== undefined) {
        const connection = yield this.privConnectionConfigurationPromise;
        yield connection.dispose(reason);
      }
    });
  }
  connect() {
    return __awaiter(this, void 0, void 0, function* () {
      yield this.connectImpl();
    });
  }
  sendNetworkMessage(path, payload) {
    return __awaiter(this, void 0, void 0, function* () {
      const type = typeof payload === "string" ? _common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text : _common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Binary;
      const contentType = typeof payload === "string" ? "application/json" : "";
      const connection = yield this.fetchConnection();
      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage(type, path, this.privSynthesisTurn.requestId, contentType, payload));
    });
  }
  Speak(text, isSSML, requestId, successCallback, errorCallBack, audioDestination) {
    return __awaiter(this, void 0, void 0, function* () {
      let ssml;
      if (isSSML) {
        ssml = text;
      } else {
        ssml = this.privSpeechSynthesizer.buildSsml(text);
      }
      if (this.speakOverride !== undefined) {
        return this.speakOverride(ssml, requestId, successCallback, errorCallBack);
      }
      this.privSuccessCallback = successCallback;
      this.privErrorCallback = errorCallBack;
      this.privSynthesisTurn.startNewSynthesis(requestId, text, isSSML, audioDestination);
      try {
        yield this.connectImpl();
        const connection = yield this.fetchConnection();
        yield this.sendSynthesisContext(connection);
        yield this.sendSsmlMessage(connection, ssml, requestId);
        const synthesisStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechSynthesisEventArgs(new _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.SpeechSynthesisResult(requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.ResultReason.SynthesizingAudioStarted));
        if (!!this.privSpeechSynthesizer.synthesisStarted) {
          this.privSpeechSynthesizer.synthesisStarted(this.privSpeechSynthesizer, synthesisStartEventArgs);
        }
        void this.receiveMessage();
      } catch (e) {
        this.cancelSynthesisLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.ConnectionFailure, e);
        return Promise.reject(e);
      }
    });
  }
  // Cancels synthesis.
  cancelSynthesis(requestId, cancellationReason, errorCode, error) {
    const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyCollection();
    properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_13__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode[errorCode]);
    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.SpeechSynthesisResult(requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.ResultReason.Canceled, undefined, error, properties);
    if (!!this.privSpeechSynthesizer.SynthesisCanceled) {
      const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechSynthesisEventArgs(result);
      try {
        this.privSpeechSynthesizer.SynthesisCanceled(this.privSpeechSynthesizer, cancelEvent);
        /* eslint-disable no-empty */
      } catch (_a) {}
    }
    if (!!this.privSuccessCallback) {
      try {
        this.privSuccessCallback(result);
        /* eslint-disable no-empty */
      } catch (_b) {}
    }
  }
  // Cancels synthesis.
  cancelSynthesisLocal(cancellationReason, errorCode, error) {
    if (!!this.privSynthesisTurn.isSynthesizing) {
      this.privSynthesisTurn.onStopSynthesizing();
      this.cancelSynthesis(this.privSynthesisTurn.requestId, cancellationReason, errorCode, error);
    }
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  processTypeSpecificMessages(connectionMessage) {
    return true;
  }
  receiveMessage() {
    return __awaiter(this, void 0, void 0, function* () {
      try {
        const connection = yield this.fetchConnection();
        const message = yield connection.read();
        if (this.receiveMessageOverride !== undefined) {
          return this.receiveMessageOverride();
        }
        if (this.privIsDisposed) {
          // We're done.
          return;
        }
        // indicates we are draining the queue and it came with no message;
        if (!message) {
          if (!this.privSynthesisTurn.isSynthesizing) {
            return;
          } else {
            return this.receiveMessage();
          }
        }
        const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage.fromConnectionMessage(message);
        if (connectionMessage.requestId.toLowerCase() === this.privSynthesisTurn.requestId.toLowerCase()) {
          switch (connectionMessage.path.toLowerCase()) {
            case "turn.start":
              this.privSynthesisTurn.onServiceTurnStartResponse();
              break;
            case "response":
              this.privSynthesisTurn.onServiceResponseMessage(connectionMessage.textBody);
              break;
            case "audio":
              if (this.privSynthesisTurn.streamId.toLowerCase() === connectionMessage.streamId.toLowerCase() && !!connectionMessage.binaryBody) {
                this.privSynthesisTurn.onAudioChunkReceived(connectionMessage.binaryBody);
                if (!!this.privSpeechSynthesizer.synthesizing) {
                  try {
                    const audioWithHeader = SynthesisAdapterBase.addHeader(connectionMessage.binaryBody, this.privSynthesisTurn.audioOutputFormat);
                    const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechSynthesisEventArgs(new _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.SpeechSynthesisResult(this.privSynthesisTurn.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.ResultReason.SynthesizingAudio, audioWithHeader));
                    this.privSpeechSynthesizer.synthesizing(this.privSpeechSynthesizer, ev);
                  } catch (error) {
                    // Not going to let errors in the event handler
                    // trip things up.
                  }
                }
                if (this.privSessionAudioDestination !== undefined) {
                  this.privSessionAudioDestination.write(connectionMessage.binaryBody);
                }
              }
              break;
            case "audio.metadata":
              const metadataList = _Exports__WEBPACK_IMPORTED_MODULE_14__.SynthesisAudioMetadata.fromJSON(connectionMessage.textBody).Metadata;
              for (const metadata of metadataList) {
                switch (metadata.Type) {
                  case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.WordBoundary:
                  case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.SentenceBoundary:
                    this.privSynthesisTurn.onTextBoundaryEvent(metadata);
                    const wordBoundaryEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechSynthesisWordBoundaryEventArgs(metadata.Data.Offset, metadata.Data.Duration, metadata.Data.text.Text, metadata.Data.text.Length, metadata.Type === _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.WordBoundary ? this.privSynthesisTurn.currentTextOffset : this.privSynthesisTurn.currentSentenceOffset, metadata.Data.text.BoundaryType);
                    if (!!this.privSpeechSynthesizer.wordBoundary) {
                      try {
                        this.privSpeechSynthesizer.wordBoundary(this.privSpeechSynthesizer, wordBoundaryEventArgs);
                      } catch (error) {
                        // Not going to let errors in the event handler
                        // trip things up.
                      }
                    }
                    break;
                  case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.Bookmark:
                    const bookmarkEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.SpeechSynthesisBookmarkEventArgs(metadata.Data.Offset, metadata.Data.Bookmark);
                    if (!!this.privSpeechSynthesizer.bookmarkReached) {
                      try {
                        this.privSpeechSynthesizer.bookmarkReached(this.privSpeechSynthesizer, bookmarkEventArgs);
                      } catch (error) {
                        // Not going to let errors in the event handler
                        // trip things up.
                      }
                    }
                    break;
                  case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.Viseme:
                    this.privSynthesisTurn.onVisemeMetadataReceived(metadata);
                    if (metadata.Data.IsLastAnimation) {
                      const visemeEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_17__.SpeechSynthesisVisemeEventArgs(metadata.Data.Offset, metadata.Data.VisemeId, this.privSynthesisTurn.getAndClearVisemeAnimation());
                      if (!!this.privSpeechSynthesizer.visemeReceived) {
                        try {
                          this.privSpeechSynthesizer.visemeReceived(this.privSpeechSynthesizer, visemeEventArgs);
                        } catch (error) {
                          // Not going to let errors in the event handler
                          // trip things up.
                        }
                      }
                    }
                    break;
                  case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.SessionEnd:
                    this.privSynthesisTurn.onSessionEnd(metadata);
                    break;
                }
              }
              break;
            case "turn.end":
              this.privSynthesisTurn.onServiceTurnEndResponse();
              let result;
              try {
                const audioBuffer = yield this.privSynthesisTurn.getAllReceivedAudioWithHeader();
                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.SpeechSynthesisResult(this.privSynthesisTurn.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.ResultReason.SynthesizingAudioCompleted, audioBuffer, undefined, undefined, this.privSynthesisTurn.audioDuration);
                if (!!this.privSuccessCallback) {
                  this.privSuccessCallback(result);
                }
              } catch (error) {
                if (!!this.privErrorCallback) {
                  this.privErrorCallback(error);
                }
              }
              if (this.privSpeechSynthesizer.synthesisCompleted) {
                try {
                  this.privSpeechSynthesizer.synthesisCompleted(this.privSpeechSynthesizer, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechSynthesisEventArgs(result));
                } catch (e) {
                  // Not going to let errors in the event handler
                  // trip things up.
                }
              }
              break;
            default:
              if (!this.processTypeSpecificMessages(connectionMessage)) {
                // here are some messages that the derived class has not processed, dispatch them to connect class
                if (!!this.privServiceEvents) {
                  this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_18__.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));
                }
              }
          }
        }
        return this.receiveMessage();
      } catch (e) {
        // TODO: What goes here?
      }
    });
  }
  sendSynthesisContext(connection) {
    const synthesisContextJson = this.synthesisContext.toJSON();
    if (synthesisContextJson) {
      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text, "synthesis.context", this.privSynthesisTurn.requestId, "application/json", synthesisContextJson));
    }
    return;
  }
  connectImpl(isUnAuthorized = false) {
    if (this.privConnectionPromise != null) {
      return this.privConnectionPromise.then(connection => {
        if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_19__.ConnectionState.Disconnected) {
          this.privConnectionId = null;
          this.privConnectionPromise = null;
          return this.connectImpl();
        }
        return this.privConnectionPromise;
      }, () => {
        this.privConnectionId = null;
        this.privConnectionPromise = null;
        return this.connectImpl();
      });
    }
    this.privAuthFetchEventId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_20__.createNoDashGuid)();
    this.privConnectionId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_20__.createNoDashGuid)();
    this.privSynthesisTurn.onPreConnectionStart(this.privAuthFetchEventId);
    const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);
    this.privConnectionPromise = authPromise.then(result => __awaiter(this, void 0, void 0, function* () {
      this.privSynthesisTurn.onAuthCompleted(false);
      const connection = this.privConnectionFactory.create(this.privSynthesizerConfig, result, this.privConnectionId);
      // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,
      // it'll stop sending events.
      connection.events.attach(event => {
        this.connectionEvents.onEvent(event);
      });
      const response = yield connection.open();
      if (response.statusCode === 200) {
        this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);
        return Promise.resolve(connection);
      } else if (response.statusCode === 403 && !isUnAuthorized) {
        return this.connectImpl(true);
      } else {
        this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);
        return Promise.reject(`Unable to contact server. StatusCode: ${response.statusCode}, ${this.privSynthesizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_21__.PropertyId.SpeechServiceConnection_Endpoint)} Reason: ${response.reason}`);
      }
    }), error => {
      this.privSynthesisTurn.onAuthCompleted(true);
      throw new Error(error);
    });
    // Attach an empty handler to allow the promise to run in the background while
    // other startup events happen. It'll eventually be awaited on.
    // eslint-disable-next-line @typescript-eslint/no-empty-function
    this.privConnectionPromise.catch(() => {});
    return this.privConnectionPromise;
  }
  sendSpeechServiceConfig(connection, SpeechServiceConfigJson) {
    if (SpeechServiceConfigJson) {
      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text, "speech.config", this.privSynthesisTurn.requestId, "application/json", SpeechServiceConfigJson));
    }
  }
  sendSsmlMessage(connection, ssml, requestId) {
    return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text, "ssml", requestId, "application/ssml+xml", ssml));
  }
  fetchConnection() {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privConnectionConfigurationPromise !== undefined) {
        return this.privConnectionConfigurationPromise.then(connection => {
          if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_19__.ConnectionState.Disconnected) {
            this.privConnectionId = null;
            this.privConnectionConfigurationPromise = undefined;
            return this.fetchConnection();
          }
          return this.privConnectionConfigurationPromise;
        }, () => {
          this.privConnectionId = null;
          this.privConnectionConfigurationPromise = undefined;
          return this.fetchConnection();
        });
      }
      this.privConnectionConfigurationPromise = this.configureConnection();
      return yield this.privConnectionConfigurationPromise;
    });
  }
  // Takes an established websocket connection to the endpoint and sends speech configuration information.
  configureConnection() {
    return __awaiter(this, void 0, void 0, function* () {
      const connection = yield this.connectImpl();
      if (this.configConnectionOverride !== undefined) {
        return this.configConnectionOverride(connection);
      }
      yield this.sendSpeechServiceConfig(connection, this.privSynthesizerConfig.SpeechServiceConfig.serialize());
      return connection;
    });
  }
}
SynthesisAdapterBase.telemetryDataEnabled = true;

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SynthesisContext: () => (/* binding */ SynthesisContext)
/* harmony export */ });
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Represents the JSON used in the synthesis.context message sent to the speech service.
 * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.
 */
class SynthesisContext {
  constructor(speechSynthesizer) {
    this.privContext = {};
    this.privSpeechSynthesizer = speechSynthesizer;
  }
  /**
   * Adds a section to the synthesis.context object.
   * @param sectionName Name of the section to add.
   * @param value JSON serializable object that represents the value.
   */
  setSection(sectionName, value) {
    this.privContext[sectionName] = value;
  }
  /**
   * Sets the audio output format for synthesis context generation.
   * @param format {AudioOutputFormatImpl} the output format
   */
  set audioOutputFormat(format) {
    this.privAudioOutputFormat = format;
  }
  toJSON() {
    const synthesisSection = this.buildSynthesisContext();
    this.setSection("synthesis", synthesisSection);
    return JSON.stringify(this.privContext);
  }
  buildSynthesisContext() {
    return {
      audio: {
        metadataOptions: {
          bookmarkEnabled: !!this.privSpeechSynthesizer.bookmarkReached,
          punctuationBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_RequestPunctuationBoundary, !!this.privSpeechSynthesizer.wordBoundary),
          sentenceBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_RequestSentenceBoundary, false),
          sessionEndEnabled: true,
          visemeEnabled: !!this.privSpeechSynthesizer.visemeReceived,
          wordBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_RequestWordBoundary, !!this.privSpeechSynthesizer.wordBoundary)
        },
        outputFormat: this.privAudioOutputFormat.requestAudioFormatString
      },
      language: {
        autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage
      }
    };
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConnectingToSynthesisServiceEvent: () => (/* binding */ ConnectingToSynthesisServiceEvent),
/* harmony export */   SpeechSynthesisEvent: () => (/* binding */ SpeechSynthesisEvent),
/* harmony export */   SynthesisStartedEvent: () => (/* binding */ SynthesisStartedEvent),
/* harmony export */   SynthesisTriggeredEvent: () => (/* binding */ SynthesisTriggeredEvent)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */

class SpeechSynthesisEvent extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {
  constructor(eventName, requestId, eventType = _common_Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Info) {
    super(eventName, eventType);
    this.privRequestId = requestId;
  }
  get requestId() {
    return this.privRequestId;
  }
}
class SynthesisTriggeredEvent extends SpeechSynthesisEvent {
  constructor(requestId, sessionAudioDestinationId, turnAudioDestinationId) {
    super("SynthesisTriggeredEvent", requestId);
    this.privSessionAudioDestinationId = sessionAudioDestinationId;
    this.privTurnAudioDestinationId = turnAudioDestinationId;
  }
  get audioSessionDestinationId() {
    return this.privSessionAudioDestinationId;
  }
  get audioTurnDestinationId() {
    return this.privTurnAudioDestinationId;
  }
}
class ConnectingToSynthesisServiceEvent extends SpeechSynthesisEvent {
  constructor(requestId, authFetchEventId) {
    super("ConnectingToSynthesisServiceEvent", requestId);
    this.privAuthFetchEventId = authFetchEventId;
  }
  get authFetchEventId() {
    return this.privAuthFetchEventId;
  }
}
class SynthesisStartedEvent extends SpeechSynthesisEvent {
  constructor(requestId, authFetchEventId) {
    super("SynthesisStartedEvent", requestId);
    this.privAuthFetchEventId = authFetchEventId;
  }
  get authFetchEventId() {
    return this.privAuthFetchEventId;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SynthesisRestAdapter: () => (/* binding */ SynthesisRestAdapter)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js");
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");




/**
 * Implements methods for speaker recognition classes, sending requests to endpoint
 * and parsing response into expected format
 * @class SynthesisRestAdapter
 */
class SynthesisRestAdapter {
  constructor(config, authentication) {
    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Endpoint, undefined);
    if (!endpoint) {
      const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Region, "westus");
      const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__.ConnectionFactoryBase.getHostSuffix(region);
      endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Host, `https://${region}.tts.speech${hostSuffix}`);
    }
    this.privUri = `${endpoint}/cognitiveservices/voices/list`;
    const options = _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__.RestConfigBase.requestOptions;
    this.privRestAdapter = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestMessageAdapter(options);
    this.privAuthentication = authentication;
  }
  /**
   * Sends list voices request to endpoint.
   * @function
   * @public
   * @param connectionId - guid for connectionId
   * @returns {Promise<IRestResponse>} rest response to status request
   */
  getVoicesList(connectionId) {
    this.privRestAdapter.setHeaders(_HeaderNames__WEBPACK_IMPORTED_MODULE_4__.HeaderNames.ConnectionId, connectionId);
    return this.privAuthentication.fetch(connectionId).then(authInfo => {
      this.privRestAdapter.setHeaders(authInfo.headerName, authInfo.token);
      return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Get, this.privUri);
    });
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SynthesisTurn: () => (/* binding */ SynthesisTurn)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js");
/* harmony import */ var _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js");
/* harmony import */ var _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ServiceMessages/SynthesisAudioMetadata */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js");
/* harmony import */ var _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./SynthesisAdapterBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js");
/* harmony import */ var _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./SynthesisEvents */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};





class SynthesisTurn {
  constructor() {
    this.privIsDisposed = false;
    this.privIsSynthesizing = false;
    this.privIsSynthesisEnded = false;
    this.privBytesReceived = 0;
    this.privInTurn = false;
    this.privTextOffset = 0;
    this.privNextSearchTextIndex = 0;
    this.privSentenceOffset = 0;
    this.privNextSearchSentenceIndex = 0;
    this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();
    this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();
    // We're not in a turn, so resolve.
    this.privTurnDeferral.resolve();
  }
  get requestId() {
    return this.privRequestId;
  }
  get streamId() {
    return this.privStreamId;
  }
  set streamId(value) {
    this.privStreamId = value;
  }
  get audioOutputFormat() {
    return this.privAudioOutputFormat;
  }
  set audioOutputFormat(format) {
    this.privAudioOutputFormat = format;
  }
  get turnCompletionPromise() {
    return this.privTurnDeferral.promise;
  }
  get isSynthesisEnded() {
    return this.privIsSynthesisEnded;
  }
  get isSynthesizing() {
    return this.privIsSynthesizing;
  }
  get currentTextOffset() {
    return this.privTextOffset;
  }
  get currentSentenceOffset() {
    return this.privSentenceOffset;
  }
  // The number of bytes received for current turn
  get bytesReceived() {
    return this.privBytesReceived;
  }
  get audioDuration() {
    return this.privAudioDuration;
  }
  getAllReceivedAudio() {
    return __awaiter(this, void 0, void 0, function* () {
      if (!!this.privReceivedAudio) {
        return Promise.resolve(this.privReceivedAudio);
      }
      if (!this.privIsSynthesisEnded) {
        return null;
      }
      yield this.readAllAudioFromStream();
      return Promise.resolve(this.privReceivedAudio);
    });
  }
  getAllReceivedAudioWithHeader() {
    return __awaiter(this, void 0, void 0, function* () {
      if (!!this.privReceivedAudioWithHeader) {
        return this.privReceivedAudioWithHeader;
      }
      if (!this.privIsSynthesisEnded) {
        return null;
      }
      if (this.audioOutputFormat.hasHeader) {
        const audio = yield this.getAllReceivedAudio();
        this.privReceivedAudioWithHeader = _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_2__.SynthesisAdapterBase.addHeader(audio, this.audioOutputFormat);
        return this.privReceivedAudioWithHeader;
      } else {
        return this.getAllReceivedAudio();
      }
    });
  }
  startNewSynthesis(requestId, rawText, isSSML, audioDestination) {
    this.privIsSynthesisEnded = false;
    this.privIsSynthesizing = true;
    this.privRequestId = requestId;
    this.privRawText = rawText;
    this.privIsSSML = isSSML;
    this.privAudioOutputStream = new _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__.PullAudioOutputStreamImpl();
    this.privAudioOutputStream.format = this.privAudioOutputFormat;
    this.privReceivedAudio = null;
    this.privReceivedAudioWithHeader = null;
    this.privBytesReceived = 0;
    this.privTextOffset = 0;
    this.privNextSearchTextIndex = 0;
    this.privSentenceOffset = 0;
    this.privNextSearchSentenceIndex = 0;
    this.privPartialVisemeAnimation = "";
    if (audioDestination !== undefined) {
      this.privTurnAudioDestination = audioDestination;
      this.privTurnAudioDestination.format = this.privAudioOutputFormat;
    }
    this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__.SynthesisTriggeredEvent(this.requestId, undefined, audioDestination === undefined ? undefined : audioDestination.id()));
  }
  onPreConnectionStart(authFetchEventId) {
    this.privAuthFetchEventId = authFetchEventId;
    this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__.ConnectingToSynthesisServiceEvent(this.privRequestId, this.privAuthFetchEventId));
  }
  onAuthCompleted(isError) {
    if (isError) {
      this.onComplete();
    }
  }
  onConnectionEstablishCompleted(statusCode) {
    if (statusCode === 200) {
      this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__.SynthesisStartedEvent(this.requestId, this.privAuthFetchEventId));
      this.privBytesReceived = 0;
      return;
    } else if (statusCode === 403) {
      this.onComplete();
    }
  }
  onServiceResponseMessage(responseJson) {
    const response = JSON.parse(responseJson);
    this.streamId = response.audio.streamId;
  }
  onServiceTurnEndResponse() {
    this.privInTurn = false;
    this.privTurnDeferral.resolve();
    this.onComplete();
  }
  onServiceTurnStartResponse() {
    if (!!this.privTurnDeferral && !!this.privInTurn) {
      // What? How are we starting a turn with another not done?
      this.privTurnDeferral.reject("Another turn started before current completed.");
      // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited
      // eslint-disable-next-line @typescript-eslint/no-empty-function
      this.privTurnDeferral.promise.then().catch(() => {});
    }
    this.privInTurn = true;
    this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();
  }
  onAudioChunkReceived(data) {
    if (this.isSynthesizing) {
      this.privAudioOutputStream.write(data);
      this.privBytesReceived += data.byteLength;
      if (this.privTurnAudioDestination !== undefined) {
        this.privTurnAudioDestination.write(data);
      }
    }
  }
  onTextBoundaryEvent(metadata) {
    this.updateTextOffset(metadata.Data.text.Text, metadata.Type);
  }
  onVisemeMetadataReceived(metadata) {
    if (metadata.Data.AnimationChunk !== undefined) {
      this.privPartialVisemeAnimation += metadata.Data.AnimationChunk;
    }
  }
  onSessionEnd(metadata) {
    this.privAudioDuration = metadata.Data.Offset;
  }
  dispose() {
    if (!this.privIsDisposed) {
      // we should have completed by now. If we did not its an unknown error.
      this.privIsDisposed = true;
    }
  }
  onStopSynthesizing() {
    this.onComplete();
  }
  /**
   * Gets the viseme animation string (merged from animation chunk), and clears the internal
   * partial animation.
   */
  getAndClearVisemeAnimation() {
    const animation = this.privPartialVisemeAnimation;
    this.privPartialVisemeAnimation = "";
    return animation;
  }
  onEvent(event) {
    _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Events.instance.onEvent(event);
  }
  /**
   * Check if the text is an XML(SSML) tag
   * @param text
   * @private
   */
  static isXmlTag(text) {
    return text.length >= 2 && text[0] === "<" && text[text.length - 1] === ">";
  }
  updateTextOffset(text, type) {
    if (type === _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_6__.MetadataType.WordBoundary) {
      this.privTextOffset = this.privRawText.indexOf(text, this.privNextSearchTextIndex);
      if (this.privTextOffset >= 0) {
        this.privNextSearchTextIndex = this.privTextOffset + text.length;
        if (this.privIsSSML) {
          if (this.withinXmlTag(this.privTextOffset) && !SynthesisTurn.isXmlTag(text)) {
            this.updateTextOffset(text, type);
          }
        }
      }
    } else {
      this.privSentenceOffset = this.privRawText.indexOf(text, this.privNextSearchSentenceIndex);
      if (this.privSentenceOffset >= 0) {
        this.privNextSearchSentenceIndex = this.privSentenceOffset + text.length;
        if (this.privIsSSML) {
          if (this.withinXmlTag(this.privSentenceOffset) && !SynthesisTurn.isXmlTag(text)) {
            this.updateTextOffset(text, type);
          }
        }
      }
    }
  }
  onComplete() {
    if (this.privIsSynthesizing) {
      this.privIsSynthesizing = false;
      this.privIsSynthesisEnded = true;
      this.privAudioOutputStream.close();
      this.privInTurn = false;
      if (this.privTurnAudioDestination !== undefined) {
        this.privTurnAudioDestination.close();
        this.privTurnAudioDestination = undefined;
      }
    }
  }
  readAllAudioFromStream() {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privIsSynthesisEnded) {
        this.privReceivedAudio = new ArrayBuffer(this.bytesReceived);
        try {
          yield this.privAudioOutputStream.read(this.privReceivedAudio);
        } catch (e) {
          this.privReceivedAudio = new ArrayBuffer(0);
        }
      }
    });
  }
  /**
   * Check if current idx is in XML(SSML) tag
   * @param idx
   * @private
   */
  withinXmlTag(idx) {
    return this.privRawText.indexOf("<", idx + 1) > this.privRawText.indexOf(">", idx + 1);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SynthesisServiceType: () => (/* binding */ SynthesisServiceType),
/* harmony export */   SynthesizerConfig: () => (/* binding */ SynthesizerConfig)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

var SynthesisServiceType;
(function (SynthesisServiceType) {
  SynthesisServiceType[SynthesisServiceType["Standard"] = 0] = "Standard";
  SynthesisServiceType[SynthesisServiceType["Custom"] = 1] = "Custom";
})(SynthesisServiceType || (SynthesisServiceType = {}));
class SynthesizerConfig {
  constructor(speechServiceConfig, parameters) {
    this.privSynthesisServiceType = SynthesisServiceType.Standard;
    this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechServiceConfig(new _Exports__WEBPACK_IMPORTED_MODULE_0__.Context(null));
    this.privParameters = parameters;
  }
  get parameters() {
    return this.privParameters;
  }
  get synthesisServiceType() {
    return this.privSynthesisServiceType;
  }
  set synthesisServiceType(value) {
    this.privSynthesisServiceType = value;
  }
  get SpeechServiceConfig() {
    return this.privSpeechServiceConfig;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranscriberConnectionFactory: () => (/* binding */ TranscriberConnectionFactory)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js");
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./QueryParameterNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.






class TranscriberConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {
  constructor() {
    super(...arguments);
    this.multiaudioRelativeUri = "/speech/recognition/multiaudio";
  }
  create(config, authInfo, connectionId) {
    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint, undefined);
    const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region, "centralus");
    const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);
    const hostDefault = "wss://transcribe." + region + ".cts.speech" + hostSuffix + this.multiaudioRelativeUri;
    const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, hostDefault);
    const queryParams = {};
    this.setQueryParams(queryParams, config, endpoint);
    if (!endpoint) {
      endpoint = host;
    }
    const headers = {};
    if (authInfo.token !== undefined && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ConnectionId] = connectionId;
    config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Url, endpoint);
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_4__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
  setQueryParams(queryParams, config, endpointUrl) {
    const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId, undefined);
    const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage, undefined);
    if (endpointId && !(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_6__.QueryParameterNames.CustomSpeechDeploymentId in queryParams)) {
      queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_6__.QueryParameterNames.CustomSpeechDeploymentId] = endpointId;
    }
    if (language && !(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_6__.QueryParameterNames.Language in queryParams)) {
      queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_6__.QueryParameterNames.Language] = language;
    }
    const wordLevelTimings = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, "false").toLowerCase() === "true";
    const detailed = config.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_7__.OutputFormatPropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat.Simple]) !== _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat.Simple];
    if (wordLevelTimings || detailed) {
      queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_6__.QueryParameterNames.Format] = _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.OutputFormat.Detailed].toLowerCase();
    }
    this.setCommonUrlParams(config, queryParams, endpointUrl);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranscriptionServiceRecognizer: () => (/* binding */ TranscriptionServiceRecognizer)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConversationServiceRecognizer.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};




// eslint-disable-next-line max-classes-per-file
class TranscriptionServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ConversationServiceRecognizer {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, transcriber) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, transcriber);
    this.privTranscriberRecognizer = transcriber;
    this.sendPrePayloadJSONOverride = connection => this.sendTranscriptionStartJSON(connection);
    if (this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps) === "true") {
      this.privSpeechContext.setWordLevelTimings();
    }
  }
  sendSpeechEventAsync(info, command) {
    return __awaiter(this, void 0, void 0, function* () {
      if (!!this.privRequestSession.isRecognizing) {
        const connection = yield this.fetchConnection();
        yield this.sendSpeechEvent(connection, this.createSpeechEventPayload(info, command));
      }
    });
  }
  processTypeSpecificMessages(connectionMessage) {
    return this.processSpeechMessages(connectionMessage);
  }
  handleRecognizedCallback(result, offset, sessionId) {
    try {
      const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechRecognitionEventArgs(result, offset, sessionId);
      this.privTranscriberRecognizer.recognized(this.privTranscriberRecognizer, event);
      if (!!this.privSuccessCallback) {
        try {
          this.privSuccessCallback(result);
        } catch (e) {
          if (!!this.privErrorCallback) {
            this.privErrorCallback(e);
          }
        }
        // Only invoke the call back once.
        // and if it's successful don't invoke the
        // error after that.
        this.privSuccessCallback = undefined;
        this.privErrorCallback = undefined;
      }
      /* eslint-disable no-empty */
    } catch (error) {
      // Not going to let errors in the event handler
      // trip things up.
    }
  }
  handleRecognizingCallback(result, duration, sessionId) {
    try {
      const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechRecognitionEventArgs(result, duration, sessionId);
      this.privTranscriberRecognizer.recognizing(this.privTranscriberRecognizer, ev);
      /* eslint-disable no-empty */
    } catch (error) {
      // Not going to let errors in the event handler
      // trip things up.
    }
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyCollection();
    properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationErrorCode[errorCode]);
    if (!!this.privTranscriberRecognizer.canceled) {
      const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ConversationTranscriptionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);
      try {
        this.privTranscriberRecognizer.canceled(this.privTranscriberRecognizer, cancelEvent);
        /* eslint-disable no-empty */
      } catch (_a) {}
    }
    if (!!this.privSuccessCallback) {
      const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.SpeechRecognitionResult(requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.ResultReason.Canceled, undefined,
      // Text
      undefined,
      // Duration
      undefined,
      // Offset
      undefined,
      // Language
      undefined,
      // Language Detection Confidence
      undefined,
      // Speaker Id
      error, undefined,
      // Json
      properties);
      try {
        this.privSuccessCallback(result);
        this.privSuccessCallback = undefined;
        /* eslint-disable no-empty */
      } catch (_b) {}
    }
  }
  // Encapsulated for derived service recognizers that need to send additional JSON
  sendTranscriptionStartJSON(connection) {
    return __awaiter(this, void 0, void 0, function* () {
      yield this.sendSpeechContext(connection, true);
      const info = this.privTranscriberRecognizer.getConversationInfo();
      const payload = this.createSpeechEventPayload(info, "start");
      yield this.sendSpeechEvent(connection, payload);
      yield this.sendWaveHeader(connection);
      return;
    });
  }
  sendSpeechEvent(connection, payload) {
    const speechEventJson = JSON.stringify(payload);
    if (speechEventJson) {
      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_9__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_10__.MessageType.Text, "speech.event", this.privRequestSession.requestId, "application/json", speechEventJson));
    }
    return;
  }
  createSpeechEventPayload(info, command) {
    const eventDict = {
      id: "meeting",
      name: command,
      meeting: info.conversationProperties
    };
    eventDict.meeting.id = info.id;
    eventDict.meeting.attendees = info.participants;
    eventDict.meeting.record = info.conversationProperties.audiorecording === "on" ? "true" : "false";
    return eventDict;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js":
/*!********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js ***!
  \********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationConnectionConfig: () => (/* binding */ ConversationConnectionConfig)
/* harmony export */ });
/* harmony import */ var _common_browser_RestConfigBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/RestConfigBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class ConversationConnectionConfig extends _common_browser_RestConfigBase__WEBPACK_IMPORTED_MODULE_0__.RestConfigBase {
  static get host() {
    return ConversationConnectionConfig.privHost;
  }
  static get apiVersion() {
    return ConversationConnectionConfig.privApiVersion;
  }
  static get clientAppId() {
    return ConversationConnectionConfig.privClientAppId;
  }
  static get defaultLanguageCode() {
    return ConversationConnectionConfig.privDefaultLanguageCode;
  }
  static get restPath() {
    return ConversationConnectionConfig.privRestPath;
  }
  static get webSocketPath() {
    return ConversationConnectionConfig.privWebSocketPath;
  }
  static get transcriptionEventKeys() {
    return ConversationConnectionConfig.privTranscriptionEventKeys;
  }
}
ConversationConnectionConfig.privHost = "dev.microsofttranslator.com";
ConversationConnectionConfig.privRestPath = "/capito/room";
ConversationConnectionConfig.privApiVersion = "2.0";
ConversationConnectionConfig.privDefaultLanguageCode = "en-US";
ConversationConnectionConfig.privClientAppId = "FC539C22-1767-4F1F-84BC-B4D811114F15";
ConversationConnectionConfig.privWebSocketPath = "/capito/translate";
ConversationConnectionConfig.privTranscriptionEventKeys = ["iCalUid", "callId", "organizer", "FLAC", "MTUri", "DifferentiateGuestSpeakers", "audiorecording", "Threadid", "OrganizerMri", "OrganizerTenantId", "UserToken"];

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js":
/*!*********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js ***!
  \*********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationConnectionFactory: () => (/* binding */ ConversationConnectionFactory)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js");
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../sdk/Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationConnectionConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js");
/* harmony import */ var _ConversationWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ConversationWebsocketMessageFormatter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.







/**
 * Create a connection to the Conversation Translator websocket for sending instant messages and commands, and for receiving translated messages.
 * The conversation must already have been started or joined.
 */
class ConversationConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {
  create(config, authInfo, connectionId) {
    const endpointHost = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.ConversationTranslator_Host, _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.host);
    const correlationId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.ConversationTranslator_CorrelationId, (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.createGuid)());
    const endpoint = `wss://${endpointHost}${_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.webSocketPath}`;
    const token = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.ConversationTranslator_Token, undefined);
    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_4__.Contracts.throwIfNullOrUndefined(token, "token");
    const queryParams = {};
    queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.configParams.apiVersion] = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.apiVersion;
    queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.configParams.token] = token;
    queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.configParams.correlationId] = correlationId;
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__.WebsocketConnection(endpoint, queryParams, {}, new _ConversationWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_6__.ConversationWebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js":
/*!*********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js ***!
  \*********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationConnectionMessage: () => (/* binding */ ConversationConnectionMessage)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class ConversationConnectionMessage extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ConnectionMessage {
  constructor(messageType, body, headers, id) {
    super(messageType, body, headers, id);
    const json = JSON.parse(this.textBody);
    if (json.type !== undefined) {
      this.privConversationMessageType = json.type;
    }
  }
  get conversationMessageType() {
    return this.privConversationMessageType;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationManager: () => (/* binding */ ConversationManager)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js");
/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConversationConnectionConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.




class ConversationManager {
  constructor() {
    //
    this.privRequestParams = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.configParams;
    this.privErrors = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.restErrors;
    this.privHost = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.host;
    this.privApiVersion = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.apiVersion;
    this.privRestPath = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.restPath;
    this.privRestAdapter = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.RestMessageAdapter({});
  }
  /**
   * Make a POST request to the Conversation Manager service endpoint to create or join a conversation.
   * @param args
   * @param conversationCode
   * @param callback
   * @param errorCallback
   */
  createOrJoin(args, conversationCode, cb, err) {
    try {
      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(args, "args");
      const languageCode = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage, _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.defaultLanguageCode);
      const nickname = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_Name, "conversation_host");
      const endpointHost = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_Host, this.privHost);
      const correlationId = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_CorrelationId);
      const subscriptionKey = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_Key);
      const subscriptionRegion = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_Region);
      const authToken = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceAuthorization_Token);
      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(languageCode, "languageCode");
      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(nickname, "nickname");
      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(endpointHost, "endpointHost");
      const queryParams = {};
      queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;
      queryParams[this.privRequestParams.languageCode] = languageCode;
      queryParams[this.privRequestParams.nickname] = nickname;
      const headers = {};
      if (correlationId) {
        headers[this.privRequestParams.correlationId] = correlationId;
      }
      headers[this.privRequestParams.clientAppId] = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.clientAppId;
      if (conversationCode !== undefined) {
        queryParams[this.privRequestParams.roomId] = conversationCode;
      } else {
        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(subscriptionRegion, this.privErrors.authInvalidSubscriptionRegion);
        headers[this.privRequestParams.subscriptionRegion] = subscriptionRegion;
        if (subscriptionKey) {
          headers[this.privRequestParams.subscriptionKey] = subscriptionKey;
        } else if (authToken) {
          headers[this.privRequestParams.authorization] = `Bearer ${authToken}`;
        } else {
          _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(subscriptionKey, this.privErrors.authInvalidSubscriptionKey);
        }
      }
      const config = {};
      config.headers = headers;
      this.privRestAdapter.options = config;
      const endpoint = `https://${endpointHost}${this.privRestPath}`;
      // TODO: support a proxy and certificate validation
      this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.RestRequestType.Post, endpoint, queryParams, null).then(response => {
        const requestId = _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.RestMessageAdapter.extractHeaderValue(this.privRequestParams.requestId, response.headers);
        if (!response.ok) {
          if (!!err) {
            // get the error
            let errorMessage = this.privErrors.invalidCreateJoinConversationResponse.replace("{status}", response.status.toString());
            let errMessageRaw;
            try {
              errMessageRaw = JSON.parse(response.data);
              errorMessage += ` [${errMessageRaw.error.code}: ${errMessageRaw.error.message}]`;
            } catch (e) {
              errorMessage += ` [${response.data}]`;
            }
            if (requestId) {
              errorMessage += ` ${requestId}`;
            }
            err(errorMessage);
          }
          return;
        }
        const conversation = JSON.parse(response.data);
        if (conversation) {
          conversation.requestId = requestId;
        }
        if (!!cb) {
          try {
            cb(conversation);
          } catch (e) {
            if (!!err) {
              err(e);
            }
          }
          cb = undefined;
        }
        // eslint-disable-next-line @typescript-eslint/no-empty-function
      }).catch(() => {});
    } catch (error) {
      if (!!err) {
        if (error instanceof Error) {
          const typedError = error;
          err(typedError.name + ": " + typedError.message);
        } else {
          err(error);
        }
      }
    }
  }
  /**
   * Make a DELETE request to the Conversation Manager service endpoint to leave the conversation.
   * @param args
   * @param sessionToken
   * @param callback
   */
  leave(args, sessionToken) {
    return new Promise((resolve, reject) => {
      try {
        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(args, this.privErrors.invalidArgs.replace("{arg}", "config"));
        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(sessionToken, this.privErrors.invalidArgs.replace("{arg}", "token"));
        const endpointHost = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_Host, this.privHost);
        const correlationId = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_CorrelationId);
        const queryParams = {};
        queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;
        queryParams[this.privRequestParams.sessionToken] = sessionToken;
        const headers = {};
        if (correlationId) {
          headers[this.privRequestParams.correlationId] = correlationId;
        }
        const config = {};
        config.headers = headers;
        this.privRestAdapter.options = config;
        const endpoint = `https://${endpointHost}${this.privRestPath}`;
        // TODO: support a proxy and certificate validation
        this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.RestRequestType.Delete, endpoint, queryParams, null).then(response => {
          if (!response.ok) {
            // ignore errors on delete
          }
          resolve();
          // eslint-disable-next-line @typescript-eslint/no-empty-function
        }).catch(() => {});
      } catch (error) {
        if (error instanceof Error) {
          const typedError = error;
          reject(typedError.name + ": " + typedError.message);
        } else {
          reject(error);
        }
      }
    });
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js ***!
  \******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationRequestSession: () => (/* binding */ ConversationRequestSession)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};

/**
 * Placeholder class for the Conversation Request Session. Based off RequestSession.
 * TODO: define what telemetry is required.
 */
class ConversationRequestSession {
  constructor(sessionId) {
    this.privIsDisposed = false;
    this.privDetachables = new Array();
    this.privSessionId = sessionId;
    this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();
    this.privRequestCompletionDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();
  }
  get sessionId() {
    return this.privSessionId;
  }
  get requestId() {
    return this.privRequestId;
  }
  get completionPromise() {
    return this.privRequestCompletionDeferral.promise;
  }
  onPreConnectionStart(authFetchEventId, connectionId) {
    this.privSessionId = connectionId;
  }
  onAuthCompleted(isError) {
    if (isError) {
      this.onComplete();
    }
  }
  onConnectionEstablishCompleted(statusCode) {
    if (statusCode === 200) {
      return;
    } else if (statusCode === 403) {
      this.onComplete();
    }
  }
  onServiceTurnEndResponse(continuousRecognition) {
    if (!continuousRecognition) {
      this.onComplete();
    } else {
      this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();
    }
  }
  dispose() {
    return __awaiter(this, void 0, void 0, function* () {
      if (!this.privIsDisposed) {
        // we should have completed by now. If we did not its an unknown error.
        this.privIsDisposed = true;
        for (const detachable of this.privDetachables) {
          yield detachable.detach();
        }
      }
    });
  }
  onComplete() {
    //
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js ***!
  \******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationServiceAdapter: () => (/* binding */ ConversationServiceAdapter)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js");
/* harmony import */ var _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConversationConnectionMessage */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js");
/* harmony import */ var _ConversationRequestSession__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConversationRequestSession */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js");
/* harmony import */ var _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./ConversationTranslatorEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js");
/* harmony import */ var _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./ConversationTranslatorInterfaces */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js");
/* harmony import */ var _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./ServiceMessages/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js");
/* harmony import */ var _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./ServiceMessages/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js");
/* harmony import */ var _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./ServiceMessages/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};








/**
 * The service adapter handles sending and receiving messages to the Conversation Translator websocket.
 */
class ConversationServiceAdapter extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector);
    this.privConnectionConfigPromise = undefined;
    this.privLastPartialUtteranceId = "";
    this.privConversationServiceConnector = conversationServiceConnector;
    this.privConversationAuthentication = authentication;
    this.receiveMessageOverride = () => this.receiveConversationMessageOverride();
    this.recognizeOverride = () => this.noOp();
    this.postConnectImplOverride = connection => this.conversationConnectImpl(connection);
    this.configConnectionOverride = () => this.configConnection();
    this.disconnectOverride = () => this.privDisconnect();
    this.privConversationRequestSession = new _ConversationRequestSession__WEBPACK_IMPORTED_MODULE_1__.ConversationRequestSession((0,_common_Exports__WEBPACK_IMPORTED_MODULE_2__.createNoDashGuid)());
    this.privConversationConnectionFactory = connectionFactory;
    this.privConversationIsDisposed = false;
  }
  isDisposed() {
    return super.isDisposed() || this.privConversationIsDisposed;
  }
  dispose(reason) {
    const _super = Object.create(null, {
      dispose: {
        get: () => super.dispose
      }
    });
    return __awaiter(this, void 0, void 0, function* () {
      this.privConversationIsDisposed = true;
      if (this.privConnectionConfigPromise !== undefined) {
        const connection = yield this.privConnectionConfigPromise;
        yield connection.dispose(reason);
      }
      yield _super.dispose.call(this, reason);
    });
  }
  sendMessage(message) {
    return __awaiter(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      return connection.send(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__.ConversationConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_4__.MessageType.Text, message));
    });
  }
  sendMessageAsync(message) {
    return __awaiter(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      yield connection.send(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__.ConversationConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_4__.MessageType.Text, message));
    });
  }
  privDisconnect() {
    if (this.terminateMessageLoop) {
      return;
    }
    this.cancelRecognition(this.privConversationRequestSession.sessionId, this.privConversationRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.NoError, "Disconnecting");
    this.terminateMessageLoop = true;
    return Promise.resolve();
  }
  // eslint-disable-next-line @typescript-eslint/require-await
  processTypeSpecificMessages() {
    return __awaiter(this, void 0, void 0, function* () {
      return true;
    });
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    this.terminateMessageLoop = true;
    const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.ConversationTranslationCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);
    try {
      if (!!this.privConversationServiceConnector.canceled) {
        this.privConversationServiceConnector.canceled(this.privConversationServiceConnector, cancelEvent);
      }
    } catch (_a) {
      // continue on error
    }
  }
  /**
   * Establishes a websocket connection to the end point.
   */
  conversationConnectImpl(connection) {
    return __awaiter(this, void 0, void 0, function* () {
      this.privConnectionLoop = this.startMessageLoop();
      return connection;
    });
  }
  /**
   * Process incoming websocket messages
   */
  receiveConversationMessageOverride() {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.isDisposed() || this.terminateMessageLoop) {
        return Promise.resolve();
      }
      // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages
      const communicationCustodian = new _common_Exports__WEBPACK_IMPORTED_MODULE_8__.Deferred();
      try {
        const connection = yield this.fetchConnection();
        const message = yield connection.read();
        if (this.isDisposed() || this.terminateMessageLoop) {
          // We're done.
          communicationCustodian.resolve();
          return Promise.resolve();
        }
        if (!message) {
          return this.receiveConversationMessageOverride();
        }
        const sessionId = this.privConversationRequestSession.sessionId;
        let sendFinal = false;
        try {
          switch (message.conversationMessageType.toLowerCase()) {
            case "info":
            case "participant_command":
            case "command":
              const commandPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_9__.CommandResponsePayload.fromJSON(message.textBody);
              switch (commandPayload.command.toLowerCase()) {
                /**
                 * 'ParticpantList' is the first message sent to the user after the websocket connection has opened.
                 * The consuming client must wait for this message to arrive
                 * before starting to send their own data.
                 */
                case "participantlist":
                  const participantsPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_10__.ParticipantsListPayloadResponse.fromJSON(message.textBody);
                  const participantsResult = participantsPayload.participants.map(p => {
                    const participant = {
                      avatar: p.avatar,
                      displayName: p.nickname,
                      id: p.participantId,
                      isHost: p.ishost,
                      isMuted: p.ismuted,
                      isUsingTts: p.usetts,
                      preferredLanguage: p.locale
                    };
                    return participant;
                  });
                  if (!!this.privConversationServiceConnector.participantsListReceived) {
                    this.privConversationServiceConnector.participantsListReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantsListEventArgs(participantsPayload.roomid, participantsPayload.token, participantsPayload.translateTo, participantsPayload.profanityFilter, participantsPayload.roomProfanityFilter, participantsPayload.roomLocked, participantsPayload.muteAll, participantsResult, sessionId));
                  }
                  break;
                /**
                 * 'SetTranslateToLanguages' represents the list of languages being used in the Conversation by all users(?).
                 * This is sent at the start of the Conversation
                 */
                case "settranslatetolanguages":
                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.setTranslateToLanguages, commandPayload.value, sessionId));
                  }
                  break;
                /**
                 * 'SetProfanityFiltering' lets the client set the level of profanity filtering.
                 * If sent by the participant the setting will effect only their own profanity level.
                 * If sent by the host, the setting will effect all participants including the host.
                 * Note: the profanity filters differ from Speech Service (?): 'marked', 'raw', 'removed', 'tagged'
                 */
                case "setprofanityfiltering":
                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.setProfanityFiltering, commandPayload.value, sessionId));
                  }
                  break;
                /**
                 * 'SetMute' is sent if the participant has been muted by the host.
                 * Check the 'participantId' to determine if the current user has been muted.
                 */
                case "setmute":
                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.setMute, commandPayload.value, sessionId));
                  }
                  break;
                /**
                 * 'SetMuteAll' is sent if the Conversation has been muted by the host.
                 */
                case "setmuteall":
                  if (!!this.privConversationServiceConnector.muteAllCommandReceived) {
                    this.privConversationServiceConnector.muteAllCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.MuteAllEventArgs(commandPayload.value, sessionId));
                  }
                  break;
                /**
                 * 'RoomExpirationWarning' is sent towards the end of the Conversation session to give a timeout warning.
                 */
                case "roomexpirationwarning":
                  if (!!this.privConversationServiceConnector.conversationExpiration) {
                    this.privConversationServiceConnector.conversationExpiration(this.privConversationServiceConnector, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.ConversationExpirationEventArgs(commandPayload.value, this.privConversationRequestSession.sessionId));
                  }
                  break;
                /**
                 * 'SetUseTts' is sent as a confirmation if the user requests TTS to be turned on or off.
                 */
                case "setusetts":
                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.setUseTTS, commandPayload.value, sessionId));
                  }
                  break;
                /**
                 * 'SetLockState' is set if the host has locked or unlocked the Conversation.
                 */
                case "setlockstate":
                  if (!!this.privConversationServiceConnector.lockRoomCommandReceived) {
                    this.privConversationServiceConnector.lockRoomCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.LockRoomEventArgs(commandPayload.value, sessionId));
                  }
                  break;
                /**
                 * 'ChangeNickname' is received if a user changes their display name.
                 * Any cached particpiants list should be updated to reflect the display name.
                 */
                case "changenickname":
                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.changeNickname, commandPayload.nickname, sessionId));
                  }
                  break;
                /**
                 * 'JoinSession' is sent when a user joins the Conversation.
                 */
                case "joinsession":
                  const joinParticipantPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_10__.ParticipantPayloadResponse.fromJSON(message.textBody);
                  const joiningParticipant = {
                    avatar: joinParticipantPayload.avatar,
                    displayName: joinParticipantPayload.nickname,
                    id: joinParticipantPayload.participantId,
                    isHost: joinParticipantPayload.ishost,
                    isMuted: joinParticipantPayload.ismuted,
                    isUsingTts: joinParticipantPayload.usetts,
                    preferredLanguage: joinParticipantPayload.locale
                  };
                  if (!!this.privConversationServiceConnector.participantJoinCommandReceived) {
                    this.privConversationServiceConnector.participantJoinCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantEventArgs(joiningParticipant, sessionId));
                  }
                  break;
                /**
                 * 'LeaveSession' is sent when a user leaves the Conversation'.
                 */
                case "leavesession":
                  const leavingParticipant = {
                    id: commandPayload.participantId
                  };
                  if (!!this.privConversationServiceConnector.participantLeaveCommandReceived) {
                    this.privConversationServiceConnector.participantLeaveCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantEventArgs(leavingParticipant, sessionId));
                  }
                  break;
                /**
                 * 'DisconnectSession' is sent when a user is disconnected from the session (e.g. network problem).
                 * Check the 'ParticipantId' to check whether the message is for the current user.
                 */
                case "disconnectsession":
                  // eslint-disable-next-line @typescript-eslint/no-unused-vars
                  const disconnectParticipant = {
                    id: commandPayload.participantId
                  };
                  break;
                case "token":
                  const token = new _Exports__WEBPACK_IMPORTED_MODULE_14__.CognitiveTokenAuthentication(() => {
                    const authorizationToken = commandPayload.token;
                    return Promise.resolve(authorizationToken);
                  }, () => {
                    const authorizationToken = commandPayload.token;
                    return Promise.resolve(authorizationToken);
                  });
                  this.authentication = token;
                  break;
                /**
                 * Message not recognized.
                 */
                default:
                  break;
              }
              break;
            /**
             * 'partial' (or 'hypothesis') represents a unfinalized speech message.
             */
            case "partial":
            /**
             * 'final' (or 'phrase') represents a finalized speech message.
             */
            case "final":
              const speechPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechResponsePayload.fromJSON(message.textBody);
              const speechResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.ConversationTranslationResult(speechPayload.participantId, this.getTranslations(speechPayload.translations), speechPayload.language, undefined, undefined, speechPayload.recognition, undefined, undefined, message.textBody, undefined);
              if (speechPayload.isFinal) {
                // check the length, sometimes empty finals are returned
                if (speechResult.text !== undefined && speechResult.text.length > 0) {
                  sendFinal = true;
                } else if (speechPayload.id === this.privLastPartialUtteranceId) {
                  // send final as normal. We had a non-empty partial for this same utterance
                  // so sending the empty final is important
                  sendFinal = true;
                } else {
                  // suppress unneeded final
                }
                if (sendFinal) {
                  if (!!this.privConversationServiceConnector.translationReceived) {
                    this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ConversationReceivedTranslationEventArgs(_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorMessageTypes.final, speechResult, sessionId));
                  }
                }
              } else if (speechResult.text !== undefined) {
                this.privLastPartialUtteranceId = speechPayload.id;
                if (!!this.privConversationServiceConnector.translationReceived) {
                  this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ConversationReceivedTranslationEventArgs(_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorMessageTypes.partial, speechResult, sessionId));
                }
              }
              break;
            /**
             * "translated_message" is a text message or instant message (IM).
             */
            case "translated_message":
              const textPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_15__.TextResponsePayload.fromJSON(message.textBody);
              const textResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.ConversationTranslationResult(textPayload.participantId, this.getTranslations(textPayload.translations), textPayload.language, undefined, undefined, textPayload.originalText, undefined, undefined, undefined, message.textBody, undefined);
              if (!!this.privConversationServiceConnector.translationReceived) {
                this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ConversationReceivedTranslationEventArgs(_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorMessageTypes.instantMessage, textResult, sessionId));
              }
              break;
            default:
              // ignore any unsupported message types
              break;
          }
        } catch (e) {
          // continue
        }
        return this.receiveConversationMessageOverride();
      } catch (e) {
        this.terminateMessageLoop = true;
      }
      return communicationCustodian.promise;
    });
  }
  startMessageLoop() {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.isDisposed()) {
        return Promise.resolve();
      }
      this.terminateMessageLoop = false;
      const messageRetrievalPromise = this.receiveConversationMessageOverride();
      try {
        const r = yield messageRetrievalPromise;
        return r;
      } catch (error) {
        this.cancelRecognition(this.privRequestSession ? this.privRequestSession.sessionId : "", this.privRequestSession ? this.privRequestSession.requestId : "", _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.RuntimeError, error);
        return null;
      }
    });
  }
  // Takes an established websocket connection to the endpoint
  configConnection() {
    if (this.isDisposed()) {
      return Promise.resolve(undefined);
    }
    if (this.privConnectionConfigPromise !== undefined) {
      return this.privConnectionConfigPromise.then(connection => {
        if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_17__.ConnectionState.Disconnected) {
          this.privConnectionId = null;
          this.privConnectionConfigPromise = undefined;
          return this.configConnection();
        }
        return this.privConnectionConfigPromise;
      }, () => {
        this.privConnectionId = null;
        this.privConnectionConfigPromise = undefined;
        return this.configConnection();
      });
    }
    if (this.terminateMessageLoop) {
      return Promise.resolve(undefined);
    }
    this.privConnectionConfigPromise = this.connectImpl().then(connection => connection);
    return this.privConnectionConfigPromise;
  }
  getTranslations(serviceResultTranslations) {
    let translations;
    if (undefined !== serviceResultTranslations) {
      translations = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_18__.Translations();
      for (const translation of serviceResultTranslations) {
        translations.set(translation.lang, translation.translation);
      }
    }
    return translations;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorConnectionFactory.js":
/*!*******************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorConnectionFactory.js ***!
  \*******************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationTranslatorConnectionFactory: () => (/* binding */ ConversationTranslatorConnectionFactory)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js");
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js");
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js");
/* harmony import */ var _common_StringUtils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/StringUtils */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/StringUtils.js");
/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../QueryParameterNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.








/**
 * Connection factory for the conversation translator. Handles connecting to the regular translator endpoint,
 * as well as the virtual microphone array transcription endpoint
 */
class ConversationTranslatorConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {
  constructor(convGetter) {
    super();
    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(convGetter, "convGetter");
    this.privConvGetter = convGetter;
  }
  create(config, authInfo, connectionId) {
    const isVirtMicArrayEndpoint = config.parameters.getProperty("ConversationTranslator_MultiChannelAudio", "").toUpperCase() === "TRUE";
    const convInfo = this.privConvGetter().room;
    const region = convInfo.cognitiveSpeechRegion || config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region, "");
    const replacementValues = {
      hostSuffix: _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region),
      path: ConversationTranslatorConnectionFactory.CTS_VIRT_MIC_PATH,
      region: encodeURIComponent(region)
    };
    replacementValues[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.Language] = encodeURIComponent(config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage, ""));
    replacementValues[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.CtsMeetingId] = encodeURIComponent(convInfo.roomId);
    replacementValues[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.CtsDeviceId] = encodeURIComponent(convInfo.participantId);
    replacementValues[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.CtsIsParticipant] = convInfo.isHost ? "" : "&" + _QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.CtsIsParticipant;
    let endpointUrl = "";
    const queryParams = {};
    const headers = {};
    if (isVirtMicArrayEndpoint) {
      // connecting to the conversation transcription virtual microphone array endpoint
      endpointUrl = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Endpoint);
      if (!endpointUrl) {
        const hostName = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Host, "transcribe.{region}.cts.speech{hostSuffix}");
        endpointUrl = "wss://" + hostName + "{path}";
      }
      // because the region can change during a session, we support being passed a format string which we can then
      // replace with the correct information.
      endpointUrl = _common_StringUtils__WEBPACK_IMPORTED_MODULE_4__.StringUtils.formatString(endpointUrl, replacementValues);
      const parsedUrl = new URL(endpointUrl);
      parsedUrl.searchParams.forEach((val, key) => {
        queryParams[key] = val;
      });
      const connFactory = new _Exports__WEBPACK_IMPORTED_MODULE_5__.TranscriberConnectionFactory();
      connFactory.setQueryParams(queryParams, config, endpointUrl);
      // Some query parameters are required for the CTS endpoint, let's explicity set them here
      queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.CtsMeetingId] = replacementValues[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.CtsMeetingId];
      queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.CtsDeviceId] = replacementValues[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.CtsDeviceId];
      if (!convInfo.isHost) {
        queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.CtsIsParticipant] = ""; // this doesn't have a value so set to an empty string
      }

      if (!(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.Format in queryParams)) {
        queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.Format] = "simple";
      }
      parsedUrl.searchParams.forEach((val, key) => {
        parsedUrl.searchParams.set(key, queryParams[key]);
        delete queryParams[key];
      });
      endpointUrl = parsedUrl.toString();
    } else {
      // connecting to regular translation endpoint
      const connFactory = new _Exports__WEBPACK_IMPORTED_MODULE_6__.TranslationConnectionFactory();
      endpointUrl = connFactory.getEndpointUrl(config, true);
      endpointUrl = _common_StringUtils__WEBPACK_IMPORTED_MODULE_4__.StringUtils.formatString(endpointUrl, replacementValues);
      connFactory.setQueryParams(queryParams, config, endpointUrl);
    }
    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_7__.HeaderNames.ConnectionId] = connectionId;
    headers[_common_browser_Exports__WEBPACK_IMPORTED_MODULE_8__.RestConfigBase.configParams.token] = convInfo.token;
    if (authInfo.token) {
      headers[authInfo.headerName] = authInfo.token;
    }
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "").toUpperCase() === "TRUE";
    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__.WebsocketConnection(endpointUrl, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_10__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_11__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
}
ConversationTranslatorConnectionFactory.CTS_VIRT_MIC_PATH = "/speech/recognition/dynamicaudio";

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js":
/*!***********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js ***!
  \***********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationReceivedTranslationEventArgs: () => (/* binding */ ConversationReceivedTranslationEventArgs),
/* harmony export */   LockRoomEventArgs: () => (/* binding */ LockRoomEventArgs),
/* harmony export */   MuteAllEventArgs: () => (/* binding */ MuteAllEventArgs),
/* harmony export */   ParticipantAttributeEventArgs: () => (/* binding */ ParticipantAttributeEventArgs),
/* harmony export */   ParticipantEventArgs: () => (/* binding */ ParticipantEventArgs),
/* harmony export */   ParticipantsListEventArgs: () => (/* binding */ ParticipantsListEventArgs)
/* harmony export */ });
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */

class MuteAllEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {
  constructor(isMuted, sessionId) {
    super(sessionId);
    this.privIsMuted = isMuted;
  }
  get isMuted() {
    return this.privIsMuted;
  }
}
class LockRoomEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {
  constructor(isLocked, sessionId) {
    super(sessionId);
    this.privIsLocked = isLocked;
  }
  get isMuted() {
    return this.privIsLocked;
  }
}
class ParticipantEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {
  constructor(participant, sessionId) {
    super(sessionId);
    this.privParticipant = participant;
  }
  get participant() {
    return this.privParticipant;
  }
}
class ParticipantAttributeEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {
  constructor(participantId, key, value, sessionId) {
    super(sessionId);
    this.privKey = key;
    this.privValue = value;
    this.privParticipantId = participantId;
  }
  get value() {
    return this.privValue;
  }
  get key() {
    return this.privKey;
  }
  get id() {
    return this.privParticipantId;
  }
}
class ParticipantsListEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {
  constructor(conversationId, token, translateTo, profanityFilter, roomProfanityFilter, isRoomLocked, isMuteAll, participants, sessionId) {
    super(sessionId);
    this.privRoomId = conversationId;
    this.privSessionToken = token;
    this.privTranslateTo = translateTo;
    this.privProfanityFilter = profanityFilter;
    this.privRoomProfanityFilter = roomProfanityFilter;
    this.privIsRoomLocked = isRoomLocked;
    this.privIsRoomLocked = isMuteAll;
    this.privParticipants = participants;
  }
  get sessionToken() {
    return this.privSessionToken;
  }
  get conversationId() {
    return this.privRoomId;
  }
  get translateTo() {
    return this.privTranslateTo;
  }
  get profanityFilter() {
    return this.privProfanityFilter;
  }
  get roomProfanityFilter() {
    return this.privRoomProfanityFilter;
  }
  get isRoomLocked() {
    return this.privIsRoomLocked;
  }
  get isMuteAll() {
    return this.privIsMuteAll;
  }
  get participants() {
    return this.privParticipants;
  }
}
class ConversationReceivedTranslationEventArgs {
  constructor(command, payload, sessionId) {
    this.privPayload = payload;
    this.privCommand = command;
    this.privSessionId = sessionId;
  }
  get payload() {
    return this.privPayload;
  }
  get command() {
    return this.privCommand;
  }
  get sessionId() {
    return this.privSessionId;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js":
/*!************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js ***!
  \************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationTranslatorCommandTypes: () => (/* binding */ ConversationTranslatorCommandTypes),
/* harmony export */   ConversationTranslatorMessageTypes: () => (/* binding */ ConversationTranslatorMessageTypes),
/* harmony export */   InternalParticipants: () => (/* binding */ InternalParticipants)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/** Users participating in the conversation */
class InternalParticipants {
  constructor(participants = [], meId) {
    this.participants = participants;
    this.meId = meId;
  }
  /**
   * Add or update a participant
   * @param value
   */
  addOrUpdateParticipant(value) {
    if (value === undefined) {
      return;
    }
    const exists = this.getParticipantIndex(value.id);
    if (exists > -1) {
      this.participants.splice(exists, 1, value);
    } else {
      this.participants.push(value);
    }
    // ensure it was added ok
    return this.getParticipant(value.id);
  }
  /**
   * Find the participant's position in the participants list.
   * @param id
   */
  getParticipantIndex(id) {
    return this.participants.findIndex(p => p.id === id);
  }
  /**
   * Find the participant by id.
   * @param id
   */
  getParticipant(id) {
    return this.participants.find(p => p.id === id);
  }
  /**
   * Remove a participant from the participants list.
   */
  deleteParticipant(id) {
    this.participants = this.participants.filter(p => p.id !== id);
  }
  /**
   * Helper to return the conversation host.
   */
  get host() {
    return this.participants.find(p => p.isHost === true);
  }
  /**
   * Helper to return the current user.
   */
  get me() {
    return this.getParticipant(this.meId);
  }
}
/**
 * List of command message types
 */
const ConversationTranslatorMessageTypes = {
  command: "command",
  final: "final",
  info: "info",
  instantMessage: "instant_message",
  keepAlive: "keep_alive",
  partial: "partial",
  participantCommand: "participant_command",
  translatedMessage: "translated_message"
};
/**
 * List of command types
 */
const ConversationTranslatorCommandTypes = {
  changeNickname: "ChangeNickname",
  disconnectSession: "DisconnectSession",
  ejectParticipant: "EjectParticipant",
  instant_message: "instant_message",
  joinSession: "JoinSession",
  leaveSession: "LeaveSession",
  participantList: "ParticipantList",
  roomExpirationWarning: "RoomExpirationWarning",
  setLockState: "SetLockState",
  setMute: "SetMute",
  setMuteAll: "SetMuteAll",
  setProfanityFiltering: "SetProfanityFiltering",
  setTranslateToLanguages: "SetTranslateToLanguages",
  setUseTTS: "SetUseTTS"
};

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js":
/*!************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js ***!
  \************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationRecognizerFactory: () => (/* binding */ ConversationRecognizerFactory),
/* harmony export */   ConversationTranslatorRecognizer: () => (/* binding */ ConversationTranslatorRecognizer)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js");
/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js");
/* harmony import */ var _ConversationConnectionFactory__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js");
/* harmony import */ var _ConversationServiceAdapter__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./ConversationServiceAdapter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
// eslint-disable-next-line max-classes-per-file






class ConversationRecognizerFactory {
  static fromConfig(conversation, speechConfig, audioConfig) {
    return new ConversationTranslatorRecognizer(conversation, speechConfig, audioConfig);
  }
}
/**
 * Sends messages to the Conversation Translator websocket and listens for incoming events containing websocket messages.
 * Based off the recognizers in the SDK folder.
 */
class ConversationTranslatorRecognizer extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {
  constructor(conversation, speechConfig, audioConfig) {
    const serviceConfigImpl = speechConfig;
    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(serviceConfigImpl, "speechConfig");
    const conversationImpl = conversation;
    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(conversationImpl, "conversationImpl");
    super(audioConfig, serviceConfigImpl.properties, new _ConversationConnectionFactory__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionFactory());
    this.privConversation = conversationImpl;
    this.privIsDisposed = false;
    this.privProperties = serviceConfigImpl.properties.clone();
    this.privConnection = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.Connection.fromRecognizer(this);
    this.privSetTimeout = typeof Blob !== "undefined" && typeof Worker !== "undefined" ? _common_Exports__WEBPACK_IMPORTED_MODULE_4__.Timeout.setTimeout : setTimeout;
    this.privClearTimeout = typeof Blob !== "undefined" && typeof Worker !== "undefined" ? _common_Exports__WEBPACK_IMPORTED_MODULE_4__.Timeout.clearTimeout : clearTimeout;
  }
  set connected(cb) {
    this.privConnection.connected = cb;
  }
  set disconnected(cb) {
    this.privConnection.disconnected = cb;
  }
  /**
   * Return the speech language used by the recognizer
   */
  get speechRecognitionLanguage() {
    return this.privSpeechRecognitionLanguage;
  }
  /**
   * Return the properties for the recognizer
   */
  get properties() {
    return this.privProperties;
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  /**
   * Connect to the recognizer
   * @param token
   */
  connect(token, cb, err) {
    try {
      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privIsDisposed);
      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, "token");
      this.privReco.conversationTranslatorToken = token;
      this.resetConversationTimeout();
      this.privReco.connectAsync(cb, err);
    } catch (error) {
      if (!!err) {
        if (error instanceof Error) {
          const typedError = error;
          err(typedError.name + ": " + typedError.message);
        } else {
          err(error);
        }
      }
    }
  }
  /**
   * Disconnect from the recognizer
   */
  disconnect(cb, err) {
    try {
      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privIsDisposed);
      if (this.privTimeoutToken !== undefined) {
        // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
        this.privClearTimeout(this.privTimeoutToken);
      }
      this.privReco.disconnect().then(() => {
        if (!!cb) {
          cb();
        }
      }, error => {
        if (!!err) {
          err(error);
        }
      });
    } catch (error) {
      if (!!err) {
        if (error instanceof Error) {
          const typedError = error;
          err(typedError.name + ": " + typedError.message);
        } else {
          err(error);
        }
      }
      // Destroy the recognizer.
      this.dispose(true).catch(reason => {
        _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.BackgroundEvent(reason));
      });
    }
  }
  /**
   * Send the mute all participants command to the websocket
   * @param conversationId
   * @param participantId
   * @param isMuted
   */
  sendRequest(command, cb, err) {
    try {
      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privIsDisposed);
      this.sendMessage(command, cb, err);
    } catch (error) {
      if (!!err) {
        if (error instanceof Error) {
          const typedError = error;
          err(typedError.name + ": " + typedError.message);
        } else {
          err(error);
        }
      }
      // Destroy the recognizer.
      this.dispose(true).catch(reason => {
        _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.BackgroundEvent(reason));
      });
    }
  }
  /**
   * Close and dispose the recognizer
   */
  close() {
    return __awaiter(this, void 0, void 0, function* () {
      if (!this.privIsDisposed) {
        if (!!this.privConnection) {
          this.privConnection.closeConnection();
          this.privConnection.close();
        }
        this.privConnection = undefined;
        yield this.dispose(true);
      }
    });
  }
  /**
   * Dispose the recognizer
   * @param disposing
   */
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: {
        get: () => super.dispose
      }
    });
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privIsDisposed) {
        return;
      }
      if (disposing) {
        if (this.privTimeoutToken !== undefined) {
          // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
          this.privClearTimeout(this.privTimeoutToken);
        }
        this.privIsDisposed = true;
        if (!!this.privConnection) {
          this.privConnection.closeConnection();
          this.privConnection.close();
          this.privConnection = undefined;
        }
        yield _super.dispose.call(this, disposing);
      }
    });
  }
  /**
   * Create the config for the recognizer
   * @param speechConfig
   */
  createRecognizerConfig(speechConfig) {
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.RecognizerConfig(speechConfig, this.privProperties);
  }
  /**
   * Create the service recognizer.
   * The audio source is redundnant here but is required by the implementation.
   * @param authentication
   * @param connectionFactory
   * @param audioConfig
   * @param recognizerConfig
   */
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const audioSource = audioConfig;
    return new _ConversationServiceAdapter__WEBPACK_IMPORTED_MODULE_8__.ConversationServiceAdapter(authentication, connectionFactory, audioSource, recognizerConfig, this);
  }
  sendMessage(msg, cb, err) {
    const withAsync = this.privReco;
    const PromiseToEmptyCallback = (promise, cb, err) => {
      if (promise !== undefined) {
        promise.then(() => {
          try {
            if (!!cb) {
              cb();
            }
          } catch (e) {
            if (!!err) {
              err(`'Unhandled error on promise callback: ${e}'`);
            }
          }
        }, reason => {
          try {
            if (!!err) {
              err(reason);
            }
            // eslint-disable-next-line no-empty
          } catch (error) {}
        });
      } else {
        if (!!err) {
          err("Null promise");
        }
      }
    };
    PromiseToEmptyCallback(withAsync.sendMessageAsync(msg), cb, err);
    this.resetConversationTimeout();
  }
  resetConversationTimeout() {
    if (this.privTimeoutToken !== undefined) {
      // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
      this.privClearTimeout(this.privTimeoutToken);
    }
    this.privTimeoutToken = this.privSetTimeout(() => {
      this.sendRequest(this.privConversation.getKeepAlive());
    }, 60000);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js":
/*!*****************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js ***!
  \*****************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationWebsocketMessageFormatter: () => (/* binding */ ConversationWebsocketMessageFormatter)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js");
/* harmony import */ var _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationConnectionMessage */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Based off WebsocketMessageFormatter. The messages for Conversation Translator have some variations from the Speech messages.
 */
class ConversationWebsocketMessageFormatter {
  /**
   * Format incoming messages: text (speech partial/final, IM) or binary (tts)
   */
  toConnectionMessage(message) {
    const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.Deferred();
    try {
      if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {
        const incomingMessage = new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionMessage(message.messageType, message.textContent, {}, message.id);
        deferral.resolve(incomingMessage);
      } else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary) {
        deferral.resolve(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionMessage(message.messageType, message.binaryContent, undefined, message.id));
      }
    } catch (e) {
      deferral.reject(`Error formatting the message. Error: ${e}`);
    }
    return deferral.promise;
  }
  /**
   * Format outgoing messages: text (commands or IM)
   */
  fromConnectionMessage(message) {
    const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.Deferred();
    try {
      if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {
        const payload = `${message.textBody ? message.textBody : ""}`;
        deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text, payload, message.id));
      }
    } catch (e) {
      deferral.reject(`Error formatting the message. ${e}`);
    }
    return deferral.promise;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationConnectionConfig: () => (/* reexport safe */ _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig),
/* harmony export */   ConversationManager: () => (/* reexport safe */ _ConversationManager__WEBPACK_IMPORTED_MODULE_0__.ConversationManager),
/* harmony export */   ConversationReceivedTranslationEventArgs: () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.ConversationReceivedTranslationEventArgs),
/* harmony export */   ConversationRecognizerFactory: () => (/* reexport safe */ _ConversationTranslatorRecognizer__WEBPACK_IMPORTED_MODULE_2__.ConversationRecognizerFactory),
/* harmony export */   ConversationTranslatorCommandTypes: () => (/* reexport safe */ _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__.ConversationTranslatorCommandTypes),
/* harmony export */   ConversationTranslatorMessageTypes: () => (/* reexport safe */ _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__.ConversationTranslatorMessageTypes),
/* harmony export */   InternalParticipants: () => (/* reexport safe */ _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__.InternalParticipants),
/* harmony export */   LockRoomEventArgs: () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.LockRoomEventArgs),
/* harmony export */   MuteAllEventArgs: () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.MuteAllEventArgs),
/* harmony export */   ParticipantAttributeEventArgs: () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.ParticipantAttributeEventArgs),
/* harmony export */   ParticipantEventArgs: () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.ParticipantEventArgs),
/* harmony export */   ParticipantsListEventArgs: () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.ParticipantsListEventArgs),
/* harmony export */   TranscriberRecognizer: () => (/* reexport safe */ _TranscriberRecognizer__WEBPACK_IMPORTED_MODULE_3__.TranscriberRecognizer)
/* harmony export */ });
/* harmony import */ var _ConversationManager__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConversationManager */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js");
/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConversationConnectionConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js");
/* harmony import */ var _ConversationTranslatorRecognizer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationTranslatorRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js");
/* harmony import */ var _TranscriberRecognizer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./TranscriberRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js");
/* harmony import */ var _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ConversationTranslatorEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js");
/* harmony import */ var _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConversationTranslatorInterfaces */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.







/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js":
/*!******************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js ***!
  \******************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CommandResponsePayload: () => (/* binding */ CommandResponsePayload)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
const parseCommandResponse = json => JSON.parse(json);
class CommandResponsePayload {
  constructor(json) {
    this.privCommandResponse = parseCommandResponse(json);
  }
  get type() {
    return this.privCommandResponse.type;
  }
  get command() {
    return this.privCommandResponse.command;
  }
  get id() {
    return this.privCommandResponse.id;
  }
  get nickname() {
    return this.privCommandResponse.nickname;
  }
  get participantId() {
    return this.privCommandResponse.participantId;
  }
  get roomid() {
    return this.privCommandResponse.roomid;
  }
  get value() {
    return this.privCommandResponse.value;
  }
  get token() {
    return this.privCommandResponse.token;
  }
  static fromJSON(json) {
    return new CommandResponsePayload(json);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js":
/*!**********************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js ***!
  \**********************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ParticipantPayloadResponse: () => (/* binding */ ParticipantPayloadResponse),
/* harmony export */   ParticipantsListPayloadResponse: () => (/* binding */ ParticipantsListPayloadResponse)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
const parseListResponse = json => JSON.parse(json);
const parseParticipantResponse = json => JSON.parse(json);
class ParticipantsListPayloadResponse {
  constructor(json) {
    this.privParticipantsPayloadResponse = parseListResponse(json);
  }
  get roomid() {
    return this.privParticipantsPayloadResponse.roomid;
  }
  get id() {
    return this.privParticipantsPayloadResponse.id;
  }
  get command() {
    return this.privParticipantsPayloadResponse.command;
  }
  get participants() {
    return this.privParticipantsPayloadResponse.participants;
  }
  get token() {
    return this.privParticipantsPayloadResponse.token;
  }
  get translateTo() {
    return this.privParticipantsPayloadResponse.translateTo;
  }
  get profanityFilter() {
    return this.privParticipantsPayloadResponse.profanityFilter;
  }
  get roomProfanityFilter() {
    return this.privParticipantsPayloadResponse.roomProfanityFilter;
  }
  get roomLocked() {
    return this.privParticipantsPayloadResponse.roomLocked;
  }
  get muteAll() {
    return this.privParticipantsPayloadResponse.muteAll;
  }
  get type() {
    return this.privParticipantsPayloadResponse.type;
  }
  static fromJSON(json) {
    return new ParticipantsListPayloadResponse(json);
  }
}
class ParticipantPayloadResponse {
  constructor(json) {
    this.privParticipantPayloadResponse = parseParticipantResponse(json);
  }
  get nickname() {
    return this.privParticipantPayloadResponse.nickname;
  }
  get locale() {
    return this.privParticipantPayloadResponse.locale;
  }
  get usetts() {
    return this.privParticipantPayloadResponse.usetts;
  }
  get ismuted() {
    return this.privParticipantPayloadResponse.ismuted;
  }
  get ishost() {
    return this.privParticipantPayloadResponse.ishost;
  }
  get participantId() {
    return this.privParticipantPayloadResponse.participantId;
  }
  get avatar() {
    return this.privParticipantPayloadResponse.avatar;
  }
  static fromJSON(json) {
    return new ParticipantPayloadResponse(json);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js":
/*!**********************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js ***!
  \**********************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechResponsePayload: () => (/* binding */ SpeechResponsePayload),
/* harmony export */   TextResponsePayload: () => (/* binding */ TextResponsePayload)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
const parseSpeechResponse = json => JSON.parse(json);
const parseTextResponse = json => JSON.parse(json);
class SpeechResponsePayload {
  constructor(json) {
    this.privSpeechResponse = parseSpeechResponse(json);
  }
  get recognition() {
    return this.privSpeechResponse.recognition;
  }
  get translations() {
    return this.privSpeechResponse.translations;
  }
  get id() {
    return this.privSpeechResponse.id;
  }
  get language() {
    return this.privSpeechResponse.language;
  }
  get nickname() {
    return this.privSpeechResponse.nickname;
  }
  get participantId() {
    return this.privSpeechResponse.participantId;
  }
  get roomid() {
    return this.privSpeechResponse.roomid;
  }
  get timestamp() {
    return this.privSpeechResponse.timestamp;
  }
  get type() {
    return this.privSpeechResponse.type;
  }
  get isFinal() {
    return this.privSpeechResponse.type === "final";
  }
  static fromJSON(json) {
    return new SpeechResponsePayload(json);
  }
}
class TextResponsePayload {
  constructor(json) {
    this.privTextResponse = parseTextResponse(json);
  }
  get originalText() {
    return this.privTextResponse.originalText;
  }
  get translations() {
    return this.privTextResponse.translations;
  }
  get id() {
    return this.privTextResponse.id;
  }
  get language() {
    return this.privTextResponse.language;
  }
  get nickname() {
    return this.privTextResponse.nickname;
  }
  get participantId() {
    return this.privTextResponse.participantId;
  }
  get roomid() {
    return this.privTextResponse.roomid;
  }
  get timestamp() {
    return this.privTextResponse.timestamp;
  }
  get type() {
    return this.privTextResponse.type;
  }
  static fromJSON(json) {
    return new TextResponsePayload(json);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js ***!
  \*************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranscriberRecognizer: () => (/* binding */ TranscriberRecognizer)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};




class TranscriberRecognizer extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {
  /**
   * TranscriberRecognizer constructor.
   * @constructor
   * @param {SpeechTranslationConfig} speechTranslationConfig - Non-audio configuration associated with the recognizer
   * @param {AudioConfig} audioConfig - An audio configuration associated with the recognizer
   */
  constructor(speechTranslationConfig, audioConfig) {
    const speechTranslationConfigImpl = speechTranslationConfig;
    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(speechTranslationConfigImpl, "speechTranslationConfig");
    const audioConfigImpl = audioConfig;
    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(audioConfigImpl, "audioConfigImpl");
    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(speechTranslationConfigImpl.speechRecognitionLanguage, _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage]);
    super(audioConfig, speechTranslationConfigImpl.properties, new _Exports__WEBPACK_IMPORTED_MODULE_3__.TranscriberConnectionFactory());
    this.privDisposedRecognizer = false;
  }
  get speechRecognitionLanguage() {
    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);
    return this.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage);
  }
  get properties() {
    return this.privProperties;
  }
  get authorizationToken() {
    return this.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token);
  }
  set authorizationToken(token) {
    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, token);
  }
  set conversation(c) {
    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(c, "Conversation");
    this.privConversation = c;
  }
  getConversationInfo() {
    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(this.privConversation, "Conversation");
    return this.privConversation.conversationInfo;
  }
  startContinuousRecognitionAsync(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation), cb, err);
  }
  stopContinuousRecognitionAsync(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);
  }
  close() {
    return __awaiter(this, void 0, void 0, function* () {
      if (!this.privDisposedRecognizer) {
        yield this.dispose(true);
      }
    });
  }
  // Push async join/leave conversation message via serviceRecognizer
  pushConversationEvent(conversationInfo, command) {
    return __awaiter(this, void 0, void 0, function* () {
      const reco = this.privReco;
      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(reco, "serviceRecognizer");
      yield reco.sendSpeechEventAsync(conversationInfo, command);
    });
  }
  enforceAudioGating() {
    return __awaiter(this, void 0, void 0, function* () {
      const audioConfigImpl = this.audioConfig;
      const format = yield audioConfigImpl.format;
      const channels = format.channels;
      if (channels === 1) {
        if (this.properties.getProperty("f0f5debc-f8c9-4892-ac4b-90a7ab359fd2", "false").toLowerCase() !== "true") {
          throw new Error("Single channel audio configuration for ConversationTranscriber is currently under private preview, please contact diarizationrequest@microsoft.com for more details");
        }
      } else if (channels !== 8) {
        throw new Error(`Unsupported audio configuration: Detected ${channels}-channel audio`);
      }
      return;
    });
  }
  connectCallbacks(transcriber) {
    this.canceled = (s, e) => {
      if (!!transcriber.canceled) {
        transcriber.canceled(transcriber, e);
      }
    };
    this.recognizing = (s, e) => {
      if (!!transcriber.transcribing) {
        transcriber.transcribing(transcriber, e);
      }
    };
    this.recognized = (s, e) => {
      if (!!transcriber.transcribed) {
        transcriber.transcribed(transcriber, e);
      }
    };
    this.sessionStarted = (s, e) => {
      if (!!transcriber.sessionStarted) {
        transcriber.sessionStarted(transcriber, e);
      }
    };
    this.sessionStopped = (s, e) => {
      if (!!transcriber.sessionStopped) {
        transcriber.sessionStopped(transcriber, e);
      }
    };
  }
  disconnectCallbacks() {
    this.canceled = undefined;
    this.recognizing = undefined;
    this.recognized = undefined;
    this.sessionStarted = undefined;
    this.sessionStopped = undefined;
  }
  /**
   * Disposes any resources held by the object.
   * @member ConversationTranscriber.prototype.dispose
   * @function
   * @public
   * @param {boolean} disposing - true if disposing the object.
   */
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: {
        get: () => super.dispose
      }
    });
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privDisposedRecognizer) {
        return;
      }
      if (disposing) {
        this.privDisposedRecognizer = true;
        yield this.implRecognizerStop();
      }
      yield _super.dispose.call(this, disposing);
    });
  }
  createRecognizerConfig(speechConfig) {
    return new _Exports__WEBPACK_IMPORTED_MODULE_5__.RecognizerConfig(speechConfig, this.properties);
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const configImpl = audioConfig;
    return new _Exports__WEBPACK_IMPORTED_MODULE_6__.TranscriptionServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranslationConnectionFactory: () => (/* binding */ TranslationConnectionFactory)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js");
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js");
/* harmony import */ var _common_StringUtils__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/StringUtils */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/StringUtils.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js");
/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./QueryParameterNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.







class TranslationConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {
  create(config, authInfo, connectionId) {
    const endpoint = this.getEndpointUrl(config);
    const queryParams = {};
    if (config.autoDetectSourceLanguages !== undefined) {
      queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.EnableLanguageId] = "true";
    }
    this.setQueryParams(queryParams, config, endpoint);
    const headers = {};
    if (authInfo.token !== undefined && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ConnectionId] = connectionId;
    config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_Url, endpoint);
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_4__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_5__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_6__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
  getEndpointUrl(config, returnRegionPlaceholder) {
    const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_Region);
    const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);
    let endpointUrl = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_Endpoint, undefined);
    if (!endpointUrl) {
      if (config.autoDetectSourceLanguages !== undefined) {
        const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_Host, "wss://{region}.stt.speech" + hostSuffix);
        endpointUrl = host + "/speech/universal/v2";
      } else {
        const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_Host, "wss://{region}.s2s.speech" + hostSuffix);
        endpointUrl = host + "/speech/translation/cognitiveservices/v1";
      }
    }
    if (returnRegionPlaceholder === true) {
      return endpointUrl;
    }
    return _common_StringUtils__WEBPACK_IMPORTED_MODULE_7__.StringUtils.formatString(endpointUrl, {
      region
    });
  }
  setQueryParams(queryParams, config, endpointUrl) {
    queryParams.from = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage);
    queryParams.to = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages);
    this.setCommonUrlParams(config, queryParams, endpointUrl);
    this.setUrlParameter(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.StableTranslation, config, queryParams, endpointUrl);
    const translationVoice = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationVoice, undefined);
    if (translationVoice !== undefined) {
      queryParams.voice = translationVoice;
      queryParams.features = "texttospeech";
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranslationServiceRecognizer: () => (/* binding */ TranslationServiceRecognizer)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConversationServiceRecognizer.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};



// eslint-disable-next-line max-classes-per-file
class TranslationServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ConversationServiceRecognizer {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer);
    this.privTranslationRecognizer = translationRecognizer;
    this.connectionEvents.attach(connectionEvent => {
      if (connectionEvent.name === "ConnectionEstablishedEvent") {
        this.privTranslationRecognizer.onConnection();
      } else if (connectionEvent.name === "ConnectionClosedEvent") {
        void this.privTranslationRecognizer.onDisconnection();
      }
    });
  }
  processTypeSpecificMessages(connectionMessage) {
    return __awaiter(this, void 0, void 0, function* () {
      const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();
      let processed = yield this.processSpeechMessages(connectionMessage);
      if (processed) {
        return true;
      }
      const handleTranslationPhrase = translatedPhrase => __awaiter(this, void 0, void 0, function* () {
        this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + translatedPhrase.Offset + translatedPhrase.Duration);
        if (translatedPhrase.RecognitionStatus === _Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionStatus.Success) {
          // OK, the recognition was successful. How'd the translation do?
          const result = this.fireEventForResult(translatedPhrase, resultProps);
          if (!!this.privTranslationRecognizer.recognized) {
            try {
              this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, result);
              /* eslint-disable no-empty */
            } catch (error) {
              // Not going to let errors in the event handler
              // trip things up.
            }
          }
          // report result to promise.
          if (!!this.privSuccessCallback) {
            try {
              this.privSuccessCallback(result.result);
            } catch (e) {
              if (!!this.privErrorCallback) {
                this.privErrorCallback(e);
              }
            }
            // Only invoke the call back once.
            // and if it's successful don't invoke the
            // error after that.
            this.privSuccessCallback = undefined;
            this.privErrorCallback = undefined;
          }
        } else {
          const reason = _Exports__WEBPACK_IMPORTED_MODULE_3__.EnumTranslation.implTranslateRecognitionResult(translatedPhrase.RecognitionStatus);
          const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.TranslationRecognitionResult(undefined, this.privRequestSession.requestId, reason, translatedPhrase.Text, translatedPhrase.Duration, this.privRequestSession.currentTurnAudioOffset + translatedPhrase.Offset, translatedPhrase.Language, translatedPhrase.Confidence, undefined, connectionMessage.textBody, resultProps);
          if (reason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled) {
            const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_3__.EnumTranslation.implTranslateCancelResult(translatedPhrase.RecognitionStatus);
            const cancellationErrorCode = _Exports__WEBPACK_IMPORTED_MODULE_3__.EnumTranslation.implTranslateCancelErrorCode(translatedPhrase.RecognitionStatus);
            yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, _Exports__WEBPACK_IMPORTED_MODULE_3__.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));
          } else {
            if (!(this.privRequestSession.isSpeechEnded && reason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.NoMatch && translatedPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionStatus.InitialSilenceTimeout)) {
              const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.TranslationRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);
              if (!!this.privTranslationRecognizer.recognized) {
                try {
                  this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, ev);
                  /* eslint-disable no-empty */
                } catch (error) {
                  // Not going to let errors in the event handler
                  // trip things up.
                }
              }
            }
            // report result to promise.
            if (!!this.privSuccessCallback) {
              try {
                this.privSuccessCallback(result);
              } catch (e) {
                if (!!this.privErrorCallback) {
                  this.privErrorCallback(e);
                }
              }
              // Only invoke the call back once.
              // and if it's successful don't invoke the
              // error after that.
              this.privSuccessCallback = undefined;
              this.privErrorCallback = undefined;
            }
          }
          processed = true;
        }
      });
      if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text) {
        resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
      }
      switch (connectionMessage.path.toLowerCase()) {
        case "translation.hypothesis":
          const result = this.fireEventForResult(_Exports__WEBPACK_IMPORTED_MODULE_9__.TranslationHypothesis.fromJSON(connectionMessage.textBody), resultProps);
          this.privRequestSession.onHypothesis(this.privRequestSession.currentTurnAudioOffset + result.offset);
          if (!!this.privTranslationRecognizer.recognizing) {
            try {
              this.privTranslationRecognizer.recognizing(this.privTranslationRecognizer, result);
              /* eslint-disable no-empty */
            } catch (error) {
              // Not going to let errors in the event handler
              // trip things up.
            }
          }
          processed = true;
          break;
        case "translation.response":
          const phrase = JSON.parse(connectionMessage.textBody);
          if (!!phrase.SpeechPhrase) {
            yield handleTranslationPhrase(_Exports__WEBPACK_IMPORTED_MODULE_10__.TranslationPhrase.fromTranslationResponse(phrase));
          }
          break;
        case "translation.phrase":
          yield handleTranslationPhrase(_Exports__WEBPACK_IMPORTED_MODULE_10__.TranslationPhrase.fromJSON(connectionMessage.textBody));
          break;
        case "translation.synthesis":
          this.sendSynthesisAudio(connectionMessage.binaryBody, this.privRequestSession.sessionId);
          processed = true;
          break;
        case "audio.end":
        case "translation.synthesis.end":
          const synthEnd = _Exports__WEBPACK_IMPORTED_MODULE_11__.TranslationSynthesisEnd.fromJSON(connectionMessage.textBody);
          switch (synthEnd.SynthesisStatus) {
            case _Exports__WEBPACK_IMPORTED_MODULE_2__.SynthesisStatus.Error:
              if (!!this.privTranslationRecognizer.synthesizing) {
                const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.TranslationSynthesisResult(_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled, undefined);
                const retEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.TranslationSynthesisEventArgs(result, this.privRequestSession.sessionId);
                try {
                  this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);
                  /* eslint-disable no-empty */
                } catch (error) {
                  // Not going to let errors in the event handler
                  // trip things up.
                }
              }
              if (!!this.privTranslationRecognizer.canceled) {
                // And raise a canceled event to send the rich(er) error message back.
                const canceledResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.TranslationRecognitionCanceledEventArgs(this.privRequestSession.sessionId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.CancellationReason.Error, synthEnd.FailureReason, _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.CancellationErrorCode.ServiceError, null);
                try {
                  this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, canceledResult);
                  /* eslint-disable no-empty */
                } catch (error) {
                  // Not going to let errors in the event handler
                  // trip things up.
                }
              }
              break;
            case _Exports__WEBPACK_IMPORTED_MODULE_2__.SynthesisStatus.Success:
              this.sendSynthesisAudio(undefined, this.privRequestSession.sessionId);
              break;
            default:
              break;
          }
          processed = true;
          break;
        default:
          break;
      }
      return processed;
    });
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();
    properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_17__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.CancellationErrorCode[errorCode]);
    if (!!this.privTranslationRecognizer.canceled) {
      const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.TranslationRecognitionCanceledEventArgs(sessionId, cancellationReason, error, errorCode, undefined);
      try {
        this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, cancelEvent);
        /* eslint-disable no-empty */
      } catch (_a) {}
    }
    if (!!this.privSuccessCallback) {
      const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.TranslationRecognitionResult(undefined,
      // Translations
      requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled, undefined,
      // Text
      undefined,
      // Druation
      undefined,
      // Offset
      undefined,
      // Language
      undefined,
      // LanguageDetectionConfidence
      error, undefined,
      // Json
      properties);
      try {
        this.privSuccessCallback(result);
        /* eslint-disable no-empty */
        this.privSuccessCallback = undefined;
      } catch (_b) {}
    }
  }
  handleRecognizingCallback(result, duration, sessionId) {
    try {
      const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.TranslationRecognitionEventArgs(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.TranslationRecognitionResult.fromSpeechRecognitionResult(result), duration, sessionId);
      this.privTranslationRecognizer.recognizing(this.privTranslationRecognizer, ev);
      /* eslint-disable no-empty */
    } catch (error) {
      // Not going to let errors in the event handler
      // trip things up.
    }
  }
  handleRecognizedCallback(result, offset, sessionId) {
    try {
      const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.TranslationRecognitionEventArgs(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.TranslationRecognitionResult.fromSpeechRecognitionResult(result), offset, sessionId);
      this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, ev);
    } catch (error) {
      // Not going to let errors in the event handler
      // trip things up.
    }
  }
  fireEventForResult(serviceResult, properties) {
    let translations;
    if (undefined !== serviceResult.Translation.Translations) {
      translations = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_18__.Translations();
      for (const translation of serviceResult.Translation.Translations) {
        translations.set(translation.Language, translation.Text || translation.DisplayText);
      }
    }
    let resultReason;
    let language;
    let confidence;
    if (serviceResult instanceof _Exports__WEBPACK_IMPORTED_MODULE_10__.TranslationPhrase) {
      if (!!serviceResult.Translation && serviceResult.Translation.TranslationStatus === _common_Exports__WEBPACK_IMPORTED_MODULE_19__.TranslationStatus.Success) {
        resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.TranslatedSpeech;
      } else {
        resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.RecognizedSpeech;
      }
      language = serviceResult.Language;
      confidence = serviceResult.Confidence;
    } else {
      resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.TranslatingSpeech;
    }
    const offset = serviceResult.Offset + this.privRequestSession.currentTurnAudioOffset;
    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.TranslationRecognitionResult(translations, this.privRequestSession.requestId, resultReason, serviceResult.Text, serviceResult.Duration, offset, language, confidence, serviceResult.Translation.FailureReason, JSON.stringify(serviceResult), properties);
    const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.TranslationRecognitionEventArgs(result, offset, this.privRequestSession.sessionId);
    return ev;
  }
  sendSynthesisAudio(audio, sessionId) {
    const reason = undefined === audio ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.SynthesizingAudioCompleted : _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.SynthesizingAudio;
    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.TranslationSynthesisResult(reason, audio);
    const retEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.TranslationSynthesisEventArgs(result, sessionId);
    if (!!this.privTranslationRecognizer.synthesizing) {
      try {
        this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);
        /* eslint-disable no-empty */
      } catch (error) {
        // Not going to let errors in the event handler
        // trip things up.
      }
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranslationStatus: () => (/* binding */ TranslationStatus)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines translation status.
 * @class TranslationStatus
 */
var TranslationStatus;
(function (TranslationStatus) {
  /**
   * @member TranslationStatus.Success
   */
  TranslationStatus[TranslationStatus["Success"] = 0] = "Success";
  /**
   * @member TranslationStatus.Error
   */
  TranslationStatus[TranslationStatus["Error"] = 1] = "Error";
})(TranslationStatus || (TranslationStatus = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/VoiceServiceRecognizer.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/VoiceServiceRecognizer.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   VoiceServiceRecognizer: () => (/* binding */ VoiceServiceRecognizer)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DeferralMap.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js");
/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../sdk/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};





// eslint-disable-next-line max-classes-per-file
class VoiceServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);
    this.privDeferralMap = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.DeferralMap();
    this.privSpeakerAudioSource = audioSource;
    this.sendPrePayloadJSONOverride = () => this.noOp();
  }
  set SpeakerAudioSource(audioSource) {
    this.privSpeakerAudioSource = audioSource;
  }
  processTypeSpecificMessages(connectionMessage) {
    let processed = false;
    const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection();
    if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_3__.MessageType.Text) {
      resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
    }
    switch (connectionMessage.path.toLowerCase()) {
      // Profile management response for create, fetch, delete, reset
      case "speaker.profiles":
        const response = JSON.parse(connectionMessage.textBody);
        switch (response.operation.toLowerCase()) {
          case "create":
            this.handleCreateResponse(response, connectionMessage.requestId);
            break;
          case "delete":
          case "reset":
            this.handleResultResponse(response, connectionMessage.requestId);
            break;
          case "fetch":
            const enrollmentResponse = JSON.parse(connectionMessage.textBody);
            this.handleFetchResponse(enrollmentResponse, connectionMessage.requestId);
            break;
          default:
            break;
        }
        processed = true;
        break;
      // Activation and authorization phrase response
      case "speaker.phrases":
        const phraseResponse = JSON.parse(connectionMessage.textBody);
        this.handlePhrasesResponse(phraseResponse, connectionMessage.requestId);
        processed = true;
        break;
      // Enrollment response
      case "speaker.profile.enrollment":
        const enrollmentResponse = JSON.parse(connectionMessage.textBody);
        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.VoiceProfileEnrollmentResult(this.enrollmentReasonFrom(!!enrollmentResponse.enrollment ? enrollmentResponse.enrollment.enrollmentStatus : enrollmentResponse.status.statusCode), !!enrollmentResponse.enrollment ? JSON.stringify(enrollmentResponse.enrollment) : undefined, enrollmentResponse.status.reason);
        if (!!this.privDeferralMap.getId(connectionMessage.requestId)) {
          this.privDeferralMap.complete(connectionMessage.requestId, result);
        }
        this.privRequestSession.onSpeechEnded();
        processed = true;
        break;
      default:
        break;
    }
    const defferal = new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Deferred();
    defferal.resolve(processed);
    return defferal.promise;
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection();
    // const enrollmentResponse: EnrollmentResponse = JSON.parse(connectionMessage.textBody) as EnrollmentResponse;
    properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode[errorCode]);
    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.VoiceProfileEnrollmentResult(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.ResultReason.Canceled, error, error);
    if (!!this.privDeferralMap.getId(requestId)) {
      this.privDeferralMap.complete(requestId, result);
    }
  }
  createProfile(profileType, locale) {
    return __awaiter(this, void 0, void 0, function* () {
      // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().
      this.voiceProfileType = profileType.toString();
      const conPromise = this.connectImpl();
      try {
        const createProfileDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Deferred();
        yield conPromise;
        yield this.sendCreateProfile(createProfileDeferral, profileType, locale);
        void this.receiveMessage();
        return createProfileDeferral.promise;
      } catch (err) {
        throw err;
      }
    });
  }
  resetProfile(profile) {
    return __awaiter(this, void 0, void 0, function* () {
      this.voiceProfileType = profile.profileType.toString();
      return this.sendCommonRequest("reset", profile.profileType, profile);
    });
  }
  deleteProfile(profile) {
    return __awaiter(this, void 0, void 0, function* () {
      this.voiceProfileType = profile.profileType.toString();
      return this.sendCommonRequest("delete", profile.profileType, profile);
    });
  }
  retrieveEnrollmentResult(profile) {
    return __awaiter(this, void 0, void 0, function* () {
      this.voiceProfileType = profile.profileType.toString();
      this.privExpectedProfileId = profile.profileId;
      return this.sendCommonRequest("fetch", profile.profileType, profile);
    });
  }
  getAllProfiles(profileType) {
    return __awaiter(this, void 0, void 0, function* () {
      this.voiceProfileType = profileType.toString();
      return this.sendCommonRequest("fetch", profileType);
    });
  }
  getActivationPhrases(profileType, lang) {
    return __awaiter(this, void 0, void 0, function* () {
      this.voiceProfileType = profileType.toString();
      // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().
      const conPromise = this.connectImpl();
      try {
        const getPhrasesDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Deferred();
        yield conPromise;
        yield this.sendPhrasesRequest(getPhrasesDeferral, profileType, lang);
        void this.receiveMessage();
        return getPhrasesDeferral.promise;
      } catch (err) {
        throw err;
      }
    });
  }
  enrollProfile(profile) {
    return __awaiter(this, void 0, void 0, function* () {
      this.voiceProfileType = profile.profileType.toString();
      const enrollmentDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Deferred();
      this.privRequestSession.startNewRecognition();
      this.privRequestSession.listenForServiceTelemetry(this.privSpeakerAudioSource.events);
      this.privRecognizerConfig.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.Speech_SessionId, this.privRequestSession.sessionId);
      // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().
      const conPromise = this.connectImpl();
      const preAudioPromise = this.sendPreAudioMessages(profile, enrollmentDeferral);
      const node = yield this.privSpeakerAudioSource.attach(this.privRequestSession.audioNodeId);
      const format = yield this.privSpeakerAudioSource.format;
      const deviceInfo = yield this.privSpeakerAudioSource.deviceInfo;
      const audioNode = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_10__.ReplayableAudioNode(node, format.avgBytesPerSec);
      yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);
      this.privRecognizerConfig.SpeechServiceConfig.Context.audio = {
        source: deviceInfo
      };
      try {
        yield conPromise;
        yield preAudioPromise;
      } catch (err) {
        this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.ConnectionFailure, err);
      }
      const sessionStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.SessionEventArgs(this.privRequestSession.sessionId);
      if (!!this.privRecognizer.sessionStarted) {
        this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);
      }
      void this.receiveMessage();
      const audioSendPromise = this.sendAudio(audioNode);
      // /* eslint-disable no-empty */
      audioSendPromise.then(() => {}, error => {
        this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.RuntimeError, error);
      });
      return enrollmentDeferral.promise;
    });
  }
  sendPreAudioMessages(profile, enrollmentDeferral) {
    return __awaiter(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      this.privRequestSession.onSpeechContext();
      this.privDeferralMap.add(this.privRequestSession.requestId, enrollmentDeferral);
      yield this.sendBaseRequest(connection, "enroll", this.scenarioFrom(profile.profileType), profile);
    });
  }
  sendPhrasesRequest(getPhrasesDeferral, profileType, locale) {
    return __awaiter(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      this.privRequestSession.onSpeechContext();
      this.privDeferralMap.add(this.privRequestSession.requestId, getPhrasesDeferral);
      const scenario = this.scenarioFrom(profileType);
      const profileCreateRequest = {
        locale,
        scenario
      };
      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_13__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_3__.MessageType.Text, "speaker.profile.phrases", this.privRequestSession.requestId, "application/json; charset=utf-8", JSON.stringify(profileCreateRequest)));
    });
  }
  sendCreateProfile(createProfileDeferral, profileType, locale) {
    return __awaiter(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      this.privRequestSession.onSpeechContext();
      this.privDeferralMap.add(this.privRequestSession.requestId, createProfileDeferral);
      const scenario = profileType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.VoiceProfileType.TextIndependentIdentification ? "TextIndependentIdentification" : profileType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.VoiceProfileType.TextIndependentVerification ? "TextIndependentVerification" : "TextDependentVerification";
      const profileCreateRequest = {
        locale,
        number: "1",
        scenario
      };
      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_13__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_3__.MessageType.Text, "speaker.profile.create", this.privRequestSession.requestId, "application/json; charset=utf-8", JSON.stringify(profileCreateRequest)));
    });
  }
  sendCommonRequest(operation, profileType, profile = undefined) {
    return __awaiter(this, void 0, void 0, function* () {
      // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().
      const conPromise = this.connectImpl();
      try {
        const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Deferred();
        this.privRequestSession.onSpeechContext();
        yield conPromise;
        const connection = yield this.fetchConnection();
        this.privDeferralMap.add(this.privRequestSession.requestId, deferral);
        yield this.sendBaseRequest(connection, operation, this.scenarioFrom(profileType), profile);
        void this.receiveMessage();
        return deferral.promise;
      } catch (err) {
        throw err;
      }
    });
  }
  sendBaseRequest(connection, operation, scenario, profile) {
    return __awaiter(this, void 0, void 0, function* () {
      const profileRequest = {
        scenario
      };
      if (!!profile) {
        profileRequest.profileIds = [profile.profileId];
      } else {
        profileRequest.maxPageSize = -1;
      }
      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_13__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_3__.MessageType.Text, `speaker.profile.${operation}`, this.privRequestSession.requestId, "application/json; charset=utf-8", JSON.stringify(profileRequest)));
    });
  }
  extractSpeakerContext(model) {
    return {
      features: {
        interimResult: "enabled",
        progressiveDetection: "disabled"
      },
      profileIds: model.profileIds,
      scenario: model.scenario
    };
  }
  handlePhrasesResponse(response, requestId) {
    if (!!this.privDeferralMap.getId(requestId)) {
      if (response.status.statusCode.toLowerCase() !== "success") {
        const reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.ResultReason.Canceled;
        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.VoiceProfilePhraseResult(reason, response.status.statusCode, response.passPhraseType, []);
        this.privDeferralMap.complete(requestId, result);
      } else if (!!response.phrases && response.phrases.length > 0) {
        const reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.ResultReason.EnrollingVoiceProfile;
        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.VoiceProfilePhraseResult(reason, response.status.statusCode, response.passPhraseType, response.phrases);
        this.privDeferralMap.complete(requestId, result);
      } else {
        throw new Error("Voice Profile get activation phrases failed, no phrases received");
      }
    } else {
      throw new Error(`Voice Profile get activation phrases request for requestID ${requestId} not found`);
    }
  }
  handleCreateResponse(response, requestId) {
    if (!!response.profiles && response.profiles.length > 0) {
      if (!!this.privDeferralMap.getId(requestId)) {
        const profileIds = response.profiles.map(profile => profile.profileId);
        this.privDeferralMap.complete(requestId, profileIds);
      } else {
        throw new Error(`Voice Profile create request for requestID ${requestId} not found`);
      }
    } else {
      throw new Error("Voice Profile create failed, no profile id received");
    }
  }
  handleResultResponse(response, requestId) {
    if (!!this.privDeferralMap.getId(requestId)) {
      const successReason = response.operation.toLowerCase() === "delete" ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.ResultReason.DeletedVoiceProfile : _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.ResultReason.ResetVoiceProfile;
      const reason = response.status.statusCode.toLowerCase() === "success" ? successReason : _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.ResultReason.Canceled;
      const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.VoiceProfileResult(reason, `statusCode: ${response.status.statusCode}, errorDetails: ${response.status.reason}`);
      this.privDeferralMap.complete(requestId, result);
    } else {
      throw new Error(`Voice Profile create request for requestID ${requestId} not found`);
    }
  }
  handleFetchResponse(enrollmentResponse, requestId) {
    if (!!this.privDeferralMap.getId(requestId) && !!enrollmentResponse.profiles[0]) {
      if (!!this.privExpectedProfileId && enrollmentResponse.profiles.length === 1 && enrollmentResponse.profiles[0].profileId === this.privExpectedProfileId) {
        this.privExpectedProfileId = undefined;
        const profileInfo = enrollmentResponse.profiles[0];
        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.VoiceProfileEnrollmentResult(this.enrollmentReasonFrom(profileInfo.enrollmentStatus), JSON.stringify(profileInfo), enrollmentResponse.status.reason);
        this.privDeferralMap.complete(requestId, result);
      } else if (enrollmentResponse.profiles.length > 0) {
        const iProfiles = enrollmentResponse.profiles;
        const profileResults = [];
        for (const profile of iProfiles) {
          profileResults.push(new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.VoiceProfileEnrollmentResult(this.enrollmentReasonFrom(profile.enrollmentStatus), JSON.stringify(profile), enrollmentResponse.status.reason));
        }
        this.privDeferralMap.complete(requestId, profileResults);
      }
    } else {
      throw new Error(`Voice Profile fetch request for requestID ${requestId} not found`);
    }
  }
  enrollmentReasonFrom(statusCode) {
    switch (statusCode.toLowerCase()) {
      case "enrolled":
        return _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.ResultReason.EnrolledVoiceProfile;
      case "invalidlocale":
      case "invalidphrase":
      case "invalidaudioformat":
      case "invalidscenario":
      case "invalidprofilecount":
      case "invalidoperation":
      case "audiotooshort":
      case "audiotoolong":
      case "toomanyenrollments":
      case "storageconflict":
      case "profilenotfound":
      case "incompatibleprofiles":
      case "incompleteenrollment":
        return _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.ResultReason.Canceled;
      default:
        return _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.ResultReason.EnrollingVoiceProfile;
    }
  }
  scenarioFrom(profileType) {
    return profileType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.VoiceProfileType.TextIndependentIdentification ? "TextIndependentIdentification" : profileType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.VoiceProfileType.TextIndependentVerification ? "TextIndependentVerification" : "TextDependentVerification";
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   WebsocketMessageFormatter: () => (/* binding */ WebsocketMessageFormatter)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

const CRLF = "\r\n";
class WebsocketMessageFormatter {
  toConnectionMessage(message) {
    const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.Deferred();
    try {
      if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {
        const textMessage = message.textContent;
        let headers = {};
        let body = null;
        if (textMessage) {
          const headerBodySplit = textMessage.split("\r\n\r\n");
          if (headerBodySplit && headerBodySplit.length > 0) {
            headers = this.parseHeaders(headerBodySplit[0]);
            if (headerBodySplit.length > 1) {
              body = headerBodySplit[1];
            }
          }
        }
        deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ConnectionMessage(message.messageType, body, headers, message.id));
      } else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary) {
        const binaryMessage = message.binaryContent;
        let headers = {};
        let body = null;
        if (!binaryMessage || binaryMessage.byteLength < 2) {
          throw new Error("Invalid binary message format. Header length missing.");
        }
        const dataView = new DataView(binaryMessage);
        const headerLength = dataView.getInt16(0);
        if (binaryMessage.byteLength < headerLength + 2) {
          throw new Error("Invalid binary message format. Header content missing.");
        }
        let headersString = "";
        for (let i = 0; i < headerLength; i++) {
          headersString += String.fromCharCode(dataView.getInt8(i + 2));
        }
        headers = this.parseHeaders(headersString);
        if (binaryMessage.byteLength > headerLength + 2) {
          body = binaryMessage.slice(2 + headerLength);
        }
        deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ConnectionMessage(message.messageType, body, headers, message.id));
      }
    } catch (e) {
      deferral.reject(`Error formatting the message. Error: ${e}`);
    }
    return deferral.promise;
  }
  fromConnectionMessage(message) {
    const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.Deferred();
    try {
      if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {
        const payload = `${this.makeHeaders(message)}${CRLF}${message.textBody ? message.textBody : ""}`;
        deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text, payload, message.id));
      } else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary) {
        const headersString = this.makeHeaders(message);
        const content = message.binaryBody;
        const headerBuffer = this.stringToArrayBuffer(headersString);
        const headerInt8Array = new Int8Array(headerBuffer);
        const headerLength = headerInt8Array.byteLength;
        const payloadInt8Array = new Int8Array(2 + headerLength + (content ? content.byteLength : 0));
        payloadInt8Array[0] = headerLength >> 8 & 0xff;
        payloadInt8Array[1] = headerLength & 0xff;
        payloadInt8Array.set(headerInt8Array, 2);
        if (content) {
          const bodyInt8Array = new Int8Array(content);
          payloadInt8Array.set(bodyInt8Array, 2 + headerLength);
        }
        const payload = payloadInt8Array.buffer;
        deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary, payload, message.id));
      }
    } catch (e) {
      deferral.reject(`Error formatting the message. ${e}`);
    }
    return deferral.promise;
  }
  makeHeaders(message) {
    let headersString = "";
    if (message.headers) {
      for (const header in message.headers) {
        if (header) {
          headersString += `${header}: ${message.headers[header]}${CRLF}`;
        }
      }
    }
    return headersString;
  }
  parseHeaders(headersString) {
    const headers = {};
    if (headersString) {
      const headerMatches = headersString.match(/[^\r\n]+/g);
      if (headers) {
        for (const header of headerMatches) {
          if (header) {
            const separatorIndex = header.indexOf(":");
            const headerName = separatorIndex > 0 ? header.substr(0, separatorIndex).trim().toLowerCase() : header;
            const headerValue = separatorIndex > 0 && header.length > separatorIndex + 1 ? header.substr(separatorIndex + 1).trim() : "";
            headers[headerName] = headerValue;
          }
        }
      }
    }
    return headers;
  }
  stringToArrayBuffer(str) {
    const buffer = new ArrayBuffer(str.length);
    const view = new DataView(buffer);
    for (let i = 0; i < str.length; i++) {
      view.setUint8(i, str.charCodeAt(i));
    }
    return buffer;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AudioSourceErrorEvent: () => (/* binding */ AudioSourceErrorEvent),
/* harmony export */   AudioSourceEvent: () => (/* binding */ AudioSourceEvent),
/* harmony export */   AudioSourceInitializingEvent: () => (/* binding */ AudioSourceInitializingEvent),
/* harmony export */   AudioSourceOffEvent: () => (/* binding */ AudioSourceOffEvent),
/* harmony export */   AudioSourceReadyEvent: () => (/* binding */ AudioSourceReadyEvent),
/* harmony export */   AudioStreamNodeAttachedEvent: () => (/* binding */ AudioStreamNodeAttachedEvent),
/* harmony export */   AudioStreamNodeAttachingEvent: () => (/* binding */ AudioStreamNodeAttachingEvent),
/* harmony export */   AudioStreamNodeDetachedEvent: () => (/* binding */ AudioStreamNodeDetachedEvent),
/* harmony export */   AudioStreamNodeErrorEvent: () => (/* binding */ AudioStreamNodeErrorEvent),
/* harmony export */   AudioStreamNodeEvent: () => (/* binding */ AudioStreamNodeEvent)
/* harmony export */ });
/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */

class AudioSourceEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {
  constructor(eventName, audioSourceId, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Info) {
    super(eventName, eventType);
    this.privAudioSourceId = audioSourceId;
  }
  get audioSourceId() {
    return this.privAudioSourceId;
  }
}
class AudioSourceInitializingEvent extends AudioSourceEvent {
  constructor(audioSourceId) {
    super("AudioSourceInitializingEvent", audioSourceId);
  }
}
class AudioSourceReadyEvent extends AudioSourceEvent {
  constructor(audioSourceId) {
    super("AudioSourceReadyEvent", audioSourceId);
  }
}
class AudioSourceOffEvent extends AudioSourceEvent {
  constructor(audioSourceId) {
    super("AudioSourceOffEvent", audioSourceId);
  }
}
class AudioSourceErrorEvent extends AudioSourceEvent {
  constructor(audioSourceId, error) {
    super("AudioSourceErrorEvent", audioSourceId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Error);
    this.privError = error;
  }
  get error() {
    return this.privError;
  }
}
class AudioStreamNodeEvent extends AudioSourceEvent {
  constructor(eventName, audioSourceId, audioNodeId) {
    super(eventName, audioSourceId);
    this.privAudioNodeId = audioNodeId;
  }
  get audioNodeId() {
    return this.privAudioNodeId;
  }
}
class AudioStreamNodeAttachingEvent extends AudioStreamNodeEvent {
  constructor(audioSourceId, audioNodeId) {
    super("AudioStreamNodeAttachingEvent", audioSourceId, audioNodeId);
  }
}
class AudioStreamNodeAttachedEvent extends AudioStreamNodeEvent {
  constructor(audioSourceId, audioNodeId) {
    super("AudioStreamNodeAttachedEvent", audioSourceId, audioNodeId);
  }
}
class AudioStreamNodeDetachedEvent extends AudioStreamNodeEvent {
  constructor(audioSourceId, audioNodeId) {
    super("AudioStreamNodeDetachedEvent", audioSourceId, audioNodeId);
  }
}
class AudioStreamNodeErrorEvent extends AudioStreamNodeEvent {
  constructor(audioSourceId, audioNodeId, error) {
    super("AudioStreamNodeErrorEvent", audioSourceId, audioNodeId);
    this.privError = error;
  }
  get error() {
    return this.privError;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   BackgroundEvent: () => (/* binding */ BackgroundEvent)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class BackgroundEvent extends _Exports__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {
  constructor(error) {
    super("BackgroundEvent", _Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Error);
    this.privError = error;
  }
  get error() {
    return this.privError;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ChunkedArrayBufferStream: () => (/* binding */ ChunkedArrayBufferStream)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class ChunkedArrayBufferStream extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Stream {
  constructor(targetChunkSize, streamId) {
    super(streamId);
    this.privTargetChunkSize = targetChunkSize;
    this.privNextBufferReadyBytes = 0;
  }
  writeStreamChunk(chunk) {
    // No pending write, and the buffer is the right size so write it.
    if (chunk.isEnd || 0 === this.privNextBufferReadyBytes && chunk.buffer.byteLength === this.privTargetChunkSize) {
      super.writeStreamChunk(chunk);
      return;
    }
    let bytesCopiedFromBuffer = 0;
    while (bytesCopiedFromBuffer < chunk.buffer.byteLength) {
      // Fill the next buffer.
      if (undefined === this.privNextBufferToWrite) {
        this.privNextBufferToWrite = new ArrayBuffer(this.privTargetChunkSize);
        this.privNextBufferStartTime = chunk.timeReceived;
      }
      // Find out how many bytes we can copy into the read buffer.
      const bytesToCopy = Math.min(chunk.buffer.byteLength - bytesCopiedFromBuffer, this.privTargetChunkSize - this.privNextBufferReadyBytes);
      const targetView = new Uint8Array(this.privNextBufferToWrite);
      const sourceView = new Uint8Array(chunk.buffer.slice(bytesCopiedFromBuffer, bytesToCopy + bytesCopiedFromBuffer));
      targetView.set(sourceView, this.privNextBufferReadyBytes);
      this.privNextBufferReadyBytes += bytesToCopy;
      bytesCopiedFromBuffer += bytesToCopy;
      // Are we ready to write?
      if (this.privNextBufferReadyBytes === this.privTargetChunkSize) {
        super.writeStreamChunk({
          buffer: this.privNextBufferToWrite,
          isEnd: false,
          timeReceived: this.privNextBufferStartTime
        });
        this.privNextBufferReadyBytes = 0;
        this.privNextBufferToWrite = undefined;
      }
    }
  }
  close() {
    // Send whatever is pending, then close the base class.
    if (0 !== this.privNextBufferReadyBytes && !this.isClosed) {
      super.writeStreamChunk({
        buffer: this.privNextBufferToWrite.slice(0, this.privNextBufferReadyBytes),
        isEnd: false,
        timeReceived: this.privNextBufferStartTime
      });
    }
    super.close();
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConnectionClosedEvent: () => (/* binding */ ConnectionClosedEvent),
/* harmony export */   ConnectionErrorEvent: () => (/* binding */ ConnectionErrorEvent),
/* harmony export */   ConnectionEstablishErrorEvent: () => (/* binding */ ConnectionEstablishErrorEvent),
/* harmony export */   ConnectionEstablishedEvent: () => (/* binding */ ConnectionEstablishedEvent),
/* harmony export */   ConnectionEvent: () => (/* binding */ ConnectionEvent),
/* harmony export */   ConnectionMessageReceivedEvent: () => (/* binding */ ConnectionMessageReceivedEvent),
/* harmony export */   ConnectionMessageSentEvent: () => (/* binding */ ConnectionMessageSentEvent),
/* harmony export */   ConnectionStartEvent: () => (/* binding */ ConnectionStartEvent),
/* harmony export */   ServiceEvent: () => (/* binding */ ServiceEvent)
/* harmony export */ });
/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class ServiceEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {
  constructor(eventName, jsonstring, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Info) {
    super(eventName, eventType);
    this.privJsonResult = jsonstring;
  }
  get jsonString() {
    return this.privJsonResult;
  }
}
class ConnectionEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {
  constructor(eventName, connectionId, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Info) {
    super(eventName, eventType);
    this.privConnectionId = connectionId;
  }
  get connectionId() {
    return this.privConnectionId;
  }
}
class ConnectionStartEvent extends ConnectionEvent {
  constructor(connectionId, uri, headers) {
    super("ConnectionStartEvent", connectionId);
    this.privUri = uri;
    this.privHeaders = headers;
  }
  get uri() {
    return this.privUri;
  }
  get headers() {
    return this.privHeaders;
  }
}
class ConnectionEstablishedEvent extends ConnectionEvent {
  constructor(connectionId) {
    super("ConnectionEstablishedEvent", connectionId);
  }
}
class ConnectionClosedEvent extends ConnectionEvent {
  constructor(connectionId, statusCode, reason) {
    super("ConnectionClosedEvent", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug);
    this.privReason = reason;
    this.privStatusCode = statusCode;
  }
  get reason() {
    return this.privReason;
  }
  get statusCode() {
    return this.privStatusCode;
  }
}
class ConnectionErrorEvent extends ConnectionEvent {
  constructor(connectionId, message, type) {
    super("ConnectionErrorEvent", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug);
    this.privMessage = message;
    this.privType = type;
  }
  get message() {
    return this.privMessage;
  }
  get type() {
    return this.privType;
  }
}
class ConnectionEstablishErrorEvent extends ConnectionEvent {
  constructor(connectionId, statuscode, reason) {
    super("ConnectionEstablishErrorEvent", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Error);
    this.privStatusCode = statuscode;
    this.privReason = reason;
  }
  get reason() {
    return this.privReason;
  }
  get statusCode() {
    return this.privStatusCode;
  }
}
class ConnectionMessageReceivedEvent extends ConnectionEvent {
  constructor(connectionId, networkReceivedTimeISO, message) {
    super("ConnectionMessageReceivedEvent", connectionId);
    this.privNetworkReceivedTime = networkReceivedTimeISO;
    this.privMessage = message;
  }
  get networkReceivedTime() {
    return this.privNetworkReceivedTime;
  }
  get message() {
    return this.privMessage;
  }
}
class ConnectionMessageSentEvent extends ConnectionEvent {
  constructor(connectionId, networkSentTimeISO, message) {
    super("ConnectionMessageSentEvent", connectionId);
    this.privNetworkSentTime = networkSentTimeISO;
    this.privMessage = message;
  }
  get networkSentTime() {
    return this.privNetworkSentTime;
  }
  get message() {
    return this.privMessage;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConnectionMessage: () => (/* binding */ ConnectionMessage),
/* harmony export */   MessageType: () => (/* binding */ MessageType)
/* harmony export */ });
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Guid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* eslint-disable @typescript-eslint/no-unsafe-return */
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


var MessageType;
(function (MessageType) {
  MessageType[MessageType["Text"] = 0] = "Text";
  MessageType[MessageType["Binary"] = 1] = "Binary";
})(MessageType || (MessageType = {}));
class ConnectionMessage {
  constructor(messageType, body, headers, id) {
    this.privBody = null;
    if (messageType === MessageType.Text && body && !(typeof body === "string")) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError("Payload must be a string");
    }
    if (messageType === MessageType.Binary && body && !(body instanceof ArrayBuffer)) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError("Payload must be ArrayBuffer");
    }
    this.privMessageType = messageType;
    // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
    this.privBody = body;
    this.privHeaders = headers ? headers : {};
    this.privId = id ? id : (0,_Guid__WEBPACK_IMPORTED_MODULE_1__.createNoDashGuid)();
    switch (this.messageType) {
      case MessageType.Binary:
        this.privSize = this.binaryBody !== null ? this.binaryBody.byteLength : 0;
        break;
      case MessageType.Text:
        this.privSize = this.textBody.length;
    }
  }
  get messageType() {
    return this.privMessageType;
  }
  get headers() {
    return this.privHeaders;
  }
  get body() {
    return this.privBody;
  }
  get textBody() {
    if (this.privMessageType === MessageType.Binary) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError("Not supported for binary message");
    }
    return this.privBody;
  }
  get binaryBody() {
    if (this.privMessageType === MessageType.Text) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError("Not supported for text message");
    }
    return this.privBody;
  }
  get id() {
    return this.privId;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConnectionOpenResponse: () => (/* binding */ ConnectionOpenResponse)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class ConnectionOpenResponse {
  constructor(statusCode, reason) {
    this.privStatusCode = statusCode;
    this.privReason = reason;
  }
  get statusCode() {
    return this.privStatusCode;
  }
  get reason() {
    return this.privReason;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DeferralMap.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DeferralMap.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   DeferralMap: () => (/* binding */ DeferralMap)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * The error that is thrown when an argument passed in is null.
 *
 * @export
 * @class DefferalMap
 */
class DeferralMap {
  constructor() {
    this.privMap = {};
  }
  add(id, deferral) {
    this.privMap[id] = deferral;
  }
  getId(id) {
    return this.privMap[id];
  }
  complete(id, result) {
    try {
      this.privMap[id].resolve(result);
    } catch (error) {
      this.privMap[id].reject(error);
    } finally {
      this.privMap[id] = undefined;
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   DialogEvent: () => (/* binding */ DialogEvent),
/* harmony export */   SendingAgentContextMessageEvent: () => (/* binding */ SendingAgentContextMessageEvent)
/* harmony export */ });
/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class DialogEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {
  constructor(eventName, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Info) {
    super(eventName, eventType);
  }
}
class SendingAgentContextMessageEvent extends DialogEvent {
  constructor(agentConfig) {
    super("SendingAgentContextMessageEvent");
    this.privAgentConfig = agentConfig;
  }
  get agentConfig() {
    return this.privAgentConfig;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ArgumentNullError: () => (/* binding */ ArgumentNullError),
/* harmony export */   InvalidOperationError: () => (/* binding */ InvalidOperationError),
/* harmony export */   ObjectDisposedError: () => (/* binding */ ObjectDisposedError)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */
/**
 * The error that is thrown when an argument passed in is null.
 *
 * @export
 * @class ArgumentNullError
 * @extends {Error}
 */
class ArgumentNullError extends Error {
  /**
   * Creates an instance of ArgumentNullError.
   *
   * @param {string} argumentName - Name of the argument that is null
   *
   * @memberOf ArgumentNullError
   */
  constructor(argumentName) {
    super(argumentName);
    this.name = "ArgumentNull";
    this.message = argumentName;
  }
}
/**
 * The error that is thrown when an invalid operation is performed in the code.
 *
 * @export
 * @class InvalidOperationError
 * @extends {Error}
 */
class InvalidOperationError extends Error {
  /**
   * Creates an instance of InvalidOperationError.
   *
   * @param {string} error - The error
   *
   * @memberOf InvalidOperationError
   */
  constructor(error) {
    super(error);
    this.name = "InvalidOperation";
    this.message = error;
  }
}
/**
 * The error that is thrown when an object is disposed.
 *
 * @export
 * @class ObjectDisposedError
 * @extends {Error}
 */
class ObjectDisposedError extends Error {
  /**
   * Creates an instance of ObjectDisposedError.
   *
   * @param {string} objectName - The object that is disposed
   * @param {string} error - The error
   *
   * @memberOf ObjectDisposedError
   */
  constructor(objectName, error) {
    super(error);
    this.name = objectName + "ObjectDisposed";
    this.message = error;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   EventSource: () => (/* binding */ EventSource)
/* harmony export */ });
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Guid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


class EventSource {
  constructor(metadata) {
    this.privEventListeners = {};
    this.privIsDisposed = false;
    this.privConsoleListener = undefined;
    this.privMetadata = metadata;
  }
  onEvent(event) {
    if (this.isDisposed()) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.ObjectDisposedError("EventSource");
    }
    if (this.metadata) {
      for (const paramName in this.metadata) {
        if (paramName) {
          if (event.metadata) {
            if (!event.metadata[paramName]) {
              event.metadata[paramName] = this.metadata[paramName];
            }
          }
        }
      }
    }
    for (const eventId in this.privEventListeners) {
      if (eventId && this.privEventListeners[eventId]) {
        this.privEventListeners[eventId](event);
      }
    }
  }
  attach(onEventCallback) {
    const id = (0,_Guid__WEBPACK_IMPORTED_MODULE_1__.createNoDashGuid)();
    this.privEventListeners[id] = onEventCallback;
    return {
      detach: () => {
        delete this.privEventListeners[id];
        return Promise.resolve();
      }
    };
  }
  attachListener(listener) {
    return this.attach(e => listener.onEvent(e));
  }
  attachConsoleListener(listener) {
    if (!!this.privConsoleListener) {
      void this.privConsoleListener.detach(); // Detach implementation for eventListeners is synchronous
    }

    this.privConsoleListener = this.attach(e => listener.onEvent(e));
    return this.privConsoleListener;
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  dispose() {
    this.privEventListeners = null;
    this.privIsDisposed = true;
  }
  get metadata() {
    return this.privMetadata;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Events: () => (/* binding */ Events)
/* harmony export */ });
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _EventSource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./EventSource */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


class Events {
  static setEventSource(eventSource) {
    if (!eventSource) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("eventSource");
    }
    Events.privInstance = eventSource;
  }
  static get instance() {
    return Events.privInstance;
  }
}
Events.privInstance = new _EventSource__WEBPACK_IMPORTED_MODULE_1__.EventSource();

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   createGuid: () => (/* binding */ createGuid),
/* harmony export */   createNoDashGuid: () => (/* binding */ createNoDashGuid)
/* harmony export */ });
/* harmony import */ var uuid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! uuid */ "./node_modules/uuid/dist/esm-browser/v4.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

const createGuid = () => (0,uuid__WEBPACK_IMPORTED_MODULE_0__["default"])();
const createNoDashGuid = () => createGuid().replace(new RegExp("-", "g"), "").toUpperCase();


/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConnectionState: () => (/* binding */ ConnectionState)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var ConnectionState;
(function (ConnectionState) {
  ConnectionState[ConnectionState["None"] = 0] = "None";
  ConnectionState[ConnectionState["Connected"] = 1] = "Connected";
  ConnectionState[ConnectionState["Connecting"] = 2] = "Connecting";
  ConnectionState[ConnectionState["Disconnected"] = 3] = "Disconnected";
})(ConnectionState || (ConnectionState = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   List: () => (/* binding */ List)
/* harmony export */ });
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class List {
  constructor(list) {
    this.privSubscriptionIdCounter = 0;
    this.privAddSubscriptions = {};
    this.privRemoveSubscriptions = {};
    this.privDisposedSubscriptions = {};
    this.privDisposeReason = null;
    this.privList = [];
    // copy the list rather than taking as is.
    if (list) {
      for (const item of list) {
        this.privList.push(item);
      }
    }
  }
  get(itemIndex) {
    this.throwIfDisposed();
    return this.privList[itemIndex];
  }
  first() {
    return this.get(0);
  }
  last() {
    return this.get(this.length() - 1);
  }
  add(item) {
    this.throwIfDisposed();
    this.insertAt(this.privList.length, item);
  }
  insertAt(index, item) {
    this.throwIfDisposed();
    if (index === 0) {
      this.privList.unshift(item);
    } else if (index === this.privList.length) {
      this.privList.push(item);
    } else {
      this.privList.splice(index, 0, item);
    }
    this.triggerSubscriptions(this.privAddSubscriptions);
  }
  removeFirst() {
    this.throwIfDisposed();
    return this.removeAt(0);
  }
  removeLast() {
    this.throwIfDisposed();
    return this.removeAt(this.length() - 1);
  }
  removeAt(index) {
    this.throwIfDisposed();
    return this.remove(index, 1)[0];
  }
  remove(index, count) {
    this.throwIfDisposed();
    const removedElements = this.privList.splice(index, count);
    this.triggerSubscriptions(this.privRemoveSubscriptions);
    return removedElements;
  }
  clear() {
    this.throwIfDisposed();
    this.remove(0, this.length());
  }
  length() {
    this.throwIfDisposed();
    return this.privList.length;
  }
  onAdded(addedCallback) {
    this.throwIfDisposed();
    const subscriptionId = this.privSubscriptionIdCounter++;
    this.privAddSubscriptions[subscriptionId] = addedCallback;
    return {
      detach: () => {
        delete this.privAddSubscriptions[subscriptionId];
        return Promise.resolve();
      }
    };
  }
  onRemoved(removedCallback) {
    this.throwIfDisposed();
    const subscriptionId = this.privSubscriptionIdCounter++;
    this.privRemoveSubscriptions[subscriptionId] = removedCallback;
    return {
      detach: () => {
        delete this.privRemoveSubscriptions[subscriptionId];
        return Promise.resolve();
      }
    };
  }
  onDisposed(disposedCallback) {
    this.throwIfDisposed();
    const subscriptionId = this.privSubscriptionIdCounter++;
    this.privDisposedSubscriptions[subscriptionId] = disposedCallback;
    return {
      detach: () => {
        delete this.privDisposedSubscriptions[subscriptionId];
        return Promise.resolve();
      }
    };
  }
  join(seperator) {
    this.throwIfDisposed();
    return this.privList.join(seperator);
  }
  toArray() {
    const cloneCopy = Array();
    this.privList.forEach(val => {
      cloneCopy.push(val);
    });
    return cloneCopy;
  }
  any(callback) {
    this.throwIfDisposed();
    if (callback) {
      return this.where(callback).length() > 0;
    } else {
      return this.length() > 0;
    }
  }
  all(callback) {
    this.throwIfDisposed();
    return this.where(callback).length() === this.length();
  }
  forEach(callback) {
    this.throwIfDisposed();
    for (let i = 0; i < this.length(); i++) {
      callback(this.privList[i], i);
    }
  }
  select(callback) {
    this.throwIfDisposed();
    const selectList = [];
    for (let i = 0; i < this.privList.length; i++) {
      selectList.push(callback(this.privList[i], i));
    }
    return new List(selectList);
  }
  where(callback) {
    this.throwIfDisposed();
    const filteredList = new List();
    for (let i = 0; i < this.privList.length; i++) {
      if (callback(this.privList[i], i)) {
        filteredList.add(this.privList[i]);
      }
    }
    return filteredList;
  }
  orderBy(compareFn) {
    this.throwIfDisposed();
    const clonedArray = this.toArray();
    const orderedArray = clonedArray.sort(compareFn);
    return new List(orderedArray);
  }
  orderByDesc(compareFn) {
    this.throwIfDisposed();
    return this.orderBy((a, b) => compareFn(b, a));
  }
  clone() {
    this.throwIfDisposed();
    return new List(this.toArray());
  }
  concat(list) {
    this.throwIfDisposed();
    return new List(this.privList.concat(list.toArray()));
  }
  concatArray(array) {
    this.throwIfDisposed();
    return new List(this.privList.concat(array));
  }
  isDisposed() {
    return this.privList == null;
  }
  dispose(reason) {
    if (!this.isDisposed()) {
      this.privDisposeReason = reason;
      this.privList = null;
      this.privAddSubscriptions = null;
      this.privRemoveSubscriptions = null;
      this.triggerSubscriptions(this.privDisposedSubscriptions);
    }
  }
  throwIfDisposed() {
    if (this.isDisposed()) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.ObjectDisposedError("List", this.privDisposeReason);
    }
  }
  triggerSubscriptions(subscriptions) {
    if (subscriptions) {
      for (const subscriptionId in subscriptions) {
        if (subscriptionId) {
          subscriptions[subscriptionId]();
        }
      }
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   EventType: () => (/* binding */ EventType),
/* harmony export */   PlatformEvent: () => (/* binding */ PlatformEvent)
/* harmony export */ });
/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Guid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

var EventType;
(function (EventType) {
  EventType[EventType["Debug"] = 0] = "Debug";
  EventType[EventType["Info"] = 1] = "Info";
  EventType[EventType["Warning"] = 2] = "Warning";
  EventType[EventType["Error"] = 3] = "Error";
  EventType[EventType["None"] = 4] = "None";
})(EventType || (EventType = {}));
class PlatformEvent {
  constructor(eventName, eventType) {
    this.privName = eventName;
    this.privEventId = (0,_Guid__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();
    this.privEventTime = new Date().toISOString();
    this.privEventType = eventType;
    this.privMetadata = {};
  }
  get name() {
    return this.privName;
  }
  get eventId() {
    return this.privEventId;
  }
  get eventTime() {
    return this.privEventTime;
  }
  get eventType() {
    return this.privEventType;
  }
  get metadata() {
    return this.privMetadata;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Deferred: () => (/* binding */ Deferred),
/* harmony export */   PromiseResult: () => (/* binding */ PromiseResult),
/* harmony export */   PromiseResultEventSource: () => (/* binding */ PromiseResultEventSource),
/* harmony export */   PromiseState: () => (/* binding */ PromiseState),
/* harmony export */   Sink: () => (/* binding */ Sink),
/* harmony export */   marshalPromiseToCallbacks: () => (/* binding */ marshalPromiseToCallbacks)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file, @typescript-eslint/typedef */
var PromiseState;
(function (PromiseState) {
  PromiseState[PromiseState["None"] = 0] = "None";
  PromiseState[PromiseState["Resolved"] = 1] = "Resolved";
  PromiseState[PromiseState["Rejected"] = 2] = "Rejected";
})(PromiseState || (PromiseState = {}));
class PromiseResult {
  constructor(promiseResultEventSource) {
    this.throwIfError = () => {
      if (this.isError) {
        throw this.error;
      }
    };
    promiseResultEventSource.on(result => {
      if (!this.privIsCompleted) {
        this.privIsCompleted = true;
        this.privIsError = false;
        this.privResult = result;
      }
    }, error => {
      if (!this.privIsCompleted) {
        this.privIsCompleted = true;
        this.privIsError = true;
        this.privError = error;
      }
    });
  }
  get isCompleted() {
    return this.privIsCompleted;
  }
  get isError() {
    return this.privIsError;
  }
  get error() {
    return this.privError;
  }
  get result() {
    return this.privResult;
  }
}
class PromiseResultEventSource {
  constructor() {
    this.setResult = result => {
      this.privOnSetResult(result);
    };
    this.setError = error => {
      this.privOnSetError(error);
    };
    this.on = (onSetResult, onSetError) => {
      this.privOnSetResult = onSetResult;
      this.privOnSetError = onSetError;
    };
  }
}
class Deferred {
  constructor() {
    this.resolve = result => {
      this.privResolve(result);
      return this;
    };
    this.reject = error => {
      this.privReject(error);
      return this;
    };
    // eslint-disable-next-line @typescript-eslint/explicit-function-return-type
    this.privPromise = new Promise((resolve, reject) => {
      this.privResolve = resolve;
      this.privReject = reject;
    });
  }
  get promise() {
    return this.privPromise;
  }
}
class Sink {
  constructor() {
    this.privState = PromiseState.None;
    this.privPromiseResult = null;
    this.privPromiseResultEvents = null;
    this.privSuccessHandlers = [];
    this.privErrorHandlers = [];
    this.privPromiseResultEvents = new PromiseResultEventSource();
    this.privPromiseResult = new PromiseResult(this.privPromiseResultEvents);
  }
  get state() {
    return this.privState;
  }
  get result() {
    return this.privPromiseResult;
  }
  resolve(result) {
    if (this.privState !== PromiseState.None) {
      throw new Error("'Cannot resolve a completed promise'");
    }
    this.privState = PromiseState.Resolved;
    this.privPromiseResultEvents.setResult(result);
    for (let i = 0; i < this.privSuccessHandlers.length; i++) {
      this.executeSuccessCallback(result, this.privSuccessHandlers[i], this.privErrorHandlers[i]);
    }
    this.detachHandlers();
  }
  reject(error) {
    if (this.privState !== PromiseState.None) {
      throw new Error("'Cannot reject a completed promise'");
    }
    this.privState = PromiseState.Rejected;
    this.privPromiseResultEvents.setError(error);
    for (const errorHandler of this.privErrorHandlers) {
      this.executeErrorCallback(error, errorHandler);
    }
    this.detachHandlers();
  }
  on(successCallback, errorCallback) {
    if (successCallback == null) {
      // eslint-disable-next-line @typescript-eslint/no-empty-function
      successCallback = () => {};
    }
    if (this.privState === PromiseState.None) {
      this.privSuccessHandlers.push(successCallback);
      this.privErrorHandlers.push(errorCallback);
    } else {
      if (this.privState === PromiseState.Resolved) {
        this.executeSuccessCallback(this.privPromiseResult.result, successCallback, errorCallback);
      } else if (this.privState === PromiseState.Rejected) {
        this.executeErrorCallback(this.privPromiseResult.error, errorCallback);
      }
      this.detachHandlers();
    }
  }
  executeSuccessCallback(result, successCallback, errorCallback) {
    try {
      successCallback(result);
    } catch (e) {
      this.executeErrorCallback(`'Unhandled callback error: ${e}'`, errorCallback);
    }
  }
  executeErrorCallback(error, errorCallback) {
    if (errorCallback) {
      try {
        errorCallback(error);
      } catch (e) {
        throw new Error(`'Unhandled callback error: ${e}. InnerError: ${error}'`);
      }
    } else {
      throw new Error(`'Unhandled error: ${error}'`);
    }
  }
  detachHandlers() {
    this.privErrorHandlers = [];
    this.privSuccessHandlers = [];
  }
}
// eslint-disable-next-line prefer-arrow/prefer-arrow-functions
function marshalPromiseToCallbacks(promise, cb, err) {
  promise.then(val => {
    try {
      if (!!cb) {
        cb(val);
      }
    } catch (error) {
      if (!!err) {
        try {
          if (error instanceof Error) {
            const typedError = error;
            err(typedError.name + ": " + typedError.message);
          } else {
            err(error);
          }
          // eslint-disable-next-line no-empty
        } catch (error) {}
      }
    }
  }, error => {
    if (!!err) {
      try {
        if (error instanceof Error) {
          const typedError = error;
          err(typedError.name + ": " + typedError.message);
        } else {
          err(error);
        }
        // eslint-disable-next-line no-empty
      } catch (error) {}
    }
  });
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Queue: () => (/* binding */ Queue)
/* harmony export */ });
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _List__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./List */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js");
/* harmony import */ var _Promise__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Promise */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};



var SubscriberType;
(function (SubscriberType) {
  SubscriberType[SubscriberType["Dequeue"] = 0] = "Dequeue";
  SubscriberType[SubscriberType["Peek"] = 1] = "Peek";
})(SubscriberType || (SubscriberType = {}));
class Queue {
  constructor(list) {
    this.privPromiseStore = new _List__WEBPACK_IMPORTED_MODULE_0__.List();
    this.privIsDrainInProgress = false;
    this.privIsDisposing = false;
    this.privDisposeReason = null;
    this.privList = list ? list : new _List__WEBPACK_IMPORTED_MODULE_0__.List();
    this.privDetachables = [];
    this.privSubscribers = new _List__WEBPACK_IMPORTED_MODULE_0__.List();
    this.privDetachables.push(this.privList.onAdded(() => this.drain()));
  }
  enqueue(item) {
    this.throwIfDispose();
    this.enqueueFromPromise(new Promise(resolve => resolve(item)));
  }
  enqueueFromPromise(promise) {
    this.throwIfDispose();
    promise.then(val => {
      this.privList.add(val);
      // eslint-disable-next-line @typescript-eslint/no-empty-function
    }, () => {});
  }
  dequeue() {
    this.throwIfDispose();
    const deferredSubscriber = new _Promise__WEBPACK_IMPORTED_MODULE_1__.Deferred();
    if (this.privSubscribers) {
      this.privSubscribers.add({
        deferral: deferredSubscriber,
        type: SubscriberType.Dequeue
      });
      this.drain();
    }
    return deferredSubscriber.promise;
  }
  peek() {
    this.throwIfDispose();
    const deferredSubscriber = new _Promise__WEBPACK_IMPORTED_MODULE_1__.Deferred();
    const subs = this.privSubscribers;
    if (subs) {
      this.privSubscribers.add({
        deferral: deferredSubscriber,
        type: SubscriberType.Peek
      });
      this.drain();
    }
    return deferredSubscriber.promise;
  }
  length() {
    this.throwIfDispose();
    return this.privList.length();
  }
  isDisposed() {
    return this.privSubscribers == null;
  }
  drainAndDispose(pendingItemProcessor, reason) {
    return __awaiter(this, void 0, void 0, function* () {
      if (!this.isDisposed() && !this.privIsDisposing) {
        this.privDisposeReason = reason;
        this.privIsDisposing = true;
        const subs = this.privSubscribers;
        if (subs) {
          while (subs.length() > 0) {
            const subscriber = subs.removeFirst();
            // TODO: this needs work (Resolve(null) instead?).
            subscriber.deferral.resolve(undefined);
            // subscriber.deferral.reject("Disposed");
          }
          // note: this block assumes cooperative multitasking, i.e.,
          // between the if-statement and the assignment there are no
          // thread switches.
          // Reason is that between the initial const = this.; and this
          // point there is the derral.resolve() operation that might have
          // caused recursive calls to the Queue, especially, calling
          // Dispose() on the queue alredy (which would reset the var
          // here to null!).
          // That should generally hold true for javascript...
          if (this.privSubscribers === subs) {
            this.privSubscribers = subs;
          }
        }
        for (const detachable of this.privDetachables) {
          yield detachable.detach();
        }
        if (this.privPromiseStore.length() > 0 && pendingItemProcessor) {
          const promiseArray = [];
          this.privPromiseStore.toArray().forEach(wrapper => {
            promiseArray.push(wrapper);
          });
          return Promise.all(promiseArray).finally(() => {
            this.privSubscribers = null;
            this.privList.forEach(item => {
              pendingItemProcessor(item);
            });
            this.privList = null;
            return;
          }).then();
        } else {
          this.privSubscribers = null;
          this.privList = null;
        }
      }
    });
  }
  dispose(reason) {
    return __awaiter(this, void 0, void 0, function* () {
      yield this.drainAndDispose(null, reason);
    });
  }
  drain() {
    if (!this.privIsDrainInProgress && !this.privIsDisposing) {
      this.privIsDrainInProgress = true;
      const subs = this.privSubscribers;
      const lists = this.privList;
      if (subs && lists) {
        while (lists.length() > 0 && subs.length() > 0 && !this.privIsDisposing) {
          const subscriber = subs.removeFirst();
          if (subscriber.type === SubscriberType.Peek) {
            subscriber.deferral.resolve(lists.first());
          } else {
            const dequeuedItem = lists.removeFirst();
            subscriber.deferral.resolve(dequeuedItem);
          }
        }
        // note: this block assumes cooperative multitasking, i.e.,
        // between the if-statement and the assignment there are no
        // thread switches.
        // Reason is that between the initial const = this.; and this
        // point there is the derral.resolve() operation that might have
        // caused recursive calls to the Queue, especially, calling
        // Dispose() on the queue alredy (which would reset the var
        // here to null!).
        // That should generally hold true for javascript...
        if (this.privSubscribers === subs) {
          this.privSubscribers = subs;
        }
        // note: this block assumes cooperative multitasking, i.e.,
        // between the if-statement and the assignment there are no
        // thread switches.
        // Reason is that between the initial const = this.; and this
        // point there is the derral.resolve() operation that might have
        // caused recursive calls to the Queue, especially, calling
        // Dispose() on the queue alredy (which would reset the var
        // here to null!).
        // That should generally hold true for javascript...
        if (this.privList === lists) {
          this.privList = lists;
        }
      }
      this.privIsDrainInProgress = false;
    }
  }
  throwIfDispose() {
    if (this.isDisposed()) {
      if (this.privDisposeReason) {
        throw new _Error__WEBPACK_IMPORTED_MODULE_2__.InvalidOperationError(this.privDisposeReason);
      }
      throw new _Error__WEBPACK_IMPORTED_MODULE_2__.ObjectDisposedError("Queue");
    } else if (this.privIsDisposing) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_2__.InvalidOperationError("Queue disposing");
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   RawWebsocketMessage: () => (/* binding */ RawWebsocketMessage)
/* harmony export */ });
/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionMessage */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Guid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* eslint-disable @typescript-eslint/no-unsafe-assignment */
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



class RawWebsocketMessage {
  constructor(messageType, payload, id) {
    this.privPayload = null;
    if (!payload) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError("payload");
    }
    // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access
    if (messageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary && payload.__proto__.constructor.name !== "ArrayBuffer") {
      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError("Payload must be ArrayBuffer");
    }
    if (messageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text && !(typeof payload === "string")) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError("Payload must be a string");
    }
    this.privMessageType = messageType;
    this.privPayload = payload;
    this.privId = id ? id : (0,_Guid__WEBPACK_IMPORTED_MODULE_2__.createNoDashGuid)();
  }
  get messageType() {
    return this.privMessageType;
  }
  get payload() {
    // eslint-disable-next-line @typescript-eslint/no-unsafe-return
    return this.privPayload;
  }
  get textContent() {
    if (this.privMessageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError("Not supported for binary message");
    }
    return this.privPayload;
  }
  get binaryContent() {
    if (this.privMessageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError("Not supported for text message");
    }
    return this.privPayload;
  }
  get id() {
    return this.privId;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   RiffPcmEncoder: () => (/* binding */ RiffPcmEncoder)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class RiffPcmEncoder {
  constructor(actualSampleRate, desiredSampleRate) {
    this.privActualSampleRate = actualSampleRate;
    this.privDesiredSampleRate = desiredSampleRate;
  }
  encode(actualAudioFrame) {
    const audioFrame = this.downSampleAudioFrame(actualAudioFrame, this.privActualSampleRate, this.privDesiredSampleRate);
    if (!audioFrame) {
      return null;
    }
    const audioLength = audioFrame.length * 2;
    const buffer = new ArrayBuffer(audioLength);
    const view = new DataView(buffer);
    this.floatTo16BitPCM(view, 0, audioFrame);
    return buffer;
  }
  setString(view, offset, str) {
    for (let i = 0; i < str.length; i++) {
      view.setUint8(offset + i, str.charCodeAt(i));
    }
  }
  floatTo16BitPCM(view, offset, input) {
    for (let i = 0; i < input.length; i++, offset += 2) {
      const s = Math.max(-1, Math.min(1, input[i]));
      view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
    }
  }
  downSampleAudioFrame(srcFrame, srcRate, dstRate) {
    if (!srcFrame) {
      return null;
    }
    if (dstRate === srcRate || dstRate > srcRate) {
      return srcFrame;
    }
    const ratio = srcRate / dstRate;
    const dstLength = Math.round(srcFrame.length / ratio);
    const dstFrame = new Float32Array(dstLength);
    let srcOffset = 0;
    let dstOffset = 0;
    while (dstOffset < dstLength) {
      const nextSrcOffset = Math.round((dstOffset + 1) * ratio);
      let accum = 0;
      let count = 0;
      while (srcOffset < nextSrcOffset && srcOffset < srcFrame.length) {
        accum += srcFrame[srcOffset++];
        count++;
      }
      dstFrame[dstOffset++] = accum / count;
    }
    return dstFrame;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Stream: () => (/* binding */ Stream)
/* harmony export */ });
/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Guid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _Queue__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Queue */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};



class Stream {
  constructor(streamId) {
    this.privIsWriteEnded = false;
    this.privIsReadEnded = false;
    this.privId = streamId ? streamId : (0,_Guid__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();
    this.privReaderQueue = new _Queue__WEBPACK_IMPORTED_MODULE_1__.Queue();
  }
  get isClosed() {
    return this.privIsWriteEnded;
  }
  get isReadEnded() {
    return this.privIsReadEnded;
  }
  get id() {
    return this.privId;
  }
  close() {
    if (!this.privIsWriteEnded) {
      this.writeStreamChunk({
        buffer: null,
        isEnd: true,
        timeReceived: Date.now()
      });
      this.privIsWriteEnded = true;
    }
  }
  writeStreamChunk(streamChunk) {
    this.throwIfClosed();
    if (!this.privReaderQueue.isDisposed()) {
      try {
        this.privReaderQueue.enqueue(streamChunk);
      } catch (e) {
        // Do nothing
      }
    }
  }
  read() {
    if (this.privIsReadEnded) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_2__.InvalidOperationError("Stream read has already finished");
    }
    return this.privReaderQueue.dequeue().then(streamChunk => __awaiter(this, void 0, void 0, function* () {
      if (streamChunk === undefined || streamChunk.isEnd) {
        yield this.privReaderQueue.dispose("End of stream reached");
      }
      return streamChunk;
    }));
  }
  readEnded() {
    if (!this.privIsReadEnded) {
      this.privIsReadEnded = true;
      this.privReaderQueue = new _Queue__WEBPACK_IMPORTED_MODULE_1__.Queue();
    }
  }
  throwIfClosed() {
    if (this.privIsWriteEnded) {
      throw new _Error__WEBPACK_IMPORTED_MODULE_2__.InvalidOperationError("Stream closed");
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/StringUtils.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/StringUtils.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   StringUtils: () => (/* binding */ StringUtils)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * String helper functions
 */
class StringUtils {
  /**
   * Formats a string by replacing the named {keys} in the string with the values contained in the replacement dictionary.
   * @param format The format string that contains the parts to replace surrounded by {}. For example: "wss://{region}.cts.speech.microsoft.com".
   * If your string needs to contain a { or } you can use the {{ and }} escape sequences respectively.
   * @param replacements The dictionary of replacements. If a replacement is not found, it is replaced with an empty string
   * @returns The formatted string. If you pass in a null or undefined format string, an empty string will be returned
   */
  static formatString(format, replacements) {
    if (!format) {
      return "";
    }
    if (!replacements) {
      return format;
    }
    let formatted = "";
    let key = "";
    const appendToFormatted = str => {
      formatted += str;
    };
    const appendToKey = str => {
      key += str;
    };
    let appendFunc = appendToFormatted;
    for (let i = 0; i < format.length; i++) {
      const c = format[i];
      const next = i + 1 < format.length ? format[i + 1] : "";
      switch (c) {
        case "{":
          if (next === "{") {
            appendFunc("{");
            i++;
          } else {
            appendFunc = appendToKey;
          }
          break;
        case "}":
          if (next === "}") {
            appendFunc("}");
            i++;
          } else {
            if (replacements.hasOwnProperty(key)) {
              formatted += replacements[key];
            }
            appendFunc = appendToFormatted;
            key = "";
          }
          break;
        default:
          appendFunc(c);
          break;
      }
    }
    return formatted;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Timeout: () => (/* binding */ Timeout)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class Timeout {
  static load() {
    // Prefilling the Maps with a function indexed by zero is necessary to be compliant with the specification.
    const scheduledTimeoutFunctions = new Map([[0, () => {}]]); // eslint-disable-line @typescript-eslint/no-empty-function
    const unhandledRequests = new Map();
    // eslint-disable-next-line
    const workerScript = `!function(e){var t={};function n(r){if(t[r])return t[r].exports;var o=t[r]={i:r,l:!1,exports:{}};return e[r].call(o.exports,o,o.exports,n),o.l=!0,o.exports}n.m=e,n.c=t,n.d=function(e,t,r){n.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:r})},n.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},n.t=function(e,t){if(1&t&&(e=n(e)),8&t)return e;if(4&t&&"object"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(n.r(r),Object.defineProperty(r,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var o in e)n.d(r,o,function(t){return e[t]}.bind(null,o));return r},n.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return n.d(t,"a",t),t},n.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},n.p="",n(n.s=14)}([function(e,t,n){"use strict";n.d(t,"a",(function(){return i})),n.d(t,"b",(function(){return u})),n.d(t,"c",(function(){return a})),n.d(t,"d",(function(){return d}));const r=new Map,o=new Map,i=e=>{const t=r.get(e);if(void 0===t)throw new Error('There is no interval scheduled with the given id "'.concat(e,'".'));clearTimeout(t),r.delete(e)},u=e=>{const t=o.get(e);if(void 0===t)throw new Error('There is no timeout scheduled with the given id "'.concat(e,'".'));clearTimeout(t),o.delete(e)},f=(e,t)=>{let n,r;if("performance"in self){const o=performance.now();n=o,r=e-Math.max(0,o-t)}else n=Date.now(),r=e;return{expected:n+r,remainingDelay:r}},c=(e,t,n,r)=>{const o="performance"in self?performance.now():Date.now();o>n?postMessage({id:null,method:"call",params:{timerId:t}}):e.set(t,setTimeout(c,n-o,e,t,n))},a=(e,t,n)=>{const{expected:o,remainingDelay:i}=f(e,n);r.set(t,setTimeout(c,i,r,t,o))},d=(e,t,n)=>{const{expected:r,remainingDelay:i}=f(e,n);o.set(t,setTimeout(c,i,o,t,r))}},function(e,t,n){"use strict";n.r(t);var r=n(2);for(var o in r)"default"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(3);for(var o in i)"default"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(4);for(var o in u)"default"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o);var f=n(5);for(var o in f)"default"!==o&&function(e){n.d(t,e,(function(){return f[e]}))}(o);var c=n(6);for(var o in c)"default"!==o&&function(e){n.d(t,e,(function(){return c[e]}))}(o);var a=n(7);for(var o in a)"default"!==o&&function(e){n.d(t,e,(function(){return a[e]}))}(o);var d=n(8);for(var o in d)"default"!==o&&function(e){n.d(t,e,(function(){return d[e]}))}(o);var s=n(9);for(var o in s)"default"!==o&&function(e){n.d(t,e,(function(){return s[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){"use strict";n.r(t);var r=n(11);for(var o in r)"default"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(12);for(var o in i)"default"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(13);for(var o in u)"default"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){"use strict";n.r(t);var r=n(0),o=n(1);for(var i in o)"default"!==i&&function(e){n.d(t,e,(function(){return o[e]}))}(i);var u=n(10);for(var i in u)"default"!==i&&function(e){n.d(t,e,(function(){return u[e]}))}(i);addEventListener("message",({data:e})=>{try{if("clear"===e.method){const{id:t,params:{timerId:n}}=e;Object(r.b)(n),postMessage({error:null,id:t})}else{if("set"!==e.method)throw new Error('The given method "'.concat(e.method,'" is not supported'));{const{params:{delay:t,now:n,timerId:o}}=e;Object(r.d)(t,o,n)}}}catch(t){postMessage({error:{message:t.message},id:e.id,result:null})}})}]);`;
    const workerUrl = "data:text/javascript;base64," + btoa(workerScript);
    const worker = new Worker(workerUrl);
    worker.addEventListener("message", ({
      data
    }) => {
      if (Timeout.isCallNotification(data)) {
        const {
          params: {
            timerId
          }
        } = data;
        const idOrFunc = scheduledTimeoutFunctions.get(timerId);
        if (typeof idOrFunc === "number") {
          const unhandledTimerId = unhandledRequests.get(idOrFunc);
          if (unhandledTimerId === undefined || unhandledTimerId !== timerId) {
            throw new Error("The timer is in an undefined state.");
          }
        } else if (typeof idOrFunc !== "undefined") {
          idOrFunc();
          // A timeout can be safely deleted because it is only called once.
          scheduledTimeoutFunctions.delete(timerId);
        } else {
          throw new Error("The timer is in an undefined state.");
        }
      } else if (Timeout.isClearResponse(data)) {
        const {
          id
        } = data;
        const unhandledTimerId = unhandledRequests.get(id);
        if (unhandledTimerId === undefined) {
          throw new Error("The timer is in an undefined state.");
        }
        unhandledRequests.delete(id);
        scheduledTimeoutFunctions.delete(unhandledTimerId);
      } else {
        const {
          error: {
            message
          }
        } = data;
        throw new Error(message);
      }
    });
    const clearTimeout = timerId => {
      const id = Math.random();
      unhandledRequests.set(id, timerId);
      scheduledTimeoutFunctions.set(timerId, id);
      worker.postMessage({
        id,
        method: "clear",
        params: {
          timerId
        }
      });
    };
    const setTimeout = (func, delay) => {
      const timerId = Math.random();
      scheduledTimeoutFunctions.set(timerId, func);
      worker.postMessage({
        id: null,
        method: "set",
        params: {
          delay,
          now: performance.now(),
          timerId
        }
      });
      return timerId;
    };
    return {
      clearTimeout,
      setTimeout
    };
  }
  static loadWorkerTimers() {
    return () => {
      if (Timeout.workerTimers !== null) {
        return Timeout.workerTimers;
      }
      Timeout.workerTimers = Timeout.load();
      return Timeout.workerTimers;
    };
  }
  static isCallNotification(message) {
    return message.method !== undefined && message.method === "call";
  }
  static isClearResponse(message) {
    return message.error === null && typeof message.id === "number";
  }
}
Timeout.workerTimers = null;
Timeout.clearTimeout = timerId => Timeout.timers().clearTimeout(timerId);
Timeout.setTimeout = (func, delay) => Timeout.timers().setTimeout(func, delay);
Timeout.timers = Timeout.loadWorkerTimers();

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ActivityReceivedEventArgs: () => (/* binding */ ActivityReceivedEventArgs)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines contents of received message/events.
 * @class ActivityReceivedEventArgs
 */
class ActivityReceivedEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {any} activity - The activity..
   */
  constructor(activity, audioStream) {
    this.privActivity = activity;
    this.privAudioStream = audioStream;
  }
  /**
   * Gets the received activity
   * @member ActivityReceivedEventArgs.prototype.activity
   * @function
   * @public
   * @returns {any} the received activity.
   */
  get activity() {
    return this.privActivity;
  }
  get audioStream() {
    return this.privAudioStream;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AudioConfig: () => (/* binding */ AudioConfig),
/* harmony export */   AudioConfigImpl: () => (/* binding */ AudioConfigImpl),
/* harmony export */   AudioOutputConfigImpl: () => (/* binding */ AudioOutputConfigImpl)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js");
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js");
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js");
/* harmony import */ var _AudioInputStream__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./AudioInputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js");
/* harmony import */ var _AudioOutputStream__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./AudioOutputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js");
/* harmony import */ var _AudioFileWriter__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./AudioFileWriter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.






/**
 * Represents audio input configuration used for specifying what type of input to use (microphone, file, stream).
 * @class AudioConfig
 * Updated in version 1.11.0
 */
class AudioConfig {
  /**
   * Creates an AudioConfig object representing the default microphone on the system.
   * @member AudioConfig.fromDefaultMicrophoneInput
   * @function
   * @public
   * @returns {AudioConfig} The audio input configuration being created.
   */
  static fromDefaultMicrophoneInput() {
    const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__.PcmRecorder(true);
    return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.MicAudioSource(pcmRecorder));
  }
  /**
   * Creates an AudioConfig object representing a microphone with the specified device ID.
   * @member AudioConfig.fromMicrophoneInput
   * @function
   * @public
   * @param {string | undefined} deviceId - Specifies the device ID of the microphone to be used.
   * Default microphone is used the value is omitted.
   * @returns {AudioConfig} The audio input configuration being created.
   */
  static fromMicrophoneInput(deviceId) {
    const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__.PcmRecorder(true);
    return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.MicAudioSource(pcmRecorder, deviceId));
  }
  /**
   * Creates an AudioConfig object representing the specified file.
   * @member AudioConfig.fromWavFileInput
   * @function
   * @public
   * @param {File} fileName - Specifies the audio input file. Currently, only WAV / PCM is supported.
   * @returns {AudioConfig} The audio input configuration being created.
   */
  static fromWavFileInput(file, name = "unnamedBuffer.wav") {
    return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__.FileAudioSource(file, name));
  }
  /**
   * Creates an AudioConfig object representing the specified stream.
   * @member AudioConfig.fromStreamInput
   * @function
   * @public
   * @param {AudioInputStream | PullAudioInputStreamCallback | MediaStream} audioStream - Specifies the custom audio input
   * stream. Currently, only WAV / PCM is supported.
   * @returns {AudioConfig} The audio input configuration being created.
   */
  static fromStreamInput(audioStream) {
    if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_3__.PullAudioInputStreamCallback) {
      return new AudioConfigImpl(new _AudioInputStream__WEBPACK_IMPORTED_MODULE_4__.PullAudioInputStreamImpl(audioStream));
    }
    if (audioStream instanceof _AudioInputStream__WEBPACK_IMPORTED_MODULE_4__.AudioInputStream) {
      return new AudioConfigImpl(audioStream);
    }
    if (typeof MediaStream !== "undefined" && audioStream instanceof MediaStream) {
      const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__.PcmRecorder(false);
      return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.MicAudioSource(pcmRecorder, null, null, audioStream));
    }
    throw new Error("Not Supported Type");
  }
  /**
   * Creates an AudioConfig object representing the default speaker.
   * @member AudioConfig.fromDefaultSpeakerOutput
   * @function
   * @public
   * @returns {AudioConfig} The audio output configuration being created.
   * Added in version 1.11.0
   */
  static fromDefaultSpeakerOutput() {
    return new AudioOutputConfigImpl(new _Exports__WEBPACK_IMPORTED_MODULE_5__.SpeakerAudioDestination());
  }
  /**
   * Creates an AudioConfig object representing the custom IPlayer object.
   * You can use the IPlayer object to control pause, resume, etc.
   * @member AudioConfig.fromSpeakerOutput
   * @function
   * @public
   * @param {IPlayer} player - the IPlayer object for playback.
   * @returns {AudioConfig} The audio output configuration being created.
   * Added in version 1.12.0
   */
  static fromSpeakerOutput(player) {
    if (player === undefined) {
      return AudioConfig.fromDefaultSpeakerOutput();
    }
    if (player instanceof _Exports__WEBPACK_IMPORTED_MODULE_5__.SpeakerAudioDestination) {
      return new AudioOutputConfigImpl(player);
    }
    throw new Error("Not Supported Type");
  }
  /**
   * Creates an AudioConfig object representing a specified output audio file
   * @member AudioConfig.fromAudioFileOutput
   * @function
   * @public
   * @param {PathLike} filename - the filename of the output audio file
   * @returns {AudioConfig} The audio output configuration being created.
   * Added in version 1.11.0
   */
  static fromAudioFileOutput(filename) {
    return new AudioOutputConfigImpl(new _AudioFileWriter__WEBPACK_IMPORTED_MODULE_6__.AudioFileWriter(filename));
  }
  /**
   * Creates an AudioConfig object representing a specified audio output stream
   * @member AudioConfig.fromStreamOutput
   * @function
   * @public
   * @param {AudioOutputStream | PushAudioOutputStreamCallback} audioStream - Specifies the custom audio output
   * stream.
   * @returns {AudioConfig} The audio output configuration being created.
   * Added in version 1.11.0
   */
  static fromStreamOutput(audioStream) {
    if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_7__.PushAudioOutputStreamCallback) {
      return new AudioOutputConfigImpl(new _AudioOutputStream__WEBPACK_IMPORTED_MODULE_8__.PushAudioOutputStreamImpl(audioStream));
    }
    if (audioStream instanceof _AudioOutputStream__WEBPACK_IMPORTED_MODULE_8__.PushAudioOutputStream) {
      return new AudioOutputConfigImpl(audioStream);
    }
    if (audioStream instanceof _AudioOutputStream__WEBPACK_IMPORTED_MODULE_8__.PullAudioOutputStream) {
      return new AudioOutputConfigImpl(audioStream);
    }
    throw new Error("Not Supported Type");
  }
}
/**
 * Represents audio input stream used for custom audio input configurations.
 * @private
 * @class AudioConfigImpl
 */
class AudioConfigImpl extends AudioConfig {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {IAudioSource} source - An audio source.
   */
  constructor(source) {
    super();
    this.privSource = source;
  }
  /**
   * Format information for the audio
   */
  get format() {
    return this.privSource.format;
  }
  /**
   * @member AudioConfigImpl.prototype.close
   * @function
   * @public
   */
  close(cb, err) {
    this.privSource.turnOff().then(() => {
      if (!!cb) {
        cb();
      }
    }, error => {
      if (!!err) {
        err(error);
      }
    });
  }
  /**
   * @member AudioConfigImpl.prototype.id
   * @function
   * @public
   */
  id() {
    return this.privSource.id();
  }
  /**
   * @member AudioConfigImpl.prototype.turnOn
   * @function
   * @public
   * @returns {Promise<void>} A promise.
   */
  turnOn() {
    return this.privSource.turnOn();
  }
  /**
   * @member AudioConfigImpl.prototype.attach
   * @function
   * @public
   * @param {string} audioNodeId - The audio node id.
   * @returns {Promise<IAudioStreamNode>} A promise.
   */
  attach(audioNodeId) {
    return this.privSource.attach(audioNodeId);
  }
  /**
   * @member AudioConfigImpl.prototype.detach
   * @function
   * @public
   * @param {string} audioNodeId - The audio node id.
   */
  detach(audioNodeId) {
    return this.privSource.detach(audioNodeId);
  }
  /**
   * @member AudioConfigImpl.prototype.turnOff
   * @function
   * @public
   * @returns {Promise<void>} A promise.
   */
  turnOff() {
    return this.privSource.turnOff();
  }
  /**
   * @member AudioConfigImpl.prototype.events
   * @function
   * @public
   * @returns {EventSource<AudioSourceEvent>} An event source for audio events.
   */
  get events() {
    return this.privSource.events;
  }
  setProperty(name, value) {
    _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNull(value, "value");
    if (undefined !== this.privSource.setProperty) {
      this.privSource.setProperty(name, value);
    } else {
      throw new Error("This AudioConfig instance does not support setting properties.");
    }
  }
  getProperty(name, def) {
    if (undefined !== this.privSource.getProperty) {
      return this.privSource.getProperty(name, def);
    } else {
      throw new Error("This AudioConfig instance does not support getting properties.");
    }
    return def;
  }
  get deviceInfo() {
    return this.privSource.deviceInfo;
  }
}
class AudioOutputConfigImpl extends AudioConfig {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {IAudioDestination} destination - An audio destination.
   */
  constructor(destination) {
    super();
    this.privDestination = destination;
  }
  set format(format) {
    this.privDestination.format = format;
  }
  write(buffer) {
    this.privDestination.write(buffer);
  }
  close() {
    this.privDestination.close();
  }
  id() {
    return this.privDestination.id();
  }
  setProperty() {
    throw new Error("This AudioConfig instance does not support setting properties.");
  }
  getProperty() {
    throw new Error("This AudioConfig instance does not support getting properties.");
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AudioFileWriter: () => (/* binding */ AudioFileWriter)
/* harmony export */ });
/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ "?9463");
/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


class AudioFileWriter {
  constructor(filename) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(fs__WEBPACK_IMPORTED_MODULE_0__.openSync, "\nFile System access not available, please use Push or PullAudioOutputStream");
    this.privFd = fs__WEBPACK_IMPORTED_MODULE_0__.openSync(filename, "w");
  }
  set format(format) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNotUndefined(this.privAudioFormat, "format is already set");
    this.privAudioFormat = format;
    let headerOffset = 0;
    if (this.privAudioFormat.hasHeader) {
      headerOffset = this.privAudioFormat.header.byteLength;
    }
    if (this.privFd !== undefined) {
      this.privWriteStream = fs__WEBPACK_IMPORTED_MODULE_0__.createWriteStream("", {
        fd: this.privFd,
        start: headerOffset,
        autoClose: false
      });
    }
  }
  write(buffer) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(this.privAudioFormat, "must set format before writing.");
    if (this.privWriteStream !== undefined) {
      this.privWriteStream.write(new Uint8Array(buffer.slice(0)));
    }
  }
  close() {
    if (this.privFd !== undefined) {
      this.privWriteStream.on("finish", () => {
        if (this.privAudioFormat.hasHeader) {
          this.privAudioFormat.updateHeader(this.privWriteStream.bytesWritten);
          fs__WEBPACK_IMPORTED_MODULE_0__.writeSync(this.privFd, new Int8Array(this.privAudioFormat.header), 0, this.privAudioFormat.header.byteLength, 0);
        }
        fs__WEBPACK_IMPORTED_MODULE_0__.closeSync(this.privFd);
        this.privFd = undefined;
      });
      this.privWriteStream.end();
    }
  }
  id() {
    return this.privId;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AudioInputStream: () => (/* binding */ AudioInputStream),
/* harmony export */   PullAudioInputStream: () => (/* binding */ PullAudioInputStream),
/* harmony export */   PullAudioInputStreamImpl: () => (/* binding */ PullAudioInputStreamImpl),
/* harmony export */   PushAudioInputStream: () => (/* binding */ PushAudioInputStream),
/* harmony export */   PushAudioInputStreamImpl: () => (/* binding */ PushAudioInputStreamImpl)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js");
/* harmony import */ var _common_Guid__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common/Guid */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
/* eslint-disable max-classes-per-file */





/**
 * Represents audio input stream used for custom audio input configurations.
 * @class AudioInputStream
 */
class AudioInputStream {
  /**
   * Creates and initializes an instance.
   * @constructor
   */
  constructor() {
    return;
  }
  /**
   * Creates a memory backed PushAudioInputStream with the specified audio format.
   * @member AudioInputStream.createPushStream
   * @function
   * @public
   * @param {AudioStreamFormat} format - The audio data format in which audio will be
   * written to the push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).
   * @returns {PushAudioInputStream} The audio input stream being created.
   */
  static createPushStream(format) {
    return PushAudioInputStream.create(format);
  }
  /**
   * Creates a PullAudioInputStream that delegates to the specified callback interface for read()
   * and close() methods.
   * @member AudioInputStream.createPullStream
   * @function
   * @public
   * @param {PullAudioInputStreamCallback} callback - The custom audio input object, derived from
   * PullAudioInputStreamCallback
   * @param {AudioStreamFormat} format - The audio data format in which audio will be returned from
   * the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).
   * @returns {PullAudioInputStream} The audio input stream being created.
   */
  static createPullStream(callback, format) {
    return PullAudioInputStream.create(callback, format);
    // throw new Error("Oops");
  }
}
/**
 * Represents memory backed push audio input stream used for custom audio input configurations.
 * @class PushAudioInputStream
 */
class PushAudioInputStream extends AudioInputStream {
  /**
   * Creates a memory backed PushAudioInputStream with the specified audio format.
   * @member PushAudioInputStream.create
   * @function
   * @public
   * @param {AudioStreamFormat} format - The audio data format in which audio will be written to the
   * push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).
   * @returns {PushAudioInputStream} The push audio input stream being created.
   */
  static create(format) {
    return new PushAudioInputStreamImpl(format);
  }
}
/**
 * Represents memory backed push audio input stream used for custom audio input configurations.
 * @private
 * @class PushAudioInputStreamImpl
 */
class PushAudioInputStreamImpl extends PushAudioInputStream {
  /**
   * Creates and initalizes an instance with the given values.
   * @constructor
   * @param {AudioStreamFormat} format - The audio stream format.
   */
  constructor(format) {
    super();
    if (format === undefined) {
      this.privFormat = _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioStreamFormatImpl.getDefaultInputFormat();
    } else {
      this.privFormat = format;
    }
    this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();
    this.privId = (0,_common_Guid__WEBPACK_IMPORTED_MODULE_2__.createNoDashGuid)();
    this.privStream = new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ChunkedArrayBufferStream(this.privFormat.avgBytesPerSec / 10);
  }
  /**
   * Format information for the audio
   */
  get format() {
    return Promise.resolve(this.privFormat);
  }
  /**
   * Writes the audio data specified by making an internal copy of the data.
   * @member PushAudioInputStreamImpl.prototype.write
   * @function
   * @public
   * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.
   */
  write(dataBuffer) {
    this.privStream.writeStreamChunk({
      buffer: dataBuffer,
      isEnd: false,
      timeReceived: Date.now()
    });
  }
  /**
   * Closes the stream.
   * @member PushAudioInputStreamImpl.prototype.close
   * @function
   * @public
   */
  close() {
    this.privStream.close();
  }
  id() {
    return this.privId;
  }
  turnOn() {
    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioSourceInitializingEvent(this.privId)); // no stream id
    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioSourceReadyEvent(this.privId));
    return;
  }
  attach(audioNodeId) {
    return __awaiter(this, void 0, void 0, function* () {
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));
      yield this.turnOn();
      const stream = this.privStream;
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));
      return {
        detach: () => __awaiter(this, void 0, void 0, function* () {
          this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
          return this.turnOff();
        }),
        id: () => audioNodeId,
        read: () => stream.read()
      };
    });
  }
  detach(audioNodeId) {
    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
  }
  turnOff() {
    return;
  }
  get events() {
    return this.privEvents;
  }
  get deviceInfo() {
    return Promise.resolve({
      bitspersample: this.privFormat.bitsPerSample,
      channelcount: this.privFormat.channels,
      connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.connectivity.Unknown,
      manufacturer: "Speech SDK",
      model: "PushStream",
      samplerate: this.privFormat.samplesPerSec,
      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.type.Stream
    });
  }
  onEvent(event) {
    this.privEvents.onEvent(event);
    _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Events.instance.onEvent(event);
  }
  toBuffer(arrayBuffer) {
    const buf = Buffer.alloc(arrayBuffer.byteLength);
    const view = new Uint8Array(arrayBuffer);
    for (let i = 0; i < buf.length; ++i) {
      buf[i] = view[i];
    }
    return buf;
  }
}
/*
 * Represents audio input stream used for custom audio input configurations.
 * @class PullAudioInputStream
 */
class PullAudioInputStream extends AudioInputStream {
  /**
   * Creates and initializes and instance.
   * @constructor
   */
  constructor() {
    super();
  }
  /**
   * Creates a PullAudioInputStream that delegates to the specified callback interface for
   * read() and close() methods, using the default format (16 kHz 16bit mono PCM).
   * @member PullAudioInputStream.create
   * @function
   * @public
   * @param {PullAudioInputStreamCallback} callback - The custom audio input object,
   * derived from PullAudioInputStreamCustomCallback
   * @param {AudioStreamFormat} format - The audio data format in which audio will be
   * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).
   * @returns {PullAudioInputStream} The push audio input stream being created.
   */
  static create(callback, format) {
    return new PullAudioInputStreamImpl(callback, format);
  }
}
/**
 * Represents audio input stream used for custom audio input configurations.
 * @private
 * @class PullAudioInputStreamImpl
 */
class PullAudioInputStreamImpl extends PullAudioInputStream {
  /**
   * Creates a PullAudioInputStream that delegates to the specified callback interface for
   * read() and close() methods, using the default format (16 kHz 16bit mono PCM).
   * @constructor
   * @param {PullAudioInputStreamCallback} callback - The custom audio input object,
   * derived from PullAudioInputStreamCustomCallback
   * @param {AudioStreamFormat} format - The audio data format in which audio will be
   * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).
   */
  constructor(callback, format) {
    super();
    if (undefined === format) {
      this.privFormat = _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioStreamFormat.getDefaultInputFormat();
    } else {
      this.privFormat = format;
    }
    this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();
    this.privId = (0,_common_Guid__WEBPACK_IMPORTED_MODULE_2__.createNoDashGuid)();
    this.privCallback = callback;
    this.privIsClosed = false;
    this.privBufferSize = this.privFormat.avgBytesPerSec / 10;
  }
  /**
   * Format information for the audio
   */
  get format() {
    return Promise.resolve(this.privFormat);
  }
  /**
   * Closes the stream.
   * @member PullAudioInputStreamImpl.prototype.close
   * @function
   * @public
   */
  close() {
    this.privIsClosed = true;
    this.privCallback.close();
  }
  id() {
    return this.privId;
  }
  turnOn() {
    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioSourceInitializingEvent(this.privId)); // no stream id
    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioSourceReadyEvent(this.privId));
    return;
  }
  attach(audioNodeId) {
    return __awaiter(this, void 0, void 0, function* () {
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));
      yield this.turnOn();
      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));
      return {
        detach: () => {
          this.privCallback.close();
          this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
          return this.turnOff();
        },
        id: () => audioNodeId,
        read: () => {
          let totalBytes = 0;
          let transmitBuff;
          // Until we have the minimum number of bytes to send in a transmission, keep asking for more.
          while (totalBytes < this.privBufferSize) {
            // Sizing the read buffer to the delta between the perfect size and what's left means we won't ever get too much
            // data back.
            const readBuff = new ArrayBuffer(this.privBufferSize - totalBytes);
            const pulledBytes = this.privCallback.read(readBuff);
            // If there is no return buffer yet defined, set the return buffer to the that was just populated.
            // This was, if we have enough data there's no copy penalty, but if we don't we have a buffer that's the
            // preferred size allocated.
            if (undefined === transmitBuff) {
              transmitBuff = readBuff;
            } else {
              // Not the first bite at the apple, so fill the return buffer with the data we got back.
              const intView = new Int8Array(transmitBuff);
              intView.set(new Int8Array(readBuff), totalBytes);
            }
            // If there are no bytes to read, just break out and be done.
            if (0 === pulledBytes) {
              break;
            }
            totalBytes += pulledBytes;
          }
          return Promise.resolve({
            buffer: transmitBuff.slice(0, totalBytes),
            isEnd: this.privIsClosed || totalBytes === 0,
            timeReceived: Date.now()
          });
        }
      };
    });
  }
  detach(audioNodeId) {
    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
  }
  turnOff() {
    return;
  }
  get events() {
    return this.privEvents;
  }
  get deviceInfo() {
    return Promise.resolve({
      bitspersample: this.privFormat.bitsPerSample,
      channelcount: this.privFormat.channels,
      connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.connectivity.Unknown,
      manufacturer: "Speech SDK",
      model: "PullStream",
      samplerate: this.privFormat.samplesPerSec,
      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.type.Stream
    });
  }
  onEvent(event) {
    this.privEvents.onEvent(event);
    _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Events.instance.onEvent(event);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AudioOutputFormatImpl: () => (/* binding */ AudioOutputFormatImpl)
/* harmony export */ });
/* harmony import */ var _SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../SpeechSynthesisOutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js");
/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * @private
 * @class AudioOutputFormatImpl
 * Updated in version 1.17.0
 */
// eslint-disable-next-line max-classes-per-file
class AudioOutputFormatImpl extends _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioStreamFormatImpl {
  /**
   * Creates an instance with the given values.
   * @constructor
   * @param formatTag
   * @param {number} channels - Number of channels.
   * @param {number} samplesPerSec - Samples per second.
   * @param {number} avgBytesPerSec - Average bytes per second.
   * @param {number} blockAlign - Block alignment.
   * @param {number} bitsPerSample - Bits per sample.
   * @param {string} audioFormatString - Audio format string
   * @param {string} requestAudioFormatString - Audio format string sent to service.
   * @param {boolean} hasHeader - If the format has header or not.
   */
  constructor(formatTag, channels, samplesPerSec, avgBytesPerSec, blockAlign, bitsPerSample, audioFormatString, requestAudioFormatString, hasHeader) {
    super(samplesPerSec, bitsPerSample, channels, formatTag);
    this.formatTag = formatTag;
    this.avgBytesPerSec = avgBytesPerSec;
    this.blockAlign = blockAlign;
    this.priAudioFormatString = audioFormatString;
    this.priRequestAudioFormatString = requestAudioFormatString;
    this.priHasHeader = hasHeader;
  }
  static fromSpeechSynthesisOutputFormat(speechSynthesisOutputFormat) {
    if (speechSynthesisOutputFormat === undefined) {
      return AudioOutputFormatImpl.getDefaultOutputFormat();
    }
    return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(AudioOutputFormatImpl.SpeechSynthesisOutputFormatToString[speechSynthesisOutputFormat]);
  }
  static fromSpeechSynthesisOutputFormatString(speechSynthesisOutputFormatString) {
    switch (speechSynthesisOutputFormatString) {
      case "raw-8khz-8bit-mono-mulaw":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "riff-16khz-16kbps-mono-siren":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, "audio-16khz-16kbps-mono-siren", true);
      case "audio-16khz-16kbps-mono-siren":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-16khz-32kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 16000, 32 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-16khz-128kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 16000, 128 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-16khz-64kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 16000, 64 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-24khz-48kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 24000, 48 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-24khz-96kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 24000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-24khz-160kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 24000, 160 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "raw-16khz-16bit-mono-truesilk":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.SILKSkype, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "riff-8khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, "raw-8khz-16bit-mono-pcm", true);
      case "riff-24khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, "raw-24khz-16bit-mono-pcm", true);
      case "riff-8khz-8bit-mono-mulaw":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, "raw-8khz-8bit-mono-mulaw", true);
      case "raw-16khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, "raw-16khz-16bit-mono-pcm", false);
      case "raw-24khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, "raw-24khz-16bit-mono-pcm", false);
      case "raw-8khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, "raw-8khz-16bit-mono-pcm", false);
      case "ogg-16khz-16bit-mono-opus":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OGG_OPUS, 1, 16000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "ogg-24khz-16bit-mono-opus":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OGG_OPUS, 1, 24000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "raw-48khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, "raw-48khz-16bit-mono-pcm", false);
      case "riff-48khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, "raw-48khz-16bit-mono-pcm", true);
      case "audio-48khz-96kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 48000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-48khz-192kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 48000, 192 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "ogg-48khz-16bit-mono-opus":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OGG_OPUS, 1, 48000, 12000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "webm-16khz-16bit-mono-opus":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.WEBM_OPUS, 1, 16000, 4000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "webm-24khz-16bit-mono-opus":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.WEBM_OPUS, 1, 24000, 6000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "webm-24khz-16bit-24kbps-mono-opus":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.WEBM_OPUS, 1, 24000, 3000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-16khz-16bit-32kbps-mono-opus":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OPUS, 1, 16000, 4000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-24khz-16bit-48kbps-mono-opus":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OPUS, 1, 24000, 6000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-24khz-16bit-24kbps-mono-opus":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OPUS, 1, 24000, 3000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-24khz-16bit-mono-flac":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.FLAC, 1, 24000, 24000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-48khz-16bit-mono-flac":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.FLAC, 1, 48000, 30000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "raw-24khz-16bit-mono-truesilk":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.SILKSkype, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "raw-8khz-8bit-mono-alaw":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "riff-8khz-8bit-mono-alaw":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, "raw-8khz-8bit-mono-alaw", true);
      case "raw-22050hz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "riff-22050hz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, "raw-22050hz-16bit-mono-pcm", true);
      case "raw-44100hz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "riff-44100hz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, "raw-44100hz-16bit-mono-pcm", true);
      case "riff-16khz-16bit-mono-pcm":
      default:
        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 16000, 32000, 2, 16, "riff-16khz-16bit-mono-pcm", "raw-16khz-16bit-mono-pcm", true);
    }
  }
  static getDefaultOutputFormat() {
    return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(typeof window !== "undefined" ? "audio-24khz-48kbitrate-mono-mp3" : "riff-16khz-16bit-mono-pcm");
  }
  /**
   * Specifies if this audio output format has a header
   * @boolean AudioOutputFormatImpl.prototype.hasHeader
   * @function
   * @public
   */
  get hasHeader() {
    return this.priHasHeader;
  }
  /**
   * Specifies the header of this format
   * @ArrayBuffer AudioOutputFormatImpl.prototype.header
   * @function
   * @public
   */
  get header() {
    if (this.hasHeader) {
      return this.privHeader;
    }
    return undefined;
  }
  /**
   * Updates the header based on the audio length
   * @member AudioOutputFormatImpl.updateHeader
   * @function
   * @public
   * @param {number} audioLength - the audio length
   */
  updateHeader(audioLength) {
    if (this.priHasHeader) {
      const view = new DataView(this.privHeader);
      view.setUint32(4, audioLength + this.privHeader.byteLength - 8, true);
      view.setUint32(40, audioLength, true);
    }
  }
  /**
   * Specifies the audio format string to be sent to the service
   * @string AudioOutputFormatImpl.prototype.requestAudioFormatString
   * @function
   * @public
   */
  get requestAudioFormatString() {
    return this.priRequestAudioFormatString;
  }
}
AudioOutputFormatImpl.SpeechSynthesisOutputFormatToString = {
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw]: "raw-8khz-8bit-mono-mulaw",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren]: "riff-16khz-16kbps-mono-siren",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren]: "audio-16khz-16kbps-mono-siren",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3]: "audio-16khz-32kbitrate-mono-mp3",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3]: "audio-16khz-128kbitrate-mono-mp3",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3]: "audio-16khz-64kbitrate-mono-mp3",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3]: "audio-24khz-48kbitrate-mono-mp3",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3]: "audio-24khz-96kbitrate-mono-mp3",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3]: "audio-24khz-160kbitrate-mono-mp3",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk]: "raw-16khz-16bit-mono-truesilk",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm]: "riff-16khz-16bit-mono-pcm",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm]: "riff-8khz-16bit-mono-pcm",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm]: "riff-24khz-16bit-mono-pcm",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw]: "riff-8khz-8bit-mono-mulaw",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm]: "raw-16khz-16bit-mono-pcm",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm]: "raw-24khz-16bit-mono-pcm",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm]: "raw-8khz-16bit-mono-pcm",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus]: "ogg-16khz-16bit-mono-opus",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus]: "ogg-24khz-16bit-mono-opus",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm]: "raw-48khz-16bit-mono-pcm",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm]: "riff-48khz-16bit-mono-pcm",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio48Khz96KBitRateMonoMp3]: "audio-48khz-96kbitrate-mono-mp3",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3]: "audio-48khz-192kbitrate-mono-mp3",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Ogg48Khz16BitMonoOpus]: "ogg-48khz-16bit-mono-opus",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Webm16Khz16BitMonoOpus]: "webm-16khz-16bit-mono-opus",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Webm24Khz16BitMonoOpus]: "webm-24khz-16bit-mono-opus",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Webm24Khz16Bit24KbpsMonoOpus]: "webm-24khz-16bit-24kbps-mono-opus",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw24Khz16BitMonoTrueSilk]: "raw-24khz-16bit-mono-truesilk",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw8Khz8BitMonoALaw]: "raw-8khz-8bit-mono-alaw",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff8Khz8BitMonoALaw]: "riff-8khz-8bit-mono-alaw",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz16Bit32KbpsMonoOpus]: "audio-16khz-16bit-32kbps-mono-opus",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz16Bit48KbpsMonoOpus]: "audio-24khz-16bit-48kbps-mono-opus",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz16Bit24KbpsMonoOpus]: "audio-24khz-16bit-24kbps-mono-opus",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw22050Hz16BitMonoPcm]: "raw-22050hz-16bit-mono-pcm",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff22050Hz16BitMonoPcm]: "riff-22050hz-16bit-mono-pcm",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw44100Hz16BitMonoPcm]: "raw-44100hz-16bit-mono-pcm",
  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff44100Hz16BitMonoPcm]: "riff-44100hz-16bit-mono-pcm"
};

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AudioOutputStream: () => (/* binding */ AudioOutputStream),
/* harmony export */   PullAudioOutputStream: () => (/* binding */ PullAudioOutputStream),
/* harmony export */   PullAudioOutputStreamImpl: () => (/* binding */ PullAudioOutputStreamImpl),
/* harmony export */   PushAudioOutputStream: () => (/* binding */ PushAudioOutputStream),
/* harmony export */   PushAudioOutputStreamImpl: () => (/* binding */ PushAudioOutputStreamImpl)
/* harmony export */ });
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AudioOutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
/* eslint-disable max-classes-per-file */



/**
 * Represents audio output stream used for custom audio output configurations.
 * @class AudioOutputStream
 */
class AudioOutputStream {
  /**
   * Creates and initializes an instance.
   * @constructor
   */
  constructor() {
    return;
  }
  /**
   * Creates a memory backed PullAudioOutputStream with the specified audio format.
   * @member AudioOutputStream.createPullStream
   * @function
   * @public
   * @returns {PullAudioOutputStream} The audio output stream being created.
   */
  static createPullStream() {
    return PullAudioOutputStream.create();
  }
}
/**
 * Represents memory backed push audio output stream used for custom audio output configurations.
 * @class PullAudioOutputStream
 */
class PullAudioOutputStream extends AudioOutputStream {
  /**
   * Creates a memory backed PullAudioOutputStream with the specified audio format.
   * @member PullAudioOutputStream.create
   * @function
   * @public
   * @returns {PullAudioOutputStream} The push audio output stream being created.
   */
  static create() {
    return new PullAudioOutputStreamImpl();
  }
}
/**
 * Represents memory backed push audio output stream used for custom audio output configurations.
 * @private
 * @class PullAudioOutputStreamImpl
 */
class PullAudioOutputStreamImpl extends PullAudioOutputStream {
  /**
   * Creates and initializes an instance with the given values.
   * @constructor
   */
  constructor() {
    super();
    this.privId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();
    this.privStream = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Stream();
  }
  /**
   * Sets the format information to the stream. For internal use only.
   * @param {AudioStreamFormat} format - the format to be set.
   */
  set format(format) {
    if (format === undefined || format === null) {
      this.privFormat = _AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__.AudioOutputFormatImpl.getDefaultOutputFormat();
    }
    this.privFormat = format;
  }
  /**
   * Format information for the audio
   */
  get format() {
    return this.privFormat;
  }
  /**
   * Checks if the stream is closed
   * @member PullAudioOutputStreamImpl.prototype.isClosed
   * @property
   * @public
   */
  get isClosed() {
    return this.privStream.isClosed;
  }
  /**
   * Gets the id of the stream
   * @member PullAudioOutputStreamImpl.prototype.id
   * @property
   * @public
   */
  id() {
    return this.privId;
  }
  /**
   * Reads audio data from the internal buffer.
   * @member PullAudioOutputStreamImpl.prototype.read
   * @function
   * @public
   * @param {ArrayBuffer} dataBuffer - An ArrayBuffer to store the read data.
   * @returns {Promise<number>} - Audio buffer length has been read.
   */
  read(dataBuffer) {
    return __awaiter(this, void 0, void 0, function* () {
      const intView = new Int8Array(dataBuffer);
      let totalBytes = 0;
      if (this.privLastChunkView !== undefined) {
        if (this.privLastChunkView.length > dataBuffer.byteLength) {
          intView.set(this.privLastChunkView.slice(0, dataBuffer.byteLength));
          this.privLastChunkView = this.privLastChunkView.slice(dataBuffer.byteLength);
          return Promise.resolve(dataBuffer.byteLength);
        }
        intView.set(this.privLastChunkView);
        totalBytes = this.privLastChunkView.length;
        this.privLastChunkView = undefined;
      }
      // Until we have the minimum number of bytes to send in a transmission, keep asking for more.
      while (totalBytes < dataBuffer.byteLength && !this.privStream.isReadEnded) {
        const chunk = yield this.privStream.read();
        if (chunk !== undefined && !chunk.isEnd) {
          let tmpBuffer;
          if (chunk.buffer.byteLength > dataBuffer.byteLength - totalBytes) {
            tmpBuffer = chunk.buffer.slice(0, dataBuffer.byteLength - totalBytes);
            this.privLastChunkView = new Int8Array(chunk.buffer.slice(dataBuffer.byteLength - totalBytes));
          } else {
            tmpBuffer = chunk.buffer;
          }
          intView.set(new Int8Array(tmpBuffer), totalBytes);
          totalBytes += tmpBuffer.byteLength;
        } else {
          this.privStream.readEnded();
        }
      }
      return totalBytes;
    });
  }
  /**
   * Writes the audio data specified by making an internal copy of the data.
   * @member PullAudioOutputStreamImpl.prototype.write
   * @function
   * @public
   * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.
   */
  write(dataBuffer) {
    _Contracts__WEBPACK_IMPORTED_MODULE_3__.Contracts.throwIfNullOrUndefined(this.privStream, "must set format before writing");
    this.privStream.writeStreamChunk({
      buffer: dataBuffer,
      isEnd: false,
      timeReceived: Date.now()
    });
  }
  /**
   * Closes the stream.
   * @member PullAudioOutputStreamImpl.prototype.close
   * @function
   * @public
   */
  close() {
    this.privStream.close();
  }
}
/*
 * Represents audio output stream used for custom audio output configurations.
 * @class PushAudioOutputStream
 */
class PushAudioOutputStream extends AudioOutputStream {
  /**
   * Creates and initializes and instance.
   * @constructor
   */
  constructor() {
    super();
  }
  /**
   * Creates a PushAudioOutputStream that delegates to the specified callback interface for
   * write() and close() methods.
   * @member PushAudioOutputStream.create
   * @function
   * @public
   * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,
   * derived from PushAudioOutputStreamCallback
   * @returns {PushAudioOutputStream} The push audio output stream being created.
   */
  static create(callback) {
    return new PushAudioOutputStreamImpl(callback);
  }
}
/**
 * Represents audio output stream used for custom audio output configurations.
 * @private
 * @class PushAudioOutputStreamImpl
 */
class PushAudioOutputStreamImpl extends PushAudioOutputStream {
  /**
   * Creates a PushAudioOutputStream that delegates to the specified callback interface for
   * read() and close() methods.
   * @constructor
   * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,
   * derived from PushAudioOutputStreamCallback
   */
  constructor(callback) {
    super();
    this.privId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();
    this.privCallback = callback;
  }
  // eslint-disable-next-line @typescript-eslint/no-empty-function
  set format(format) {}
  write(buffer) {
    if (!!this.privCallback.write) {
      this.privCallback.write(buffer);
    }
  }
  close() {
    if (!!this.privCallback.close) {
      this.privCallback.close();
    }
  }
  id() {
    return this.privId;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AudioFormatTag: () => (/* binding */ AudioFormatTag),
/* harmony export */   AudioStreamFormat: () => (/* binding */ AudioStreamFormat),
/* harmony export */   AudioStreamFormatImpl: () => (/* binding */ AudioStreamFormatImpl)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// eslint-disable-next-line max-classes-per-file
var AudioFormatTag;
(function (AudioFormatTag) {
  AudioFormatTag[AudioFormatTag["PCM"] = 1] = "PCM";
  AudioFormatTag[AudioFormatTag["MuLaw"] = 2] = "MuLaw";
  AudioFormatTag[AudioFormatTag["Siren"] = 3] = "Siren";
  AudioFormatTag[AudioFormatTag["MP3"] = 4] = "MP3";
  AudioFormatTag[AudioFormatTag["SILKSkype"] = 5] = "SILKSkype";
  AudioFormatTag[AudioFormatTag["OGG_OPUS"] = 6] = "OGG_OPUS";
  AudioFormatTag[AudioFormatTag["WEBM_OPUS"] = 7] = "WEBM_OPUS";
  AudioFormatTag[AudioFormatTag["ALaw"] = 8] = "ALaw";
  AudioFormatTag[AudioFormatTag["FLAC"] = 9] = "FLAC";
  AudioFormatTag[AudioFormatTag["OPUS"] = 10] = "OPUS";
})(AudioFormatTag || (AudioFormatTag = {}));
/**
 * Represents audio stream format used for custom audio input configurations.
 * @class AudioStreamFormat
 */
class AudioStreamFormat {
  /**
   * Creates an audio stream format object representing the default audio stream
   * format (16KHz 16bit mono PCM).
   * @member AudioStreamFormat.getDefaultInputFormat
   * @function
   * @public
   * @returns {AudioStreamFormat} The audio stream format being created.
   */
  static getDefaultInputFormat() {
    return AudioStreamFormatImpl.getDefaultInputFormat();
  }
  /**
   * Creates an audio stream format object with the specified format characteristics.
   * @member AudioStreamFormat.getWaveFormat
   * @function
   * @public
   * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).
   * @param {number} bitsPerSample - Bits per sample, typically 16.
   * @param {number} channels - Number of channels in the waveform-audio data. Monaural data
   * uses one channel and stereo data uses two channels.
   * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).
   * @returns {AudioStreamFormat} The audio stream format being created.
   */
  static getWaveFormat(samplesPerSecond, bitsPerSample, channels, format) {
    return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels, format);
  }
  /**
   * Creates an audio stream format object with the specified pcm waveformat characteristics.
   * @member AudioStreamFormat.getWaveFormatPCM
   * @function
   * @public
   * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).
   * @param {number} bitsPerSample - Bits per sample, typically 16.
   * @param {number} channels - Number of channels in the waveform-audio data. Monaural data
   * uses one channel and stereo data uses two channels.
   * @returns {AudioStreamFormat} The audio stream format being created.
   */
  static getWaveFormatPCM(samplesPerSecond, bitsPerSample, channels) {
    return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels);
  }
}
/**
 * @private
 * @class AudioStreamFormatImpl
 */
class AudioStreamFormatImpl extends AudioStreamFormat {
  /**
   * Creates an instance with the given values.
   * @constructor
   * @param {number} samplesPerSec - Samples per second.
   * @param {number} bitsPerSample - Bits per sample.
   * @param {number} channels - Number of channels.
   * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).
   */
  constructor(samplesPerSec = 16000, bitsPerSample = 16, channels = 1, format = AudioFormatTag.PCM) {
    super();
    let isWavFormat = true;
    /* 1 for PCM; 6 for alaw; 7 for mulaw */
    switch (format) {
      case AudioFormatTag.PCM:
        this.formatTag = 1;
        break;
      case AudioFormatTag.ALaw:
        this.formatTag = 6;
        break;
      case AudioFormatTag.MuLaw:
        this.formatTag = 7;
        break;
      default:
        isWavFormat = false;
    }
    this.bitsPerSample = bitsPerSample;
    this.samplesPerSec = samplesPerSec;
    this.channels = channels;
    this.avgBytesPerSec = this.samplesPerSec * this.channels * (this.bitsPerSample / 8);
    this.blockAlign = this.channels * Math.max(this.bitsPerSample, 8);
    if (isWavFormat) {
      this.privHeader = new ArrayBuffer(44);
      // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView
      const view = new DataView(this.privHeader);
      /* RIFF identifier */
      this.setString(view, 0, "RIFF");
      /* file length */
      view.setUint32(4, 0, true);
      /* RIFF type & Format */
      this.setString(view, 8, "WAVEfmt ");
      /* format chunk length */
      view.setUint32(16, 16, true);
      /* audio format */
      view.setUint16(20, this.formatTag, true);
      /* channel count */
      view.setUint16(22, this.channels, true);
      /* sample rate */
      view.setUint32(24, this.samplesPerSec, true);
      /* byte rate (sample rate * block align) */
      view.setUint32(28, this.avgBytesPerSec, true);
      /* block align (channel count * bytes per sample) */
      view.setUint16(32, this.channels * (this.bitsPerSample / 8), true);
      /* bits per sample */
      view.setUint16(34, this.bitsPerSample, true);
      /* data chunk identifier */
      this.setString(view, 36, "data");
      /* data chunk length */
      view.setUint32(40, 0, true);
    }
  }
  /**
   * Retrieves the default input format.
   * @member AudioStreamFormatImpl.getDefaultInputFormat
   * @function
   * @public
   * @returns {AudioStreamFormatImpl} The default input format.
   */
  static getDefaultInputFormat() {
    return new AudioStreamFormatImpl();
  }
  /**
   * Creates an audio context appropriate to current browser
   * @member AudioStreamFormatImpl.getAudioContext
   * @function
   * @public
   * @returns {AudioContext} An audio context instance
   */
  /* eslint-disable */
  static getAudioContext(sampleRate) {
    // Workaround for Speech SDK bug in Safari.
    const AudioContext = window.AudioContext // our preferred impl
    || window.webkitAudioContext // fallback, mostly when on Safari
    || false; // could not find.
    // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext
    if (!!AudioContext) {
      if (sampleRate !== undefined && navigator.mediaDevices.getSupportedConstraints().sampleRate) {
        return new AudioContext({
          sampleRate
        });
      } else {
        return new AudioContext();
      }
    } else {
      throw new Error("Browser does not support Web Audio API (AudioContext is not available).");
    }
  }
  /* eslint-enable */
  /**
   * Closes the configuration object.
   * @member AudioStreamFormatImpl.prototype.close
   * @function
   * @public
   */
  close() {
    return;
  }
  get header() {
    return this.privHeader;
  }
  setString(view, offset, str) {
    for (let i = 0; i < str.length; i++) {
      view.setUint8(offset + i, str.charCodeAt(i));
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   BaseAudioPlayer: () => (/* binding */ BaseAudioPlayer)
/* harmony export */ });
/* harmony import */ var _common_Error__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Error */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};



/**
 * Base audio player class
 * TODO: Plays only PCM for now.
 * @class
 */
class BaseAudioPlayer {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {AudioStreamFormat} audioFormat audio stream format recognized by the player.
   */
  constructor(audioFormat) {
    this.audioContext = null;
    this.gainNode = null;
    this.autoUpdateBufferTimer = 0;
    if (audioFormat === undefined) {
      audioFormat = _Exports__WEBPACK_IMPORTED_MODULE_0__.AudioStreamFormat.getDefaultInputFormat();
    }
    this.init(audioFormat);
  }
  /**
   * play Audio sample
   * @param newAudioData audio data to be played.
   */
  playAudioSample(newAudioData, cb, err) {
    try {
      this.ensureInitializedContext();
      const audioData = this.formatAudioData(newAudioData);
      const newSamplesData = new Float32Array(this.samples.length + audioData.length);
      newSamplesData.set(this.samples, 0);
      newSamplesData.set(audioData, this.samples.length);
      this.samples = newSamplesData;
      if (!!cb) {
        cb();
      }
    } catch (e) {
      if (!!err) {
        err(e);
      }
    }
  }
  /**
   * stops audio and clears the buffers
   */
  stopAudio(cb, err) {
    if (this.audioContext !== null) {
      this.samples = new Float32Array();
      // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
      clearInterval(this.autoUpdateBufferTimer);
      this.audioContext.close().then(() => {
        if (!!cb) {
          cb();
        }
      }, error => {
        if (!!err) {
          err(error);
        }
      });
      this.audioContext = null;
    }
  }
  init(audioFormat) {
    this.audioFormat = audioFormat;
    this.samples = new Float32Array();
  }
  ensureInitializedContext() {
    if (this.audioContext === null) {
      this.createAudioContext();
      const timerPeriod = 200;
      this.autoUpdateBufferTimer = setInterval(() => {
        this.updateAudioBuffer();
      }, timerPeriod);
    }
  }
  createAudioContext() {
    // new ((window as any).AudioContext || (window as any).webkitAudioContext)();
    this.audioContext = _Exports__WEBPACK_IMPORTED_MODULE_0__.AudioStreamFormatImpl.getAudioContext();
    // TODO: Various examples shows this gain node, it does not seem to be needed unless we plan
    // to control the volume, not likely
    this.gainNode = this.audioContext.createGain();
    this.gainNode.gain.value = 1;
    this.gainNode.connect(this.audioContext.destination);
    this.startTime = this.audioContext.currentTime;
  }
  formatAudioData(audioData) {
    switch (this.audioFormat.bitsPerSample) {
      case 8:
        return this.formatArrayBuffer(new Int8Array(audioData), 128);
      case 16:
        return this.formatArrayBuffer(new Int16Array(audioData), 32768);
      case 32:
        return this.formatArrayBuffer(new Int32Array(audioData), 2147483648);
      default:
        throw new _common_Error__WEBPACK_IMPORTED_MODULE_1__.InvalidOperationError("Only WAVE_FORMAT_PCM (8/16/32 bps) format supported at this time");
    }
  }
  formatArrayBuffer(audioData, maxValue) {
    const float32Data = new Float32Array(audioData.length);
    for (let i = 0; i < audioData.length; i++) {
      float32Data[i] = audioData[i] / maxValue;
    }
    return float32Data;
  }
  updateAudioBuffer() {
    if (this.samples.length === 0) {
      return;
    }
    const channelCount = this.audioFormat.channels;
    const bufferSource = this.audioContext.createBufferSource();
    const frameCount = this.samples.length / channelCount;
    const audioBuffer = this.audioContext.createBuffer(channelCount, frameCount, this.audioFormat.samplesPerSec);
    // TODO: Should we do the conversion in the pushAudioSample instead?
    for (let channel = 0; channel < channelCount; channel++) {
      // Fill in individual channel data
      let channelOffset = channel;
      const audioData = audioBuffer.getChannelData(channel);
      for (let i = 0; i < this.samples.length; i++, channelOffset += channelCount) {
        audioData[i] = this.samples[channelOffset];
      }
    }
    if (this.startTime < this.audioContext.currentTime) {
      this.startTime = this.audioContext.currentTime;
    }
    bufferSource.buffer = audioBuffer;
    bufferSource.connect(this.gainNode);
    bufferSource.start(this.startTime);
    // Make sure we play the next sample after the current one.
    this.startTime += audioBuffer.duration;
    // Clear the samples for the next pushed data.
    this.samples = new Float32Array();
  }
  playAudio(audioData) {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.audioContext === null) {
        this.createAudioContext();
      }
      const source = this.audioContext.createBufferSource();
      const destination = this.audioContext.destination;
      yield this.audioContext.decodeAudioData(audioData, newBuffer => {
        source.buffer = newBuffer;
        source.connect(destination);
        source.start(0);
      });
    });
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   PullAudioInputStreamCallback: () => (/* binding */ PullAudioInputStreamCallback)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * An abstract base class that defines callback methods (read() and close()) for
 * custom audio input streams).
 * @class PullAudioInputStreamCallback
 */
class PullAudioInputStreamCallback {}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   PushAudioOutputStreamCallback: () => (/* binding */ PushAudioOutputStreamCallback)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * An abstract base class that defines callback methods (write() and close()) for
 * custom audio output streams).
 * @class PushAudioOutputStreamCallback
 */
class PushAudioOutputStreamCallback {}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeakerAudioDestination: () => (/* binding */ SpeakerAudioDestination)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js");
/* harmony import */ var _AudioOutputStream__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./AudioOutputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js");
/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};




const MediaDurationPlaceholderSeconds = 60 * 30;
const AudioFormatToMimeType = {
  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM]: "audio/wav",
  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MuLaw]: "audio/x-wav",
  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3]: "audio/mpeg",
  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OGG_OPUS]: "audio/ogg",
  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.WEBM_OPUS]: "audio/webm; codecs=opus",
  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.ALaw]: "audio/x-wav",
  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.FLAC]: "audio/flac"
};
/**
 * Represents the speaker playback audio destination, which only works in browser.
 * Note: the SDK will try to use <a href="https://www.w3.org/TR/media-source/">Media Source Extensions</a> to play audio.
 * Mp3 format has better supports on Microsoft Edge, Chrome and Safari (desktop), so, it's better to specify mp3 format for playback.
 * @class SpeakerAudioDestination
 * Updated in version 1.17.0
 */
class SpeakerAudioDestination {
  constructor(audioDestinationId) {
    this.privPlaybackStarted = false;
    this.privAppendingToBuffer = false;
    this.privMediaSourceOpened = false;
    this.privBytesReceived = 0;
    this.privId = audioDestinationId ? audioDestinationId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_1__.createNoDashGuid)();
    this.privIsPaused = false;
    this.privIsClosed = false;
  }
  id() {
    return this.privId;
  }
  write(buffer, cb, err) {
    if (this.privAudioBuffer !== undefined) {
      this.privAudioBuffer.push(buffer);
      this.updateSourceBuffer().then(() => {
        if (!!cb) {
          cb();
        }
      }, error => {
        if (!!err) {
          err(error);
        }
      });
    } else if (this.privAudioOutputStream !== undefined) {
      this.privAudioOutputStream.write(buffer);
      this.privBytesReceived += buffer.byteLength;
    }
  }
  close(cb, err) {
    this.privIsClosed = true;
    if (this.privSourceBuffer !== undefined) {
      this.handleSourceBufferUpdateEnd().then(() => {
        if (!!cb) {
          cb();
        }
      }, error => {
        if (!!err) {
          err(error);
        }
      });
    } else if (this.privAudioOutputStream !== undefined && typeof window !== "undefined") {
      if ((this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM || this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MuLaw || this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.ALaw) && this.privFormat.hasHeader === false) {
        // eslint-disable-next-line no-console
        console.warn("Play back is not supported for raw PCM, mulaw or alaw format without header.");
        if (!!this.onAudioEnd) {
          this.onAudioEnd(this);
        }
      } else {
        let receivedAudio = new ArrayBuffer(this.privBytesReceived);
        this.privAudioOutputStream.read(receivedAudio).then(() => {
          receivedAudio = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.SynthesisAdapterBase.addHeader(receivedAudio, this.privFormat);
          const audioBlob = new Blob([receivedAudio], {
            type: AudioFormatToMimeType[this.privFormat.formatTag]
          });
          this.privAudio.src = window.URL.createObjectURL(audioBlob);
          this.notifyPlayback().then(() => {
            if (!!cb) {
              cb();
            }
          }, error => {
            if (!!err) {
              err(error);
            }
          });
        }, error => {
          if (!!err) {
            err(error);
          }
        });
      }
    } else {
      // unsupported format, call onAudioEnd directly.
      if (!!this.onAudioEnd) {
        this.onAudioEnd(this);
      }
    }
  }
  set format(format) {
    // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access
    if (typeof AudioContext !== "undefined" || typeof window !== "undefined" && typeof window.webkitAudioContext !== "undefined") {
      this.privFormat = format;
      const mimeType = AudioFormatToMimeType[this.privFormat.formatTag];
      if (mimeType === undefined) {
        // eslint-disable-next-line no-console
        console.warn(`Unknown mimeType for format ${_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag[this.privFormat.formatTag]}; playback is not supported.`);
      } else if (typeof MediaSource !== "undefined" && MediaSource.isTypeSupported(mimeType)) {
        this.privAudio = new Audio();
        this.privAudioBuffer = [];
        this.privMediaSource = new MediaSource();
        this.privAudio.src = URL.createObjectURL(this.privMediaSource);
        this.privAudio.load();
        this.privMediaSource.onsourceopen = () => {
          this.privMediaSourceOpened = true;
          this.privMediaSource.duration = MediaDurationPlaceholderSeconds;
          this.privSourceBuffer = this.privMediaSource.addSourceBuffer(mimeType);
          this.privSourceBuffer.onupdate = () => {
            this.updateSourceBuffer().catch(reason => {
              _common_Exports__WEBPACK_IMPORTED_MODULE_3__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.BackgroundEvent(reason));
            });
          };
          this.privSourceBuffer.onupdateend = () => {
            this.handleSourceBufferUpdateEnd().catch(reason => {
              _common_Exports__WEBPACK_IMPORTED_MODULE_3__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.BackgroundEvent(reason));
            });
          };
          this.privSourceBuffer.onupdatestart = () => {
            this.privAppendingToBuffer = false;
          };
        };
        this.updateSourceBuffer().catch(reason => {
          _common_Exports__WEBPACK_IMPORTED_MODULE_3__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.BackgroundEvent(reason));
        });
      } else {
        // eslint-disable-next-line no-console
        console.warn(`Format ${_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag[this.privFormat.formatTag]} could not be played by MSE, streaming playback is not enabled.`);
        this.privAudioOutputStream = new _AudioOutputStream__WEBPACK_IMPORTED_MODULE_5__.PullAudioOutputStreamImpl();
        this.privAudioOutputStream.format = this.privFormat;
        this.privAudio = new Audio();
      }
    }
  }
  get volume() {
    var _a, _b;
    return (_b = (_a = this.privAudio) === null || _a === void 0 ? void 0 : _a.volume) !== null && _b !== void 0 ? _b : -1;
  }
  set volume(volume) {
    if (!!this.privAudio) {
      this.privAudio.volume = volume;
    }
  }
  mute() {
    if (!!this.privAudio) {
      this.privAudio.muted = true;
    }
  }
  unmute() {
    if (!!this.privAudio) {
      this.privAudio.muted = false;
    }
  }
  get isClosed() {
    return this.privIsClosed;
  }
  get currentTime() {
    if (this.privAudio !== undefined) {
      return this.privAudio.currentTime;
    }
    return -1;
  }
  pause() {
    if (!this.privIsPaused && this.privAudio !== undefined) {
      this.privAudio.pause();
      this.privIsPaused = true;
    }
  }
  resume(cb, err) {
    if (this.privIsPaused && this.privAudio !== undefined) {
      this.privAudio.play().then(() => {
        if (!!cb) {
          cb();
        }
      }, error => {
        if (!!err) {
          err(error);
        }
      });
      this.privIsPaused = false;
    }
  }
  get internalAudio() {
    return this.privAudio;
  }
  updateSourceBuffer() {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privAudioBuffer !== undefined && this.privAudioBuffer.length > 0 && this.sourceBufferAvailable()) {
        this.privAppendingToBuffer = true;
        const binary = this.privAudioBuffer.shift();
        try {
          this.privSourceBuffer.appendBuffer(binary);
        } catch (error) {
          this.privAudioBuffer.unshift(binary);
          // eslint-disable-next-line no-console
          console.log("buffer filled, pausing addition of binaries until space is made");
          return;
        }
        yield this.notifyPlayback();
      } else if (this.canEndStream()) {
        yield this.handleSourceBufferUpdateEnd();
      }
    });
  }
  handleSourceBufferUpdateEnd() {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.canEndStream() && this.sourceBufferAvailable()) {
        this.privMediaSource.endOfStream();
        yield this.notifyPlayback();
      }
    });
  }
  notifyPlayback() {
    return __awaiter(this, void 0, void 0, function* () {
      if (!this.privPlaybackStarted && this.privAudio !== undefined) {
        this.privPlaybackStarted = true;
        if (!!this.onAudioStart) {
          this.onAudioStart(this);
        }
        this.privAudio.onended = () => {
          if (!!this.onAudioEnd) {
            this.onAudioEnd(this);
          }
        };
        if (!this.privIsPaused) {
          yield this.privAudio.play();
        }
      }
    });
  }
  canEndStream() {
    return this.isClosed && this.privSourceBuffer !== undefined && this.privAudioBuffer.length === 0 && this.privMediaSourceOpened && !this.privAppendingToBuffer && this.privMediaSource.readyState === "open";
  }
  sourceBufferAvailable() {
    return this.privSourceBuffer !== undefined && !this.privSourceBuffer.updating;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AutoDetectSourceLanguageConfig: () => (/* binding */ AutoDetectSourceLanguageConfig)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _LanguageIdMode__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./LanguageIdMode */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.




/**
 * Language auto detect configuration.
 * @class AutoDetectSourceLanguageConfig
 * Added in version 1.13.0.
 */
class AutoDetectSourceLanguageConfig {
  constructor() {
    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_LanguageIdMode, "AtStart");
    this.privLanguageIdMode = _LanguageIdMode__WEBPACK_IMPORTED_MODULE_2__.LanguageIdMode.AtStart;
  }
  /**
   * @member AutoDetectSourceLanguageConfig.fromOpenRange
   * @function
   * @public
   * Only [[SpeechSynthesizer]] supports source language auto detection from open range,
   * for [[Recognizer]], please use AutoDetectSourceLanguageConfig with specific source languages.
   * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig
   * @summary Creates an instance of the AutoDetectSourceLanguageConfig with open range.
   */
  static fromOpenRange() {
    const config = new AutoDetectSourceLanguageConfig();
    config.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.AutoDetectSourceLanguagesOpenRangeOptionName);
    return config;
  }
  /**
   * @member AutoDetectSourceLanguageConfig.fromLanguages
   * @function
   * @public
   * @param {string[]} languages Comma-separated string of languages (eg. "en-US,fr-FR") to populate properties of config.
   * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig
   * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given languages.
   */
  static fromLanguages(languages) {
    _Contracts__WEBPACK_IMPORTED_MODULE_4__.Contracts.throwIfArrayEmptyOrWhitespace(languages, "languages");
    const config = new AutoDetectSourceLanguageConfig();
    config.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, languages.join());
    return config;
  }
  /**
   * @member AutoDetectSourceLanguageConfig.fromSourceLanguageConfigs
   * @function
   * @public
   * @param {SourceLanguageConfig[]} configs SourceLanguageConfigs to populate properties of config.
   * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig
   * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given SourceLanguageConfigs.
   */
  static fromSourceLanguageConfigs(configs) {
    if (configs.length < 1) {
      throw new Error("Expected non-empty SourceLanguageConfig array.");
    }
    const autoConfig = new AutoDetectSourceLanguageConfig();
    const langs = [];
    configs.forEach(config => {
      langs.push(config.language);
      if (config.endpointId !== undefined && config.endpointId !== "") {
        const customProperty = config.language + _Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId.toString();
        autoConfig.properties.setProperty(customProperty, config.endpointId);
      }
    });
    autoConfig.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, langs.join());
    return autoConfig;
  }
  /**
   * @member AutoDetectSourceLanguageConfig.prototype.properties
   * @function
   * @public
   * @return {PropertyCollection} Properties of the config.
   * @summary Gets an auto detected language config properties
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * @member AutoDetectSourceLanguageConfig.prototype.mode
   * @function
   * @public
   * @param {LanguageIdMode} mode LID mode desired.
   * @summary Sets LID operation to desired mode
   */
  set mode(mode) {
    if (mode === _LanguageIdMode__WEBPACK_IMPORTED_MODULE_2__.LanguageIdMode.Continuous) {
      this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, "2");
      this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_LanguageIdMode, "Continuous");
    } else {
      // LanguageIdMode.AtStart
      this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, "1");
      this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_LanguageIdMode, "AtStart");
    }
    this.privLanguageIdMode = mode;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AutoDetectSourceLanguageResult: () => (/* binding */ AutoDetectSourceLanguageResult)
/* harmony export */ });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Output format
 * @class AutoDetectSourceLanguageResult
 */
class AutoDetectSourceLanguageResult {
  constructor(language, languageDetectionConfidence) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(language, "language");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(languageDetectionConfidence, "languageDetectionConfidence");
    this.privLanguage = language;
    this.privLanguageDetectionConfidence = languageDetectionConfidence;
  }
  /**
   * Creates an instance of AutoDetectSourceLanguageResult object from a SpeechRecognitionResult instance.
   * @member AutoDetectSourceLanguageResult.fromResult
   * @function
   * @public
   * @param {SpeechRecognitionResult} result - The recognition result.
   * @returns {AutoDetectSourceLanguageResult} AutoDetectSourceLanguageResult object being created.
   */
  static fromResult(result) {
    return new AutoDetectSourceLanguageResult(result.language, result.languageDetectionConfidence);
  }
  get language() {
    return this.privLanguage;
  }
  get languageDetectionConfidence() {
    return this.privLanguageDetectionConfidence;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   BotFrameworkConfig: () => (/* binding */ BotFrameworkConfig)
/* harmony export */ });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./DialogServiceConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



/**
 * Class that defines configurations for the dialog service connector object for using a Bot Framework backend.
 * @class BotFrameworkConfig
 */
class BotFrameworkConfig extends _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl {
  /**
   * Creates an instance of BotFrameworkConfig.
   */
  constructor() {
    super();
  }
  /**
   * Creates a bot framework configuration instance with the provided subscription information.
   * @member BotFrameworkConfig.fromSubscription
   * @function
   * @public
   * @param subscription Subscription key associated with the bot
   * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the
   * resource name.
   * @returns {BotFrameworkConfig} A new bot framework configuration instance.
   */
  static fromSubscription(subscription, region, botId) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(subscription, "subscription");
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(region, "region");
    const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl();
    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfig.DialogTypes.BotFramework);
    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscription);
    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region, region);
    if (botId) {
      botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_ApplicationId, botId);
    }
    return botFrameworkConfig;
  }
  /**
   * Creates a bot framework configuration instance for the specified authorization token and region.
   * Note: The caller must ensure that an authorization token is valid. Before an authorization token expires, the
   * caller must refresh it by setting the authorizationToken property on the corresponding
   * DialogServiceConnector instance created with this config. The contents of configuration objects are copied
   * when connectors are created, so setting authorizationToken on a DialogServiceConnector will not update the
   * original configuration's authorization token. Create a new configuration instance or set the
   * SpeechServiceAuthorization_Token property to update an existing instance if it will be used to create
   * further DialogServiceConnectors.
   * @member BotFrameworkConfig.fromAuthorizationToken
   * @function
   * @public
   * @param authorizationToken The authorization token associated with the bot
   * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the
   * resource name.
   * @returns {BotFrameworkConfig} A new bot framework configuration instance.
   */
  static fromAuthorizationToken(authorizationToken, region, botId) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(authorizationToken, "authorizationToken");
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(region, "region");
    const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl();
    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfig.DialogTypes.BotFramework);
    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, authorizationToken);
    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region, region);
    if (botId) {
      botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_ApplicationId, botId);
    }
    return botFrameworkConfig;
  }
  /**
   * Creates an instance of a BotFrameworkConfig.
   * This method is intended only for users who use a non-default service host. The standard resource path will be
   * assumed. For services with a non-standard resource path or no path at all, use fromEndpoint instead.
   * Note: Query parameters are not allowed in the host URI and must be set by other APIs.
   * Note: To use an authorization token with fromHost, use fromHost(URL) and then set the AuthorizationToken
   * property on the created BotFrameworkConfig instance.
   * Note: Added in version 1.15.0.
   * @member BotFrameworkConfig.fromHost
   * @function
   * @public
   * @param {URL | string} host - If a URL is provided, the fully-qualified host with protocol (e.g.
   * wss://your.host.com:1234) will be used. If a string is provided, it will be embedded in
   * wss://{host}.convai.speech.azure.us.
   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization
   * token must be set.
   * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the
   * resource name.
   * @returns {BotFrameworkConfig} A new bot framework configuration instance.
   */
  static fromHost(host, subscriptionKey, botId) {
    void botId;
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(host, "host");
    const resolvedHost = host instanceof URL ? host : new URL(`wss://${host}.convai.speech.azure.us`);
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(resolvedHost, "resolvedHost");
    const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl();
    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfig.DialogTypes.BotFramework);
    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Host, resolvedHost.toString());
    if (undefined !== subscriptionKey) {
      botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    }
    return botFrameworkConfig;
  }
  /**
   * Creates an instance of a BotFrameworkConfig.
   * This method is intended only for users who use a non-standard service endpoint or parameters.
   * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.
   * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the
   * fromEndpoint method, and then set authorizationToken="token" on the created BotFrameworkConfig instance to
   * use the authorization token.
   * Note: Added in version 1.15.0.
   * @member BotFrameworkConfig.fromEndpoint
   * @function
   * @public
   * @param {URL} endpoint - The service endpoint to connect to.
   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization
   * token must be set.
   * @returns {BotFrameworkConfig} - A new bot framework configuration instance using the provided endpoint.
   */
  static fromEndpoint(endpoint, subscriptionKey) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(endpoint, "endpoint");
    const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl();
    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfig.DialogTypes.BotFramework);
    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Endpoint, endpoint.toString());
    if (undefined !== subscriptionKey) {
      botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    }
    return botFrameworkConfig;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CancellationDetails: () => (/* binding */ CancellationDetails)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CancellationDetailsBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



/**
 * Contains detailed information about why a result was canceled.
 * @class CancellationDetails
 */
class CancellationDetails extends _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_0__.CancellationDetailsBase {
  constructor(reason, errorDetails, errorCode) {
    super(reason, errorDetails, errorCode);
  }
  /**
   * Creates an instance of CancellationDetails object for the canceled RecognitionResult.
   * @member CancellationDetails.fromResult
   * @function
   * @public
   * @param {RecognitionResult | SpeechSynthesisResult} result - The result that was canceled.
   * @returns {CancellationDetails} The cancellation details object being created.
   */
  static fromResult(result) {
    let reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.CancellationReason.Error;
    let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode.NoError;
    if (result instanceof _Exports__WEBPACK_IMPORTED_MODULE_3__.RecognitionResult && !!result.json) {
      const simpleSpeech = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.SimpleSpeechPhrase.fromJSON(result.json);
      reason = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.EnumTranslation.implTranslateCancelResult(simpleSpeech.RecognitionStatus);
    }
    if (!!result.properties) {
      errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode[result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode.NoError])];
    }
    return new CancellationDetails(reason, result.errorDetails || _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.EnumTranslation.implTranslateErrorDetails(errorCode), errorCode);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CancellationDetailsBase: () => (/* binding */ CancellationDetailsBase)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Contains detailed information about why a result was canceled.
 * @class CancellationDetailsBase
 */
class CancellationDetailsBase {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {CancellationReason} reason - The cancellation reason.
   * @param {string} errorDetails - The error details, if provided.
   */
  constructor(reason, errorDetails, errorCode) {
    this.privReason = reason;
    this.privErrorDetails = errorDetails;
    this.privErrorCode = errorCode;
  }
  /**
   * The reason the recognition was canceled.
   * @member CancellationDetailsBase.prototype.reason
   * @function
   * @public
   * @returns {CancellationReason} Specifies the reason canceled.
   */
  get reason() {
    return this.privReason;
  }
  /**
   * In case of an unsuccessful recognition, provides details of the occurred error.
   * @member CancellationDetailsBase.prototype.errorDetails
   * @function
   * @public
   * @returns {string} A String that represents the error details.
   */
  get errorDetails() {
    return this.privErrorDetails;
  }
  /**
   * The error code in case of an unsuccessful recognition.
   * Added in version 1.1.0.
   * @return An error code that represents the error reason.
   */
  get ErrorCode() {
    return this.privErrorCode;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CancellationErrorCode: () => (/* binding */ CancellationErrorCode)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines error code in case that CancellationReason is Error.
 * Added in version 1.1.0.
 */
var CancellationErrorCode;
(function (CancellationErrorCode) {
  /**
   * Indicates that no error occurred during speech recognition.
   */
  CancellationErrorCode[CancellationErrorCode["NoError"] = 0] = "NoError";
  /**
   * Indicates an authentication error.
   */
  CancellationErrorCode[CancellationErrorCode["AuthenticationFailure"] = 1] = "AuthenticationFailure";
  /**
   * Indicates that one or more recognition parameters are invalid.
   */
  CancellationErrorCode[CancellationErrorCode["BadRequestParameters"] = 2] = "BadRequestParameters";
  /**
   * Indicates that the number of parallel requests exceeded the number of allowed
   * concurrent transcriptions for the subscription.
   */
  CancellationErrorCode[CancellationErrorCode["TooManyRequests"] = 3] = "TooManyRequests";
  /**
   * Indicates a connection error.
   */
  CancellationErrorCode[CancellationErrorCode["ConnectionFailure"] = 4] = "ConnectionFailure";
  /**
   * Indicates a time-out error when waiting for response from service.
   */
  CancellationErrorCode[CancellationErrorCode["ServiceTimeout"] = 5] = "ServiceTimeout";
  /**
   * Indicates that an error is returned by the service.
   */
  CancellationErrorCode[CancellationErrorCode["ServiceError"] = 6] = "ServiceError";
  /**
   * Indicates an unexpected runtime error.
   */
  CancellationErrorCode[CancellationErrorCode["RuntimeError"] = 7] = "RuntimeError";
  /**
   * Indicates an quota overrun on existing key.
   */
  CancellationErrorCode[CancellationErrorCode["Forbidden"] = 8] = "Forbidden";
})(CancellationErrorCode || (CancellationErrorCode = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CancellationEventArgsBase: () => (/* binding */ CancellationEventArgsBase)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Defines content of a CancellationEvent.
 * @class CancellationEventArgsBase
 */
class CancellationEventArgsBase extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {CancellationReason} reason - The cancellation reason.
   * @param {string} errorDetails - Error details, if provided.
   * @param {number} offset - The offset.
   * @param {string} sessionId - The session id.
   */
  constructor(reason, errorDetails, errorCode, offset, sessionId) {
    super(offset, sessionId);
    this.privReason = reason;
    this.privErrorDetails = errorDetails;
    this.privErrorCode = errorCode;
  }
  /**
   * The reason the recognition was canceled.
   * @member CancellationEventArgsBase.prototype.reason
   * @function
   * @public
   * @returns {CancellationReason} Specifies the reason canceled.
   */
  get reason() {
    return this.privReason;
  }
  /**
   * The error code in case of an unsuccessful operation.
   * @return An error code that represents the error reason.
   */
  get errorCode() {
    return this.privErrorCode;
  }
  /**
   * In case of an unsuccessful operation, provides details of the occurred error.
   * @member CancellationEventArgsBase.prototype.errorDetails
   * @function
   * @public
   * @returns {string} A String that represents the error details.
   */
  get errorDetails() {
    return this.privErrorDetails;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CancellationReason: () => (/* binding */ CancellationReason)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines the possible reasons a recognition result might be canceled.
 * @class CancellationReason
 */
var CancellationReason;
(function (CancellationReason) {
  /**
   * Indicates that an error occurred during speech recognition.
   * @member CancellationReason.Error
   */
  CancellationReason[CancellationReason["Error"] = 0] = "Error";
  /**
   * Indicates that the end of the audio stream was reached.
   * @member CancellationReason.EndOfStream
   */
  CancellationReason[CancellationReason["EndOfStream"] = 1] = "EndOfStream";
})(CancellationReason || (CancellationReason = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Connection: () => (/* binding */ Connection)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ConnectionMessage */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js");
//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//





/**
 * Connection is a proxy class for managing connection to the speech service of the specified Recognizer.
 * By default, a Recognizer autonomously manages connection to service when needed.
 * The Connection class provides additional methods for users to explicitly open or close a connection and
 * to subscribe to connection status changes.
 * The use of Connection is optional, and mainly for scenarios where fine tuning of application
 * behavior based on connection status is needed. Users can optionally call Open() to manually set up a connection
 * in advance before starting recognition on the Recognizer associated with this Connection.
 * If the Recognizer needs to connect or disconnect to service, it will
 * setup or shutdown the connection independently. In this case the Connection will be notified by change of connection
 * status via Connected/Disconnected events.
 * Added in version 1.2.1.
 */
class Connection {
  /**
   * Gets the Connection instance from the specified recognizer.
   * @param recognizer The recognizer associated with the connection.
   * @return The Connection instance of the recognizer.
   */
  static fromRecognizer(recognizer) {
    const recoBase = recognizer.internalData;
    const ret = new Connection();
    ret.privInternalData = recoBase;
    ret.setupEvents();
    return ret;
  }
  /**
   * Gets the Connection instance from the specified synthesizer.
   * @param synthesizer The synthesizer associated with the connection.
   * @return The Connection instance of the synthesizer.
   */
  static fromSynthesizer(synthesizer) {
    const synthBase = synthesizer.internalData;
    const ret = new Connection();
    ret.privInternalData = synthBase;
    ret.setupEvents();
    return ret;
  }
  /**
   * Starts to set up connection to the service.
   * Users can optionally call openConnection() to manually set up a connection in advance before starting recognition on the
   * Recognizer associated with this Connection. After starting recognition, calling Open() will have no effect
   *
   * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to
   * be notified when the connection is established.
   */
  openConnection(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.marshalPromiseToCallbacks)(this.privInternalData.connect(), cb, err);
  }
  /**
   * Closes the connection the service.
   * Users can optionally call closeConnection() to manually shutdown the connection of the associated Recognizer.
   *
   * If closeConnection() is called during recognition, recognition will fail and cancel with an error.
   */
  closeConnection(cb, err) {
    if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.SynthesisAdapterBase) {
      throw new Error("Disconnecting a synthesizer's connection is currently not supported");
    } else {
      (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.marshalPromiseToCallbacks)(this.privInternalData.disconnect(), cb, err);
    }
  }
  /**
   * Appends a parameter in a message to service.
   * Added in version 1.12.1.
   * @param path The path of the network message.
   * @param propertyName Name of the property
   * @param propertyValue Value of the property. This is a json string.
   */
  setMessageProperty(path, propertyName, propertyValue) {
    _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(propertyName, "propertyName");
    if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.ServiceRecognizerBase) {
      if (path.toLowerCase() !== "speech.context") {
        throw new Error("Only speech.context message property sets are currently supported for recognizer");
      } else {
        this.privInternalData.speechContext.setSection(propertyName, propertyValue);
      }
    } else if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.SynthesisAdapterBase) {
      if (path.toLowerCase() !== "synthesis.context") {
        throw new Error("Only synthesis.context message property sets are currently supported for synthesizer");
      } else {
        this.privInternalData.synthesisContext.setSection(propertyName, propertyValue);
      }
    }
  }
  /**
   * Sends a message to the speech service.
   * Added in version 1.13.0.
   * @param path The WebSocket path of the message
   * @param payload The payload of the message. This is a json string or a ArrayBuffer.
   * @param success A callback to indicate success.
   * @param error A callback to indicate an error.
   */
  sendMessageAsync(path, payload, success, error) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.marshalPromiseToCallbacks)(this.privInternalData.sendNetworkMessage(path, payload), success, error);
  }
  /**
   * Dispose of associated resources.
   */
  close() {
    /* eslint-disable no-empty */
  }
  setupEvents() {
    this.privEventListener = this.privInternalData.connectionEvents.attach(connectionEvent => {
      if (connectionEvent.name === "ConnectionEstablishedEvent") {
        if (!!this.connected) {
          this.connected(new _Exports__WEBPACK_IMPORTED_MODULE_4__.ConnectionEventArgs(connectionEvent.connectionId));
        }
      } else if (connectionEvent.name === "ConnectionClosedEvent") {
        if (!!this.disconnected) {
          this.disconnected(new _Exports__WEBPACK_IMPORTED_MODULE_4__.ConnectionEventArgs(connectionEvent.connectionId));
        }
      } else if (connectionEvent.name === "ConnectionMessageSentEvent") {
        if (!!this.messageSent) {
          this.messageSent(new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConnectionMessageEventArgs(new _ConnectionMessage__WEBPACK_IMPORTED_MODULE_6__.ConnectionMessageImpl(connectionEvent.message)));
        }
      } else if (connectionEvent.name === "ConnectionMessageReceivedEvent") {
        if (!!this.messageReceived) {
          this.messageReceived(new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConnectionMessageEventArgs(new _ConnectionMessage__WEBPACK_IMPORTED_MODULE_6__.ConnectionMessageImpl(connectionEvent.message)));
        }
      }
    });
    this.privServiceEventListener = this.privInternalData.serviceEvents.attach(e => {
      if (!!this.receivedServiceMessage) {
        this.receivedServiceMessage(new _Exports__WEBPACK_IMPORTED_MODULE_7__.ServiceEventArgs(e.jsonString, e.name));
      }
    });
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConnectionEventArgs: () => (/* binding */ ConnectionEventArgs)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js");
//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//

/**
 * Defines payload for connection events like Connected/Disconnected.
 * Added in version 1.2.0
 */
class ConnectionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConnectionMessage: () => (/* binding */ ConnectionMessage),
/* harmony export */   ConnectionMessageImpl: () => (/* binding */ ConnectionMessageImpl)
/* harmony export */ });
/* harmony import */ var _common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common.speech/HeaderNames */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js");
/* harmony import */ var _PropertyCollection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PropertyCollection */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _PropertyId__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./PropertyId */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
// eslint-disable-next-line max-classes-per-file




/**
 * ConnectionMessage represents implementation specific messages sent to and received from
 * the speech service. These messages are provided for debugging purposes and should not
 * be used for production use cases with the Azure Cognitive Services Speech Service.
 * Messages sent to and received from the Speech Service are subject to change without
 * notice. This includes message contents, headers, payloads, ordering, etc.
 * Added in version 1.11.0.
 */
class ConnectionMessage {}
class ConnectionMessageImpl {
  constructor(message) {
    this.privConnectionMessage = message;
    this.privProperties = new _PropertyCollection__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();
    if (!!this.privConnectionMessage.headers[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_1__.HeaderNames.ConnectionId]) {
      this.privProperties.setProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Speech_SessionId, this.privConnectionMessage.headers[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_1__.HeaderNames.ConnectionId]);
    }
    Object.keys(this.privConnectionMessage.headers).forEach(header => {
      this.privProperties.setProperty(header, this.privConnectionMessage.headers[header]);
    });
  }
  /**
   * The message path.
   */
  get path() {
    return this.privConnectionMessage.headers[Object.keys(this.privConnectionMessage.headers).find(key => key.toLowerCase() === "path".toLowerCase())];
  }
  /**
   * Checks to see if the ConnectionMessage is a text message.
   * See also IsBinaryMessage().
   */
  get isTextMessage() {
    return this.privConnectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_3__.MessageType.Text;
  }
  /**
   * Checks to see if the ConnectionMessage is a binary message.
   * See also GetBinaryMessage().
   */
  get isBinaryMessage() {
    return this.privConnectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_3__.MessageType.Binary;
  }
  /**
   * Gets the text message payload. Typically the text message content-type is
   * application/json. To determine other content-types use
   * Properties.GetProperty("Content-Type").
   */
  get TextMessage() {
    return this.privConnectionMessage.textBody;
  }
  /**
   * Gets the binary message payload.
   */
  get binaryMessage() {
    return this.privConnectionMessage.binaryBody;
  }
  /**
   * A collection of properties and their values defined for this <see cref="ConnectionMessage"/>.
   * Message headers can be accessed via this collection (e.g. "Content-Type").
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Returns a string that represents the connection message.
   */
  toString() {
    return "";
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConnectionMessageEventArgs: () => (/* binding */ ConnectionMessageEventArgs)
/* harmony export */ });
//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
class ConnectionMessageEventArgs {
  constructor(message) {
    this.privConnectionMessage = message;
  }
  /**
   * Gets the <see cref="ConnectionMessage"/> associated with this <see cref="ConnectionMessageEventArgs"/>.
   */
  get message() {
    return this.privConnectionMessage;
  }
  /**
   * Returns a string that represents the connection message event.
   */
  toString() {
    return "Message: " + this.privConnectionMessage.toString();
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Contracts: () => (/* binding */ Contracts)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * @class Contracts
 * @private
 */
class Contracts {
  static throwIfNullOrUndefined(param, name) {
    if (param === undefined || param === null) {
      throw new Error("throwIfNullOrUndefined:" + name);
    }
  }
  static throwIfNull(param, name) {
    if (param === null) {
      throw new Error("throwIfNull:" + name);
    }
  }
  static throwIfNullOrWhitespace(param, name) {
    Contracts.throwIfNullOrUndefined(param, name);
    if (("" + param).trim().length < 1) {
      throw new Error("throwIfNullOrWhitespace:" + name);
    }
  }
  static throwIfNullOrTooLong(param, name, maxLength) {
    Contracts.throwIfNullOrUndefined(param, name);
    if (("" + param).length > maxLength) {
      throw new Error("throwIfNullOrTooLong:" + name + " (more than " + maxLength.toString() + " characters)");
    }
  }
  static throwIfNullOrTooShort(param, name, minLength) {
    Contracts.throwIfNullOrUndefined(param, name);
    if (("" + param).length < minLength) {
      throw new Error("throwIfNullOrTooShort:" + name + " (less than " + minLength.toString() + " characters)");
    }
  }
  static throwIfDisposed(isDisposed) {
    if (isDisposed) {
      throw new Error("the object is already disposed");
    }
  }
  static throwIfArrayEmptyOrWhitespace(array, name) {
    Contracts.throwIfNullOrUndefined(array, name);
    if (array.length === 0) {
      throw new Error("throwIfArrayEmptyOrWhitespace:" + name);
    }
    for (const item of array) {
      Contracts.throwIfNullOrWhitespace(item, name);
    }
  }
  static throwIfFileDoesNotExist(param, name) {
    Contracts.throwIfNullOrWhitespace(param, name);
    // TODO check for file existence.
  }

  static throwIfNotUndefined(param, name) {
    if (param !== undefined) {
      throw new Error("throwIfNotUndefined:" + name);
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationTranscriptionCanceledEventArgs: () => (/* binding */ ConversationTranscriptionCanceledEventArgs)
/* harmony export */ });
/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CancellationEventArgsBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Defines content of a RecognitionErrorEvent.
 * @class ConversationTranscriptionCanceledEventArgs
 */
class ConversationTranscriptionCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__.CancellationEventArgsBase {}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CustomCommandsConfig: () => (/* binding */ CustomCommandsConfig)
/* harmony export */ });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./DialogServiceConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.



/**
 * Class that defines configurations for the dialog service connector object for using a CustomCommands backend.
 * @class CustomCommandsConfig
 */
class CustomCommandsConfig extends _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl {
  /**
   * Creates an instance of CustomCommandsConfig.
   */
  constructor() {
    super();
  }
  /**
   * Creates an instance of the bot framework config with the specified subscription and region.
   * @member CustomCommandsConfig.fromSubscription
   * @function
   * @public
   * @param applicationId Speech Commands application id.
   * @param subscription Subscription key associated with the bot
   * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {CustomCommandsConfig} A new bot framework config.
   */
  static fromSubscription(applicationId, subscription, region) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(applicationId, "applicationId");
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(subscription, "subscription");
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(region, "region");
    const customCommandsConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl();
    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfig.DialogTypes.CustomCommands);
    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_ApplicationId, applicationId);
    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscription);
    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region, region);
    return customCommandsConfig;
  }
  /**
   * Creates an instance of the bot framework config with the specified Speech Commands application id, authorization token and region.
   * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
   * expires, the caller needs to refresh it by calling this setter with a new valid token.
   * As configuration values are copied when creating a new recognizer, the new token value will not apply to recognizers that have already been created.
   * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
   * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
   * @member CustomCommandsConfig.fromAuthorizationToken
   * @function
   * @public
   * @param applicationId Speech Commands application id.
   * @param authorizationToken The authorization token associated with the application.
   * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {CustomCommandsConfig} A new speech commands config.
   */
  static fromAuthorizationToken(applicationId, authorizationToken, region) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(applicationId, "applicationId");
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(authorizationToken, "authorizationToken");
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(region, "region");
    const customCommandsConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl();
    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfig.DialogTypes.CustomCommands);
    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_ApplicationId, applicationId);
    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, authorizationToken);
    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region, region);
    return customCommandsConfig;
  }
  /**
   * Sets the corresponding backend application identifier.
   * @member CustomCommandsConfig.prototype.Conversation_ApplicationId
   * @function
   * @public
   * @param {string} value - The application identifier to set.
   */
  set applicationId(value) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(value, "value");
    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_ApplicationId, value);
  }
  /**
   * Gets the corresponding backend application identifier.
   * @member CustomCommandsConfig.prototype.Conversation_ApplicationId
   * @function
   * @public
   * @param {string} value - The application identifier to get.
   */
  get applicationId() {
    return this.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_ApplicationId);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Diagnostics.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Diagnostics.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Diagnostics: () => (/* binding */ Diagnostics)
/* harmony export */ });
/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js");
//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//


/**
 * Defines diagnostics API for managing console output
 * Added in version 1.21.0
 */
class Diagnostics {
  static SetLoggingLevel(logLevel) {
    this.privListener = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__.ConsoleLoggingListener(logLevel);
    _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Events.instance.attachConsoleListener(this.privListener);
  }
  static StartConsoleOutput() {
    if (!!this.privListener) {
      this.privListener.enableConsoleOutput = true;
    }
  }
  static StopConsoleOutput() {
    if (!!this.privListener) {
      this.privListener.enableConsoleOutput = false;
    }
  }
  static SetLogOutputPath(path) {
    if (typeof window === "undefined") {
      if (!!this.privListener) {
        this.privListener.logPath = path;
      }
    } else {
      throw new Error("File system logging not available in browser.");
    }
  }
}
Diagnostics.privListener = undefined;

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   DialogServiceConfig: () => (/* binding */ DialogServiceConfig),
/* harmony export */   DialogServiceConfigImpl: () => (/* binding */ DialogServiceConfigImpl)
/* harmony export */ });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */


/**
 * Class that defines base configurations for dialog service connector
 * @class DialogServiceConfig
 */
class DialogServiceConfig {
  /**
   * Creates an instance of DialogService config.
   * @constructor
   */
  constructor() {
    return;
  }
  /**
   * Sets the corresponding backend application identifier.
   * @member DialogServiceConfig.prototype.Conversation_ApplicationId
   * @function
   * @public
   * @param {string} value - The application identifier to set.
   */
  // eslint-disable-next-line @typescript-eslint/no-empty-function
  set applicationId(value) {}
  static get DialogTypes() {
    return {
      BotFramework: "bot_framework",
      CustomCommands: "custom_commands"
    };
  }
}
/**
 * Dialog Service configuration.
 * @class DialogServiceConfigImpl
 */
class DialogServiceConfigImpl extends DialogServiceConfig {
  /**
   * Creates an instance of dialogService config.
   */
  constructor() {
    super();
    this.privSpeechConfig = new _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechConfigImpl();
  }
  /**
   * Provides access to custom properties.
   * @member DialogServiceConfigImpl.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The properties.
   */
  get properties() {
    return this.privSpeechConfig.properties;
  }
  /**
   * Gets the speech recognition language.
   * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage
   * @function
   * @public
   */
  get speechRecognitionLanguage() {
    return this.privSpeechConfig.speechRecognitionLanguage;
  }
  /**
   * Sets the speech recognition language.
   * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @param {string} value - The language to set.
   */
  set speechRecognitionLanguage(value) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(value, "value");
    this.privSpeechConfig.speechRecognitionLanguage = value;
  }
  get outputFormat() {
    return this.privSpeechConfig.outputFormat;
  }
  set outputFormat(value) {
    this.privSpeechConfig.outputFormat = value;
  }
  /**
   * Sets a named property as value
   * @member DialogServiceConfigImpl.prototype.setProperty
   * @function
   * @public
   * @param {PropertyId | string} name - The property to set.
   * @param {string} value - The value.
   */
  setProperty(name, value) {
    this.privSpeechConfig.setProperty(name, value);
  }
  /**
   * Sets a named property as value
   * @member DialogServiceConfigImpl.prototype.getProperty
   * @function
   * @public
   * @param {PropertyId | string} name - The property to get.
   * @param {string} def - The default value to return in case the property is not known.
   * @returns {string} The current value, or provided default, of the given property.
   */
  getProperty(name, def) {
    void def;
    return this.privSpeechConfig.getProperty(name);
  }
  /**
   * Sets the proxy configuration.
   * Only relevant in Node.js environments.
   * Added in version 1.4.0.
   * @param proxyHostName The host name of the proxy server, without the protocol scheme (http://)
   * @param proxyPort The port number of the proxy server.
   * @param proxyUserName The user name of the proxy server.
   * @param proxyPassword The password of the proxy server.
   */
  setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyHostName, proxyHostName);
    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyPort, `${proxyPort}`);
    if (proxyUserName) {
      this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyUserName, proxyUserName);
    }
    if (proxyPassword) {
      this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyPassword, proxyPassword);
    }
  }
  setServiceProperty(name, value, channel) {
    void channel;
    this.privSpeechConfig.setServiceProperty(name, value);
  }
  /**
   * Dispose of associated resources.
   * @member DialogServiceConfigImpl.prototype.close
   * @function
   * @public
   */
  close() {
    return;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   DialogServiceConnector: () => (/* binding */ DialogServiceConnector)
/* harmony export */ });
/* harmony import */ var _common_speech_DialogConnectorFactory__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/DialogConnectorFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js");
/* harmony import */ var _PropertyId__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./PropertyId */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};






/**
 * Dialog Service Connector
 * @class DialogServiceConnector
 */
class DialogServiceConnector extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {
  /**
   * Initializes an instance of the DialogServiceConnector.
   * @constructor
   * @param {DialogServiceConfig} dialogConfig - Set of properties to configure this recognizer.
   * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer
   */
  constructor(dialogConfig, audioConfig) {
    const dialogServiceConfigImpl = dialogConfig;
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(dialogConfig, "dialogConfig");
    super(audioConfig, dialogServiceConfigImpl.properties, new _common_speech_DialogConnectorFactory__WEBPACK_IMPORTED_MODULE_2__.DialogConnectionFactory());
    this.isTurnComplete = true;
    this.privIsDisposed = false;
    this.privProperties = dialogServiceConfigImpl.properties.clone();
    const agentConfig = this.buildAgentConfig();
    this.privReco.agentConfig.set(agentConfig);
  }
  /**
   * Starts a connection to the service.
   * Users can optionally call connect() to manually set up a connection in advance, before starting interactions.
   *
   * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to
   * be notified when the connection is established.
   * @member DialogServiceConnector.prototype.connect
   * @function
   * @public
   */
  connect(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.privReco.connect(), cb, err);
  }
  /**
   * Closes the connection the service.
   * Users can optionally call disconnect() to manually shutdown the connection of the associated DialogServiceConnector.
   *
   * If disconnect() is called during a recognition, recognition will fail and cancel with an error.
   */
  disconnect(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.privReco.disconnect(), cb, err);
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member DialogServiceConnector.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Sets the authorization token used to communicate with the service.
   * @member DialogServiceConnector.prototype.authorizationToken
   * @function
   * @public
   * @param {string} token - Authorization token.
   */
  set authorizationToken(token) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceAuthorization_Token, token);
  }
  /**
   * The collection of properties and their values defined for this DialogServiceConnector.
   * @member DialogServiceConnector.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this DialogServiceConnector.
   */
  get properties() {
    return this.privProperties;
  }
  /** Gets the template for the activity generated by service from speech.
   * Properties from the template will be stamped on the generated activity.
   * It can be empty
   */
  get speechActivityTemplate() {
    return this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.Conversation_Speech_Activity_Template);
  }
  /** Sets the template for the activity generated by service from speech.
   * Properties from the template will be stamped on the generated activity.
   * It can be null or empty.
   * Note: it has to be a valid Json object.
   */
  set speechActivityTemplate(speechActivityTemplate) {
    this.properties.setProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.Conversation_Speech_Activity_Template, speechActivityTemplate);
  }
  /**
   * Starts recognition and stops after the first utterance is recognized.
   * @member DialogServiceConnector.prototype.listenOnceAsync
   * @function
   * @public
   * @param cb - Callback that received the result when the reco has completed.
   * @param err - Callback invoked in case of an error.
   */
  listenOnceAsync(cb, err) {
    if (this.isTurnComplete) {
      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privIsDisposed);
      const callbackHolder = () => __awaiter(this, void 0, void 0, function* () {
        yield this.privReco.connect();
        yield this.implRecognizerStop();
        this.isTurnComplete = false;
        const ret = new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.Deferred();
        yield this.privReco.recognize(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation, ret.resolve, ret.reject);
        const e = yield ret.promise;
        yield this.implRecognizerStop();
        return e;
      });
      const retPromise = callbackHolder();
      retPromise.catch(() => {
        // Destroy the recognizer.
        // We've done all we can here.
        // eslint-disable-next-line @typescript-eslint/no-empty-function
        this.dispose(true).catch(() => {});
      });
      (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(retPromise.finally(() => {
        this.isTurnComplete = true;
      }), cb, err);
    }
  }
  sendActivityAsync(activity, cb, errCb) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.privReco.sendMessage(activity), cb, errCb);
  }
  /**
   * closes all external resources held by an instance of this class.
   * @member DialogServiceConnector.prototype.close
   * @function
   * @public
   */
  close(cb, err) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privIsDisposed);
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.dispose(true), cb, err);
  }
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: {
        get: () => super.dispose
      }
    });
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privIsDisposed) {
        return;
      }
      if (disposing) {
        this.privIsDisposed = true;
        yield this.implRecognizerStop();
        yield _super.dispose.call(this, disposing);
      }
    });
  }
  createRecognizerConfig(speechConfig) {
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognizerConfig(speechConfig, this.privProperties);
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const audioSource = audioConfig;
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.DialogServiceAdapter(authentication, connectionFactory, audioSource, recognizerConfig, this);
  }
  buildAgentConfig() {
    const communicationType = this.properties.getProperty("Conversation_Communication_Type", "Default");
    return {
      botInfo: {
        commType: communicationType,
        commandsCulture: undefined,
        connectionId: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.Conversation_Agent_Connection_Id),
        conversationId: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.Conversation_Conversation_Id, undefined),
        fromId: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.Conversation_From_Id, undefined),
        ttsAudioFormat: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)
      },
      version: 0.2
    };
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ActivityReceivedEventArgs: () => (/* reexport safe */ _ActivityReceivedEventArgs__WEBPACK_IMPORTED_MODULE_48__.ActivityReceivedEventArgs),
/* harmony export */   AudioConfig: () => (/* reexport safe */ _Audio_AudioConfig__WEBPACK_IMPORTED_MODULE_0__.AudioConfig),
/* harmony export */   AudioFormatTag: () => (/* reexport safe */ _Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__.AudioFormatTag),
/* harmony export */   AudioInputStream: () => (/* reexport safe */ _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__.AudioInputStream),
/* harmony export */   AudioOutputStream: () => (/* reexport safe */ _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__.AudioOutputStream),
/* harmony export */   AudioStreamFormat: () => (/* reexport safe */ _Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__.AudioStreamFormat),
/* harmony export */   AutoDetectSourceLanguageConfig: () => (/* reexport safe */ _AutoDetectSourceLanguageConfig__WEBPACK_IMPORTED_MODULE_63__.AutoDetectSourceLanguageConfig),
/* harmony export */   AutoDetectSourceLanguageResult: () => (/* reexport safe */ _AutoDetectSourceLanguageResult__WEBPACK_IMPORTED_MODULE_64__.AutoDetectSourceLanguageResult),
/* harmony export */   BaseAudioPlayer: () => (/* reexport safe */ _Audio_BaseAudioPlayer__WEBPACK_IMPORTED_MODULE_52__.BaseAudioPlayer),
/* harmony export */   BotFrameworkConfig: () => (/* reexport safe */ _BotFrameworkConfig__WEBPACK_IMPORTED_MODULE_45__.BotFrameworkConfig),
/* harmony export */   CancellationDetails: () => (/* reexport safe */ _CancellationDetails__WEBPACK_IMPORTED_MODULE_38__.CancellationDetails),
/* harmony export */   CancellationDetailsBase: () => (/* reexport safe */ _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_37__.CancellationDetailsBase),
/* harmony export */   CancellationErrorCode: () => (/* reexport safe */ _CancellationErrorCodes__WEBPACK_IMPORTED_MODULE_39__.CancellationErrorCode),
/* harmony export */   CancellationReason: () => (/* reexport safe */ _CancellationReason__WEBPACK_IMPORTED_MODULE_4__.CancellationReason),
/* harmony export */   Connection: () => (/* reexport safe */ _Connection__WEBPACK_IMPORTED_MODULE_42__.Connection),
/* harmony export */   ConnectionEventArgs: () => (/* reexport safe */ _ConnectionEventArgs__WEBPACK_IMPORTED_MODULE_40__.ConnectionEventArgs),
/* harmony export */   ConnectionMessage: () => (/* reexport safe */ _ConnectionMessage__WEBPACK_IMPORTED_MODULE_54__.ConnectionMessage),
/* harmony export */   ConnectionMessageEventArgs: () => (/* reexport safe */ _ConnectionMessageEventArgs__WEBPACK_IMPORTED_MODULE_53__.ConnectionMessageEventArgs),
/* harmony export */   Conversation: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__.Conversation),
/* harmony export */   ConversationExpirationEventArgs: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_68__.ConversationExpirationEventArgs),
/* harmony export */   ConversationParticipantsChangedEventArgs: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_69__.ConversationParticipantsChangedEventArgs),
/* harmony export */   ConversationTranscriber: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_74__.ConversationTranscriber),
/* harmony export */   ConversationTranscriptionCanceledEventArgs: () => (/* reexport safe */ _ConversationTranscriptionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_89__.ConversationTranscriptionCanceledEventArgs),
/* harmony export */   ConversationTranscriptionEventArgs: () => (/* reexport safe */ _SpeechRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_16__.ConversationTranscriptionEventArgs),
/* harmony export */   ConversationTranslationCanceledEventArgs: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_70__.ConversationTranslationCanceledEventArgs),
/* harmony export */   ConversationTranslationEventArgs: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_71__.ConversationTranslationEventArgs),
/* harmony export */   ConversationTranslationResult: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_72__.ConversationTranslationResult),
/* harmony export */   ConversationTranslator: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_73__.ConversationTranslator),
/* harmony export */   CustomCommandsConfig: () => (/* reexport safe */ _CustomCommandsConfig__WEBPACK_IMPORTED_MODULE_46__.CustomCommandsConfig),
/* harmony export */   Diagnostics: () => (/* reexport safe */ _Diagnostics__WEBPACK_IMPORTED_MODULE_95__.Diagnostics),
/* harmony export */   DialogServiceConfig: () => (/* reexport safe */ _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_44__.DialogServiceConfig),
/* harmony export */   DialogServiceConnector: () => (/* reexport safe */ _DialogServiceConnector__WEBPACK_IMPORTED_MODULE_47__.DialogServiceConnector),
/* harmony export */   IntentRecognitionCanceledEventArgs: () => (/* reexport safe */ _IntentRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_36__.IntentRecognitionCanceledEventArgs),
/* harmony export */   IntentRecognitionEventArgs: () => (/* reexport safe */ _IntentRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_11__.IntentRecognitionEventArgs),
/* harmony export */   IntentRecognitionResult: () => (/* reexport safe */ _IntentRecognitionResult__WEBPACK_IMPORTED_MODULE_14__.IntentRecognitionResult),
/* harmony export */   IntentRecognizer: () => (/* reexport safe */ _IntentRecognizer__WEBPACK_IMPORTED_MODULE_29__.IntentRecognizer),
/* harmony export */   KeywordRecognitionModel: () => (/* reexport safe */ _KeywordRecognitionModel__WEBPACK_IMPORTED_MODULE_7__.KeywordRecognitionModel),
/* harmony export */   LanguageIdMode: () => (/* reexport safe */ _LanguageIdMode__WEBPACK_IMPORTED_MODULE_94__.LanguageIdMode),
/* harmony export */   LanguageUnderstandingModel: () => (/* reexport safe */ _LanguageUnderstandingModel__WEBPACK_IMPORTED_MODULE_15__.LanguageUnderstandingModel),
/* harmony export */   LogLevel: () => (/* reexport safe */ _LogLevel__WEBPACK_IMPORTED_MODULE_96__.EventType),
/* harmony export */   NoMatchDetails: () => (/* reexport safe */ _NoMatchDetails__WEBPACK_IMPORTED_MODULE_34__.NoMatchDetails),
/* harmony export */   NoMatchReason: () => (/* reexport safe */ _NoMatchReason__WEBPACK_IMPORTED_MODULE_33__.NoMatchReason),
/* harmony export */   OutputFormat: () => (/* reexport safe */ _OutputFormat__WEBPACK_IMPORTED_MODULE_10__.OutputFormat),
/* harmony export */   Participant: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_75__.Participant),
/* harmony export */   ParticipantChangedReason: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_76__.ParticipantChangedReason),
/* harmony export */   PhraseListGrammar: () => (/* reexport safe */ _PhraseListGrammar__WEBPACK_IMPORTED_MODULE_43__.PhraseListGrammar),
/* harmony export */   ProfanityOption: () => (/* reexport safe */ _ProfanityOption__WEBPACK_IMPORTED_MODULE_51__.ProfanityOption),
/* harmony export */   PronunciationAssessmentConfig: () => (/* reexport safe */ _PronunciationAssessmentConfig__WEBPACK_IMPORTED_MODULE_92__.PronunciationAssessmentConfig),
/* harmony export */   PronunciationAssessmentGradingSystem: () => (/* reexport safe */ _PronunciationAssessmentGradingSystem__WEBPACK_IMPORTED_MODULE_90__.PronunciationAssessmentGradingSystem),
/* harmony export */   PronunciationAssessmentGranularity: () => (/* reexport safe */ _PronunciationAssessmentGranularity__WEBPACK_IMPORTED_MODULE_91__.PronunciationAssessmentGranularity),
/* harmony export */   PronunciationAssessmentResult: () => (/* reexport safe */ _PronunciationAssessmentResult__WEBPACK_IMPORTED_MODULE_93__.PronunciationAssessmentResult),
/* harmony export */   PropertyCollection: () => (/* reexport safe */ _PropertyCollection__WEBPACK_IMPORTED_MODULE_25__.PropertyCollection),
/* harmony export */   PropertyId: () => (/* reexport safe */ _PropertyId__WEBPACK_IMPORTED_MODULE_26__.PropertyId),
/* harmony export */   PullAudioInputStream: () => (/* reexport safe */ _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__.PullAudioInputStream),
/* harmony export */   PullAudioInputStreamCallback: () => (/* reexport safe */ _Audio_PullAudioInputStreamCallback__WEBPACK_IMPORTED_MODULE_5__.PullAudioInputStreamCallback),
/* harmony export */   PullAudioOutputStream: () => (/* reexport safe */ _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__.PullAudioOutputStream),
/* harmony export */   PushAudioInputStream: () => (/* reexport safe */ _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__.PushAudioInputStream),
/* harmony export */   PushAudioOutputStream: () => (/* reexport safe */ _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__.PushAudioOutputStream),
/* harmony export */   PushAudioOutputStreamCallback: () => (/* reexport safe */ _Audio_PushAudioOutputStreamCallback__WEBPACK_IMPORTED_MODULE_6__.PushAudioOutputStreamCallback),
/* harmony export */   RecognitionEventArgs: () => (/* reexport safe */ _RecognitionEventArgs__WEBPACK_IMPORTED_MODULE_9__.RecognitionEventArgs),
/* harmony export */   RecognitionResult: () => (/* reexport safe */ _RecognitionResult__WEBPACK_IMPORTED_MODULE_12__.RecognitionResult),
/* harmony export */   Recognizer: () => (/* reexport safe */ _Recognizer__WEBPACK_IMPORTED_MODULE_27__.Recognizer),
/* harmony export */   ResultReason: () => (/* reexport safe */ _ResultReason__WEBPACK_IMPORTED_MODULE_22__.ResultReason),
/* harmony export */   ServiceEventArgs: () => (/* reexport safe */ _ServiceEventArgs__WEBPACK_IMPORTED_MODULE_41__.ServiceEventArgs),
/* harmony export */   ServicePropertyChannel: () => (/* reexport safe */ _ServicePropertyChannel__WEBPACK_IMPORTED_MODULE_50__.ServicePropertyChannel),
/* harmony export */   SessionEventArgs: () => (/* reexport safe */ _SessionEventArgs__WEBPACK_IMPORTED_MODULE_8__.SessionEventArgs),
/* harmony export */   SourceLanguageConfig: () => (/* reexport safe */ _SourceLanguageConfig__WEBPACK_IMPORTED_MODULE_65__.SourceLanguageConfig),
/* harmony export */   SpeakerAudioDestination: () => (/* reexport safe */ _Audio_SpeakerAudioDestination__WEBPACK_IMPORTED_MODULE_88__.SpeakerAudioDestination),
/* harmony export */   SpeakerIdentificationModel: () => (/* reexport safe */ _SpeakerIdentificationModel__WEBPACK_IMPORTED_MODULE_61__.SpeakerIdentificationModel),
/* harmony export */   SpeakerRecognitionCancellationDetails: () => (/* reexport safe */ _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__.SpeakerRecognitionCancellationDetails),
/* harmony export */   SpeakerRecognitionResult: () => (/* reexport safe */ _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__.SpeakerRecognitionResult),
/* harmony export */   SpeakerRecognitionResultType: () => (/* reexport safe */ _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__.SpeakerRecognitionResultType),
/* harmony export */   SpeakerRecognizer: () => (/* reexport safe */ _SpeakerRecognizer__WEBPACK_IMPORTED_MODULE_60__.SpeakerRecognizer),
/* harmony export */   SpeakerVerificationModel: () => (/* reexport safe */ _SpeakerVerificationModel__WEBPACK_IMPORTED_MODULE_62__.SpeakerVerificationModel),
/* harmony export */   SpeechConfig: () => (/* reexport safe */ _SpeechConfig__WEBPACK_IMPORTED_MODULE_23__.SpeechConfig),
/* harmony export */   SpeechConfigImpl: () => (/* reexport safe */ _SpeechConfig__WEBPACK_IMPORTED_MODULE_23__.SpeechConfigImpl),
/* harmony export */   SpeechRecognitionCanceledEventArgs: () => (/* reexport safe */ _SpeechRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_17__.SpeechRecognitionCanceledEventArgs),
/* harmony export */   SpeechRecognitionEventArgs: () => (/* reexport safe */ _SpeechRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_16__.SpeechRecognitionEventArgs),
/* harmony export */   SpeechRecognitionResult: () => (/* reexport safe */ _SpeechRecognitionResult__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult),
/* harmony export */   SpeechRecognizer: () => (/* reexport safe */ _SpeechRecognizer__WEBPACK_IMPORTED_MODULE_28__.SpeechRecognizer),
/* harmony export */   SpeechSynthesisBookmarkEventArgs: () => (/* reexport safe */ _SpeechSynthesisBookmarkEventArgs__WEBPACK_IMPORTED_MODULE_83__.SpeechSynthesisBookmarkEventArgs),
/* harmony export */   SpeechSynthesisBoundaryType: () => (/* reexport safe */ _SpeechSynthesisBoundaryType__WEBPACK_IMPORTED_MODULE_85__.SpeechSynthesisBoundaryType),
/* harmony export */   SpeechSynthesisEventArgs: () => (/* reexport safe */ _SpeechSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_81__.SpeechSynthesisEventArgs),
/* harmony export */   SpeechSynthesisOutputFormat: () => (/* reexport safe */ _SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_77__.SpeechSynthesisOutputFormat),
/* harmony export */   SpeechSynthesisResult: () => (/* reexport safe */ _SpeechSynthesisResult__WEBPACK_IMPORTED_MODULE_80__.SpeechSynthesisResult),
/* harmony export */   SpeechSynthesisVisemeEventArgs: () => (/* reexport safe */ _SpeechSynthesisVisemeEventArgs__WEBPACK_IMPORTED_MODULE_84__.SpeechSynthesisVisemeEventArgs),
/* harmony export */   SpeechSynthesisWordBoundaryEventArgs: () => (/* reexport safe */ _SpeechSynthesisWordBoundaryEventArgs__WEBPACK_IMPORTED_MODULE_82__.SpeechSynthesisWordBoundaryEventArgs),
/* harmony export */   SpeechSynthesizer: () => (/* reexport safe */ _SpeechSynthesizer__WEBPACK_IMPORTED_MODULE_78__.SpeechSynthesizer),
/* harmony export */   SpeechTranslationConfig: () => (/* reexport safe */ _SpeechTranslationConfig__WEBPACK_IMPORTED_MODULE_24__.SpeechTranslationConfig),
/* harmony export */   SpeechTranslationConfigImpl: () => (/* reexport safe */ _SpeechTranslationConfig__WEBPACK_IMPORTED_MODULE_24__.SpeechTranslationConfigImpl),
/* harmony export */   SynthesisResult: () => (/* reexport safe */ _SynthesisResult__WEBPACK_IMPORTED_MODULE_79__.SynthesisResult),
/* harmony export */   SynthesisVoicesResult: () => (/* reexport safe */ _SynthesisVoicesResult__WEBPACK_IMPORTED_MODULE_86__.SynthesisVoicesResult),
/* harmony export */   TranslationRecognitionCanceledEventArgs: () => (/* reexport safe */ _TranslationRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_35__.TranslationRecognitionCanceledEventArgs),
/* harmony export */   TranslationRecognitionEventArgs: () => (/* reexport safe */ _TranslationRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_18__.TranslationRecognitionEventArgs),
/* harmony export */   TranslationRecognitionResult: () => (/* reexport safe */ _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_20__.TranslationRecognitionResult),
/* harmony export */   TranslationRecognizer: () => (/* reexport safe */ _TranslationRecognizer__WEBPACK_IMPORTED_MODULE_31__.TranslationRecognizer),
/* harmony export */   TranslationSynthesisEventArgs: () => (/* reexport safe */ _TranslationSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_19__.TranslationSynthesisEventArgs),
/* harmony export */   TranslationSynthesisResult: () => (/* reexport safe */ _TranslationSynthesisResult__WEBPACK_IMPORTED_MODULE_21__.TranslationSynthesisResult),
/* harmony export */   Translations: () => (/* reexport safe */ _Translations__WEBPACK_IMPORTED_MODULE_32__.Translations),
/* harmony export */   TurnStatusReceivedEventArgs: () => (/* reexport safe */ _TurnStatusReceivedEventArgs__WEBPACK_IMPORTED_MODULE_49__.TurnStatusReceivedEventArgs),
/* harmony export */   User: () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_75__.User),
/* harmony export */   VoiceInfo: () => (/* reexport safe */ _VoiceInfo__WEBPACK_IMPORTED_MODULE_87__.VoiceInfo),
/* harmony export */   VoiceProfile: () => (/* reexport safe */ _VoiceProfile__WEBPACK_IMPORTED_MODULE_55__.VoiceProfile),
/* harmony export */   VoiceProfileCancellationDetails: () => (/* reexport safe */ _VoiceProfileResult__WEBPACK_IMPORTED_MODULE_57__.VoiceProfileCancellationDetails),
/* harmony export */   VoiceProfileClient: () => (/* reexport safe */ _VoiceProfileClient__WEBPACK_IMPORTED_MODULE_59__.VoiceProfileClient),
/* harmony export */   VoiceProfileEnrollmentCancellationDetails: () => (/* reexport safe */ _VoiceProfileEnrollmentResult__WEBPACK_IMPORTED_MODULE_56__.VoiceProfileEnrollmentCancellationDetails),
/* harmony export */   VoiceProfileEnrollmentResult: () => (/* reexport safe */ _VoiceProfileEnrollmentResult__WEBPACK_IMPORTED_MODULE_56__.VoiceProfileEnrollmentResult),
/* harmony export */   VoiceProfilePhraseResult: () => (/* reexport safe */ _VoiceProfilePhraseResult__WEBPACK_IMPORTED_MODULE_58__.VoiceProfilePhraseResult),
/* harmony export */   VoiceProfileResult: () => (/* reexport safe */ _VoiceProfileResult__WEBPACK_IMPORTED_MODULE_57__.VoiceProfileResult),
/* harmony export */   VoiceProfileType: () => (/* reexport safe */ _VoiceProfileType__WEBPACK_IMPORTED_MODULE_30__.VoiceProfileType)
/* harmony export */ });
/* harmony import */ var _Audio_AudioConfig__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Audio/AudioConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js");
/* harmony import */ var _Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Audio/AudioStreamFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js");
/* harmony import */ var _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Audio/AudioInputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js");
/* harmony import */ var _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Audio/AudioOutputStream */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js");
/* harmony import */ var _CancellationReason__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./CancellationReason */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
/* harmony import */ var _Audio_PullAudioInputStreamCallback__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Audio/PullAudioInputStreamCallback */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js");
/* harmony import */ var _Audio_PushAudioOutputStreamCallback__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Audio/PushAudioOutputStreamCallback */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js");
/* harmony import */ var _KeywordRecognitionModel__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./KeywordRecognitionModel */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js");
/* harmony import */ var _SessionEventArgs__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./SessionEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js");
/* harmony import */ var _RecognitionEventArgs__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./RecognitionEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js");
/* harmony import */ var _OutputFormat__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./OutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js");
/* harmony import */ var _IntentRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./IntentRecognitionEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js");
/* harmony import */ var _RecognitionResult__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./RecognitionResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js");
/* harmony import */ var _SpeechRecognitionResult__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./SpeechRecognitionResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js");
/* harmony import */ var _IntentRecognitionResult__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./IntentRecognitionResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js");
/* harmony import */ var _LanguageUnderstandingModel__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./LanguageUnderstandingModel */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js");
/* harmony import */ var _SpeechRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./SpeechRecognitionEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js");
/* harmony import */ var _SpeechRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./SpeechRecognitionCanceledEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js");
/* harmony import */ var _TranslationRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./TranslationRecognitionEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js");
/* harmony import */ var _TranslationSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./TranslationSynthesisEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js");
/* harmony import */ var _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./TranslationRecognitionResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js");
/* harmony import */ var _TranslationSynthesisResult__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./TranslationSynthesisResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js");
/* harmony import */ var _ResultReason__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./ResultReason */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _SpeechConfig__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./SpeechConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js");
/* harmony import */ var _SpeechTranslationConfig__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./SpeechTranslationConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js");
/* harmony import */ var _PropertyCollection__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./PropertyCollection */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _PropertyId__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./PropertyId */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _Recognizer__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./Recognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js");
/* harmony import */ var _SpeechRecognizer__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./SpeechRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js");
/* harmony import */ var _IntentRecognizer__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./IntentRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js");
/* harmony import */ var _VoiceProfileType__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./VoiceProfileType */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js");
/* harmony import */ var _TranslationRecognizer__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./TranslationRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js");
/* harmony import */ var _Translations__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./Translations */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js");
/* harmony import */ var _NoMatchReason__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./NoMatchReason */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js");
/* harmony import */ var _NoMatchDetails__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./NoMatchDetails */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js");
/* harmony import */ var _TranslationRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./TranslationRecognitionCanceledEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js");
/* harmony import */ var _IntentRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./IntentRecognitionCanceledEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js");
/* harmony import */ var _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./CancellationDetailsBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js");
/* harmony import */ var _CancellationDetails__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./CancellationDetails */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js");
/* harmony import */ var _CancellationErrorCodes__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./CancellationErrorCodes */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _ConnectionEventArgs__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./ConnectionEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js");
/* harmony import */ var _ServiceEventArgs__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./ServiceEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js");
/* harmony import */ var _Connection__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./Connection */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js");
/* harmony import */ var _PhraseListGrammar__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./PhraseListGrammar */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js");
/* harmony import */ var _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./DialogServiceConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js");
/* harmony import */ var _BotFrameworkConfig__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./BotFrameworkConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js");
/* harmony import */ var _CustomCommandsConfig__WEBPACK_IMPORTED_MODULE_46__ = __webpack_require__(/*! ./CustomCommandsConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js");
/* harmony import */ var _DialogServiceConnector__WEBPACK_IMPORTED_MODULE_47__ = __webpack_require__(/*! ./DialogServiceConnector */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js");
/* harmony import */ var _ActivityReceivedEventArgs__WEBPACK_IMPORTED_MODULE_48__ = __webpack_require__(/*! ./ActivityReceivedEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js");
/* harmony import */ var _TurnStatusReceivedEventArgs__WEBPACK_IMPORTED_MODULE_49__ = __webpack_require__(/*! ./TurnStatusReceivedEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js");
/* harmony import */ var _ServicePropertyChannel__WEBPACK_IMPORTED_MODULE_50__ = __webpack_require__(/*! ./ServicePropertyChannel */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js");
/* harmony import */ var _ProfanityOption__WEBPACK_IMPORTED_MODULE_51__ = __webpack_require__(/*! ./ProfanityOption */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js");
/* harmony import */ var _Audio_BaseAudioPlayer__WEBPACK_IMPORTED_MODULE_52__ = __webpack_require__(/*! ./Audio/BaseAudioPlayer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js");
/* harmony import */ var _ConnectionMessageEventArgs__WEBPACK_IMPORTED_MODULE_53__ = __webpack_require__(/*! ./ConnectionMessageEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js");
/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_54__ = __webpack_require__(/*! ./ConnectionMessage */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js");
/* harmony import */ var _VoiceProfile__WEBPACK_IMPORTED_MODULE_55__ = __webpack_require__(/*! ./VoiceProfile */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js");
/* harmony import */ var _VoiceProfileEnrollmentResult__WEBPACK_IMPORTED_MODULE_56__ = __webpack_require__(/*! ./VoiceProfileEnrollmentResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js");
/* harmony import */ var _VoiceProfileResult__WEBPACK_IMPORTED_MODULE_57__ = __webpack_require__(/*! ./VoiceProfileResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js");
/* harmony import */ var _VoiceProfilePhraseResult__WEBPACK_IMPORTED_MODULE_58__ = __webpack_require__(/*! ./VoiceProfilePhraseResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js");
/* harmony import */ var _VoiceProfileClient__WEBPACK_IMPORTED_MODULE_59__ = __webpack_require__(/*! ./VoiceProfileClient */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js");
/* harmony import */ var _SpeakerRecognizer__WEBPACK_IMPORTED_MODULE_60__ = __webpack_require__(/*! ./SpeakerRecognizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js");
/* harmony import */ var _SpeakerIdentificationModel__WEBPACK_IMPORTED_MODULE_61__ = __webpack_require__(/*! ./SpeakerIdentificationModel */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js");
/* harmony import */ var _SpeakerVerificationModel__WEBPACK_IMPORTED_MODULE_62__ = __webpack_require__(/*! ./SpeakerVerificationModel */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js");
/* harmony import */ var _AutoDetectSourceLanguageConfig__WEBPACK_IMPORTED_MODULE_63__ = __webpack_require__(/*! ./AutoDetectSourceLanguageConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js");
/* harmony import */ var _AutoDetectSourceLanguageResult__WEBPACK_IMPORTED_MODULE_64__ = __webpack_require__(/*! ./AutoDetectSourceLanguageResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js");
/* harmony import */ var _SourceLanguageConfig__WEBPACK_IMPORTED_MODULE_65__ = __webpack_require__(/*! ./SourceLanguageConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js");
/* harmony import */ var _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__ = __webpack_require__(/*! ./SpeakerRecognitionResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js");
/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__ = __webpack_require__(/*! ./Transcription/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js");
/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_68__ = __webpack_require__(/*! ./Transcription/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js");
/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_69__ = __webpack_require__(/*! ./Transcription/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js");
/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_70__ = __webpack_require__(/*! ./Transcription/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js");
/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_71__ = __webpack_require__(/*! ./Transcription/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js");
/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_72__ = __webpack_require__(/*! ./Transcription/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js");
/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_73__ = __webpack_require__(/*! ./Transcription/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js");
/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_74__ = __webpack_require__(/*! ./Transcription/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js");
/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_75__ = __webpack_require__(/*! ./Transcription/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js");
/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_76__ = __webpack_require__(/*! ./Transcription/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js");
/* harmony import */ var _SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_77__ = __webpack_require__(/*! ./SpeechSynthesisOutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js");
/* harmony import */ var _SpeechSynthesizer__WEBPACK_IMPORTED_MODULE_78__ = __webpack_require__(/*! ./SpeechSynthesizer */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js");
/* harmony import */ var _SynthesisResult__WEBPACK_IMPORTED_MODULE_79__ = __webpack_require__(/*! ./SynthesisResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js");
/* harmony import */ var _SpeechSynthesisResult__WEBPACK_IMPORTED_MODULE_80__ = __webpack_require__(/*! ./SpeechSynthesisResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js");
/* harmony import */ var _SpeechSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_81__ = __webpack_require__(/*! ./SpeechSynthesisEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js");
/* harmony import */ var _SpeechSynthesisWordBoundaryEventArgs__WEBPACK_IMPORTED_MODULE_82__ = __webpack_require__(/*! ./SpeechSynthesisWordBoundaryEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js");
/* harmony import */ var _SpeechSynthesisBookmarkEventArgs__WEBPACK_IMPORTED_MODULE_83__ = __webpack_require__(/*! ./SpeechSynthesisBookmarkEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js");
/* harmony import */ var _SpeechSynthesisVisemeEventArgs__WEBPACK_IMPORTED_MODULE_84__ = __webpack_require__(/*! ./SpeechSynthesisVisemeEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js");
/* harmony import */ var _SpeechSynthesisBoundaryType__WEBPACK_IMPORTED_MODULE_85__ = __webpack_require__(/*! ./SpeechSynthesisBoundaryType */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBoundaryType.js");
/* harmony import */ var _SynthesisVoicesResult__WEBPACK_IMPORTED_MODULE_86__ = __webpack_require__(/*! ./SynthesisVoicesResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js");
/* harmony import */ var _VoiceInfo__WEBPACK_IMPORTED_MODULE_87__ = __webpack_require__(/*! ./VoiceInfo */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js");
/* harmony import */ var _Audio_SpeakerAudioDestination__WEBPACK_IMPORTED_MODULE_88__ = __webpack_require__(/*! ./Audio/SpeakerAudioDestination */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js");
/* harmony import */ var _ConversationTranscriptionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_89__ = __webpack_require__(/*! ./ConversationTranscriptionCanceledEventArgs */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js");
/* harmony import */ var _PronunciationAssessmentGradingSystem__WEBPACK_IMPORTED_MODULE_90__ = __webpack_require__(/*! ./PronunciationAssessmentGradingSystem */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js");
/* harmony import */ var _PronunciationAssessmentGranularity__WEBPACK_IMPORTED_MODULE_91__ = __webpack_require__(/*! ./PronunciationAssessmentGranularity */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js");
/* harmony import */ var _PronunciationAssessmentConfig__WEBPACK_IMPORTED_MODULE_92__ = __webpack_require__(/*! ./PronunciationAssessmentConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js");
/* harmony import */ var _PronunciationAssessmentResult__WEBPACK_IMPORTED_MODULE_93__ = __webpack_require__(/*! ./PronunciationAssessmentResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js");
/* harmony import */ var _LanguageIdMode__WEBPACK_IMPORTED_MODULE_94__ = __webpack_require__(/*! ./LanguageIdMode */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js");
/* harmony import */ var _Diagnostics__WEBPACK_IMPORTED_MODULE_95__ = __webpack_require__(/*! ./Diagnostics */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Diagnostics.js");
/* harmony import */ var _LogLevel__WEBPACK_IMPORTED_MODULE_96__ = __webpack_require__(/*! ./LogLevel */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

























































































/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   IntentRecognitionCanceledEventArgs: () => (/* binding */ IntentRecognitionCanceledEventArgs)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Define payload of intent recognition canceled result events.
 * @class IntentRecognitionCanceledEventArgs
 */
class IntentRecognitionCanceledEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.IntentRecognitionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {CancellationReason} result - The result of the intent recognition.
   * @param {string} offset - The offset.
   * @param {IntentRecognitionResult} sessionId - The session id.
   */
  constructor(reason, errorDetails, errorCode, result, offset, sessionId) {
    super(result, offset, sessionId);
    this.privReason = reason;
    this.privErrorDetails = errorDetails;
    this.privErrorCode = errorCode;
  }
  /**
   * The reason the recognition was canceled.
   * @member IntentRecognitionCanceledEventArgs.prototype.reason
   * @function
   * @public
   * @returns {CancellationReason} Specifies the reason canceled.
   */
  get reason() {
    return this.privReason;
  }
  /**
   * The error code in case of an unsuccessful recognition.
   * Added in version 1.1.0.
   * @return An error code that represents the error reason.
   */
  get errorCode() {
    return this.privErrorCode;
  }
  /**
   * In case of an unsuccessful recognition, provides details of the occurred error.
   * @member IntentRecognitionCanceledEventArgs.prototype.errorDetails
   * @function
   * @public
   * @returns {string} A String that represents the error details.
   */
  get errorDetails() {
    return this.privErrorDetails;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   IntentRecognitionEventArgs: () => (/* binding */ IntentRecognitionEventArgs)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Intent recognition result event arguments.
 * @class
 */
class IntentRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param result - The result of the intent recognition.
   * @param offset - The offset.
   * @param sessionId - The session id.
   */
  constructor(result, offset, sessionId) {
    super(offset, sessionId);
    this.privResult = result;
  }
  /**
   * Represents the intent recognition result.
   * @member IntentRecognitionEventArgs.prototype.result
   * @function
   * @public
   * @returns {IntentRecognitionResult} Represents the intent recognition result.
   */
  get result() {
    return this.privResult;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   IntentRecognitionResult: () => (/* binding */ IntentRecognitionResult)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Intent recognition result.
 * @class
 */
class IntentRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechRecognitionResult {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param intentId - The intent id.
   * @param resultId - The result id.
   * @param reason - The reason.
   * @param text - The recognized text.
   * @param duration - The duration.
   * @param offset - The offset into the stream.
   * @param language - Primary Language detected, if provided.
   * @param languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
   * @param errorDetails - Error details, if provided.
   * @param json - Additional Json, if provided.
   * @param properties - Additional properties, if provided.
   */
  constructor(intentId, resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {
    super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, undefined, errorDetails, json, properties);
    this.privIntentId = intentId;
  }
  /**
   * A String that represents the intent identifier being recognized.
   * @member IntentRecognitionResult.prototype.intentId
   * @function
   * @public
   * @returns {string} A String that represents the intent identifier being recognized.
   */
  get intentId() {
    return this.privIntentId;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   IntentRecognizer: () => (/* binding */ IntentRecognizer)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};




/**
 * Intent recognizer.
 * @class
 */
class IntentRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {
  /**
   * Initializes an instance of the IntentRecognizer.
   * @constructor
   * @param {SpeechConfig} speechConfig - The set of configuration properties.
   * @param {AudioConfig} audioConfig - An optional audio input config associated with the recognizer
   */
  constructor(speechConfig, audioConfig) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(speechConfig, "speechConfig");
    const configImpl = speechConfig;
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(configImpl, "speechConfig");
    super(audioConfig, configImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.IntentConnectionFactory());
    this.privAddedIntents = [];
    this.privAddedLmIntents = {};
    this.privDisposedIntentRecognizer = false;
    this.privProperties = configImpl.properties;
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage), _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage]);
  }
  /**
   * Gets the spoken language of recognition.
   * @member IntentRecognizer.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @returns {string} the spoken language of recognition.
   */
  get speechRecognitionLanguage() {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage);
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member IntentRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * Note: Please use a token derived from your LanguageUnderstanding subscription key for the Intent recognizer.
   * @member IntentRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @param {string} value - Authorization token.
   */
  set authorizationToken(value) {
    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceAuthorization_Token, value);
  }
  /**
   * The collection of properties and their values defined for this IntentRecognizer.
   * @member IntentRecognizer.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their
   * values defined for this IntentRecognizer.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Starts intent recognition, and stops after the first utterance is recognized.
   * The task returns the recognition text and intent as result.
   * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,
   * so it is suitable only for single shot recognition like command or query.
   * For long-running recognition, use StartContinuousRecognitionAsync() instead.
   * @member IntentRecognizer.prototype.recognizeOnceAsync
   * @function
   * @public
   * @param cb - Callback that received the recognition has finished with an IntentRecognitionResult.
   * @param err - Callback invoked in case of an error.
   */
  recognizeOnceAsync(cb, err) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);
    if (Object.keys(this.privAddedLmIntents).length !== 0 || undefined !== this.privUmbrellaIntent) {
      const context = this.buildSpeechContext();
      this.privReco.speechContext.setSection("intent", context.Intent);
      this.privReco.dynamicGrammar.addReferenceGrammar(context.ReferenceGrammars);
      const intentReco = this.privReco;
      intentReco.setIntents(this.privAddedLmIntents, this.privUmbrellaIntent);
    }
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.recognizeOnceAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Interactive), cb, err);
  }
  /**
   * Starts speech recognition, until stopContinuousRecognitionAsync() is called.
   * User must subscribe to events to receive recognition results.
   * @member IntentRecognizer.prototype.startContinuousRecognitionAsync
   * @function
   * @public
   * @param cb - Callback invoked once the recognition has started.
   * @param err - Callback invoked in case of an error.
   */
  startContinuousRecognitionAsync(cb, err) {
    if (Object.keys(this.privAddedLmIntents).length !== 0 || undefined !== this.privUmbrellaIntent) {
      const context = this.buildSpeechContext();
      this.privReco.speechContext.setSection("intent", context.Intent);
      this.privReco.dynamicGrammar.addReferenceGrammar(context.ReferenceGrammars);
      const intentReco = this.privReco;
      intentReco.setIntents(this.privAddedLmIntents, this.privUmbrellaIntent);
    }
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation), cb, err);
  }
  /**
   * Stops continuous intent recognition.
   * @member IntentRecognizer.prototype.stopContinuousRecognitionAsync
   * @function
   * @public
   * @param cb - Callback invoked once the recognition has stopped.
   * @param err - Callback invoked in case of an error.
   */
  stopContinuousRecognitionAsync(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);
  }
  /**
   * Starts speech recognition with keyword spotting, until stopKeywordRecognitionAsync() is called.
   * User must subscribe to events to receive recognition results.
   * Note: Key word spotting functionality is only available on the Speech Devices SDK.
   * This functionality is currently not included in the SDK itself.
   * @member IntentRecognizer.prototype.startKeywordRecognitionAsync
   * @function
   * @public
   * @param {KeywordRecognitionModel} model - The keyword recognition model that specifies the keyword to be recognized.
   * @param cb - Callback invoked once the recognition has started.
   * @param err - Callback invoked in case of an error.
   */
  startKeywordRecognitionAsync(model, cb, err) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(model, "model");
    if (!!err) {
      err("Not yet implemented.");
    }
  }
  /**
   * Stops continuous speech recognition.
   * Note: Key word spotting functionality is only available on the Speech Devices SDK.
   * This functionality is currently not included in the SDK itself.
   * @member IntentRecognizer.prototype.stopKeywordRecognitionAsync
   * @function
   * @public
   * @param cb - Callback invoked once the recognition has stopped.
   * @param err - Callback invoked in case of an error.
   */
  stopKeywordRecognitionAsync(cb, err) {
    if (!!cb) {
      try {
        cb();
      } catch (e) {
        if (!!err) {
          err(e);
        }
      }
    }
  }
  /**
   * Adds a phrase that should be recognized as intent.
   * @member IntentRecognizer.prototype.addIntent
   * @function
   * @public
   * @param {string} intentId - A String that represents the identifier of the intent to be recognized.
   * @param {string} phrase - A String that specifies the phrase representing the intent.
   */
  addIntent(simplePhrase, intentId) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(intentId, "intentId");
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(simplePhrase, "simplePhrase");
    this.privAddedIntents.push([intentId, simplePhrase]);
  }
  /**
   * Adds an intent from Language Understanding service for recognition.
   * @member IntentRecognizer.prototype.addIntentWithLanguageModel
   * @function
   * @public
   * @param {string} intentId - A String that represents the identifier of the intent
   * to be recognized. Ignored if intentName is empty.
   * @param {string} model - The intent model from Language Understanding service.
   * @param {string} intentName - The intent name defined in the intent model. If it
   * is empty, all intent names defined in the model will be added.
   */
  addIntentWithLanguageModel(intentId, model, intentName) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(intentId, "intentId");
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(model, "model");
    const modelImpl = model;
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(modelImpl.appId, "model.appId");
    this.privAddedLmIntents[intentId] = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.AddedLmIntent(modelImpl, intentName);
  }
  /**
   * @summary Adds all intents from the specified Language Understanding Model.
   * @member IntentRecognizer.prototype.addAllIntents
   * @function
   * @public
   * @function
   * @public
   * @param {LanguageUnderstandingModel} model - The language understanding model containing the intents.
   * @param {string} intentId - A custom id String to be returned in the IntentRecognitionResult's getIntentId() method.
   */
  addAllIntents(model, intentId) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(model, "model");
    const modelImpl = model;
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(modelImpl.appId, "model.appId");
    this.privUmbrellaIntent = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.AddedLmIntent(modelImpl, intentId);
  }
  /**
   * closes all external resources held by an instance of this class.
   * @member IntentRecognizer.prototype.close
   * @function
   * @public
   */
  close(cb, errorCb) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);
  }
  createRecognizerConfig(speechConfig) {
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognizerConfig(speechConfig, this.privProperties);
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const audioImpl = audioConfig;
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentServiceRecognizer(authentication, connectionFactory, audioImpl, recognizerConfig, this);
  }
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: {
        get: () => super.dispose
      }
    });
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privDisposedIntentRecognizer) {
        return;
      }
      if (disposing) {
        this.privDisposedIntentRecognizer = true;
        yield _super.dispose.call(this, disposing);
      }
    });
  }
  buildSpeechContext() {
    let appId;
    let region;
    let subscriptionKey;
    const refGrammers = [];
    if (undefined !== this.privUmbrellaIntent) {
      appId = this.privUmbrellaIntent.modelImpl.appId;
      region = this.privUmbrellaIntent.modelImpl.region;
      subscriptionKey = this.privUmbrellaIntent.modelImpl.subscriptionKey;
    }
    // Build the reference grammer array.
    for (const intentId of Object.keys(this.privAddedLmIntents)) {
      const addedLmIntent = this.privAddedLmIntents[intentId];
      // validate all the same model, region, and key...
      if (appId === undefined) {
        appId = addedLmIntent.modelImpl.appId;
      } else {
        if (appId !== addedLmIntent.modelImpl.appId) {
          throw new Error("Intents must all be from the same LUIS model");
        }
      }
      if (region === undefined) {
        region = addedLmIntent.modelImpl.region;
      } else {
        if (region !== addedLmIntent.modelImpl.region) {
          throw new Error("Intents must all be from the same LUIS model in a single region");
        }
      }
      if (subscriptionKey === undefined) {
        subscriptionKey = addedLmIntent.modelImpl.subscriptionKey;
      } else {
        if (subscriptionKey !== addedLmIntent.modelImpl.subscriptionKey) {
          throw new Error("Intents must all use the same subscription key");
        }
      }
      const grammer = "luis/" + appId + "-PRODUCTION#" + intentId;
      refGrammers.push(grammer);
    }
    return {
      Intent: {
        id: appId,
        key: subscriptionKey === undefined ? this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_Key]) : subscriptionKey,
        provider: "LUIS"
      },
      ReferenceGrammars: undefined === this.privUmbrellaIntent ? refGrammers : ["luis/" + appId + "-PRODUCTION"]
    };
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   KeywordRecognitionModel: () => (/* binding */ KeywordRecognitionModel)
/* harmony export */ });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Represents a keyword recognition model for recognizing when
 * the user says a keyword to initiate further speech recognition.
 * @class KeywordRecognitionModel
 */
class KeywordRecognitionModel {
  /**
   * Create and initializes a new instance.
   * @constructor
   */
  constructor() {
    this.privDisposed = false;
    return;
  }
  /**
   * Creates a keyword recognition model using the specified filename.
   * @member KeywordRecognitionModel.fromFile
   * @function
   * @public
   * @param {string} fileName - A string that represents file name for the keyword recognition model.
   * Note, the file can point to a zip file in which case the model
   * will be extracted from the zip.
   * @returns {KeywordRecognitionModel} The keyword recognition model being created.
   */
  static fromFile(fileName) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfFileDoesNotExist(fileName, "fileName");
    throw new Error("Not yet implemented.");
  }
  /**
   * Creates a keyword recognition model using the specified filename.
   * @member KeywordRecognitionModel.fromStream
   * @function
   * @public
   * @param {string} file - A File that represents file for the keyword recognition model.
   * Note, the file can point to a zip file in which case the model will be extracted from the zip.
   * @returns {KeywordRecognitionModel} The keyword recognition model being created.
   */
  static fromStream(file) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(file, "file");
    throw new Error("Not yet implemented.");
  }
  /**
   * Dispose of associated resources.
   * @member KeywordRecognitionModel.prototype.close
   * @function
   * @public
   */
  close() {
    if (this.privDisposed) {
      return;
    }
    this.privDisposed = true;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   LanguageIdMode: () => (/* binding */ LanguageIdMode)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Language Identification mode
 * @class LanguageIdMode
 */
var LanguageIdMode;
(function (LanguageIdMode) {
  /**
   * Detect language at audio start
   * @member LanguageIdMode.AtStart
   */
  LanguageIdMode[LanguageIdMode["AtStart"] = 0] = "AtStart";
  /**
   * Continuously detect language
   * @member LanguageIdMode.Continuous
   */
  LanguageIdMode[LanguageIdMode["Continuous"] = 1] = "Continuous";
})(LanguageIdMode || (LanguageIdMode = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   LanguageUnderstandingModel: () => (/* binding */ LanguageUnderstandingModel),
/* harmony export */   LanguageUnderstandingModelImpl: () => (/* binding */ LanguageUnderstandingModelImpl)
/* harmony export */ });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// eslint-disable-next-line max-classes-per-file

/**
 * Language understanding model
 * @class LanguageUnderstandingModel
 */
class LanguageUnderstandingModel {
  /**
   * Creates and initializes a new instance
   * @constructor
   */
  constructor() {
    return;
  }
  /**
   * Creates an language understanding model using the specified endpoint.
   * @member LanguageUnderstandingModel.fromEndpoint
   * @function
   * @public
   * @param {URL} uri - A String that represents the endpoint of the language understanding model.
   * @returns {LanguageUnderstandingModel} The language understanding model being created.
   */
  static fromEndpoint(uri) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(uri, "uri");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(uri.hostname, "uri");
    const langModelImp = new LanguageUnderstandingModelImpl();
    // Need to extract the app ID from the URL.
    // URL is in the format: https://<region>.api.cognitive.microsoft.com/luis/v2.0/apps/<Guid>?subscription-key=<key>&timezoneOffset=-360
    // Start tearing the string apart.
    // region can be extracted from the host name.
    const firstDot = uri.host.indexOf(".");
    if (-1 === firstDot) {
      throw new Error("Could not determine region from endpoint");
    }
    langModelImp.region = uri.host.substr(0, firstDot);
    // Now the app ID.
    const lastSegment = uri.pathname.lastIndexOf("/") + 1;
    if (-1 === lastSegment) {
      throw new Error("Could not determine appId from endpoint");
    }
    langModelImp.appId = uri.pathname.substr(lastSegment);
    // And finally the key.
    langModelImp.subscriptionKey = uri.searchParams.get("subscription-key");
    if (undefined === langModelImp.subscriptionKey) {
      throw new Error("Could not determine subscription key from endpoint");
    }
    return langModelImp;
  }
  /**
   * Creates an language understanding model using the application id of Language Understanding service.
   * @member LanguageUnderstandingModel.fromAppId
   * @function
   * @public
   * @param {string} appId - A String that represents the application id of Language Understanding service.
   * @returns {LanguageUnderstandingModel} The language understanding model being created.
   */
  static fromAppId(appId) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(appId, "appId");
    const langModelImp = new LanguageUnderstandingModelImpl();
    langModelImp.appId = appId;
    return langModelImp;
  }
  /**
   * Creates a language understanding model using hostname, subscription key and application
   * id of Language Understanding service.
   * @member LanguageUnderstandingModel.fromSubscription
   * @function
   * @public
   * @param {string} subscriptionKey - A String that represents the subscription key of
   * Language Understanding service.
   * @param {string} appId - A String that represents the application id of Language
   * Understanding service.
   * @param {LanguageUnderstandingModel} region - A String that represents the region
   * of the Language Understanding service (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {LanguageUnderstandingModel} The language understanding model being created.
   */
  static fromSubscription(subscriptionKey, appId, region) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(subscriptionKey, "subscriptionKey");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(appId, "appId");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(region, "region");
    const langModelImp = new LanguageUnderstandingModelImpl();
    langModelImp.appId = appId;
    langModelImp.region = region;
    langModelImp.subscriptionKey = subscriptionKey;
    return langModelImp;
  }
}
/**
 * @private
 * @class LanguageUnderstandingModelImpl
 */
class LanguageUnderstandingModelImpl extends LanguageUnderstandingModel {}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   NoMatchDetails: () => (/* binding */ NoMatchDetails)
/* harmony export */ });
/* harmony import */ var _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../src/common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js");
/* harmony import */ var _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../src/common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Contains detailed information for NoMatch recognition results.
 * @class NoMatchDetails
 */
class NoMatchDetails {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {NoMatchReason} reason - The no-match reason.
   */
  constructor(reason) {
    this.privReason = reason;
  }
  /**
   * Creates an instance of NoMatchDetails object for the NoMatch SpeechRecognitionResults.
   * @member NoMatchDetails.fromResult
   * @function
   * @public
   * @param {SpeechRecognitionResult | IntentRecognitionResult | TranslationRecognitionResult}
   * result - The recognition result that was not recognized.
   * @returns {NoMatchDetails} The no match details object being created.
   */
  static fromResult(result) {
    const simpleSpeech = _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__.SimpleSpeechPhrase.fromJSON(result.json);
    let reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.NoMatchReason.NotRecognized;
    switch (simpleSpeech.RecognitionStatus) {
      case _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionStatus.BabbleTimeout:
        reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.NoMatchReason.InitialBabbleTimeout;
        break;
      case _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionStatus.InitialSilenceTimeout:
        reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.NoMatchReason.InitialSilenceTimeout;
        break;
      default:
        reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.NoMatchReason.NotRecognized;
        break;
    }
    return new NoMatchDetails(reason);
  }
  /**
   * The reason the recognition was canceled.
   * @member NoMatchDetails.prototype.reason
   * @function
   * @public
   * @returns {NoMatchReason} Specifies the reason canceled.
   */
  get reason() {
    return this.privReason;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   NoMatchReason: () => (/* binding */ NoMatchReason)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines the possible reasons a recognition result might not be recognized.
 * @class NoMatchReason
 */
var NoMatchReason;
(function (NoMatchReason) {
  /**
   * Indicates that speech was detected, but not recognized.
   * @member NoMatchReason.NotRecognized
   */
  NoMatchReason[NoMatchReason["NotRecognized"] = 0] = "NotRecognized";
  /**
   * Indicates that the start of the audio stream contained only silence,
   * and the service timed out waiting for speech.
   * @member NoMatchReason.InitialSilenceTimeout
   */
  NoMatchReason[NoMatchReason["InitialSilenceTimeout"] = 1] = "InitialSilenceTimeout";
  /**
   * Indicates that the start of the audio stream contained only noise,
   * and the service timed out waiting for speech.
   * @member NoMatchReason.InitialBabbleTimeout
   */
  NoMatchReason[NoMatchReason["InitialBabbleTimeout"] = 2] = "InitialBabbleTimeout";
})(NoMatchReason || (NoMatchReason = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   OutputFormat: () => (/* binding */ OutputFormat)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Define Speech Recognizer output formats.
 * @class OutputFormat
 */
var OutputFormat;
(function (OutputFormat) {
  /**
   * @member OutputFormat.Simple
   */
  OutputFormat[OutputFormat["Simple"] = 0] = "Simple";
  /**
   * @member OutputFormat.Detailed
   */
  OutputFormat[OutputFormat["Detailed"] = 1] = "Detailed";
})(OutputFormat || (OutputFormat = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   PhraseListGrammar: () => (/* binding */ PhraseListGrammar)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Allows additions of new phrases to improve speech recognition.
 *
 * Phrases added to the recognizer are effective at the start of the next recognition, or the next time the SpeechSDK must reconnect
 * to the speech service.
 */
class PhraseListGrammar {
  constructor(recogBase) {
    this.privGrammerBuilder = recogBase.dynamicGrammar;
  }
  /**
   * Creates a PhraseListGrammar from a given speech recognizer. Will accept any recognizer that derives from @class Recognizer.
   * @param recognizer The recognizer to add phrase lists to.
   */
  static fromRecognizer(recognizer) {
    const recoBase = recognizer.internalData;
    return new PhraseListGrammar(recoBase);
  }
  /**
   * Adds a single phrase to the current recognizer.
   * @param phrase Phrase to add.
   */
  addPhrase(phrase) {
    this.privGrammerBuilder.addPhrase(phrase);
  }
  /**
   * Adds multiple phrases to the current recognizer.
   * @param phrases Array of phrases to add.
   */
  addPhrases(phrases) {
    this.privGrammerBuilder.addPhrase(phrases);
  }
  /**
   * Clears all phrases added to the current recognizer.
   */
  clear() {
    this.privGrammerBuilder.clearPhrases();
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ProfanityOption: () => (/* binding */ ProfanityOption)
/* harmony export */ });
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Profanity option.
 * Added in version 1.7.0.
 */
var ProfanityOption;
(function (ProfanityOption) {
  ProfanityOption[ProfanityOption["Masked"] = 0] = "Masked";
  ProfanityOption[ProfanityOption["Removed"] = 1] = "Removed";
  ProfanityOption[ProfanityOption["Raw"] = 2] = "Raw";
})(ProfanityOption || (ProfanityOption = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   PronunciationAssessmentConfig: () => (/* binding */ PronunciationAssessmentConfig)
/* harmony export */ });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Pronunciation assessment configuration.
 * @class PronunciationAssessmentConfig
 * Added in version 1.15.0.
 */
class PronunciationAssessmentConfig {
  /**
   * PronunciationAssessmentConfig constructor.
   * @constructor
   * @param {string} referenceText
   * @param gradingSystem
   * @param granularity
   * @param enableMiscue
   */
  constructor(referenceText, gradingSystem = _Exports__WEBPACK_IMPORTED_MODULE_0__.PronunciationAssessmentGradingSystem.FivePoint, granularity = _Exports__WEBPACK_IMPORTED_MODULE_1__.PronunciationAssessmentGranularity.Phoneme, enableMiscue = false) {
    _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(referenceText, "referenceText");
    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyCollection();
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_ReferenceText, referenceText);
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_GradingSystem, _Exports__WEBPACK_IMPORTED_MODULE_0__.PronunciationAssessmentGradingSystem[gradingSystem]);
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Granularity, _Exports__WEBPACK_IMPORTED_MODULE_1__.PronunciationAssessmentGranularity[granularity]);
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_EnableMiscue, String(enableMiscue));
  }
  /**
   * @member PronunciationAssessmentConfig.fromJSON
   * @function
   * @public
   * @param {string} json The json string containing the pronunciation assessment parameters.
   * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig
   * @summary Creates an instance of the PronunciationAssessmentConfig from json.
   */
  static fromJSON(json) {
    _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(json, "json");
    const config = new PronunciationAssessmentConfig("");
    config.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyCollection();
    config.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Json, json);
    return config;
  }
  toJSON() {
    this.updateJson();
    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Params);
  }
  applyTo(recognizer) {
    this.updateJson();
    const recoBase = recognizer.internalData;
    recoBase.speechContext.setPronunciationAssessmentParams(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Params));
  }
  /**
   * Gets the reference text.
   * @member PronunciationAssessmentConfig.prototype.referenceText
   * @function
   * @public
   * @returns {string} Reference text.
   */
  get referenceText() {
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_ReferenceText);
  }
  /**
   * Gets/Sets the reference text.
   * @member PronunciationAssessmentConfig.prototype.referenceText
   * @function
   * @public
   * @param {string} referenceText - Reference text.
   */
  set referenceText(referenceText) {
    _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(referenceText, "referenceText");
    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_ReferenceText, referenceText);
  }
  /**
   * Sets the phoneme alphabet.
   * The valid values are "SAPI" (default) and "IPA".
   * Added in version 1.20.0
   * @member PronunciationAssessmentConfig.prototype.phonemeAlphabet
   * @function
   * @public
   * @param {string} phonemeAlphabet - Phoneme alphabet.
   */
  set phonemeAlphabet(phonemeAlphabet) {
    _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(phonemeAlphabet, "phonemeAlphabet");
    this.privPhonemeAlphabet = phonemeAlphabet;
  }
  /**
   * Sets the boolean enableMiscue property.
   * Added in version 1.26.0
   * @member PronunciationAssessmentConfig.prototype.enableMiscue
   * @function
   * @public
   * @param {boolean} enableMiscue - enable miscue.
   */
  set enableMiscue(enableMiscue) {
    const enableMiscueString = enableMiscue ? "true" : "false";
    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_EnableMiscue, enableMiscueString);
  }
  /**
   * Gets the boolean enableMiscue property.
   * Added in version 1.26.0
   * @member PronunciationAssessmentConfig.prototype.enableMiscue
   * @function
   * @public
   * @return {boolean} enableMiscue - enable miscue.
   */
  get enableMiscue() {
    const enableMiscueString = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_EnableMiscue, "false");
    return enableMiscueString.toLowerCase() === "true";
  }
  /**
   * Sets the nbest phoneme count
   * Added in version 1.20.0
   * @member PronunciationAssessmentConfig.prototype.nbestPhonemeCount
   * @function
   * @public
   * @param {number} nbestPhonemeCount - NBest phoneme count.
   */
  set nbestPhonemeCount(nbestPhonemeCount) {
    this.privNBestPhonemeCount = nbestPhonemeCount;
  }
  /**
   * @member PronunciationAssessmentConfig.prototype.properties
   * @function
   * @public
   * @return {PropertyCollection} Properties of the config.
   * @summary Gets a pronunciation assessment config properties
   */
  get properties() {
    return this.privProperties;
  }
  updateJson() {
    const jsonString = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Json, "{}");
    const paramsJson = JSON.parse(jsonString);
    const referenceText = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_ReferenceText);
    if (referenceText) {
      paramsJson.referenceText = referenceText;
    }
    const gradingSystem = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_GradingSystem);
    if (gradingSystem) {
      paramsJson.gradingSystem = gradingSystem;
    }
    const granularity = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Granularity);
    if (granularity) {
      paramsJson.granularity = granularity;
    }
    if (this.privPhonemeAlphabet) {
      paramsJson.phonemeAlphabet = this.privPhonemeAlphabet;
    }
    if (this.privNBestPhonemeCount) {
      paramsJson.nbestPhonemeCount = this.privNBestPhonemeCount;
    }
    // always set dimension to Comprehensive
    paramsJson.dimension = "Comprehensive";
    paramsJson.enableMiscue = this.enableMiscue;
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Params, JSON.stringify(paramsJson));
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   PronunciationAssessmentGradingSystem: () => (/* binding */ PronunciationAssessmentGradingSystem)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines the point system for pronunciation score calibration; default value is FivePoint.
 * Added in version 1.15.0
 * @class PronunciationAssessmentGradingSystem
 */
var PronunciationAssessmentGradingSystem;
(function (PronunciationAssessmentGradingSystem) {
  /**
   * Five point calibration
   * @member PronunciationAssessmentGradingSystem.FivePoint
   */
  PronunciationAssessmentGradingSystem[PronunciationAssessmentGradingSystem["FivePoint"] = 1] = "FivePoint";
  /**
   * Hundred mark
   * @member PronunciationAssessmentGradingSystem.HundredMark
   */
  PronunciationAssessmentGradingSystem[PronunciationAssessmentGradingSystem["HundredMark"] = 2] = "HundredMark";
})(PronunciationAssessmentGradingSystem || (PronunciationAssessmentGradingSystem = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   PronunciationAssessmentGranularity: () => (/* binding */ PronunciationAssessmentGranularity)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines the pronunciation evaluation granularity; default value is Phoneme.
 * Added in version 1.15.0
 * @class PronunciationAssessmentGranularity
 */
var PronunciationAssessmentGranularity;
(function (PronunciationAssessmentGranularity) {
  /**
   * Shows the score on the full text, word and phoneme level
   * @member PronunciationAssessmentGranularity.Phoneme
   */
  PronunciationAssessmentGranularity[PronunciationAssessmentGranularity["Phoneme"] = 1] = "Phoneme";
  /**
   * Shows the score on the full text and word level
   * @member PronunciationAssessmentGranularity.Word
   */
  PronunciationAssessmentGranularity[PronunciationAssessmentGranularity["Word"] = 2] = "Word";
  /**
   * Shows the score on the full text level only
   * @member PronunciationAssessmentGranularity.FullText
   */
  PronunciationAssessmentGranularity[PronunciationAssessmentGranularity["FullText"] = 3] = "FullText";
})(PronunciationAssessmentGranularity || (PronunciationAssessmentGranularity = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   PronunciationAssessmentResult: () => (/* binding */ PronunciationAssessmentResult)
/* harmony export */ });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Pronunciation assessment results.
 * @class PronunciationAssessmentResult
 * Added in version 1.15.0.
 */
class PronunciationAssessmentResult {
  constructor(jsonString) {
    const j = JSON.parse(jsonString);
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(j.NBest[0], "NBest");
    this.privPronJson = j.NBest[0];
  }
  /**
   * @member PronunciationAssessmentResult.fromResult
   * @function
   * @public
   * @param {RecognitionResult} result The recognition result.
   * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig
   * @summary Creates an instance of the PronunciationAssessmentResult from recognition result.
   */
  static fromResult(result) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(result, "result");
    const json = result.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_JsonResult);
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(json, "json");
    return new PronunciationAssessmentResult(json);
  }
  /**
   * Gets the detail result of pronunciation assessment.
   * @member PronunciationAssessmentConfig.prototype.detailResult
   * @function
   * @public
   * @returns {DetailResult} detail result.
   */
  get detailResult() {
    return this.privPronJson;
  }
  /**
   * The score indicating the pronunciation accuracy of the given speech, which indicates
   * how closely the phonemes match a native speaker's pronunciation.
   * @member PronunciationAssessmentResult.prototype.accuracyScore
   * @function
   * @public
   * @returns {number} Accuracy score.
   */
  get accuracyScore() {
    return this.detailResult.PronunciationAssessment.AccuracyScore;
  }
  /**
   * The overall score indicating the pronunciation quality of the given speech.
   * This is calculated from AccuracyScore, FluencyScore and CompletenessScore with weight.
   * @member PronunciationAssessmentResult.prototype.pronunciationScore
   * @function
   * @public
   * @returns {number} Pronunciation score.
   */
  get pronunciationScore() {
    return this.detailResult.PronunciationAssessment.PronScore;
  }
  /**
   * The score indicating the completeness of the given speech by calculating the ratio of pronounced words towards entire input.
   * @member PronunciationAssessmentResult.prototype.completenessScore
   * @function
   * @public
   * @returns {number} Completeness score.
   */
  get completenessScore() {
    return this.detailResult.PronunciationAssessment.CompletenessScore;
  }
  /**
   * The score indicating the fluency of the given speech.
   * @member PronunciationAssessmentResult.prototype.fluencyScore
   * @function
   * @public
   * @returns {number} Fluency score.
   */
  get fluencyScore() {
    return this.detailResult.PronunciationAssessment.FluencyScore;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   PropertyCollection: () => (/* binding */ PropertyCollection)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Represents collection of properties and their values.
 * @class PropertyCollection
 */
class PropertyCollection {
  constructor() {
    this.privKeys = [];
    this.privValues = [];
  }
  /**
   * Returns the property value in type String.
   * Currently only String, int and bool are allowed.
   * If the name is not available, the specified defaultValue is returned.
   * @member PropertyCollection.prototype.getProperty
   * @function
   * @public
   * @param {string} key - The parameter name.
   * @param {string | number | boolean} def - The default value which is returned if the parameter
   * is not available in the collection.
   * @returns {string} value of the parameter.
   */
  getProperty(key, def) {
    let keyToUse;
    if (typeof key === "string") {
      keyToUse = key;
    } else {
      keyToUse = _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId[key];
    }
    for (let n = 0; n < this.privKeys.length; n++) {
      if (this.privKeys[n] === keyToUse) {
        return this.privValues[n];
      }
    }
    if (def === undefined) {
      return undefined;
    }
    return String(def);
  }
  /**
   * Sets the String value of the parameter specified by name.
   * @member PropertyCollection.prototype.setProperty
   * @function
   * @public
   * @param {string} key - The parameter name.
   * @param {string} value - The value of the parameter.
   */
  setProperty(key, value) {
    let keyToUse;
    if (typeof key === "string") {
      keyToUse = key;
    } else {
      keyToUse = _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId[key];
    }
    for (let n = 0; n < this.privKeys.length; n++) {
      if (this.privKeys[n] === keyToUse) {
        this.privValues[n] = value;
        return;
      }
    }
    this.privKeys.push(keyToUse);
    this.privValues.push(value);
  }
  /**
   * Clones the collection.
   * @member PropertyCollection.prototype.clone
   * @function
   * @public
   * @returns {PropertyCollection} A copy of the collection.
   */
  clone() {
    const clonedMap = new PropertyCollection();
    for (let n = 0; n < this.privKeys.length; n++) {
      clonedMap.privKeys.push(this.privKeys[n]);
      clonedMap.privValues.push(this.privValues[n]);
    }
    return clonedMap;
  }
  /**
   * Merges this set of properties into another, no overwrites.
   * @member PropertyCollection.prototype.mergeTo
   * @function
   * @public
   * @param {PropertyCollection}  destinationCollection - The collection to merge into.
   */
  mergeTo(destinationCollection) {
    this.privKeys.forEach(key => {
      if (destinationCollection.getProperty(key, undefined) === undefined) {
        const value = this.getProperty(key);
        destinationCollection.setProperty(key, value);
      }
    });
  }
  /**
   * Get the keys in Property Collection.
   * @member PropertyCollection.prototype.keys
   * @function
   * @public
   * @returns {string []} Keys in the collection.
   */
  get keys() {
    return this.privKeys;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   PropertyId: () => (/* binding */ PropertyId)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines speech property ids.
 * @class PropertyId
 */
var PropertyId;
(function (PropertyId) {
  /**
   * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to
   * specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't
   * have to use this property directly.
   * Instead, use [[SpeechConfig.fromSubscription]].
   * @member PropertyId.SpeechServiceConnection_Key
   */
  PropertyId[PropertyId["SpeechServiceConnection_Key"] = 0] = "SpeechServiceConnection_Key";
  /**
   * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't
   * have to use this property directly.
   * Instead, use [[SpeechConfig.fromEndpoint]].
   * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.
   * @member PropertyId.SpeechServiceConnection_Endpoint
   */
  PropertyId[PropertyId["SpeechServiceConnection_Endpoint"] = 1] = "SpeechServiceConnection_Endpoint";
  /**
   * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to
   * use this property directly.
   * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].
   * @member PropertyId.SpeechServiceConnection_Region
   */
  PropertyId[PropertyId["SpeechServiceConnection_Region"] = 2] = "SpeechServiceConnection_Region";
  /**
   * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,
   * you shouldn't have to use this property directly.
   * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],
   * [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].
   * @member PropertyId.SpeechServiceAuthorization_Token
   */
  PropertyId[PropertyId["SpeechServiceAuthorization_Token"] = 3] = "SpeechServiceAuthorization_Token";
  /**
   * The Cognitive Services Speech Service authorization type. Currently unused.
   * @member PropertyId.SpeechServiceAuthorization_Type
   */
  PropertyId[PropertyId["SpeechServiceAuthorization_Type"] = 4] = "SpeechServiceAuthorization_Type";
  /**
   * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't
   * have to use this property directly.
   * Instead, use [[SpeechConfig.endpointId]].
   * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.
   * @member PropertyId.SpeechServiceConnection_EndpointId
   */
  PropertyId[PropertyId["SpeechServiceConnection_EndpointId"] = 5] = "SpeechServiceConnection_EndpointId";
  /**
   * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,
   * you shouldn't have to use this property directly.
   * Instead use [[SpeechTranslationConfig.addTargetLanguage]],
   * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].
   * @member PropertyId.SpeechServiceConnection_TranslationToLanguages
   */
  PropertyId[PropertyId["SpeechServiceConnection_TranslationToLanguages"] = 6] = "SpeechServiceConnection_TranslationToLanguages";
  /**
   * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this
   * property directly.
   * Instead, use [[SpeechTranslationConfig.voiceName]].
   * NOTE: Valid voice names can be found <a href="https://aka.ms/csspeech/voicenames">here</a>.
   * @member PropertyId.SpeechServiceConnection_TranslationVoice
   */
  PropertyId[PropertyId["SpeechServiceConnection_TranslationVoice"] = 7] = "SpeechServiceConnection_TranslationVoice";
  /**
   * Translation features.
   * @member PropertyId.SpeechServiceConnection_TranslationFeatures
   */
  PropertyId[PropertyId["SpeechServiceConnection_TranslationFeatures"] = 8] = "SpeechServiceConnection_TranslationFeatures";
  /**
   * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.
   * Instead, use [[LanguageUnderstandingModel]].
   * @member PropertyId.SpeechServiceConnection_IntentRegion
   */
  PropertyId[PropertyId["SpeechServiceConnection_IntentRegion"] = 9] = "SpeechServiceConnection_IntentRegion";
  /**
   * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
   * You shouldn't have to use this property directly.
   * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
   * Added in version 1.4.0.
   */
  PropertyId[PropertyId["SpeechServiceConnection_ProxyHostName"] = 10] = "SpeechServiceConnection_ProxyHostName";
  /**
   * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
   * You shouldn't have to use this property directly.
   * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
   * Added in version 1.4.0.
   */
  PropertyId[PropertyId["SpeechServiceConnection_ProxyPort"] = 11] = "SpeechServiceConnection_ProxyPort";
  /**
   * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
   * You shouldn't have to use this property directly.
   * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
   * Added in version 1.4.0.
   */
  PropertyId[PropertyId["SpeechServiceConnection_ProxyUserName"] = 12] = "SpeechServiceConnection_ProxyUserName";
  /**
   * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
   * You shouldn't have to use this property directly.
   * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
   * Added in version 1.4.0.
   */
  PropertyId[PropertyId["SpeechServiceConnection_ProxyPassword"] = 13] = "SpeechServiceConnection_ProxyPassword";
  /**
   * The Cognitive Services Speech Service recognition Mode. Can be "INTERACTIVE", "CONVERSATION", "DICTATION".
   * This property is intended to be read-only. The SDK is using it internally.
   * @member PropertyId.SpeechServiceConnection_RecoMode
   */
  PropertyId[PropertyId["SpeechServiceConnection_RecoMode"] = 14] = "SpeechServiceConnection_RecoMode";
  /**
   * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property
   * directly.
   * Instead, use [[SpeechConfig.speechRecognitionLanguage]].
   * @member PropertyId.SpeechServiceConnection_RecoLanguage
   */
  PropertyId[PropertyId["SpeechServiceConnection_RecoLanguage"] = 15] = "SpeechServiceConnection_RecoLanguage";
  /**
   * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream
   * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this
   * property directly.
   * Instead use [[SessionEventArgs.sessionId]].
   * @member PropertyId.Speech_SessionId
   */
  PropertyId[PropertyId["Speech_SessionId"] = 16] = "Speech_SessionId";
  /**
   * The spoken language to be synthesized (e.g. en-US)
   * @member PropertyId.SpeechServiceConnection_SynthLanguage
   */
  PropertyId[PropertyId["SpeechServiceConnection_SynthLanguage"] = 17] = "SpeechServiceConnection_SynthLanguage";
  /**
   * The name of the TTS voice to be used for speech synthesis
   * @member PropertyId.SpeechServiceConnection_SynthVoice
   */
  PropertyId[PropertyId["SpeechServiceConnection_SynthVoice"] = 18] = "SpeechServiceConnection_SynthVoice";
  /**
   * The string to specify TTS output audio format
   * @member PropertyId.SpeechServiceConnection_SynthOutputFormat
   */
  PropertyId[PropertyId["SpeechServiceConnection_SynthOutputFormat"] = 19] = "SpeechServiceConnection_SynthOutputFormat";
  /**
   * The list of comma separated languages used as possible source languages
   * Added in version 1.13.0
   * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages
   */
  PropertyId[PropertyId["SpeechServiceConnection_AutoDetectSourceLanguages"] = 20] = "SpeechServiceConnection_AutoDetectSourceLanguages";
  /**
   * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have
   * to use this property directly.
   * Instead use [[SpeechConfig.outputFormat]].
   * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
   */
  PropertyId[PropertyId["SpeechServiceResponse_RequestDetailedResultTrueFalse"] = 21] = "SpeechServiceResponse_RequestDetailedResultTrueFalse";
  /**
   * The requested Cognitive Services Speech Service response output profanity level. Currently unused.
   * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
   */
  PropertyId[PropertyId["SpeechServiceResponse_RequestProfanityFilterTrueFalse"] = 22] = "SpeechServiceResponse_RequestProfanityFilterTrueFalse";
  /**
   * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.
   * @member PropertyId.SpeechServiceResponse_JsonResult
   */
  PropertyId[PropertyId["SpeechServiceResponse_JsonResult"] = 23] = "SpeechServiceResponse_JsonResult";
  /**
   * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to
   * use this property directly. Instead use [[CancellationDetails.errorDetails]].
   * @member PropertyId.SpeechServiceResponse_JsonErrorDetails
   */
  PropertyId[PropertyId["SpeechServiceResponse_JsonErrorDetails"] = 24] = "SpeechServiceResponse_JsonErrorDetails";
  /**
   * The cancellation reason. Currently unused.
   * @member PropertyId.CancellationDetails_Reason
   */
  PropertyId[PropertyId["CancellationDetails_Reason"] = 25] = "CancellationDetails_Reason";
  /**
   * The cancellation text. Currently unused.
   * @member PropertyId.CancellationDetails_ReasonText
   */
  PropertyId[PropertyId["CancellationDetails_ReasonText"] = 26] = "CancellationDetails_ReasonText";
  /**
   * The Cancellation detailed text. Currently unused.
   * @member PropertyId.CancellationDetails_ReasonDetailedText
   */
  PropertyId[PropertyId["CancellationDetails_ReasonDetailedText"] = 27] = "CancellationDetails_ReasonDetailedText";
  /**
   * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]
   * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult
   */
  PropertyId[PropertyId["LanguageUnderstandingServiceResponse_JsonResult"] = 28] = "LanguageUnderstandingServiceResponse_JsonResult";
  /**
   * The URL string built from speech configuration.
   * This property is intended to be read-only. The SDK is using it internally.
   * NOTE: Added in version 1.7.0.
   */
  PropertyId[PropertyId["SpeechServiceConnection_Url"] = 29] = "SpeechServiceConnection_Url";
  /**
   * The initial silence timeout value (in milliseconds) used by the service.
   * Added in version 1.7.0
   */
  PropertyId[PropertyId["SpeechServiceConnection_InitialSilenceTimeoutMs"] = 30] = "SpeechServiceConnection_InitialSilenceTimeoutMs";
  /**
   * The end silence timeout value (in milliseconds) used by the service.
   * Added in version 1.7.0
   */
  PropertyId[PropertyId["SpeechServiceConnection_EndSilenceTimeoutMs"] = 31] = "SpeechServiceConnection_EndSilenceTimeoutMs";
  /**
   * A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken
   * phrase has ended and generate a final Recognized result. Configuring this timeout may be helpful in situations
   * where spoken input is significantly faster or slower than usual and default segmentation behavior consistently
   * yields results that are too long or too short. Segmentation timeout values that are inappropriately high or low
   * can negatively affect speech-to-text accuracy; this property should be carefully configured and the resulting
   * behavior should be thoroughly validated as intended.
   *
   * For more information about timeout configuration that includes discussion of default behaviors, please visit
   * https://aka.ms/csspeech/timeouts.
   *
   * Added in version 1.21.0.
   */
  PropertyId[PropertyId["Speech_SegmentationSilenceTimeoutMs"] = 32] = "Speech_SegmentationSilenceTimeoutMs";
  /**
   * A boolean value specifying whether audio logging is enabled in the service or not.
   * Audio and content logs are stored either in Microsoft-owned storage, or in your own storage account linked
   * to your Cognitive Services subscription (Bring Your Own Storage (BYOS) enabled Speech resource).
   * The logs will be removed after 30 days.
   * Added in version 1.7.0
   */
  PropertyId[PropertyId["SpeechServiceConnection_EnableAudioLogging"] = 33] = "SpeechServiceConnection_EnableAudioLogging";
  /**
   * The speech service connection language identifier mode.
   * Can be "AtStart" (the default), or "Continuous". See Language
   * Identification document https://aka.ms/speech/lid?pivots=programming-language-javascript
   * for more details.
   * Added in 1.25.0
   **/
  PropertyId[PropertyId["SpeechServiceConnection_LanguageIdMode"] = 34] = "SpeechServiceConnection_LanguageIdMode";
  /**
   * A string value representing the desired endpoint version to target for Speech Recognition.
   * Added in version 1.21.0
   */
  PropertyId[PropertyId["SpeechServiceConnection_RecognitionEndpointVersion"] = 35] = "SpeechServiceConnection_RecognitionEndpointVersion";
  /**
  /**
   * A string value the current speaker recognition scenario/mode (TextIndependentIdentification, etc.).
   * Added in version 1.23.0
   */
  PropertyId[PropertyId["SpeechServiceConnection_SpeakerIdMode"] = 36] = "SpeechServiceConnection_SpeakerIdMode";
  /**
   * The requested Cognitive Services Speech Service response output profanity setting.
   * Allowed values are "masked", "removed", and "raw".
   * Added in version 1.7.0.
   */
  PropertyId[PropertyId["SpeechServiceResponse_ProfanityOption"] = 37] = "SpeechServiceResponse_ProfanityOption";
  /**
   * A string value specifying which post processing option should be used by service.
   * Allowed values are "TrueText".
   * Added in version 1.7.0
   */
  PropertyId[PropertyId["SpeechServiceResponse_PostProcessingOption"] = 38] = "SpeechServiceResponse_PostProcessingOption";
  /**
   * A boolean value specifying whether to include word-level timestamps in the response result.
   * Added in version 1.7.0
   */
  PropertyId[PropertyId["SpeechServiceResponse_RequestWordLevelTimestamps"] = 39] = "SpeechServiceResponse_RequestWordLevelTimestamps";
  /**
   * The number of times a word has to be in partial results to be returned.
   * Added in version 1.7.0
   */
  PropertyId[PropertyId["SpeechServiceResponse_StablePartialResultThreshold"] = 40] = "SpeechServiceResponse_StablePartialResultThreshold";
  /**
   * A string value specifying the output format option in the response result. Internal use only.
   * Added in version 1.7.0.
   */
  PropertyId[PropertyId["SpeechServiceResponse_OutputFormatOption"] = 41] = "SpeechServiceResponse_OutputFormatOption";
  /**
   * A boolean value to request for stabilizing translation partial results by omitting words in the end.
   * Added in version 1.7.0.
   */
  PropertyId[PropertyId["SpeechServiceResponse_TranslationRequestStablePartialResult"] = 42] = "SpeechServiceResponse_TranslationRequestStablePartialResult";
  /**
   * A boolean value specifying whether to request WordBoundary events.
   * @member PropertyId.SpeechServiceResponse_RequestWordBoundary
   * Added in version 1.21.0.
   */
  PropertyId[PropertyId["SpeechServiceResponse_RequestWordBoundary"] = 43] = "SpeechServiceResponse_RequestWordBoundary";
  /**
   * A boolean value specifying whether to request punctuation boundary in WordBoundary Events. Default is true.
   * @member PropertyId.SpeechServiceResponse_RequestPunctuationBoundary
   * Added in version 1.21.0.
   */
  PropertyId[PropertyId["SpeechServiceResponse_RequestPunctuationBoundary"] = 44] = "SpeechServiceResponse_RequestPunctuationBoundary";
  /**
   * A boolean value specifying whether to request sentence boundary in WordBoundary Events. Default is false.
   * @member PropertyId.SpeechServiceResponse_RequestSentenceBoundary
   * Added in version 1.21.0.
   */
  PropertyId[PropertyId["SpeechServiceResponse_RequestSentenceBoundary"] = 45] = "SpeechServiceResponse_RequestSentenceBoundary";
  /**
   * Identifier used to connect to the backend service.
   * @member PropertyId.Conversation_ApplicationId
   */
  PropertyId[PropertyId["Conversation_ApplicationId"] = 46] = "Conversation_ApplicationId";
  /**
   * Type of dialog backend to connect to.
   * @member PropertyId.Conversation_DialogType
   */
  PropertyId[PropertyId["Conversation_DialogType"] = 47] = "Conversation_DialogType";
  /**
   * Silence timeout for listening
   * @member PropertyId.Conversation_Initial_Silence_Timeout
   */
  PropertyId[PropertyId["Conversation_Initial_Silence_Timeout"] = 48] = "Conversation_Initial_Silence_Timeout";
  /**
   * From Id to add to speech recognition activities.
   * @member PropertyId.Conversation_From_Id
   */
  PropertyId[PropertyId["Conversation_From_Id"] = 49] = "Conversation_From_Id";
  /**
   * ConversationId for the session.
   * @member PropertyId.Conversation_Conversation_Id
   */
  PropertyId[PropertyId["Conversation_Conversation_Id"] = 50] = "Conversation_Conversation_Id";
  /**
   * Comma separated list of custom voice deployment ids.
   * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids
   */
  PropertyId[PropertyId["Conversation_Custom_Voice_Deployment_Ids"] = 51] = "Conversation_Custom_Voice_Deployment_Ids";
  /**
   * Speech activity template, stamp properties from the template on the activity generated by the service for speech.
   * @member PropertyId.Conversation_Speech_Activity_Template
   * Added in version 1.10.0.
   */
  PropertyId[PropertyId["Conversation_Speech_Activity_Template"] = 52] = "Conversation_Speech_Activity_Template";
  /**
   * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.
   * @member PropertyId.Conversation_Request_Bot_Status_Messages
   * Added in version 1.15.0.
   */
  PropertyId[PropertyId["Conversation_Request_Bot_Status_Messages"] = 53] = "Conversation_Request_Bot_Status_Messages";
  /**
   * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for
   * channel authentication.
   * Added in version 1.15.1.
   */
  PropertyId[PropertyId["Conversation_Agent_Connection_Id"] = 54] = "Conversation_Agent_Connection_Id";
  /**
   * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.
   * Instead, use [[SpeechConfig.fromHost]].
   */
  PropertyId[PropertyId["SpeechServiceConnection_Host"] = 55] = "SpeechServiceConnection_Host";
  /**
   * Set the host for service calls to the Conversation Translator REST management and websocket calls.
   */
  PropertyId[PropertyId["ConversationTranslator_Host"] = 56] = "ConversationTranslator_Host";
  /**
   * Optionally set the the host's display name.
   * Used when joining a conversation.
   */
  PropertyId[PropertyId["ConversationTranslator_Name"] = 57] = "ConversationTranslator_Name";
  /**
   * Optionally set a value for the X-CorrelationId request header.
   * Used for troubleshooting errors in the server logs. It should be a valid guid.
   */
  PropertyId[PropertyId["ConversationTranslator_CorrelationId"] = 58] = "ConversationTranslator_CorrelationId";
  /**
   * Set the conversation token to be sent to the speech service. This enables the
   * service to service call from the speech service to the Conversation Translator service for relaying
   * recognitions. For internal use.
   */
  PropertyId[PropertyId["ConversationTranslator_Token"] = 59] = "ConversationTranslator_Token";
  /**
   * The reference text of the audio for pronunciation evaluation.
   * For this and the following pronunciation assessment parameters, see
   * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.
   * Under normal circumstances, you shouldn't have to use this property directly.
   * Added in version 1.15.0
   */
  PropertyId[PropertyId["PronunciationAssessment_ReferenceText"] = 60] = "PronunciationAssessment_ReferenceText";
  /**
   * The point system for pronunciation score calibration (FivePoint or HundredMark).
   * Under normal circumstances, you shouldn't have to use this property directly.
   * Added in version 1.15.0
   */
  PropertyId[PropertyId["PronunciationAssessment_GradingSystem"] = 61] = "PronunciationAssessment_GradingSystem";
  /**
   * The pronunciation evaluation granularity (Phoneme, Word, or FullText).
   * Under normal circumstances, you shouldn't have to use this property directly.
   * Added in version 1.15.0
   */
  PropertyId[PropertyId["PronunciationAssessment_Granularity"] = 62] = "PronunciationAssessment_Granularity";
  /**
   * Defines if enable miscue calculation.
   * With this enabled, the pronounced words will be compared to the reference text,
   * and will be marked with omission/insertion based on the comparison. The default setting is False.
   * Under normal circumstances, you shouldn't have to use this property directly.
   * Added in version 1.15.0
   */
  PropertyId[PropertyId["PronunciationAssessment_EnableMiscue"] = 63] = "PronunciationAssessment_EnableMiscue";
  /**
   * The json string of pronunciation assessment parameters
   * Under normal circumstances, you shouldn't have to use this property directly.
   * Added in version 1.15.0
   */
  PropertyId[PropertyId["PronunciationAssessment_Json"] = 64] = "PronunciationAssessment_Json";
  /**
   * Pronunciation assessment parameters.
   * This property is intended to be read-only. The SDK is using it internally.
   * Added in version 1.15.0
   */
  PropertyId[PropertyId["PronunciationAssessment_Params"] = 65] = "PronunciationAssessment_Params";
  /**
   * Version of Speaker Recognition API to use.
   * Added in version 1.18.0
   */
  PropertyId[PropertyId["SpeakerRecognition_Api_Version"] = 66] = "SpeakerRecognition_Api_Version";
})(PropertyId || (PropertyId = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   RecognitionEventArgs: () => (/* binding */ RecognitionEventArgs)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Defines payload for session events like Speech Start/End Detected
 * @class
 */
class RecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {number} offset - The offset.
   * @param {string} sessionId - The session id.
   */
  constructor(offset, sessionId) {
    super(sessionId);
    this.privOffset = offset;
  }
  /**
   * Represents the message offset
   * @member RecognitionEventArgs.prototype.offset
   * @function
   * @public
   */
  get offset() {
    return this.privOffset;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   RecognitionResult: () => (/* binding */ RecognitionResult)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines result of speech recognition.
 * @class RecognitionResult
 */
class RecognitionResult {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} resultId - The result id.
   * @param {ResultReason} reason - The reason.
   * @param {string} text - The recognized text.
   * @param {number} duration - The duration.
   * @param {number} offset - The offset into the stream.
   * @param {string} language - Primary Language detected, if provided.
   * @param {string} languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
   * @param {string} errorDetails - Error details, if provided.
   * @param {string} json - Additional Json, if provided.
   * @param {PropertyCollection} properties - Additional properties, if provided.
   */
  constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {
    this.privResultId = resultId;
    this.privReason = reason;
    this.privText = text;
    this.privDuration = duration;
    this.privOffset = offset;
    this.privLanguage = language;
    this.privLanguageDetectionConfidence = languageDetectionConfidence;
    this.privErrorDetails = errorDetails;
    this.privJson = json;
    this.privProperties = properties;
  }
  /**
   * Specifies the result identifier.
   * @member RecognitionResult.prototype.resultId
   * @function
   * @public
   * @returns {string} Specifies the result identifier.
   */
  get resultId() {
    return this.privResultId;
  }
  /**
   * Specifies status of the result.
   * @member RecognitionResult.prototype.reason
   * @function
   * @public
   * @returns {ResultReason} Specifies status of the result.
   */
  get reason() {
    return this.privReason;
  }
  /**
   * Presents the recognized text in the result.
   * @member RecognitionResult.prototype.text
   * @function
   * @public
   * @returns {string} Presents the recognized text in the result.
   */
  get text() {
    return this.privText;
  }
  /**
   * Duration of recognized speech in 100 nano second increments.
   * @member RecognitionResult.prototype.duration
   * @function
   * @public
   * @returns {number} Duration of recognized speech in 100 nano second increments.
   */
  get duration() {
    return this.privDuration;
  }
  /**
   * Offset of recognized speech in 100 nano second increments.
   * @member RecognitionResult.prototype.offset
   * @function
   * @public
   * @returns {number} Offset of recognized speech in 100 nano second increments.
   */
  get offset() {
    return this.privOffset;
  }
  /**
   * Primary Language detected.
   * @member RecognitionResult.prototype.language
   * @function
   * @public
   * @returns {string} language detected.
   */
  get language() {
    return this.privLanguage;
  }
  /**
   * Primary Language detection confidence (Unknown, Low, Medium, High).
   * @member RecognitionResult.prototype.languageDetectionConfidence
   * @function
   * @public
   * @returns {string} detection confidence strength.
   */
  get languageDetectionConfidence() {
    return this.privLanguageDetectionConfidence;
  }
  /**
   * In case of an unsuccessful recognition, provides details of the occurred error.
   * @member RecognitionResult.prototype.errorDetails
   * @function
   * @public
   * @returns {string} a brief description of an error.
   */
  get errorDetails() {
    return this.privErrorDetails;
  }
  /**
   * A string containing Json serialized recognition result as it was received from the service.
   * @member RecognitionResult.prototype.json
   * @function
   * @private
   * @returns {string} Json serialized representation of the result.
   */
  get json() {
    return this.privJson;
  }
  /**
   * The set of properties exposed in the result.
   * @member RecognitionResult.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The set of properties exposed in the result.
   */
  get properties() {
    return this.privProperties;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Recognizer: () => (/* binding */ Recognizer)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};




/**
 * Defines the base class Recognizer which mainly contains common event handlers.
 * @class Recognizer
 */
class Recognizer {
  /**
   * Creates and initializes an instance of a Recognizer
   * @constructor
   * @param {AudioConfig} audioInput - An optional audio input stream associated with the recognizer
   */
  constructor(audioConfig, properties, connectionFactory) {
    this.audioConfig = audioConfig !== undefined ? audioConfig : _Exports__WEBPACK_IMPORTED_MODULE_0__.AudioConfig.fromDefaultMicrophoneInput();
    this.privDisposed = false;
    this.privProperties = properties.clone();
    this.privConnectionFactory = connectionFactory;
    this.implCommonRecognizerSetup();
  }
  /**
   * Dispose of associated resources.
   * @member Recognizer.prototype.close
   * @function
   * @public
   */
  close(cb, errorCb) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposed);
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_2__.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);
  }
  /**
   * @Internal
   * Internal data member to support fromRecognizer* pattern methods on other classes.
   * Do not use externally, object returned will change without warning or notice.
   */
  get internalData() {
    return this.privReco;
  }
  /**
   * This method performs cleanup of resources.
   * The Boolean parameter disposing indicates whether the method is called
   * from Dispose (if disposing is true) or from the finalizer (if disposing is false).
   * Derived classes should override this method to dispose resource if needed.
   * @member Recognizer.prototype.dispose
   * @function
   * @public
   * @param {boolean} disposing - Flag to request disposal.
   */
  dispose(disposing) {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privDisposed) {
        return;
      }
      this.privDisposed = true;
      if (disposing) {
        if (this.privReco) {
          yield this.privReco.audioSource.turnOff();
          yield this.privReco.dispose();
        }
      }
    });
  }
  /**
   * This method returns the current state of the telemetry setting.
   * @member Recognizer.prototype.telemetryEnabled
   * @function
   * @public
   * @returns true if the telemetry is enabled, false otherwise.
   */
  static get telemetryEnabled() {
    return _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.ServiceRecognizerBase.telemetryDataEnabled;
  }
  /**
   * This method globally enables or disables telemetry.
   * @member Recognizer.prototype.enableTelemetry
   * @function
   * @public
   * @param enabled - Global setting for telemetry collection.
   * If set to true, telemetry information like microphone errors,
   * recognition errors are collected and sent to Microsoft.
   * If set to false, no telemetry is sent to Microsoft.
   */
  static enableTelemetry(enabled) {
    _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.ServiceRecognizerBase.telemetryDataEnabled = enabled;
  }
  // Does the generic recognizer setup that is common across all recognizer types.
  implCommonRecognizerSetup() {
    let osPlatform = typeof window !== "undefined" ? "Browser" : "Node";
    let osName = "unknown";
    let osVersion = "unknown";
    if (typeof navigator !== "undefined") {
      osPlatform = osPlatform + "/" + navigator.platform;
      osName = navigator.userAgent;
      osVersion = navigator.appVersion;
    }
    const recognizerConfig = this.createRecognizerConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechServiceConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.Context(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OS(osPlatform, osName, osVersion))));
    this.privReco = this.createServiceRecognizer(Recognizer.getAuthFromProperties(this.privProperties), this.privConnectionFactory, this.audioConfig, recognizerConfig);
  }
  recognizeOnceAsyncImpl(recognitionMode) {
    return __awaiter(this, void 0, void 0, function* () {
      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposed);
      const ret = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.Deferred();
      yield this.implRecognizerStop();
      yield this.privReco.recognize(recognitionMode, ret.resolve, ret.reject);
      const result = yield ret.promise;
      yield this.implRecognizerStop();
      return result;
    });
  }
  startContinuousRecognitionAsyncImpl(recognitionMode) {
    return __awaiter(this, void 0, void 0, function* () {
      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposed);
      yield this.implRecognizerStop();
      yield this.privReco.recognize(recognitionMode, undefined, undefined);
    });
  }
  stopContinuousRecognitionAsyncImpl() {
    return __awaiter(this, void 0, void 0, function* () {
      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposed);
      yield this.implRecognizerStop();
    });
  }
  implRecognizerStop() {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privReco) {
        yield this.privReco.stopRecognizing();
      }
      return;
    });
  }
  static getAuthFromProperties(properties) {
    const subscriptionKey = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_5__.PropertyId.SpeechServiceConnection_Key, undefined);
    const authentication = subscriptionKey && subscriptionKey !== "" ? new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.CognitiveSubscriptionKeyAuthentication(subscriptionKey) : new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.CognitiveTokenAuthentication(() => {
      const authorizationToken = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_5__.PropertyId.SpeechServiceAuthorization_Token, undefined);
      return Promise.resolve(authorizationToken);
    }, () => {
      const authorizationToken = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_5__.PropertyId.SpeechServiceAuthorization_Token, undefined);
      return Promise.resolve(authorizationToken);
    });
    return authentication;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ResultReason: () => (/* binding */ ResultReason)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines the possible reasons a recognition result might be generated.
 * @class ResultReason
 */
var ResultReason;
(function (ResultReason) {
  /**
   * Indicates speech could not be recognized. More details
   * can be found in the NoMatchDetails object.
   * @member ResultReason.NoMatch
   */
  ResultReason[ResultReason["NoMatch"] = 0] = "NoMatch";
  /**
   * Indicates that the recognition was canceled. More details
   * can be found using the CancellationDetails object.
   * @member ResultReason.Canceled
   */
  ResultReason[ResultReason["Canceled"] = 1] = "Canceled";
  /**
   * Indicates the speech result contains hypothesis text.
   * @member ResultReason.RecognizedSpeech
   */
  ResultReason[ResultReason["RecognizingSpeech"] = 2] = "RecognizingSpeech";
  /**
   * Indicates the speech result contains final text that has been recognized.
   * Speech Recognition is now complete for this phrase.
   * @member ResultReason.RecognizedSpeech
   */
  ResultReason[ResultReason["RecognizedSpeech"] = 3] = "RecognizedSpeech";
  /**
   * Indicates the speech result contains a finalized acceptance of a provided keyword.
   * Speech recognition will continue unless otherwise configured.
   * @member ResultReason.RecognizedKeyword
   */
  ResultReason[ResultReason["RecognizedKeyword"] = 4] = "RecognizedKeyword";
  /**
   * Indicates the intent result contains hypothesis text and intent.
   * @member ResultReason.RecognizingIntent
   */
  ResultReason[ResultReason["RecognizingIntent"] = 5] = "RecognizingIntent";
  /**
   * Indicates the intent result contains final text and intent.
   * Speech Recognition and Intent determination are now complete for this phrase.
   * @member ResultReason.RecognizedIntent
   */
  ResultReason[ResultReason["RecognizedIntent"] = 6] = "RecognizedIntent";
  /**
   * Indicates the translation result contains hypothesis text and its translation(s).
   * @member ResultReason.TranslatingSpeech
   */
  ResultReason[ResultReason["TranslatingSpeech"] = 7] = "TranslatingSpeech";
  /**
   * Indicates the translation result contains final text and corresponding translation(s).
   * Speech Recognition and Translation are now complete for this phrase.
   * @member ResultReason.TranslatedSpeech
   */
  ResultReason[ResultReason["TranslatedSpeech"] = 8] = "TranslatedSpeech";
  /**
   * Indicates the synthesized audio result contains a non-zero amount of audio data
   * @member ResultReason.SynthesizingAudio
   */
  ResultReason[ResultReason["SynthesizingAudio"] = 9] = "SynthesizingAudio";
  /**
   * Indicates the synthesized audio is now complete for this phrase.
   * @member ResultReason.SynthesizingAudioCompleted
   */
  ResultReason[ResultReason["SynthesizingAudioCompleted"] = 10] = "SynthesizingAudioCompleted";
  /**
   * Indicates the speech synthesis is now started
   * @member ResultReason.SynthesizingAudioStarted
   */
  ResultReason[ResultReason["SynthesizingAudioStarted"] = 11] = "SynthesizingAudioStarted";
  /**
   * Indicates the voice profile is being enrolled and customers need to send more audio to create a voice profile.
   * @member ResultReason.EnrollingVoiceProfile
   */
  ResultReason[ResultReason["EnrollingVoiceProfile"] = 12] = "EnrollingVoiceProfile";
  /**
   * Indicates the voice profile has been enrolled.
   * @member ResultReason.EnrolledVoiceProfile
   */
  ResultReason[ResultReason["EnrolledVoiceProfile"] = 13] = "EnrolledVoiceProfile";
  /**
   * Indicates successful identification of some speakers.
   * @member ResultReason.RecognizedSpeakers
   */
  ResultReason[ResultReason["RecognizedSpeakers"] = 14] = "RecognizedSpeakers";
  /**
   * Indicates successfully verified one speaker.
   * @member ResultReason.RecognizedSpeaker
   */
  ResultReason[ResultReason["RecognizedSpeaker"] = 15] = "RecognizedSpeaker";
  /**
   * Indicates a voice profile has been reset successfully.
   * @member ResultReason.ResetVoiceProfile
   */
  ResultReason[ResultReason["ResetVoiceProfile"] = 16] = "ResetVoiceProfile";
  /**
   * Indicates a voice profile has been deleted successfully.
   * @member ResultReason.DeletedVoiceProfile
   */
  ResultReason[ResultReason["DeletedVoiceProfile"] = 17] = "DeletedVoiceProfile";
  /**
   * Indicates synthesis voices list has been successfully retrieved.
   * @member ResultReason.VoicesListRetrieved
   */
  ResultReason[ResultReason["VoicesListRetrieved"] = 18] = "VoicesListRetrieved";
})(ResultReason || (ResultReason = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ServiceEventArgs: () => (/* binding */ ServiceEventArgs)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js");
//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//

/**
 * Defines payload for any Service message event
 * Added in version 1.9.0
 */
class ServiceEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} json - json payload of the USP message.
   */
  constructor(json, name, sessionId) {
    super(sessionId);
    this.privJsonResult = json;
    this.privEventName = name;
  }
  get jsonString() {
    return this.privJsonResult;
  }
  get eventName() {
    return this.privEventName;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ServicePropertyChannel: () => (/* binding */ ServicePropertyChannel)
/* harmony export */ });
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Defines channels used to pass property settings to service.
 * Added in version 1.7.0.
 */
var ServicePropertyChannel;
(function (ServicePropertyChannel) {
  /**
   * Uses URI query parameter to pass property settings to service.
   */
  ServicePropertyChannel[ServicePropertyChannel["UriQueryParameter"] = 0] = "UriQueryParameter";
})(ServicePropertyChannel || (ServicePropertyChannel = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SessionEventArgs: () => (/* binding */ SessionEventArgs)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines content for session events like SessionStarted/Stopped, SoundStarted/Stopped.
 * @class SessionEventArgs
 */
class SessionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} sessionId - The session id.
   */
  constructor(sessionId) {
    this.privSessionId = sessionId;
  }
  /**
   * Represents the session identifier.
   * @member SessionEventArgs.prototype.sessionId
   * @function
   * @public
   * @returns {string} Represents the session identifier.
   */
  get sessionId() {
    return this.privSessionId;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SourceLanguageConfig: () => (/* binding */ SourceLanguageConfig)
/* harmony export */ });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Source Language configuration.
 * @class SourceLanguageConfig
 */
class SourceLanguageConfig {
  constructor(language, endpointId) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(language, "language");
    this.privLanguage = language;
    this.privEndpointId = endpointId;
  }
  /**
   * @member SourceLanguageConfig.fromLanguage
   * @function
   * @public
   * @param {string} language language (eg. "en-US") value of config.
   * @param {string?} endpointId endpointId of model bound to given language of config.
   * @return {SourceLanguageConfig} Instance of SourceLanguageConfig
   * @summary Creates an instance of the SourceLanguageConfig with the given language and optional endpointId.
   * Added in version 1.13.0.
   */
  static fromLanguage(language, endpointId) {
    return new SourceLanguageConfig(language, endpointId);
  }
  get language() {
    return this.privLanguage;
  }
  get endpointId() {
    return this.privEndpointId;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeakerIdentificationModel: () => (/* binding */ SpeakerIdentificationModel)
/* harmony export */ });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Defines SpeakerIdentificationModel class for Speaker Recognition
 * Model contains a set of profiles against which to identify speaker(s)
 * @class SpeakerIdentificationModel
 */
class SpeakerIdentificationModel {
  constructor(profiles) {
    this.privVoiceProfiles = [];
    this.privProfileIds = [];
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(profiles, "VoiceProfiles");
    if (profiles.length === 0) {
      throw new Error("Empty Voice Profiles array");
    }
    for (const profile of profiles) {
      if (profile.profileType !== _Exports__WEBPACK_IMPORTED_MODULE_1__.VoiceProfileType.TextIndependentIdentification) {
        throw new Error("Identification model can only be created from Identification profile: " + profile.profileId);
      }
      this.privVoiceProfiles.push(profile);
      this.privProfileIds.push(profile.profileId);
    }
  }
  static fromProfiles(profiles) {
    return new SpeakerIdentificationModel(profiles);
  }
  get voiceProfileIds() {
    return this.privProfileIds.join(",");
  }
  get profileIds() {
    return this.privProfileIds;
  }
  get scenario() {
    return "TextIndependentIdentification";
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeakerRecognitionCancellationDetails: () => (/* binding */ SpeakerRecognitionCancellationDetails),
/* harmony export */   SpeakerRecognitionResult: () => (/* binding */ SpeakerRecognitionResult),
/* harmony export */   SpeakerRecognitionResultType: () => (/* binding */ SpeakerRecognitionResultType)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */


var SpeakerRecognitionResultType;
(function (SpeakerRecognitionResultType) {
  SpeakerRecognitionResultType[SpeakerRecognitionResultType["Verify"] = 0] = "Verify";
  SpeakerRecognitionResultType[SpeakerRecognitionResultType["Identify"] = 1] = "Identify";
})(SpeakerRecognitionResultType || (SpeakerRecognitionResultType = {}));
/**
 * Output format
 * @class SpeakerRecognitionResult
 */
class SpeakerRecognitionResult {
  constructor(response, resultReason = _Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.RecognizedSpeaker, cancellationErrorCode = _Exports__WEBPACK_IMPORTED_MODULE_1__.CancellationErrorCode.NoError, errorDetails = "") {
    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection();
    const resultType = response.scenario === "TextIndependentIdentification" ? SpeakerRecognitionResultType.Identify : SpeakerRecognitionResultType.Verify;
    this.privReason = resultReason;
    if (this.privReason !== _Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.Canceled) {
      if (resultType === SpeakerRecognitionResultType.Identify) {
        this.privProfileId = response.identificationResult.identifiedProfile.profileId;
        this.privScore = response.identificationResult.identifiedProfile.score;
        this.privReason = _Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.RecognizedSpeakers;
      } else {
        this.privScore = response.verificationResult.score;
        if (response.verificationResult.recognitionResult.toLowerCase() !== "accept") {
          this.privReason = _Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.NoMatch;
        }
        if (response.verificationResult.profileId !== undefined && response.verificationResult.profileId !== "") {
          this.privProfileId = response.verificationResult.profileId;
        }
      }
    } else {
      this.privErrorDetails = errorDetails;
      this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_1__.CancellationErrorCode[cancellationErrorCode]);
    }
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceResponse_JsonResult, JSON.stringify(response));
  }
  get properties() {
    return this.privProperties;
  }
  get reason() {
    return this.privReason;
  }
  get profileId() {
    return this.privProfileId;
  }
  get errorDetails() {
    return this.privErrorDetails;
  }
  get score() {
    return this.privScore;
  }
}
/**
 * @class SpeakerRecognitionCancellationDetails
 */
class SpeakerRecognitionCancellationDetails extends _Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationDetailsBase {
  constructor(reason, errorDetails, errorCode) {
    super(reason, errorDetails, errorCode);
  }
  /**
   * Creates an instance of SpeakerRecognitionCancellationDetails object for the canceled SpeakerRecognitionResult
   * @member SpeakerRecognitionCancellationDetails.fromResult
   * @function
   * @public
   * @param {SpeakerRecognitionResult} result - The result that was canceled.
   * @returns {SpeakerRecognitionCancellationDetails} The cancellation details object being created.
   */
  static fromResult(result) {
    const reason = _Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error;
    let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_1__.CancellationErrorCode.NoError;
    if (!!result.properties) {
      errorCode = _Exports__WEBPACK_IMPORTED_MODULE_1__.CancellationErrorCode[result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_1__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_1__.CancellationErrorCode.NoError])];
    }
    return new SpeakerRecognitionCancellationDetails(reason, result.errorDetails, errorCode);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeakerRecognizer: () => (/* binding */ SpeakerRecognizer)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConnectionFactory.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerServiceRecognizer.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};



/**
 * Defines SpeakerRecognizer class for Speaker Recognition
 * Handles operations from user for Voice Profile operations (e.g. createProfile, deleteProfile)
 * @class SpeakerRecognizer
 */
class SpeakerRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {
  /**
   * Initializes an instance of the SpeakerRecognizer.
   * @constructor
   * @param {SpeechConfig} speechConfig - The set of configuration properties.
   * @param {AudioConfig} audioConfig - An optional audio input config associated with the recognizer
   */
  constructor(speechConfig, audioConfig) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(speechConfig, "speechConfig");
    const configImpl = speechConfig;
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(configImpl, "speechConfig");
    super(audioConfig, configImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerRecognitionConnectionFactory());
    this.privAudioConfigImpl = audioConfig;
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(this.privAudioConfigImpl, "audioConfig");
    this.privDisposedSpeakerRecognizer = false;
    this.privProperties = configImpl.properties;
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member SpeakerRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * @member SpeakerRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @param {string} token - Authorization token.
   */
  set authorizationToken(token) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceAuthorization_Token, token);
  }
  /**
   * The collection of properties and their values defined for this SpeakerRecognizer.
   * @member SpeakerRecognizer.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this SpeakerRecognizer.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Get recognition result for model using given audio
   * @member SpeakerRecognizer.prototype.recognizeOnceAsync
   * @function
   * @public
   * @async
   * @param {SpeakerIdentificationModel | SpeakerVerificationModel} model Model containing Voice Profiles to be identified
   * @param cb - Callback invoked once result is returned.
   * @param err - Callback invoked in case of an error.
   */
  recognizeOnceAsync(model) {
    return __awaiter(this, void 0, void 0, function* () {
      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedSpeakerRecognizer);
      return this.recognizeSpeakerOnceAsyncImpl(model);
    });
  }
  /**
   * Included for compatibility
   * @member SpeakerRecognizer.prototype.close
   * @function
   * @public
   * @async
   */
  close() {
    return __awaiter(this, void 0, void 0, function* () {
      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedSpeakerRecognizer);
      yield this.dispose(true);
    });
  }
  recognizeSpeakerOnceAsyncImpl(model) {
    return __awaiter(this, void 0, void 0, function* () {
      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedSpeakerRecognizer);
      yield this.implRecognizerStop();
      const result = yield this.privReco.recognizeSpeaker(model);
      yield this.implRecognizerStop();
      return result;
    });
  }
  implRecognizerStop() {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privReco) {
        yield this.privReco.stopRecognizing();
      }
      return;
    });
  }
  createRecognizerConfig(speechConfig) {
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.RecognizerConfig(speechConfig, this.privProperties);
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const audioImpl = audioConfig;
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.SpeakerServiceRecognizer(authentication, connectionFactory, audioImpl, recognizerConfig, this);
  }
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: {
        get: () => super.dispose
      }
    });
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privDisposedSpeakerRecognizer) {
        return;
      }
      if (disposing) {
        this.privDisposedSpeakerRecognizer = true;
        yield _super.dispose.call(this, disposing);
      }
    });
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeakerVerificationModel: () => (/* binding */ SpeakerVerificationModel)
/* harmony export */ });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Defines SpeakerVerificationModel class for Speaker Recognition
 * Model contains a profile against which to verify a speaker
 * @class SpeakerVerificationModel
 */
class SpeakerVerificationModel {
  constructor(profile) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(profile, "VoiceProfile");
    if (profile.profileType === _Exports__WEBPACK_IMPORTED_MODULE_1__.VoiceProfileType.TextIndependentIdentification) {
      throw new Error("Verification model cannot be created from Identification profile");
    }
    this.privVoiceProfile = profile;
  }
  static fromProfile(profile) {
    return new SpeakerVerificationModel(profile);
  }
  get voiceProfile() {
    return this.privVoiceProfile;
  }
  get profileIds() {
    return [this.voiceProfile.profileId];
  }
  get scenario() {
    if (this.voiceProfile.profileType === _Exports__WEBPACK_IMPORTED_MODULE_1__.VoiceProfileType.TextDependentVerification) {
      return "TextDependentVerification";
    } else {
      return "TextIndependentVerification";
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechConfig: () => (/* binding */ SpeechConfig),
/* harmony export */   SpeechConfigImpl: () => (/* binding */ SpeechConfigImpl)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */



/**
 * Speech configuration.
 * @class SpeechConfig
 */
class SpeechConfig {
  /**
   * Creates and initializes an instance.
   * @constructor
   */
  constructor() {
    return;
  }
  /**
   * Static instance of SpeechConfig returned by passing subscriptionKey and service region.
   * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.
   * @member SpeechConfig.fromSubscription
   * @function
   * @public
   * @param {string} subscriptionKey - The subscription key.
   * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {SpeechConfig} The speech factory
   */
  static fromSubscription(subscriptionKey, region) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(subscriptionKey, "subscriptionKey");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(region, "region");
    const speechImpl = new SpeechConfigImpl();
    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region, region);
    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_IntentRegion, region);
    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    return speechImpl;
  }
  /**
   * Creates an instance of the speech config with specified endpoint and subscription key.
   * This method is intended only for users who use a non-standard service endpoint or parameters.
   * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.
   * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.
   * For example, if language is defined in the uri as query parameter "language=de-DE", and also set by
   * SpeechConfig.speechRecognitionLanguage = "en-US", the language setting in uri takes precedence,
   * and the effective language is "de-DE". Only the parameters that are not specified in the
   * endpoint URL can be set by other APIs.
   * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the
   * fromEndpoint method, and then set authorizationToken="token" on the created SpeechConfig instance to
   * use the authorization token.
   * @member SpeechConfig.fromEndpoint
   * @function
   * @public
   * @param {URL} endpoint - The service endpoint to connect to.
   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.
   * @returns {SpeechConfig} A speech factory instance.
   */
  static fromEndpoint(endpoint, subscriptionKey) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(endpoint, "endpoint");
    const speechImpl = new SpeechConfigImpl();
    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint, endpoint.href);
    if (undefined !== subscriptionKey) {
      speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    }
    return speechImpl;
  }
  /**
   * Creates an instance of the speech config with specified host and subscription key.
   * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.
   * For services with a non-standard resource path or no path at all, use fromEndpoint instead.
   * Note: Query parameters are not allowed in the host URI and must be set by other APIs.
   * Note: To use an authorization token with fromHost, use fromHost(URL),
   * and then set the AuthorizationToken property on the created SpeechConfig instance.
   * Note: Added in version 1.9.0.
   * @member SpeechConfig.fromHost
   * @function
   * @public
   * @param {URL} host - The service endpoint to connect to. Format is "protocol://host:port" where ":port" is optional.
   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.
   * @returns {SpeechConfig} A speech factory instance.
   */
  static fromHost(hostName, subscriptionKey) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(hostName, "hostName");
    const speechImpl = new SpeechConfigImpl();
    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, hostName.protocol + "//" + hostName.hostname + (hostName.port === "" ? "" : ":" + hostName.port));
    if (undefined !== subscriptionKey) {
      speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    }
    return speechImpl;
  }
  /**
   * Creates an instance of the speech factory with specified initial authorization token and region.
   * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
   * expires, the caller needs to refresh it by calling this setter with a new valid token.
   * Note: Please use a token derived from your LanguageUnderstanding subscription key in case you want
   * to use the Intent recognizer. As configuration values are copied when creating a new recognizer,
   * the new token value will not apply to recognizers that have already been created. For recognizers
   * that have been created before, you need to set authorization token of the corresponding recognizer
   * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
   * @member SpeechConfig.fromAuthorizationToken
   * @function
   * @public
   * @param {string} authorizationToken - The initial authorization token.
   * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {SpeechConfig} A speech factory instance.
   */
  static fromAuthorizationToken(authorizationToken, region) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(authorizationToken, "authorizationToken");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(region, "region");
    const speechImpl = new SpeechConfigImpl();
    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region, region);
    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_IntentRegion, region);
    speechImpl.authorizationToken = authorizationToken;
    return speechImpl;
  }
  /**
   * Closes the configuration.
   * @member SpeechConfig.prototype.close
   * @function
   * @public
   */
  // eslint-disable-next-line @typescript-eslint/no-empty-function
  close() {}
}
/**
 * @public
 * @class SpeechConfigImpl
 */
class SpeechConfigImpl extends SpeechConfig {
  constructor() {
    super();
    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection();
    this.speechRecognitionLanguage = "en-US"; // Should we have a default?
    this.outputFormat = _Exports__WEBPACK_IMPORTED_MODULE_3__.OutputFormat.Simple;
  }
  get properties() {
    return this.privProperties;
  }
  get endPoint() {
    return new URL(this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint));
  }
  get subscriptionKey() {
    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Key);
  }
  get region() {
    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region);
  }
  get authorizationToken() {
    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceAuthorization_Token);
  }
  set authorizationToken(value) {
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceAuthorization_Token, value);
  }
  get speechRecognitionLanguage() {
    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage);
  }
  set speechRecognitionLanguage(value) {
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage, value);
  }
  get autoDetectSourceLanguages() {
    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages);
  }
  set autoDetectSourceLanguages(value) {
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, value);
  }
  get outputFormat() {
    return _Exports__WEBPACK_IMPORTED_MODULE_3__.OutputFormat[this.privProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormatPropertyName, undefined)];
  }
  set outputFormat(value) {
    this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormatPropertyName, _Exports__WEBPACK_IMPORTED_MODULE_3__.OutputFormat[value]);
  }
  get endpointId() {
    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId);
  }
  set endpointId(value) {
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId, value);
  }
  setProperty(name, value) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(value, "value");
    this.privProperties.setProperty(name, value);
  }
  getProperty(name, def) {
    return this.privProperties.getProperty(name, def);
  }
  setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ProxyHostName], proxyHostName);
    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ProxyPort], proxyPort);
    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ProxyUserName], proxyUserName);
    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ProxyPassword], proxyPassword);
  }
  setServiceProperty(name, value) {
    const currentProperties = JSON.parse(this.privProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ServicePropertiesPropertyName, "{}"));
    currentProperties[name] = value;
    this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ServicePropertiesPropertyName, JSON.stringify(currentProperties));
  }
  setProfanity(profanity) {
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_ProfanityOption, _Exports__WEBPACK_IMPORTED_MODULE_5__.ProfanityOption[profanity]);
  }
  enableAudioLogging() {
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EnableAudioLogging, "true");
  }
  requestWordLevelTimestamps() {
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, "true");
  }
  enableDictation() {
    this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ForceDictationPropertyName, "true");
  }
  clone() {
    const ret = new SpeechConfigImpl();
    ret.privProperties = this.privProperties.clone();
    return ret;
  }
  get speechSynthesisLanguage() {
    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthLanguage);
  }
  set speechSynthesisLanguage(language) {
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthLanguage, language);
  }
  get speechSynthesisVoiceName() {
    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthVoice);
  }
  set speechSynthesisVoiceName(voice) {
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthVoice, voice);
  }
  get speechSynthesisOutputFormat() {
    return _Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechSynthesisOutputFormat[this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)];
  }
  set speechSynthesisOutputFormat(format) {
    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthOutputFormat, _Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechSynthesisOutputFormat[format]);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechRecognitionCanceledEventArgs: () => (/* binding */ SpeechRecognitionCanceledEventArgs)
/* harmony export */ });
/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CancellationEventArgsBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

class SpeechRecognitionCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__.CancellationEventArgsBase {}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationTranscriptionEventArgs: () => (/* binding */ ConversationTranscriptionEventArgs),
/* harmony export */   SpeechRecognitionEventArgs: () => (/* binding */ SpeechRecognitionEventArgs)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */

/**
 * Defines contents of speech recognizing/recognized event.
 * @class SpeechRecognitionEventArgs
 */
class SpeechRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {SpeechRecognitionResult} result - The speech recognition result.
   * @param {number} offset - The offset.
   * @param {string} sessionId - The session id.
   */
  constructor(result, offset, sessionId) {
    super(offset, sessionId);
    this.privResult = result;
  }
  /**
   * Specifies the recognition result.
   * @member SpeechRecognitionEventArgs.prototype.result
   * @function
   * @public
   * @returns {SpeechRecognitionResult} the recognition result.
   */
  get result() {
    return this.privResult;
  }
}
/**
 * Defines contents of conversation transcribed/transcribing event.
 * @class ConversationTranscriptionEventArgs
 */
class ConversationTranscriptionEventArgs extends SpeechRecognitionEventArgs {}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechRecognitionResult: () => (/* binding */ SpeechRecognitionResult)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Defines result of speech recognition.
 * @class SpeechRecognitionResult
 */
class SpeechRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionResult {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @public
   * @param {string} resultId - The result id.
   * @param {ResultReason} reason - The reason.
   * @param {string} text - The recognized text.
   * @param {number} duration - The duration.
   * @param {number} offset - The offset into the stream.
   * @param {string} language - Primary Language detected, if provided.
   * @param {string} languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
   * @param {string} speakerId - speaker id for conversation transcription, if provided.
   * @param {string} errorDetails - Error details, if provided.
   * @param {string} json - Additional Json, if provided.
   * @param {PropertyCollection} properties - Additional properties, if provided.
   */
  constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, speakerId, errorDetails, json, properties) {
    super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties);
    this.privSpeakerId = speakerId;
  }
  /**
   * speaker id from conversation transcription/id scenarios
   * @member SpeechRecognitionResult.prototype.speakerId
   * @function
   * @public
   * @returns {string} id of speaker in given result
   */
  get speakerId() {
    return this.privSpeakerId;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechRecognizer: () => (/* binding */ SpeechRecognizer)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};




/**
 * Performs speech recognition from microphone, file, or other audio input streams, and gets transcribed text as result.
 * @class SpeechRecognizer
 */
class SpeechRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {
  /**
   * SpeechRecognizer constructor.
   * @constructor
   * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer
   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
   */
  constructor(speechConfig, audioConfig) {
    const speechConfigImpl = speechConfig;
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(speechConfigImpl, "speechConfig");
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(speechConfigImpl.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage), _Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage]);
    super(audioConfig, speechConfigImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.SpeechConnectionFactory());
    this.privDisposedRecognizer = false;
  }
  /**
   * SpeechRecognizer constructor.
   * @constructor
   * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer
   * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the recognizer
   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
   */
  static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {
    const speechConfigImpl = speechConfig;
    autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);
    const recognizer = new SpeechRecognizer(speechConfig, audioConfig);
    return recognizer;
  }
  /**
   * Gets the endpoint id of a customized speech model that is used for speech recognition.
   * @member SpeechRecognizer.prototype.endpointId
   * @function
   * @public
   * @returns {string} the endpoint id of a customized speech model that is used for speech recognition.
   */
  get endpointId() {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_EndpointId, "00000000-0000-0000-0000-000000000000");
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member SpeechRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * @member SpeechRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @param {string} token - Authorization token.
   */
  set authorizationToken(token) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, token);
  }
  /**
   * Gets the spoken language of recognition.
   * @member SpeechRecognizer.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @returns {string} The spoken language of recognition.
   */
  get speechRecognitionLanguage() {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage);
  }
  /**
   * Gets the output format of recognition.
   * @member SpeechRecognizer.prototype.outputFormat
   * @function
   * @public
   * @returns {OutputFormat} The output format of recognition.
   */
  get outputFormat() {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);
    if (this.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormatPropertyName, _Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat[_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Simple]) === _Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat[_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Simple]) {
      return _Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Simple;
    } else {
      return _Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Detailed;
    }
  }
  /**
   * The collection of properties and their values defined for this SpeechRecognizer.
   * @member SpeechRecognizer.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechRecognizer.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Starts speech recognition, and stops after the first utterance is recognized.
   * The task returns the recognition text as result.
   * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,
   * so it is suitable only for single shot recognition
   * like command or query. For long-running recognition, use StartContinuousRecognitionAsync() instead.
   * @member SpeechRecognizer.prototype.recognizeOnceAsync
   * @function
   * @public
   * @param cb - Callback that received the SpeechRecognitionResult.
   * @param err - Callback invoked in case of an error.
   */
  recognizeOnceAsync(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.recognizeOnceAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.RecognitionMode.Interactive), cb, err);
  }
  /**
   * Starts speech recognition, until stopContinuousRecognitionAsync() is called.
   * User must subscribe to events to receive recognition results.
   * @member SpeechRecognizer.prototype.startContinuousRecognitionAsync
   * @function
   * @public
   * @param cb - Callback invoked once the recognition has started.
   * @param err - Callback invoked in case of an error.
   */
  startContinuousRecognitionAsync(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.RecognitionMode.Conversation), cb, err);
  }
  /**
   * Stops continuous speech recognition.
   * @member SpeechRecognizer.prototype.stopContinuousRecognitionAsync
   * @function
   * @public
   * @param cb - Callback invoked once the recognition has stopped.
   * @param err - Callback invoked in case of an error.
   */
  stopContinuousRecognitionAsync(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);
  }
  /**
   * Starts speech recognition with keyword spotting, until
   * stopKeywordRecognitionAsync() is called.
   * User must subscribe to events to receive recognition results.
   * Note: Key word spotting functionality is only available on the
   * Speech Devices SDK. This functionality is currently not included in the SDK itself.
   * @member SpeechRecognizer.prototype.startKeywordRecognitionAsync
   * @function
   * @public
   * @param {KeywordRecognitionModel} model The keyword recognition model that
   * specifies the keyword to be recognized.
   * @param cb - Callback invoked once the recognition has started.
   * @param err - Callback invoked in case of an error.
   */
  startKeywordRecognitionAsync(model, cb, err) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(model, "model");
    if (!!err) {
      err("Not yet implemented.");
    }
  }
  /**
   * Stops continuous speech recognition.
   * Note: Key word spotting functionality is only available on the
   * Speech Devices SDK. This functionality is currently not included in the SDK itself.
   * @member SpeechRecognizer.prototype.stopKeywordRecognitionAsync
   * @function
   * @public
   * @param cb - Callback invoked once the recognition has stopped.
   * @param err - Callback invoked in case of an error.
   */
  stopKeywordRecognitionAsync(cb) {
    if (!!cb) {
      cb();
    }
  }
  /**
   * closes all external resources held by an instance of this class.
   * @member SpeechRecognizer.prototype.close
   * @function
   * @public
   */
  close(cb, errorCb) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);
  }
  /**
   * Disposes any resources held by the object.
   * @member SpeechRecognizer.prototype.dispose
   * @function
   * @public
   * @param {boolean} disposing - true if disposing the object.
   */
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: {
        get: () => super.dispose
      }
    });
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privDisposedRecognizer) {
        return;
      }
      if (disposing) {
        this.privDisposedRecognizer = true;
        yield this.implRecognizerStop();
      }
      yield _super.dispose.call(this, disposing);
    });
  }
  createRecognizerConfig(speechConfig) {
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.RecognizerConfig(speechConfig, this.privProperties);
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const configImpl = audioConfig;
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__.SpeechServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechSynthesisBookmarkEventArgs: () => (/* binding */ SpeechSynthesisBookmarkEventArgs)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines contents of speech synthesis bookmark event.
 * @class SpeechSynthesisBookmarkEventArgs
 * Added in version 1.16.0
 */
class SpeechSynthesisBookmarkEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {number} audioOffset - The audio offset.
   * @param {string} text - The bookmark text.
   */
  constructor(audioOffset, text) {
    this.privAudioOffset = audioOffset;
    this.privText = text;
  }
  /**
   * Specifies the audio offset.
   * @member SpeechSynthesisBookmarkEventArgs.prototype.audioOffset
   * @function
   * @public
   * @returns {number} the audio offset.
   */
  get audioOffset() {
    return this.privAudioOffset;
  }
  /**
   * Specifies the bookmark.
   * @member SpeechSynthesisBookmarkEventArgs.prototype.text
   * @function
   * @public
   * @returns {string} the bookmark text.
   */
  get text() {
    return this.privText;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBoundaryType.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBoundaryType.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechSynthesisBoundaryType: () => (/* binding */ SpeechSynthesisBoundaryType)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines the boundary type of speech synthesis boundary event.
 * @class SpeechSynthesisBoundaryType
 * Added in version 1.21.0
 */
var SpeechSynthesisBoundaryType;
(function (SpeechSynthesisBoundaryType) {
  /**
   * Indicates the boundary text is a word.
   * @member SpeechSynthesisBoundaryType.Word
   */
  SpeechSynthesisBoundaryType["Word"] = "WordBoundary";
  /**
   * Indicates the boundary text is a punctuation.
   * @member SpeechSynthesisBoundaryType.Punctuation
   */
  SpeechSynthesisBoundaryType["Punctuation"] = "PunctuationBoundary";
  /**
   * Indicates the boundary text is a sentence.
   * @member SpeechSynthesisBoundaryType.Sentence
   */
  SpeechSynthesisBoundaryType["Sentence"] = "SentenceBoundary";
})(SpeechSynthesisBoundaryType || (SpeechSynthesisBoundaryType = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechSynthesisEventArgs: () => (/* binding */ SpeechSynthesisEventArgs)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines contents of speech synthesis events.
 * @class SpeechSynthesisEventArgs
 * Added in version 1.11.0
 */
class SpeechSynthesisEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {SpeechSynthesisResult} result - The speech synthesis result.
   */
  constructor(result) {
    this.privResult = result;
  }
  /**
   * Specifies the synthesis result.
   * @member SpeechSynthesisEventArgs.prototype.result
   * @function
   * @public
   * @returns {SpeechSynthesisResult} the synthesis result.
   */
  get result() {
    return this.privResult;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechSynthesisOutputFormat: () => (/* binding */ SpeechSynthesisOutputFormat)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Define speech synthesis audio output formats.
 * @enum SpeechSynthesisOutputFormat
 * Updated in version 1.17.0
 */
var SpeechSynthesisOutputFormat;
(function (SpeechSynthesisOutputFormat) {
  /**
   * raw-8khz-8bit-mono-mulaw
   * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw,
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw8Khz8BitMonoMULaw"] = 0] = "Raw8Khz8BitMonoMULaw";
  /**
   * riff-16khz-16kbps-mono-siren
   * @note Unsupported by the service. Do not use this value.
   * @member SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff16Khz16KbpsMonoSiren"] = 1] = "Riff16Khz16KbpsMonoSiren";
  /**
   * audio-16khz-16kbps-mono-siren
   * @note Unsupported by the service. Do not use this value.
   * @member SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz16KbpsMonoSiren"] = 2] = "Audio16Khz16KbpsMonoSiren";
  /**
   * audio-16khz-32kbitrate-mono-mp3
   * @member SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz32KBitRateMonoMp3"] = 3] = "Audio16Khz32KBitRateMonoMp3";
  /**
   * audio-16khz-128kbitrate-mono-mp3
   * @member SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz128KBitRateMonoMp3"] = 4] = "Audio16Khz128KBitRateMonoMp3";
  /**
   * audio-16khz-64kbitrate-mono-mp3
   * @member SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz64KBitRateMonoMp3"] = 5] = "Audio16Khz64KBitRateMonoMp3";
  /**
   * audio-24khz-48kbitrate-mono-mp3
   * @member SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio24Khz48KBitRateMonoMp3"] = 6] = "Audio24Khz48KBitRateMonoMp3";
  /**
   * audio-24khz-96kbitrate-mono-mp3
   * @member SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio24Khz96KBitRateMonoMp3"] = 7] = "Audio24Khz96KBitRateMonoMp3";
  /**
   * audio-24khz-160kbitrate-mono-mp3
   * @member SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio24Khz160KBitRateMonoMp3"] = 8] = "Audio24Khz160KBitRateMonoMp3";
  /**
   * raw-16khz-16bit-mono-truesilk
   * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw16Khz16BitMonoTrueSilk"] = 9] = "Raw16Khz16BitMonoTrueSilk";
  /**
   * riff-16khz-16bit-mono-pcm
   * @member SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff16Khz16BitMonoPcm"] = 10] = "Riff16Khz16BitMonoPcm";
  /**
   * riff-8khz-16bit-mono-pcm
   * @member SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff8Khz16BitMonoPcm"] = 11] = "Riff8Khz16BitMonoPcm";
  /**
   * riff-24khz-16bit-mono-pcm
   * @member SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff24Khz16BitMonoPcm"] = 12] = "Riff24Khz16BitMonoPcm";
  /**
   * riff-8khz-8bit-mono-mulaw
   * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff8Khz8BitMonoMULaw"] = 13] = "Riff8Khz8BitMonoMULaw";
  /**
   * raw-16khz-16bit-mono-pcm
   * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw16Khz16BitMonoPcm"] = 14] = "Raw16Khz16BitMonoPcm";
  /**
   * raw-24khz-16bit-mono-pcm
   * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw24Khz16BitMonoPcm"] = 15] = "Raw24Khz16BitMonoPcm";
  /**
   * raw-8khz-16bit-mono-pcm
   * @member SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw8Khz16BitMonoPcm"] = 16] = "Raw8Khz16BitMonoPcm";
  /**
   * ogg-16khz-16bit-mono-opus
   * @member SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Ogg16Khz16BitMonoOpus"] = 17] = "Ogg16Khz16BitMonoOpus";
  /**
   * ogg-24khz-16bit-mono-opus
   * @member SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Ogg24Khz16BitMonoOpus"] = 18] = "Ogg24Khz16BitMonoOpus";
  /**
   * raw-48khz-16bit-mono-pcm
   * @member SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw48Khz16BitMonoPcm"] = 19] = "Raw48Khz16BitMonoPcm";
  /**
   * riff-48khz-16bit-mono-pcm
   * @member SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff48Khz16BitMonoPcm"] = 20] = "Riff48Khz16BitMonoPcm";
  /**
   * audio-48khz-96kbitrate-mono-mp3
   * @member SpeechSynthesisOutputFormat.Audio48Khz96KBitRateMonoMp3
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio48Khz96KBitRateMonoMp3"] = 21] = "Audio48Khz96KBitRateMonoMp3";
  /**
   * audio-48khz-192kbitrate-mono-mp3
   * @member SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio48Khz192KBitRateMonoMp3"] = 22] = "Audio48Khz192KBitRateMonoMp3";
  /**
   * ogg-48khz-16bit-mono-opus
   * Added in version 1.16.0
   * @member SpeechSynthesisOutputFormat.Ogg48Khz16BitMonoOpus
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Ogg48Khz16BitMonoOpus"] = 23] = "Ogg48Khz16BitMonoOpus";
  /**
   * webm-16khz-16bit-mono-opus
   * Added in version 1.16.0
   * @member SpeechSynthesisOutputFormat.Webm16Khz16BitMonoOpus
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Webm16Khz16BitMonoOpus"] = 24] = "Webm16Khz16BitMonoOpus";
  /**
   * webm-24khz-16bit-mono-opus
   * Added in version 1.16.0
   * @member SpeechSynthesisOutputFormat.Webm24Khz16BitMonoOpus
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Webm24Khz16BitMonoOpus"] = 25] = "Webm24Khz16BitMonoOpus";
  /**
   * raw-24khz-16bit-mono-truesilk
   * Added in version 1.17.0
   * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoTrueSilk
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw24Khz16BitMonoTrueSilk"] = 26] = "Raw24Khz16BitMonoTrueSilk";
  /**
   * raw-8khz-8bit-mono-alaw
   * Added in version 1.17.0
   * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoALaw
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw8Khz8BitMonoALaw"] = 27] = "Raw8Khz8BitMonoALaw";
  /**
   * riff-8khz-8bit-mono-alaw
   * Added in version 1.17.0
   * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoALaw
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff8Khz8BitMonoALaw"] = 28] = "Riff8Khz8BitMonoALaw";
  /**
   * webm-24khz-16bit-24kbps-mono-opus
   * Audio compressed by OPUS codec in a webm container, with bitrate of 24kbps, optimized for IoT scenario.
   * Added in version 1.19.0
   * @member SpeechSynthesisOutputFormat.Webm24Khz16Bit24KbpsMonoOpus
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Webm24Khz16Bit24KbpsMonoOpus"] = 29] = "Webm24Khz16Bit24KbpsMonoOpus";
  /**
   * audio-16khz-16bit-32kbps-mono-opus
   * Audio compressed by OPUS codec without container, with bitrate of 32kbps.
   * Added in version 1.20.0
   * @member SpeechSynthesisOutputFormat.Audio16Khz16Bit32KbpsMonoOpus
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz16Bit32KbpsMonoOpus"] = 30] = "Audio16Khz16Bit32KbpsMonoOpus";
  /**
   * audio-24khz-16bit-48kbps-mono-opus
   * Audio compressed by OPUS codec without container, with bitrate of 48kbps.
   * Added in version 1.20.0
   * @member SpeechSynthesisOutputFormat.Audio24Khz16Bit48KbpsMonoOpus
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio24Khz16Bit48KbpsMonoOpus"] = 31] = "Audio24Khz16Bit48KbpsMonoOpus";
  /**
   * audio-24khz-16bit-24kbps-mono-opus
   * Audio compressed by OPUS codec without container, with bitrate of 24kbps.
   * Added in version 1.20.0
   * @member SpeechSynthesisOutputFormat.Audio24Khz16Bit24KbpsMonoOpus
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio24Khz16Bit24KbpsMonoOpus"] = 32] = "Audio24Khz16Bit24KbpsMonoOpus";
  /**
   * raw-22050hz-16bit-mono-pcm
   * Raw PCM audio at 22050Hz sampling rate and 16-bit depth.
   * Added in version 1.22.0
   * @member SpeechSynthesisOutputFormat.Raw22050Hz16BitMonoPcm
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw22050Hz16BitMonoPcm"] = 33] = "Raw22050Hz16BitMonoPcm";
  /**
   * riff-22050hz-16bit-mono-pcm
   * PCM audio at 22050Hz sampling rate and 16-bit depth, with RIFF header.
   * Added in version 1.22.0
   * @member SpeechSynthesisOutputFormat.Riff22050Hz16BitMonoPcm
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff22050Hz16BitMonoPcm"] = 34] = "Riff22050Hz16BitMonoPcm";
  /**
   * raw-44100hz-16bit-mono-pcm
   * Raw PCM audio at 44100Hz sampling rate and 16-bit depth.
   * Added in version 1.22.0
   * @member SpeechSynthesisOutputFormat.Raw44100Hz16BitMonoPcm
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw44100Hz16BitMonoPcm"] = 35] = "Raw44100Hz16BitMonoPcm";
  /**
   * riff-44100hz-16bit-mono-pcm
   * PCM audio at 44100Hz sampling rate and 16-bit depth, with RIFF header.
   * Added in version 1.22.0
   * @member SpeechSynthesisOutputFormat.Riff44100Hz16BitMonoPcm
   */
  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff44100Hz16BitMonoPcm"] = 36] = "Riff44100Hz16BitMonoPcm";
})(SpeechSynthesisOutputFormat || (SpeechSynthesisOutputFormat = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechSynthesisResult: () => (/* binding */ SpeechSynthesisResult)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Defines result of speech synthesis.
 * @class SpeechSynthesisResult
 * Added in version 1.11.0
 */
class SpeechSynthesisResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SynthesisResult {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} resultId - The result id.
   * @param {ResultReason} reason - The reason.
   * @param {ArrayBuffer} audioData - The synthesized audio binary.
   * @param {string} errorDetails - Error details, if provided.
   * @param {PropertyCollection} properties - Additional properties, if provided.
   * @param {number} audioDuration - The audio duration.
   */
  constructor(resultId, reason, audioData, errorDetails, properties, audioDuration) {
    super(resultId, reason, errorDetails, properties);
    this.privAudioData = audioData;
    this.privAudioDuration = audioDuration;
  }
  /**
   * The synthesized audio data
   * @member SpeechSynthesisResult.prototype.audioData
   * @function
   * @public
   * @returns {ArrayBuffer} The synthesized audio data.
   */
  get audioData() {
    return this.privAudioData;
  }
  /**
   * The time duration of synthesized audio, in ticks (100 nanoseconds).
   * @member SpeechSynthesisResult.prototype.audioDuration
   * @function
   * @public
   * @returns {number} The time duration of synthesized audio.
   */
  get audioDuration() {
    return this.privAudioDuration;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechSynthesisVisemeEventArgs: () => (/* binding */ SpeechSynthesisVisemeEventArgs)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines contents of speech synthesis viseme event.
 * @class SpeechSynthesisVisemeEventArgs
 * Added in version 1.16.0
 */
class SpeechSynthesisVisemeEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {number} audioOffset - The audio offset.
   * @param {number} visemeId - The viseme ID.
   * @param {string} animation - The animation, could be in svg or other format.
   */
  constructor(audioOffset, visemeId, animation) {
    this.privAudioOffset = audioOffset;
    this.privVisemeId = visemeId;
    this.privAnimation = animation;
  }
  /**
   * Specifies the audio offset.
   * @member SpeechSynthesisVisemeEventArgs.prototype.audioOffset
   * @function
   * @public
   * @returns {number} the audio offset.
   */
  get audioOffset() {
    return this.privAudioOffset;
  }
  /**
   * Specifies the viseme ID.
   * @member SpeechSynthesisVisemeEventArgs.prototype.visemeId
   * @function
   * @public
   * @returns {number} the viseme ID.
   */
  get visemeId() {
    return this.privVisemeId;
  }
  /**
   * Specifies the animation.
   * @member SpeechSynthesisVisemeEventArgs.prototype.animation
   * @function
   * @public
   * @returns {string} the animation, could be in svg or other format.
   */
  get animation() {
    return this.privAnimation;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechSynthesisWordBoundaryEventArgs: () => (/* binding */ SpeechSynthesisWordBoundaryEventArgs)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines contents of speech synthesis word boundary event.
 * @class SpeechSynthesisWordBoundaryEventArgs
 * Added in version 1.11.0
 */
class SpeechSynthesisWordBoundaryEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {number} audioOffset - The audio offset.
   * @param {number} duration - The audio duration.
   * @param {string} text - The text.
   * @param {number} wordLength - The length of the word.
   * @param {number} textOffset - The text offset.
   * @param {SpeechSynthesisBoundaryType} boundaryType - The boundary type
   */
  constructor(audioOffset, duration, text, wordLength, textOffset, boundaryType) {
    this.privAudioOffset = audioOffset;
    this.privDuration = duration;
    this.privText = text;
    this.privWordLength = wordLength;
    this.privTextOffset = textOffset;
    this.privBoundaryType = boundaryType;
  }
  /**
   * Specifies the audio offset.
   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.audioOffset
   * @function
   * @public
   * @returns {number} the audio offset.
   */
  get audioOffset() {
    return this.privAudioOffset;
  }
  /**
   * Specifies the duration, in ticks (100 nanoseconds).
   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.duration
   * @function
   * @public
   * @returns {number} Duration in 100 nanosecond increments.
   */
  get duration() {
    return this.privDuration;
  }
  /**
   * Specifies the text of the word boundary event.
   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.text
   * @function
   * @public
   * @returns {string} the text.
   */
  get text() {
    return this.privText;
  }
  /**
   * Specifies the word length
   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.wordLength
   * @function
   * @public
   * @returns {number} the word length
   */
  get wordLength() {
    return this.privWordLength;
  }
  /**
   * Specifies the text offset.
   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.textOffset
   * @function
   * @public
   * @returns {number} the text offset.
   */
  get textOffset() {
    return this.privTextOffset;
  }
  /**
   * Specifies the boundary type.
   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.boundaryType
   * @function
   * @public
   * @returns {SpeechSynthesisBoundaryType} the boundary type.
   */
  get boundaryType() {
    return this.privBoundaryType;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechSynthesizer: () => (/* binding */ SpeechSynthesizer),
/* harmony export */   SynthesisRequest: () => (/* binding */ SynthesisRequest)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js");
/* harmony import */ var _Audio_AudioFileWriter__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./Audio/AudioFileWriter */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js");
/* harmony import */ var _Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Audio/AudioOutputFormat */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js");
/* harmony import */ var _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js");
/* eslint-disable @typescript-eslint/no-empty-function */
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};







/**
 * Defines the class SpeechSynthesizer for text to speech.
 * Updated in version 1.16.0
 * @class SpeechSynthesizer
 */
class SpeechSynthesizer {
  /**
   * SpeechSynthesizer constructor.
   * @constructor
   * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer.
   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer.
   */
  constructor(speechConfig, audioConfig) {
    const speechConfigImpl = speechConfig;
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(speechConfigImpl, "speechConfig");
    if (audioConfig !== null) {
      if (audioConfig === undefined) {
        this.audioConfig = typeof window === "undefined" ? undefined : _Exports__WEBPACK_IMPORTED_MODULE_1__.AudioConfig.fromDefaultSpeakerOutput();
      } else {
        this.audioConfig = audioConfig;
      }
    }
    this.privProperties = speechConfigImpl.properties.clone();
    this.privDisposed = false;
    this.privSynthesizing = false;
    this.privConnectionFactory = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisConnectionFactory();
    this.synthesisRequestQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.Queue();
    this.implCommonSynthesizeSetup();
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member SpeechSynthesizer.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * @member SpeechSynthesizer.prototype.authorizationToken
   * @function
   * @public
   * @param {string} token - Authorization token.
   */
  set authorizationToken(token) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceAuthorization_Token, token);
  }
  /**
   * The collection of properties and their values defined for this SpeechSynthesizer.
   * @member SpeechSynthesizer.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechSynthesizer.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Indicates if auto detect source language is enabled
   * @member SpeechSynthesizer.prototype.properties
   * @function
   * @public
   * @returns {boolean} if auto detect source language is enabled
   */
  get autoDetectSourceLanguage() {
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages) === _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.AutoDetectSourceLanguagesOpenRangeOptionName;
  }
  /**
   * SpeechSynthesizer constructor.
   * @constructor
   * @param {SpeechConfig} speechConfig - an set of initial properties for this synthesizer
   * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the synthesizer
   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer
   */
  static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {
    const speechConfigImpl = speechConfig;
    autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);
    return new SpeechSynthesizer(speechConfig, audioConfig);
  }
  buildSsml(text) {
    const languageToDefaultVoice = {
      ["af-ZA"]: "af-ZA-AdriNeural",
      ["am-ET"]: "am-ET-AmehaNeural",
      ["ar-AE"]: "ar-AE-FatimaNeural",
      ["ar-BH"]: "ar-BH-AliNeural",
      ["ar-DZ"]: "ar-DZ-AminaNeural",
      ["ar-EG"]: "ar-EG-SalmaNeural",
      ["ar-IQ"]: "ar-IQ-BasselNeural",
      ["ar-JO"]: "ar-JO-SanaNeural",
      ["ar-KW"]: "ar-KW-FahedNeural",
      ["ar-LY"]: "ar-LY-ImanNeural",
      ["ar-MA"]: "ar-MA-JamalNeural",
      ["ar-QA"]: "ar-QA-AmalNeural",
      ["ar-SA"]: "ar-SA-HamedNeural",
      ["ar-SY"]: "ar-SY-AmanyNeural",
      ["ar-TN"]: "ar-TN-HediNeural",
      ["ar-YE"]: "ar-YE-MaryamNeural",
      ["bg-BG"]: "bg-BG-BorislavNeural",
      ["bn-BD"]: "bn-BD-NabanitaNeural",
      ["bn-IN"]: "bn-IN-BashkarNeural",
      ["ca-ES"]: "ca-ES-JoanaNeural",
      ["cs-CZ"]: "cs-CZ-AntoninNeural",
      ["cy-GB"]: "cy-GB-AledNeural",
      ["da-DK"]: "da-DK-ChristelNeural",
      ["de-AT"]: "de-AT-IngridNeural",
      ["de-CH"]: "de-CH-JanNeural",
      ["de-DE"]: "de-DE-KatjaNeural",
      ["el-GR"]: "el-GR-AthinaNeural",
      ["en-AU"]: "en-AU-NatashaNeural",
      ["en-CA"]: "en-CA-ClaraNeural",
      ["en-GB"]: "en-GB-LibbyNeural",
      ["en-HK"]: "en-HK-SamNeural",
      ["en-IE"]: "en-IE-ConnorNeural",
      ["en-IN"]: "en-IN-NeerjaNeural",
      ["en-KE"]: "en-KE-AsiliaNeural",
      ["en-NG"]: "en-NG-AbeoNeural",
      ["en-NZ"]: "en-NZ-MitchellNeural",
      ["en-PH"]: "en-PH-JamesNeural",
      ["en-SG"]: "en-SG-LunaNeural",
      ["en-TZ"]: "en-TZ-ElimuNeural",
      ["en-US"]: "en-US-JennyNeural",
      ["en-ZA"]: "en-ZA-LeahNeural",
      ["es-AR"]: "es-AR-ElenaNeural",
      ["es-BO"]: "es-BO-MarceloNeural",
      ["es-CL"]: "es-CL-CatalinaNeural",
      ["es-CO"]: "es-CO-GonzaloNeural",
      ["es-CR"]: "es-CR-JuanNeural",
      ["es-CU"]: "es-CU-BelkysNeural",
      ["es-DO"]: "es-DO-EmilioNeural",
      ["es-EC"]: "es-EC-AndreaNeural",
      ["es-ES"]: "es-ES-AlvaroNeural",
      ["es-GQ"]: "es-GQ-JavierNeural",
      ["es-GT"]: "es-GT-AndresNeural",
      ["es-HN"]: "es-HN-CarlosNeural",
      ["es-MX"]: "es-MX-DaliaNeural",
      ["es-NI"]: "es-NI-FedericoNeural",
      ["es-PA"]: "es-PA-MargaritaNeural",
      ["es-PE"]: "es-PE-AlexNeural",
      ["es-PR"]: "es-PR-KarinaNeural",
      ["es-PY"]: "es-PY-MarioNeural",
      ["es-SV"]: "es-SV-LorenaNeural",
      ["es-US"]: "es-US-AlonsoNeural",
      ["es-UY"]: "es-UY-MateoNeural",
      ["es-VE"]: "es-VE-PaolaNeural",
      ["et-EE"]: "et-EE-AnuNeural",
      ["fa-IR"]: "fa-IR-DilaraNeural",
      ["fi-FI"]: "fi-FI-SelmaNeural",
      ["fil-PH"]: "fil-PH-AngeloNeural",
      ["fr-BE"]: "fr-BE-CharlineNeural",
      ["fr-CA"]: "fr-CA-SylvieNeural",
      ["fr-CH"]: "fr-CH-ArianeNeural",
      ["fr-FR"]: "fr-FR-DeniseNeural",
      ["ga-IE"]: "ga-IE-ColmNeural",
      ["gl-ES"]: "gl-ES-RoiNeural",
      ["gu-IN"]: "gu-IN-DhwaniNeural",
      ["he-IL"]: "he-IL-AvriNeural",
      ["hi-IN"]: "hi-IN-MadhurNeural",
      ["hr-HR"]: "hr-HR-GabrijelaNeural",
      ["hu-HU"]: "hu-HU-NoemiNeural",
      ["id-ID"]: "id-ID-ArdiNeural",
      ["is-IS"]: "is-IS-GudrunNeural",
      ["it-IT"]: "it-IT-IsabellaNeural",
      ["ja-JP"]: "ja-JP-NanamiNeural",
      ["jv-ID"]: "jv-ID-DimasNeural",
      ["kk-KZ"]: "kk-KZ-AigulNeural",
      ["km-KH"]: "km-KH-PisethNeural",
      ["kn-IN"]: "kn-IN-GaganNeural",
      ["ko-KR"]: "ko-KR-SunHiNeural",
      ["lo-LA"]: "lo-LA-ChanthavongNeural",
      ["lt-LT"]: "lt-LT-LeonasNeural",
      ["lv-LV"]: "lv-LV-EveritaNeural",
      ["mk-MK"]: "mk-MK-AleksandarNeural",
      ["ml-IN"]: "ml-IN-MidhunNeural",
      ["mr-IN"]: "mr-IN-AarohiNeural",
      ["ms-MY"]: "ms-MY-OsmanNeural",
      ["mt-MT"]: "mt-MT-GraceNeural",
      ["my-MM"]: "my-MM-NilarNeural",
      ["nb-NO"]: "nb-NO-PernilleNeural",
      ["nl-BE"]: "nl-BE-ArnaudNeural",
      ["nl-NL"]: "nl-NL-ColetteNeural",
      ["pl-PL"]: "pl-PL-AgnieszkaNeural",
      ["ps-AF"]: "ps-AF-GulNawazNeural",
      ["pt-BR"]: "pt-BR-FranciscaNeural",
      ["pt-PT"]: "pt-PT-DuarteNeural",
      ["ro-RO"]: "ro-RO-AlinaNeural",
      ["ru-RU"]: "ru-RU-SvetlanaNeural",
      ["si-LK"]: "si-LK-SameeraNeural",
      ["sk-SK"]: "sk-SK-LukasNeural",
      ["sl-SI"]: "sl-SI-PetraNeural",
      ["so-SO"]: "so-SO-MuuseNeural",
      ["sr-RS"]: "sr-RS-NicholasNeural",
      ["su-ID"]: "su-ID-JajangNeural",
      ["sv-SE"]: "sv-SE-SofieNeural",
      ["sw-KE"]: "sw-KE-RafikiNeural",
      ["sw-TZ"]: "sw-TZ-DaudiNeural",
      ["ta-IN"]: "ta-IN-PallaviNeural",
      ["ta-LK"]: "ta-LK-KumarNeural",
      ["ta-SG"]: "ta-SG-AnbuNeural",
      ["te-IN"]: "te-IN-MohanNeural",
      ["th-TH"]: "th-TH-PremwadeeNeural",
      ["tr-TR"]: "tr-TR-AhmetNeural",
      ["uk-UA"]: "uk-UA-OstapNeural",
      ["ur-IN"]: "ur-IN-GulNeural",
      ["ur-PK"]: "ur-PK-AsadNeural",
      ["uz-UZ"]: "uz-UZ-MadinaNeural",
      ["vi-VN"]: "vi-VN-HoaiMyNeural",
      ["zh-CN"]: "zh-CN-XiaoxiaoNeural",
      ["zh-HK"]: "zh-HK-HiuMaanNeural",
      ["zh-TW"]: "zh-TW-HsiaoChenNeural",
      ["zu-ZA"]: "zu-ZA-ThandoNeural"
    };
    let language = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceConnection_SynthLanguage, "en-US");
    let voice = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceConnection_SynthVoice, "");
    let ssml = SpeechSynthesizer.XMLEncode(text);
    if (this.autoDetectSourceLanguage) {
      language = "en-US";
    } else {
      voice = voice || languageToDefaultVoice[language];
    }
    if (voice) {
      ssml = `<voice name='${voice}'>${ssml}</voice>`;
    }
    ssml = `<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts' xmlns:emo='http://www.w3.org/2009/10/emotionml' xml:lang='${language}'>${ssml}</speak>`;
    return ssml;
  }
  /**
   * Executes speech synthesis on plain text.
   * The task returns the synthesis result.
   * @member SpeechSynthesizer.prototype.speakTextAsync
   * @function
   * @public
   * @param text - Text to be synthesized.
   * @param cb - Callback that received the SpeechSynthesisResult.
   * @param err - Callback invoked in case of an error.
   * @param stream - AudioOutputStream to receive the synthesized audio.
   */
  speakTextAsync(text, cb, err, stream) {
    this.speakImpl(text, false, cb, err, stream);
  }
  /**
   * Executes speech synthesis on SSML.
   * The task returns the synthesis result.
   * @member SpeechSynthesizer.prototype.speakSsmlAsync
   * @function
   * @public
   * @param ssml - SSML to be synthesized.
   * @param cb - Callback that received the SpeechSynthesisResult.
   * @param err - Callback invoked in case of an error.
   * @param stream - AudioOutputStream to receive the synthesized audio.
   */
  speakSsmlAsync(ssml, cb, err, stream) {
    this.speakImpl(ssml, true, cb, err, stream);
  }
  /**
   * Get list of synthesis voices available.
   * The task returns the synthesis voice result.
   * @member SpeechSynthesizer.prototype.getVoicesAsync
   * @function
   * @async
   * @public
   * @param locale - Locale of voices in BCP-47 format; if left empty, get all available voices.
   * @return {Promise<SynthesisVoicesResult>} - Promise of a SynthesisVoicesResult.
   */
  getVoicesAsync(locale = "") {
    return __awaiter(this, void 0, void 0, function* () {
      return this.getVoices(locale);
    });
  }
  /**
   * Dispose of associated resources.
   * @member SpeechSynthesizer.prototype.close
   * @function
   * @public
   */
  close(cb, err) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privDisposed);
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.dispose(true), cb, err);
  }
  /**
   * @Internal
   * Do not use externally, object returned will change without warning or notice.
   */
  get internalData() {
    return this.privAdapter;
  }
  /**
   * This method performs cleanup of resources.
   * The Boolean parameter disposing indicates whether the method is called
   * from Dispose (if disposing is true) or from the finalizer (if disposing is false).
   * Derived classes should override this method to dispose resource if needed.
   * @member SpeechSynthesizer.prototype.dispose
   * @function
   * @public
   * @param {boolean} disposing - Flag to request disposal.
   */
  dispose(disposing) {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privDisposed) {
        return;
      }
      if (disposing) {
        if (this.privAdapter) {
          yield this.privAdapter.dispose();
        }
      }
      this.privDisposed = true;
    });
  }
  //
  // ################################################################################################################
  // IMPLEMENTATION.
  // Move to independent class
  // ################################################################################################################
  //
  createSynthesizerConfig(speechConfig) {
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.SynthesizerConfig(speechConfig, this.privProperties);
  }
  // Creates the synthesis adapter
  createSynthesisAdapter(authentication, connectionFactory, audioConfig, synthesizerConfig) {
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__.SynthesisAdapterBase(authentication, connectionFactory, synthesizerConfig, this, this.audioConfig);
  }
  implCommonSynthesizeSetup() {
    let osPlatform = typeof window !== "undefined" ? "Browser" : "Node";
    let osName = "unknown";
    let osVersion = "unknown";
    if (typeof navigator !== "undefined") {
      osPlatform = osPlatform + "/" + navigator.platform;
      osName = navigator.userAgent;
      osVersion = navigator.appVersion;
    }
    const synthesizerConfig = this.createSynthesizerConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechServiceConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__.Context(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__.OS(osPlatform, osName, osVersion))));
    const subscriptionKey = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceConnection_Key, undefined);
    const authentication = subscriptionKey && subscriptionKey !== "" ? new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_10__.CognitiveSubscriptionKeyAuthentication(subscriptionKey) : new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_11__.CognitiveTokenAuthentication(() => {
      const authorizationToken = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceAuthorization_Token, undefined);
      return Promise.resolve(authorizationToken);
    }, () => {
      const authorizationToken = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceAuthorization_Token, undefined);
      return Promise.resolve(authorizationToken);
    });
    this.privAdapter = this.createSynthesisAdapter(authentication, this.privConnectionFactory, this.audioConfig, synthesizerConfig);
    this.privAdapter.audioOutputFormat = _Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_12__.AudioOutputFormatImpl.fromSpeechSynthesisOutputFormat(_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechSynthesisOutputFormat[this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)]);
    this.privRestAdapter = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_14__.SynthesisRestAdapter(synthesizerConfig, authentication);
  }
  speakImpl(text, IsSsml, cb, err, dataStream) {
    try {
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privDisposed);
      const requestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_15__.createNoDashGuid)();
      let audioDestination;
      if (dataStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_16__.PushAudioOutputStreamCallback) {
        audioDestination = new _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_17__.PushAudioOutputStreamImpl(dataStream);
      } else if (dataStream instanceof _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_17__.PullAudioOutputStream) {
        audioDestination = dataStream;
      } else if (dataStream !== undefined) {
        audioDestination = new _Audio_AudioFileWriter__WEBPACK_IMPORTED_MODULE_18__.AudioFileWriter(dataStream);
      } else {
        audioDestination = undefined;
      }
      this.synthesisRequestQueue.enqueue(new SynthesisRequest(requestId, text, IsSsml, e => {
        this.privSynthesizing = false;
        if (!!cb) {
          try {
            cb(e);
          } catch (e) {
            if (!!err) {
              err(e);
            }
          }
        }
        cb = undefined;
        /* eslint-disable no-empty */
        this.adapterSpeak().catch(() => {});
      }, e => {
        if (!!err) {
          err(e);
        }
      }, audioDestination));
      /* eslint-disable no-empty-function */
      this.adapterSpeak().catch(() => {});
    } catch (error) {
      if (!!err) {
        if (error instanceof Error) {
          const typedError = error;
          err(typedError.name + ": " + typedError.message);
        } else {
          err(error);
        }
      }
      // Destroy the synthesizer.
      /* eslint-disable no-empty */
      this.dispose(true).catch(() => {});
    }
  }
  getVoices(locale) {
    return __awaiter(this, void 0, void 0, function* () {
      const requestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_15__.createNoDashGuid)();
      const response = yield this.privRestAdapter.getVoicesList(requestId);
      if (response.ok && Array.isArray(response.json)) {
        let json = response.json;
        if (!!locale && locale.length > 0) {
          json = json.filter(item => !!item.Locale && item.Locale.toLowerCase() === locale.toLowerCase());
        }
        return new _Exports__WEBPACK_IMPORTED_MODULE_19__.SynthesisVoicesResult(requestId, json, undefined);
      } else {
        return new _Exports__WEBPACK_IMPORTED_MODULE_19__.SynthesisVoicesResult(requestId, undefined, `Error: ${response.status}: ${response.statusText}`);
      }
    });
  }
  adapterSpeak() {
    return __awaiter(this, void 0, void 0, function* () {
      if (!this.privDisposed && !this.privSynthesizing) {
        this.privSynthesizing = true;
        const request = yield this.synthesisRequestQueue.dequeue();
        return this.privAdapter.Speak(request.text, request.isSSML, request.requestId, request.cb, request.err, request.dataStream);
      }
    });
  }
  static XMLEncode(text) {
    return text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;").replace(/"/g, "&quot;").replace(/'/g, "&apos;");
  }
}
class SynthesisRequest {
  constructor(requestId, text, isSSML, cb, err, dataStream) {
    this.requestId = requestId;
    this.text = text;
    this.isSSML = isSSML;
    this.cb = cb;
    this.err = err;
    this.dataStream = dataStream;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SpeechTranslationConfig: () => (/* binding */ SpeechTranslationConfig),
/* harmony export */   SpeechTranslationConfigImpl: () => (/* binding */ SpeechTranslationConfigImpl)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */



/**
 * Speech translation configuration.
 * @class SpeechTranslationConfig
 */
class SpeechTranslationConfig extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechConfig {
  /**
   * Creates an instance of recognizer config.
   */
  constructor() {
    super();
  }
  /**
   * Static instance of SpeechTranslationConfig returned by passing a subscription key and service region.
   * @member SpeechTranslationConfig.fromSubscription
   * @function
   * @public
   * @param {string} subscriptionKey - The subscription key.
   * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {SpeechTranslationConfig} The speech translation config.
   */
  static fromSubscription(subscriptionKey, region) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(subscriptionKey, "subscriptionKey");
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(region, "region");
    const ret = new SpeechTranslationConfigImpl();
    ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region, region);
    return ret;
  }
  /**
   * Static instance of SpeechTranslationConfig returned by passing authorization token and service region.
   * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
   * expires, the caller needs to refresh it by setting the property authorizationToken with a new
   * valid token. Otherwise, all the recognizers created by this SpeechTranslationConfig instance
   * will encounter errors during recognition.
   * As configuration values are copied when creating a new recognizer, the new token value will not apply
   * to recognizers that have already been created.
   * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
   * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
   * @member SpeechTranslationConfig.fromAuthorizationToken
   * @function
   * @public
   * @param {string} authorizationToken - The authorization token.
   * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {SpeechTranslationConfig} The speech translation config.
   */
  static fromAuthorizationToken(authorizationToken, region) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(authorizationToken, "authorizationToken");
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(region, "region");
    const ret = new SpeechTranslationConfigImpl();
    ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, authorizationToken);
    ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region, region);
    return ret;
  }
  /**
   * Creates an instance of the speech config with specified host and subscription key.
   * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.
   * For services with a non-standard resource path or no path at all, use fromEndpoint instead.
   * Note: Query parameters are not allowed in the host URI and must be set by other APIs.
   * Note: To use an authorization token with fromHost, use fromHost(URL),
   * and then set the AuthorizationToken property on the created SpeechConfig instance.
   * Note: Added in version 1.9.0.
   * @member SpeechConfig.fromHost
   * @function
   * @public
   * @param {URL} host - The service endpoint to connect to. Format is "protocol://host:port" where ":port" is optional.
   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.
   * @returns {SpeechConfig} A speech factory instance.
   */
  static fromHost(hostName, subscriptionKey) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(hostName, "hostName");
    const speechImpl = new SpeechTranslationConfigImpl();
    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Host, hostName.protocol + "//" + hostName.hostname + (hostName.port === "" ? "" : ":" + hostName.port));
    if (undefined !== subscriptionKey) {
      speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    }
    return speechImpl;
  }
  /**
   * Creates an instance of the speech translation config with specified endpoint and subscription key.
   * This method is intended only for users who use a non-standard service endpoint or paramters.
   * Note: The query properties specified in the endpoint URL are not changed, even if they are
   * set by any other APIs. For example, if language is defined in the uri as query parameter
   * "language=de-DE", and also set by the speechRecognitionLanguage property, the language
   * setting in uri takes precedence, and the effective language is "de-DE".
   * Only the properties that are not specified in the endpoint URL can be set by other APIs.
   * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the
   * fromEndpoint method, and then set authorizationToken="token" on the created SpeechConfig instance to
   * use the authorization token.
   * @member SpeechTranslationConfig.fromEndpoint
   * @function
   * @public
   * @param {URL} endpoint - The service endpoint to connect to.
   * @param {string} subscriptionKey - The subscription key.
   * @returns {SpeechTranslationConfig} A speech config instance.
   */
  static fromEndpoint(endpoint, subscriptionKey) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(endpoint, "endpoint");
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(subscriptionKey, "subscriptionKey");
    const ret = new SpeechTranslationConfigImpl();
    ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Endpoint, endpoint.href);
    ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    return ret;
  }
}
/**
 * @private
 * @class SpeechTranslationConfigImpl
 */
class SpeechTranslationConfigImpl extends SpeechTranslationConfig {
  constructor() {
    super();
    this.privSpeechProperties = new _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyCollection();
    this.outputFormat = _Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat.Simple;
  }
  /**
   * Gets/Sets the authorization token.
   * If this is set, subscription key is ignored.
   * User needs to make sure the provided authorization token is valid and not expired.
   * @member SpeechTranslationConfigImpl.prototype.authorizationToken
   * @function
   * @public
   * @param {string} value - The authorization token.
   */
  set authorizationToken(value) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(value, "value");
    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, value);
  }
  /**
   * Sets the speech recognition language.
   * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @param {string} value - The authorization token.
   */
  set speechRecognitionLanguage(value) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(value, "value");
    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage, value);
  }
  /**
   * Gets the speech recognition language.
   * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @return {string} The speechRecognitionLanguage.
   */
  get speechRecognitionLanguage() {
    return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage]);
  }
  /**
   * @member SpeechTranslationConfigImpl.prototype.subscriptionKey
   * @function
   * @public
   */
  get subscriptionKey() {
    return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key]);
  }
  /**
   * Gets the output format
   * @member SpeechTranslationConfigImpl.prototype.outputFormat
   * @function
   * @public
   */
  get outputFormat() {
    // eslint-disable-next-line
    return _Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat[this.privSpeechProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormatPropertyName, undefined)];
  }
  /**
   * Gets/Sets the output format
   * @member SpeechTranslationConfigImpl.prototype.outputFormat
   * @function
   * @public
   */
  set outputFormat(value) {
    this.privSpeechProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormatPropertyName, _Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat[value]);
  }
  /**
   * Gets the endpoint id.
   * @member SpeechTranslationConfigImpl.prototype.endpointId
   * @function
   * @public
   */
  get endpointId() {
    return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_EndpointId);
  }
  /**
   * Gets/Sets the endpoint id.
   * @member SpeechTranslationConfigImpl.prototype.endpointId
   * @function
   * @public
   */
  set endpointId(value) {
    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_EndpointId, value);
  }
  /**
   * Add a (text) target language to translate into.
   * @member SpeechTranslationConfigImpl.prototype.addTargetLanguage
   * @function
   * @public
   * @param {string} value - The language such as de-DE
   */
  addTargetLanguage(value) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(value, "value");
    const languages = this.targetLanguages;
    languages.push(value);
    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(","));
  }
  /**
   * Gets the (text) target language to translate into.
   * @member SpeechTranslationConfigImpl.prototype.targetLanguages
   * @function
   * @public
   * @param {string} value - The language such as de-DE
   */
  get targetLanguages() {
    if (this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {
      return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(",");
    } else {
      return [];
    }
  }
  /**
   * Gets the voice name.
   * @member SpeechTranslationConfigImpl.prototype.voiceName
   * @function
   * @public
   */
  get voiceName() {
    return this.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_TranslationVoice]);
  }
  /**
   * Gets/Sets the voice of the translated language, enable voice synthesis output.
   * @member SpeechTranslationConfigImpl.prototype.voiceName
   * @function
   * @public
   * @param {string} value - The name of the voice.
   */
  set voiceName(value) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(value, "value");
    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_TranslationVoice, value);
  }
  /**
   * Provides the region.
   * @member SpeechTranslationConfigImpl.prototype.region
   * @function
   * @public
   * @returns {string} The region.
   */
  get region() {
    return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region);
  }
  setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyHostName], proxyHostName);
    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyPort], proxyPort);
    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyUserName], proxyUserName);
    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyPassword], proxyPassword);
  }
  /**
   * Gets an arbitrary property value.
   * @member SpeechTranslationConfigImpl.prototype.getProperty
   * @function
   * @public
   * @param {string} name - The name of the property.
   * @param {string} def - The default value of the property in case it is not set.
   * @returns {string} The value of the property.
   */
  getProperty(name, def) {
    return this.privSpeechProperties.getProperty(name, def);
  }
  /**
   * Gets/Sets an arbitrary property value.
   * @member SpeechTranslationConfigImpl.prototype.setProperty
   * @function
   * @public
   * @param {string | PropertyId} name - The name of the property to set.
   * @param {string} value - The value of the property.
   */
  setProperty(name, value) {
    this.privSpeechProperties.setProperty(name, value);
  }
  /**
   * Provides access to custom properties.
   * @member SpeechTranslationConfigImpl.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The properties.
   */
  get properties() {
    return this.privSpeechProperties;
  }
  /**
   * Dispose of associated resources.
   * @member SpeechTranslationConfigImpl.prototype.close
   * @function
   * @public
   */
  close() {
    return;
  }
  setServiceProperty(name, value) {
    const currentProperties = JSON.parse(this.privSpeechProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.ServicePropertiesPropertyName, "{}"));
    currentProperties[name] = value;
    this.privSpeechProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.ServicePropertiesPropertyName, JSON.stringify(currentProperties));
  }
  setProfanity(profanity) {
    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceResponse_ProfanityOption, _Exports__WEBPACK_IMPORTED_MODULE_6__.ProfanityOption[profanity]);
  }
  enableAudioLogging() {
    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_EnableAudioLogging, "true");
  }
  requestWordLevelTimestamps() {
    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, "true");
  }
  enableDictation() {
    this.privSpeechProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.ForceDictationPropertyName, "true");
  }
  get speechSynthesisLanguage() {
    return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_SynthLanguage);
  }
  set speechSynthesisLanguage(language) {
    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_SynthLanguage, language);
  }
  get speechSynthesisVoiceName() {
    return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_SynthVoice);
  }
  set speechSynthesisVoiceName(voice) {
    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_SynthVoice, voice);
  }
  get speechSynthesisOutputFormat() {
    // eslint-disable-next-line
    return _Exports__WEBPACK_IMPORTED_MODULE_7__.SpeechSynthesisOutputFormat[this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)];
  }
  set speechSynthesisOutputFormat(format) {
    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_SynthOutputFormat, _Exports__WEBPACK_IMPORTED_MODULE_7__.SpeechSynthesisOutputFormat[format]);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SynthesisResult: () => (/* binding */ SynthesisResult)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Base class for synthesis results
 * @class SynthesisResult
 * Added in version 1.20.0
 */
class SynthesisResult {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} resultId - The result id.
   * @param {ResultReason} reason - The reason.
   * @param {string} errorDetails - Error details, if provided.
   * @param {PropertyCollection} properties - Additional properties, if provided.
   */
  constructor(resultId, reason, errorDetails, properties) {
    this.privResultId = resultId;
    this.privReason = reason;
    this.privErrorDetails = errorDetails;
    this.privProperties = properties;
  }
  /**
   * Specifies the result identifier.
   * @member SynthesisResult.prototype.resultId
   * @function
   * @public
   * @returns {string} Specifies the result identifier.
   */
  get resultId() {
    return this.privResultId;
  }
  /**
   * Specifies status of the result.
   * @member SynthesisResult.prototype.reason
   * @function
   * @public
   * @returns {ResultReason} Specifies status of the result.
   */
  get reason() {
    return this.privReason;
  }
  /**
   * In case of an unsuccessful synthesis, provides details of the occurred error.
   * @member SynthesisResult.prototype.errorDetails
   * @function
   * @public
   * @returns {string} a brief description of an error.
   */
  get errorDetails() {
    return this.privErrorDetails;
  }
  /**
   * The set of properties exposed in the result.
   * @member SynthesisResult.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The set of properties exposed in the result.
   */
  get properties() {
    return this.privProperties;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SynthesisVoicesResult: () => (/* binding */ SynthesisVoicesResult)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Defines result of speech synthesis.
 * @class SynthesisVoicesResult
 * Added in version 1.20.0
 */
class SynthesisVoicesResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SynthesisResult {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param requestId - result id for request.
   * @param json - json payload from endpoint.
   */
  constructor(requestId, json, errorDetails) {
    if (Array.isArray(json)) {
      super(requestId, _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.VoicesListRetrieved, undefined, new _Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection());
      this.privVoices = [];
      for (const item of json) {
        this.privVoices.push(new _Exports__WEBPACK_IMPORTED_MODULE_3__.VoiceInfo(item));
      }
    } else {
      super(requestId, _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.Canceled, errorDetails ? errorDetails : "Error information unavailable", new _Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection());
    }
  }
  /**
   * The list of voices
   * @member SynthesisVoicesResult.prototype.voices
   * @function
   * @public
   * @returns {VoiceInfo[]} List of synthesized voices.
   */
  get voices() {
    return this.privVoices;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Conversation: () => (/* binding */ Conversation),
/* harmony export */   ConversationImpl: () => (/* binding */ ConversationImpl)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
/* eslint-disable max-classes-per-file */




class Conversation {
  constructor() {
    return;
  }
  /**
   * Create a conversation
   * @param speechConfig
   * @param cb
   * @param err
   */
  static createConversationAsync(speechConfig, arg2, arg3, arg4) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(speechConfig, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig.restErrors.invalidArgs.replace("{arg}", "config"));
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(speechConfig.region, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig.restErrors.invalidArgs.replace("{arg}", "SpeechServiceConnection_Region"));
    if (!speechConfig.subscriptionKey && !speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token])) {
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(speechConfig.subscriptionKey, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig.restErrors.invalidArgs.replace("{arg}", "SpeechServiceConnection_Key"));
    }
    let conversationImpl;
    let cb;
    let err;
    if (typeof arg2 === "string") {
      conversationImpl = new ConversationImpl(speechConfig, arg2);
      // eslint-disable-next-line @typescript-eslint/no-empty-function
      (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)((() => __awaiter(this, void 0, void 0, function* () {}))(), arg3, arg4);
    } else {
      conversationImpl = new ConversationImpl(speechConfig);
      cb = arg2;
      err = arg3;
      conversationImpl.createConversationAsync(() => {
        if (!!cb) {
          cb();
        }
      }, error => {
        if (!!err) {
          err(error);
        }
      });
    }
    return conversationImpl;
  }
}
class ConversationImpl extends Conversation {
  /**
   * Create a conversation impl
   * @param speechConfig
   * @param {string} id - optional conversationId
   */
  constructor(speechConfig, id) {
    super();
    this.privErrors = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig.restErrors;
    /** websocket callbacks */
    /* eslint-disable @typescript-eslint/typedef */
    this.onConnected = e => {
      var _a;
      this.privIsConnected = true;
      try {
        if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.sessionStarted)) {
          this.privConversationTranslator.sessionStarted(this.privConversationTranslator, e);
        }
      } catch (e) {
        //
      }
    };
    this.onDisconnected = e => {
      var _a;
      try {
        if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.sessionStopped)) {
          this.privConversationTranslator.sessionStopped(this.privConversationTranslator, e);
        }
      } catch (e) {
        //
      } finally {
        void this.close(false);
      }
    };
    this.onCanceled = (r, e) => {
      var _a;
      try {
        if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.canceled)) {
          this.privConversationTranslator.canceled(this.privConversationTranslator, e);
        }
      } catch (e) {
        //
      }
    };
    this.onParticipantUpdateCommandReceived = (r, e) => {
      try {
        const updatedParticipant = this.privParticipants.getParticipant(e.id);
        if (updatedParticipant !== undefined) {
          switch (e.key) {
            case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.changeNickname:
              updatedParticipant.displayName = e.value;
              break;
            case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setUseTTS:
              updatedParticipant.isUsingTts = e.value;
              break;
            case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setProfanityFiltering:
              updatedParticipant.profanity = e.value;
              break;
            case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setMute:
              updatedParticipant.isMuted = e.value;
              break;
            case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setTranslateToLanguages:
              updatedParticipant.translateToLanguages = e.value;
              break;
          }
          this.privParticipants.addOrUpdateParticipant(updatedParticipant);
          if (!!this.privConversationTranslator) {
            this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationParticipantsChangedEventArgs(_Exports__WEBPACK_IMPORTED_MODULE_6__.ParticipantChangedReason.Updated, [this.toParticipant(updatedParticipant)], e.sessionId));
          }
        }
      } catch (e) {
        //
      }
    };
    this.onLockRoomCommandReceived = () => {
      // TODO
    };
    this.onMuteAllCommandReceived = (r, e) => {
      try {
        this.privParticipants.participants.forEach(p => p.isMuted = p.isHost ? false : e.isMuted);
        if (!!this.privConversationTranslator) {
          this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationParticipantsChangedEventArgs(_Exports__WEBPACK_IMPORTED_MODULE_6__.ParticipantChangedReason.Updated, this.toParticipants(false), e.sessionId));
        }
      } catch (e) {
        //
      }
    };
    this.onParticipantJoinCommandReceived = (r, e) => {
      try {
        const newParticipant = this.privParticipants.addOrUpdateParticipant(e.participant);
        if (newParticipant !== undefined) {
          if (!!this.privConversationTranslator) {
            this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationParticipantsChangedEventArgs(_Exports__WEBPACK_IMPORTED_MODULE_6__.ParticipantChangedReason.JoinedConversation, [this.toParticipant(newParticipant)], e.sessionId));
          }
        }
      } catch (e) {
        //
      }
    };
    this.onParticipantLeaveCommandReceived = (r, e) => {
      try {
        const ejectedParticipant = this.privParticipants.getParticipant(e.participant.id);
        if (ejectedParticipant !== undefined) {
          // remove the participant from the internal participants list
          this.privParticipants.deleteParticipant(e.participant.id);
          if (!!this.privConversationTranslator) {
            // notify subscribers that the participant has left the conversation
            this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationParticipantsChangedEventArgs(_Exports__WEBPACK_IMPORTED_MODULE_6__.ParticipantChangedReason.LeftConversation, [this.toParticipant(ejectedParticipant)], e.sessionId));
          }
        }
      } catch (e) {
        //
      }
    };
    this.onTranslationReceived = (r, e) => {
      try {
        switch (e.command) {
          case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.final:
            if (!!this.privConversationTranslator) {
              this.privConversationTranslator.transcribed(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_7__.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));
            }
            break;
          case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.partial:
            if (!!this.privConversationTranslator) {
              this.privConversationTranslator.transcribing(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_7__.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));
            }
            break;
          case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.instantMessage:
            if (!!this.privConversationTranslator) {
              this.privConversationTranslator.textMessageReceived(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_7__.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));
            }
            break;
        }
      } catch (e) {
        //
      }
    };
    this.onParticipantsListReceived = (r, e) => {
      var _a;
      try {
        // check if the session token needs to be updated
        if (e.sessionToken !== undefined && e.sessionToken !== null) {
          this.privRoom.token = e.sessionToken;
        }
        // save the participants
        this.privParticipants.participants = [...e.participants];
        // enable the conversation
        if (this.privParticipants.me !== undefined) {
          this.privIsReady = true;
        }
        if (!!this.privConversationTranslator) {
          this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationParticipantsChangedEventArgs(_Exports__WEBPACK_IMPORTED_MODULE_6__.ParticipantChangedReason.JoinedConversation, this.toParticipants(true), e.sessionId));
        }
        // if this is the host, update the nickname if needed
        if (this.me.isHost) {
          const nickname = (_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.ConversationTranslator_Name);
          if (nickname !== undefined && nickname.length > 0 && nickname !== this.me.displayName) {
            // issue a change nickname request
            this.changeNicknameAsync(nickname);
          }
        }
      } catch (e) {
        //
      }
    };
    this.onConversationExpiration = (r, e) => {
      try {
        if (!!this.privConversationTranslator) {
          this.privConversationTranslator.conversationExpiration(this.privConversationTranslator, e);
        }
      } catch (e) {
        //
      }
    };
    this.privIsConnected = false;
    this.privIsDisposed = false;
    this.privConversationId = "";
    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_8__.PropertyCollection();
    this.privManager = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__.ConversationManager();
    // check the speech language
    const language = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage]);
    if (!language) {
      speechConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage], _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig.defaultLanguageCode);
    }
    this.privLanguage = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage]);
    if (!id) {
      // check the target language(s)
      if (speechConfig.targetLanguages.length === 0) {
        speechConfig.addTargetLanguage(this.privLanguage);
      }
      // check the profanity setting: speech and conversationTranslator should be in sync
      const profanity = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceResponse_ProfanityOption]);
      if (!profanity) {
        speechConfig.setProfanity(_Exports__WEBPACK_IMPORTED_MODULE_10__.ProfanityOption.Masked);
      }
      // check the nickname: it should pass this regex: ^\w+([\s-][\w\(\)]+)*$"
      // TODO: specify the regex required. Nicknames must be unique or get the duplicate nickname error
      // TODO: check what the max length is and if a truncation is required or if the service handles it without an error
      let hostNickname = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.ConversationTranslator_Name]);
      if (hostNickname === undefined || hostNickname === null) {
        hostNickname = "Host";
      }
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrTooLong(hostNickname, "nickname", 50);
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrTooShort(hostNickname, "nickname", 2);
      speechConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.ConversationTranslator_Name], hostNickname);
    } else {
      this.privConversationId = id;
    }
    // save the speech config for future usage
    this.privConfig = speechConfig;
    // save the config properties
    const configImpl = speechConfig;
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(configImpl, "speechConfig");
    this.privProperties = configImpl.properties.clone();
    this.privIsConnected = false;
    this.privParticipants = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.InternalParticipants();
    this.privIsReady = false;
    this.privTextMessageMaxLength = 1000;
  }
  // get the internal data about a conversation
  get room() {
    return this.privRoom;
  }
  // get the wrapper for connecting to the websockets
  get connection() {
    return this.privConversationRecognizer; // this.privConnection;
  }
  // get the config
  get config() {
    return this.privConfig;
  }
  // get the conversation Id
  get conversationId() {
    return this.privRoom ? this.privRoom.roomId : this.privConversationId;
  }
  // get the properties
  get properties() {
    return this.privProperties;
  }
  // get the speech language
  get speechRecognitionLanguage() {
    return this.privLanguage;
  }
  get isMutedByHost() {
    var _a, _b;
    return ((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isHost) ? false : (_b = this.privParticipants.me) === null || _b === void 0 ? void 0 : _b.isMuted;
  }
  get isConnected() {
    return this.privIsConnected && this.privIsReady;
  }
  get participants() {
    return this.toParticipants(true);
  }
  get me() {
    return this.toParticipant(this.privParticipants.me);
  }
  get host() {
    return this.toParticipant(this.privParticipants.host);
  }
  get transcriberRecognizer() {
    return this.privTranscriberRecognizer;
  }
  get conversationInfo() {
    const convId = this.conversationId;
    const p = this.participants.map(part => ({
      id: part.id,
      preferredLanguage: part.preferredLanguage,
      voice: part.voice
    }));
    const props = {};
    for (const key of _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig.transcriptionEventKeys) {
      const val = this.properties.getProperty(key, "");
      if (val !== "") {
        props[key] = val;
      }
    }
    const info = {
      id: convId,
      participants: p,
      conversationProperties: props
    };
    return info;
  }
  get canSend() {
    var _a;
    return this.privIsConnected && !((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isMuted);
  }
  get canSendAsHost() {
    var _a;
    return this.privIsConnected && ((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isHost);
  }
  // get / set the speech auth token
  // eslint-disable-next-line @typescript-eslint/member-ordering
  get authorizationToken() {
    return this.privToken;
  }
  set authorizationToken(value) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(value, "authorizationToken");
    this.privToken = value;
  }
  set conversationTranslator(conversationTranslator) {
    this.privConversationTranslator = conversationTranslator;
  }
  /**
   * Create a new conversation as Host
   * @param cb
   * @param err
   */
  createConversationAsync(cb, err) {
    try {
      if (!!this.privConversationRecognizer) {
        this.handleError(new Error(this.privErrors.permissionDeniedStart), err);
      }
      this.privManager.createOrJoin(this.privProperties, undefined, room => {
        if (!room) {
          this.handleError(new Error(this.privErrors.permissionDeniedConnect), err);
        }
        this.privRoom = room;
        this.handleCallback(cb, err);
      }, error => {
        this.handleError(error, err);
      });
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Starts a new conversation as host.
   * @param cb
   * @param err
   */
  startConversationAsync(cb, err) {
    try {
      // check if there is already a recognizer
      if (!!this.privConversationRecognizer) {
        this.handleError(new Error(this.privErrors.permissionDeniedStart), err);
      }
      // check if there is conversation data available
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedConnect);
      // connect to the conversation websocket
      this.privParticipants.meId = this.privRoom.participantId;
      this.privConversationRecognizer = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_11__.ConversationRecognizerFactory.fromConfig(this, this.privConfig);
      // Because ConversationTranslator manually sets up and manages the connection, Conversation
      // has to forward serviceRecognizer connection events that usually get passed automatically
      this.privConversationRecognizer.connected = this.onConnected;
      this.privConversationRecognizer.disconnected = this.onDisconnected;
      this.privConversationRecognizer.canceled = this.onCanceled;
      this.privConversationRecognizer.participantUpdateCommandReceived = this.onParticipantUpdateCommandReceived;
      this.privConversationRecognizer.lockRoomCommandReceived = this.onLockRoomCommandReceived;
      this.privConversationRecognizer.muteAllCommandReceived = this.onMuteAllCommandReceived;
      this.privConversationRecognizer.participantJoinCommandReceived = this.onParticipantJoinCommandReceived;
      this.privConversationRecognizer.participantLeaveCommandReceived = this.onParticipantLeaveCommandReceived;
      this.privConversationRecognizer.translationReceived = this.onTranslationReceived;
      this.privConversationRecognizer.participantsListReceived = this.onParticipantsListReceived;
      this.privConversationRecognizer.conversationExpiration = this.onConversationExpiration;
      this.privConversationRecognizer.connect(this.privRoom.token, () => {
        this.handleCallback(cb, err);
      }, error => {
        this.handleError(error, err);
      });
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Join a conversation as a participant.
   * @param { IParticipant } participant - participant to add
   * @param cb
   * @param err
   */
  addParticipantAsync(participant, cb, err) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(participant, "Participant");
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.addParticipantImplAsync(participant), cb, err);
  }
  /**
   * Join a conversation as a participant.
   * @param conversation
   * @param nickname
   * @param lang
   * @param cb
   * @param err
   */
  joinConversationAsync(conversationId, nickname, lang, cb, err) {
    try {
      // TODO
      // if (!!this.privConversationRecognizer) {
      //     throw new Error(this.privErrors.permissionDeniedStart);
      // }
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(conversationId, this.privErrors.invalidArgs.replace("{arg}", "conversationId"));
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(lang, this.privErrors.invalidArgs.replace("{arg}", "language"));
      // join the conversation
      this.privManager.createOrJoin(this.privProperties, conversationId, room => {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(room, this.privErrors.permissionDeniedConnect);
        this.privRoom = room;
        this.privConfig.authorizationToken = room.cognitiveSpeechAuthToken;
        // join callback
        if (!!cb) {
          cb(room.cognitiveSpeechAuthToken);
        }
      }, error => {
        this.handleError(error, err);
      });
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Deletes a conversation
   * @param cb
   * @param err
   */
  deleteConversationAsync(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.deleteConversationImplAsync(), cb, err);
  }
  deleteConversationImplAsync() {
    return __awaiter(this, void 0, void 0, function* () {
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privProperties, this.privErrors.permissionDeniedConnect);
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.token, this.privErrors.permissionDeniedConnect);
      yield this.privManager.leave(this.privProperties, this.privRoom.token);
      this.dispose();
    });
  }
  /**
   * Issues a request to close the client websockets
   * @param cb
   * @param err
   */
  endConversationAsync(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.endConversationImplAsync(), cb, err);
  }
  endConversationImplAsync() {
    return this.close(true);
  }
  /**
   * Issues a request to lock the conversation
   * @param cb
   * @param err
   */
  lockConversationAsync(cb, err) {
    try {
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSendAsHost) {
        this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "lock")), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getLockCommand(true), () => {
          this.handleCallback(cb, err);
        }, error => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Issues a request to mute the conversation
   * @param cb
   * @param err
   */
  muteAllParticipantsAsync(cb, err) {
    try {
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privConversationRecognizer, this.privErrors.permissionDeniedSend);
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      // check the user's permissions
      if (!this.canSendAsHost) {
        this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "mute")), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(true), () => {
          this.handleCallback(cb, err);
        }, error => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Issues a request to mute a participant in the conversation
   * @param userId
   * @param cb
   * @param err
   */
  muteParticipantAsync(userId, cb, err) {
    try {
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      // check the connection is open (host + participant can perform the mute command)
      if (!this.canSend) {
        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
      }
      // if not host, check the participant is not muting another participant
      if (!this.me.isHost && this.me.id !== userId) {
        this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "mute")), err);
      }
      // check the user exists
      const exists = this.privParticipants.getParticipantIndex(userId);
      if (exists === -1) {
        this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, true), () => {
          this.handleCallback(cb, err);
        }, error => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Issues a request to remove a participant from the conversation
   * @param userId
   * @param cb
   * @param err
   */
  removeParticipantAsync(userId, cb, err) {
    try {
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);
      if (!!this.privTranscriberRecognizer && userId.hasOwnProperty("id")) {
        // Assume this is a transcription participant
        (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.removeParticipantImplAsync(userId), cb, err);
      } else {
        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
        if (!this.canSendAsHost) {
          this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "remove")), err);
        }
        let participantId = "";
        if (typeof userId === "string") {
          participantId = userId;
        } else if (userId.hasOwnProperty("id")) {
          const participant = userId;
          participantId = participant.id;
        } else if (userId.hasOwnProperty("userId")) {
          const user = userId;
          participantId = user.userId;
        }
        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(participantId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
        // check the participant exists
        const index = this.participants.findIndex(p => p.id === participantId);
        if (index === -1) {
          this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
        }
        if (!!this.privConversationRecognizer) {
          this.privConversationRecognizer.sendRequest(this.getEjectCommand(participantId), () => {
            this.handleCallback(cb, err);
          }, error => {
            this.handleError(error, err);
          });
        }
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Issues a request to unlock the conversation
   * @param cb
   * @param err
   */
  unlockConversationAsync(cb, err) {
    try {
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSendAsHost) {
        this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "unlock")), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getLockCommand(false), () => {
          this.handleCallback(cb, err);
        }, error => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Issues a request to unmute all participants in the conversation
   * @param cb
   * @param err
   */
  unmuteAllParticipantsAsync(cb, err) {
    try {
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSendAsHost) {
        this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "unmute all")), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(false), () => {
          this.handleCallback(cb, err);
        }, error => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Issues a request to unmute a participant in the conversation
   * @param userId
   * @param cb
   * @param err
   */
  unmuteParticipantAsync(userId, cb, err) {
    try {
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      // check the connection is open (host + participant can perform the mute command)
      if (!this.canSend) {
        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
      }
      // if not host, check the participant is not muting another participant
      if (!this.me.isHost && this.me.id !== userId) {
        this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "mute")), err);
      }
      // check the user exists
      const exists = this.privParticipants.getParticipantIndex(userId);
      if (exists === -1) {
        this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, false), () => {
          this.handleCallback(cb, err);
        }, error => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Send a text message
   * @param message
   * @param cb
   * @param err
   */
  sendTextMessageAsync(message, cb, err) {
    try {
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace("{arg}", "message"));
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSend) {
        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
      }
      // TODO: is a max length check required?
      if (message.length > this.privTextMessageMaxLength) {
        this.handleError(new Error(this.privErrors.invalidArgs.replace("{arg}", "message length")), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getMessageCommand(message), () => {
          this.handleCallback(cb, err);
        }, error => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Set translated to languages
   * @param {string[]} languages - languages to translate to
   * @param cb
   * @param err
   */
  setTranslatedLanguagesAsync(languages, cb, err) {
    try {
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfArrayEmptyOrWhitespace(languages, this.privErrors.invalidArgs.replace("{arg}", "languages"));
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSend) {
        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getSetTranslateToLanguagesCommand(languages), () => {
          this.handleCallback(cb, err);
        }, error => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Change nickname
   * @param {string} nickname - new nickname for the room
   * @param cb
   * @param err
   */
  changeNicknameAsync(nickname, cb, err) {
    try {
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSend) {
        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getChangeNicknameCommand(nickname), () => {
          this.handleCallback(cb, err);
        }, error => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  dispose() {
    if (this.isDisposed) {
      return;
    }
    this.privIsDisposed = true;
    if (!!this.config) {
      this.config.close();
    }
    this.privConfig = undefined;
    this.privLanguage = undefined;
    this.privProperties = undefined;
    this.privRoom = undefined;
    this.privToken = undefined;
    this.privManager = undefined;
    this.privIsConnected = false;
    this.privIsReady = false;
    this.privParticipants = undefined;
  }
  connectTranscriberRecognizer(recognizer) {
    return __awaiter(this, void 0, void 0, function* () {
      if (!!this.privTranscriberRecognizer) {
        yield this.privTranscriberRecognizer.close();
      }
      yield recognizer.enforceAudioGating();
      this.privTranscriberRecognizer = recognizer;
      this.privTranscriberRecognizer.conversation = this;
    });
  }
  getKeepAlive() {
    const nickname = !!this.me ? this.me.displayName : "default_nickname";
    return JSON.stringify({
      id: "0",
      nickname,
      participantId: this.privRoom.participantId,
      roomId: this.privRoom.roomId,
      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.keepAlive
    });
  }
  /* eslint-enable @typescript-eslint/typedef */
  addParticipantImplAsync(participant) {
    const newParticipant = this.privParticipants.addOrUpdateParticipant(participant);
    if (newParticipant !== undefined) {
      if (!!this.privTranscriberRecognizer) {
        const conversationInfo = this.conversationInfo;
        conversationInfo.participants = [participant];
        return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, "join");
      }
    }
  }
  removeParticipantImplAsync(participant) {
    this.privParticipants.deleteParticipant(participant.id);
    const conversationInfo = this.conversationInfo;
    conversationInfo.participants = [participant];
    return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, "leave");
  }
  close(dispose) {
    var _a;
    return __awaiter(this, void 0, void 0, function* () {
      try {
        this.privIsConnected = false;
        yield (_a = this.privConversationRecognizer) === null || _a === void 0 ? void 0 : _a.close();
        this.privConversationRecognizer = undefined;
        if (!!this.privConversationTranslator) {
          this.privConversationTranslator.dispose();
        }
      } catch (e) {
        // ignore error
        throw e;
      }
      if (dispose) {
        this.dispose();
      }
    });
  }
  /** Helpers */
  handleCallback(cb, err) {
    if (!!cb) {
      try {
        cb();
      } catch (e) {
        if (!!err) {
          err(e);
        }
      }
      cb = undefined;
    }
  }
  handleError(error, err) {
    if (!!err) {
      if (error instanceof Error) {
        const typedError = error;
        err(typedError.name + ": " + typedError.message);
      } else {
        err(error);
      }
    }
  }
  /** Participant Helpers */
  toParticipants(includeHost) {
    const participants = this.privParticipants.participants.map(p => this.toParticipant(p));
    if (!includeHost) {
      return participants.filter(p => p.isHost === false);
    } else {
      return participants;
    }
  }
  toParticipant(p) {
    return new _Exports__WEBPACK_IMPORTED_MODULE_12__.Participant(p.id, p.avatar, p.displayName, p.isHost, p.isMuted, p.isUsingTts, p.preferredLanguage, p.voice);
  }
  getMuteAllCommand(isMuted) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
    return JSON.stringify({
      command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setMuteAll,
      participantId: this.privRoom.participantId,
      roomid: this.privRoom.roomId,
      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.participantCommand,
      value: isMuted
    });
  }
  getMuteCommand(participantId, isMuted) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(participantId, "participantId");
    return JSON.stringify({
      command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setMute,
      // eslint-disable-next-line object-shorthand
      participantId: participantId,
      roomid: this.privRoom.roomId,
      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.participantCommand,
      value: isMuted
    });
  }
  getLockCommand(isLocked) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
    return JSON.stringify({
      command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setLockState,
      participantId: this.privRoom.participantId,
      roomid: this.privRoom.roomId,
      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.participantCommand,
      value: isLocked
    });
  }
  getEjectCommand(participantId) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(participantId, "participantId");
    return JSON.stringify({
      command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.ejectParticipant,
      // eslint-disable-next-line object-shorthand
      participantId: participantId,
      roomid: this.privRoom.roomId,
      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.participantCommand
    });
  }
  getSetTranslateToLanguagesCommand(languages) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
    return JSON.stringify({
      command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setTranslateToLanguages,
      participantId: this.privRoom.participantId,
      roomid: this.privRoom.roomId,
      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.participantCommand,
      value: languages
    });
  }
  getChangeNicknameCommand(nickname) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(nickname, "nickname");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
    return JSON.stringify({
      command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.changeNickname,
      nickname,
      participantId: this.privRoom.participantId,
      roomid: this.privRoom.roomId,
      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.participantCommand,
      value: nickname
    });
  }
  getMessageCommand(message) {
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(message, "message");
    return JSON.stringify({
      participantId: this.privRoom.participantId,
      roomId: this.privRoom.roomId,
      text: message,
      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.instantMessage
    });
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationCommon: () => (/* binding */ ConversationCommon)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
class ConversationCommon {
  constructor(audioConfig) {
    this.privAudioConfig = audioConfig;
  }
  handleCallback(cb, err) {
    if (!!cb) {
      try {
        cb();
      } catch (e) {
        if (!!err) {
          err(e);
        }
      }
      cb = undefined;
    }
  }
  handleError(error, err) {
    if (!!err) {
      if (error instanceof Error) {
        const typedError = error;
        err(typedError.name + ": " + typedError.message);
      } else {
        err(error);
      }
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js ***!
  \*************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationExpirationEventArgs: () => (/* binding */ ConversationExpirationEventArgs)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.

class ConversationExpirationEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {
  constructor(expirationTime, sessionId) {
    super(sessionId);
    this.privExpirationTime = expirationTime;
  }
  /** How much longer until the conversation expires (in minutes). */
  get expirationTime() {
    return this.privExpirationTime;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js":
/*!**********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js ***!
  \**********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationParticipantsChangedEventArgs: () => (/* binding */ ConversationParticipantsChangedEventArgs)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.

class ConversationParticipantsChangedEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {
  constructor(reason, participants, sessionId) {
    super(sessionId);
    this.privReason = reason;
    this.privParticipant = participants;
  }
  get reason() {
    return this.privReason;
  }
  get participants() {
    return this.privParticipant;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationTranscriber: () => (/* binding */ ConversationTranscriber)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};




class ConversationTranscriber {
  /**
   * ConversationTranscriber constructor.
   * @constructor
   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
   */
  constructor(audioConfig) {
    this.privAudioConfig = audioConfig;
    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();
    this.privRecognizer = undefined;
    this.privDisposedRecognizer = false;
  }
  /**
   * Gets the spoken language of recognition.
   * @member ConversationTranscriber.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @returns {string} The spoken language of recognition.
   */
  get speechRecognitionLanguage() {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage);
  }
  /**
   * The collection of properties and their values defined for this ConversationTranscriber.
   * @member ConversationTranscriber.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this ConversationTranscriber.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * @Internal
   * Internal data member to support fromRecognizer* pattern methods on other classes.
   * Do not use externally, object returned will change without warning or notice.
   */
  get internalData() {
    return this.privRecognizer.internalData;
  }
  /**
   * @Deprecated
   * @Obsolete
   * Please use the Connection.fromRecognizer pattern to obtain a connection object
   */
  get connection() {
    return _Exports__WEBPACK_IMPORTED_MODULE_3__.Connection.fromRecognizer(this.privRecognizer);
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member ConversationTranscriber.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * @member ConversationTranscriber.prototype.authorizationToken
   * @function
   * @public
   * @param {string} token - Authorization token.
   */
  set authorizationToken(token) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, token);
  }
  /**
   * @param {Conversation} conversation - conversation to be recognized
   */
  joinConversationAsync(conversation, cb, err) {
    const conversationImpl = conversation;
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(conversationImpl, "Conversation");
    // ref the conversation object
    // create recognizer and subscribe to recognizer events
    this.privRecognizer = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.TranscriberRecognizer(conversation.config, this.privAudioConfig);
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(this.privRecognizer, "Recognizer");
    this.privRecognizer.connectCallbacks(this);
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_5__.marshalPromiseToCallbacks)(conversationImpl.connectTranscriberRecognizer(this.privRecognizer), cb, err);
  }
  /**
   * Starts conversation transcription, until stopTranscribingAsync() is called.
   * User must subscribe to events to receive transcription results.
   * @member ConversationTranscriber.prototype.startTranscribingAsync
   * @function
   * @public
   * @param cb - Callback invoked once the transcription has started.
   * @param err - Callback invoked in case of an error.
   */
  startTranscribingAsync(cb, err) {
    this.privRecognizer.startContinuousRecognitionAsync(cb, err);
  }
  /**
   * Starts conversation transcription, until stopTranscribingAsync() is called.
   * User must subscribe to events to receive transcription results.
   * @member ConversationTranscriber.prototype.stopTranscribingAsync
   * @function
   * @public
   * @param cb - Callback invoked once the transcription has started.
   * @param err - Callback invoked in case of an error.
   */
  stopTranscribingAsync(cb, err) {
    this.privRecognizer.stopContinuousRecognitionAsync(cb, err);
  }
  /**
   * Leave the current conversation. After this is called, you will no longer receive any events.
   */
  leaveConversationAsync(cb, err) {
    this.privRecognizer.disconnectCallbacks();
    // eslint-disable-next-line
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_5__.marshalPromiseToCallbacks)((() => __awaiter(this, void 0, void 0, function* () {
      return;
    }))(), cb, err);
  }
  /**
   * closes all external resources held by an instance of this class.
   * @member ConversationTranscriber.prototype.close
   * @function
   * @public
   */
  close(cb, errorCb) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_5__.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);
  }
  /**
   * Disposes any resources held by the object.
   * @member ConversationTranscriber.prototype.dispose
   * @function
   * @public
   * @param {boolean} disposing - true if disposing the object.
   */
  dispose(disposing) {
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privDisposedRecognizer) {
        return;
      }
      if (!!this.privRecognizer) {
        yield this.privRecognizer.close();
        this.privRecognizer = undefined;
      }
      if (disposing) {
        this.privDisposedRecognizer = true;
      }
    });
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js":
/*!**********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js ***!
  \**********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationTranslationCanceledEventArgs: () => (/* binding */ ConversationTranslationCanceledEventArgs)
/* harmony export */ });
/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../CancellationEventArgsBase */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.

class ConversationTranslationCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__.CancellationEventArgsBase {}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationTranslationEventArgs: () => (/* binding */ ConversationTranslationEventArgs)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.

class ConversationTranslationEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {ConversationTranslationResult} result - The translation recognition result.
   * @param {number} offset - The offset.
   * @param {string} sessionId - The session id.
   */
  constructor(result, offset, sessionId) {
    super(offset, sessionId);
    this.privResult = result;
  }
  /**
   * Specifies the recognition result.
   * @returns {ConversationTranslationResult} the recognition result.
   */
  get result() {
    return this.privResult;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationTranslationResult: () => (/* binding */ ConversationTranslationResult)
/* harmony export */ });
/* harmony import */ var _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../TranslationRecognitionResult */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.

class ConversationTranslationResult extends _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_0__.TranslationRecognitionResult {
  constructor(participantId, translations, originalLanguage, resultId, reason, text, duration, offset, errorDetails, json, properties) {
    super(translations, resultId, reason, text, duration, offset, undefined, undefined, errorDetails, json, properties);
    this.privId = participantId;
    this.privOrigLang = originalLanguage;
  }
  /**
   * The unique identifier for the participant this result is for.
   */
  get participantId() {
    return this.privId;
  }
  /**
   * The original language this result was in.
   */
  get originalLang() {
    return this.privOrigLang;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConversationTranslator: () => (/* binding */ ConversationTranslator),
/* harmony export */   SpeechState: () => (/* binding */ SpeechState)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _common_speech_Transcription_ConversationTranslatorConnectionFactory__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common.speech/Transcription/ConversationTranslatorConnectionFactory */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorConnectionFactory.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js");
/* harmony import */ var _Conversation__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./Conversation */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
/* eslint-disable max-classes-per-file */







var SpeechState;
(function (SpeechState) {
  SpeechState[SpeechState["Inactive"] = 0] = "Inactive";
  SpeechState[SpeechState["Connecting"] = 1] = "Connecting";
  SpeechState[SpeechState["Connected"] = 2] = "Connected";
})(SpeechState || (SpeechState = {}));
// child class of TranslationRecognizer meant only for use with ConversationTranslator
class ConversationTranslationRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.TranslationRecognizer {
  constructor(speechConfig, audioConfig, translator, convGetter) {
    super(speechConfig, audioConfig, new _common_speech_Transcription_ConversationTranslatorConnectionFactory__WEBPACK_IMPORTED_MODULE_1__.ConversationTranslatorConnectionFactory(convGetter));
    this.privSpeechState = SpeechState.Inactive;
    if (!!translator) {
      this.privTranslator = translator;
      this.sessionStarted = () => {
        this.privSpeechState = SpeechState.Connected;
      };
      this.sessionStopped = () => {
        this.privSpeechState = SpeechState.Inactive;
      };
      this.recognizing = (tr, e) => {
        if (!!this.privTranslator.recognizing) {
          this.privTranslator.recognizing(this.privTranslator, e);
        }
      };
      // eslint-disable-next-line @typescript-eslint/no-misused-promises
      this.recognized = (tr, e) => __awaiter(this, void 0, void 0, function* () {
        var _a;
        // if there is an error connecting to the conversation service from the speech service the error will be returned in the ErrorDetails field.
        if ((_a = e.result) === null || _a === void 0 ? void 0 : _a.errorDetails) {
          yield this.cancelSpeech();
          // TODO: format the error message contained in 'errorDetails'
          this.fireCancelEvent(e.result.errorDetails);
        } else {
          if (!!this.privTranslator.recognized) {
            this.privTranslator.recognized(this.privTranslator, e);
          }
        }
        return;
      });
      // eslint-disable-next-line @typescript-eslint/no-misused-promises
      this.canceled = () => __awaiter(this, void 0, void 0, function* () {
        if (this.privSpeechState !== SpeechState.Inactive) {
          try {
            yield this.cancelSpeech();
          } catch (error) {
            this.privSpeechState = SpeechState.Inactive;
          }
        }
      });
    }
  }
  get state() {
    return this.privSpeechState;
  }
  set state(newState) {
    this.privSpeechState = newState;
  }
  onConnection() {
    this.privSpeechState = SpeechState.Connected;
  }
  onDisconnection() {
    return __awaiter(this, void 0, void 0, function* () {
      this.privSpeechState = SpeechState.Inactive;
      yield this.cancelSpeech();
    });
  }
  /**
   * Fire a cancel event
   * @param error
   */
  fireCancelEvent(error) {
    try {
      if (!!this.privTranslator.canceled) {
        const cancelEvent = new _Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranslationCanceledEventArgs(_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationReason.Error, error, _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode.RuntimeError);
        this.privTranslator.canceled(this.privTranslator, cancelEvent);
      }
    } catch (e) {
      //
    }
  }
  cancelSpeech() {
    var _a;
    return __awaiter(this, void 0, void 0, function* () {
      try {
        this.stopContinuousRecognitionAsync();
        yield (_a = this.privReco) === null || _a === void 0 ? void 0 : _a.disconnect();
        this.privSpeechState = SpeechState.Inactive;
      } catch (e) {
        // ignore the error
      }
    });
  }
}
/**
 * Join, leave or connect to a conversation.
 */
class ConversationTranslator extends _Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationCommon {
  constructor(audioConfig) {
    super(audioConfig);
    this.privErrors = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.ConversationConnectionConfig.restErrors;
    this.privIsDisposed = false;
    this.privIsSpeaking = false;
    this.privPlaceholderKey = "abcdefghijklmnopqrstuvwxyz012345";
    this.privPlaceholderRegion = "westus";
    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_7__.PropertyCollection();
  }
  get properties() {
    return this.privProperties;
  }
  get speechRecognitionLanguage() {
    return this.privSpeechRecognitionLanguage;
  }
  get participants() {
    var _a;
    return (_a = this.privConversation) === null || _a === void 0 ? void 0 : _a.participants;
  }
  get canSpeak() {
    // is there a Conversation websocket available and has the Recognizer been set up
    if (!this.privConversation.isConnected || !this.privCTRecognizer) {
      return false;
    }
    // is the user already speaking
    if (this.privIsSpeaking || this.privCTRecognizer.state === SpeechState.Connected || this.privCTRecognizer.state === SpeechState.Connecting) {
      return false;
    }
    // is the user muted
    if (this.privConversation.isMutedByHost) {
      return false;
    }
    return true;
  }
  setServiceProperty(name, value) {
    const currentProperties = JSON.parse(this.privProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__.ServicePropertiesPropertyName, "{}"));
    currentProperties[name] = value;
    this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__.ServicePropertiesPropertyName, JSON.stringify(currentProperties));
  }
  joinConversationAsync(conversation, nickname, param1, param2, param3) {
    try {
      if (typeof conversation === "string") {
        _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace("{arg}", "conversation id"));
        _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
        if (!!this.privConversation) {
          this.handleError(new Error(this.privErrors.permissionDeniedStart), param3);
        }
        let lang = param1;
        if (lang === undefined || lang === null || lang === "") {
          lang = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.ConversationConnectionConfig.defaultLanguageCode;
        }
        // create a placeholder config
        this.privSpeechTranslationConfig = _Exports__WEBPACK_IMPORTED_MODULE_10__.SpeechTranslationConfig.fromSubscription(this.privPlaceholderKey, this.privPlaceholderRegion);
        this.privSpeechTranslationConfig.setProfanity(_Exports__WEBPACK_IMPORTED_MODULE_11__.ProfanityOption.Masked);
        this.privSpeechTranslationConfig.addTargetLanguage(lang);
        this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId.SpeechServiceConnection_RecoLanguage], lang);
        this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId.ConversationTranslator_Name], nickname);
        const propertyIdsToCopy = [_Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId.SpeechServiceConnection_Host, _Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId.ConversationTranslator_Host, _Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId.SpeechServiceConnection_Endpoint, _Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId.SpeechServiceConnection_ProxyHostName, _Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId.SpeechServiceConnection_ProxyPassword, _Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId.SpeechServiceConnection_ProxyPort, _Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId.SpeechServiceConnection_ProxyUserName, "ConversationTranslator_MultiChannelAudio", "ConversationTranslator_Region"];
        for (const prop of propertyIdsToCopy) {
          const value = this.privProperties.getProperty(prop);
          if (value) {
            const key = typeof prop === "string" ? prop : _Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId[prop];
            this.privSpeechTranslationConfig.setProperty(key, value);
          }
        }
        const currentProperties = JSON.parse(this.privProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__.ServicePropertiesPropertyName, "{}"));
        for (const prop of Object.keys(currentProperties)) {
          this.privSpeechTranslationConfig.setServiceProperty(prop, currentProperties[prop], _Exports__WEBPACK_IMPORTED_MODULE_13__.ServicePropertyChannel.UriQueryParameter);
        }
        // join the conversation
        this.privConversation = new _Conversation__WEBPACK_IMPORTED_MODULE_14__.ConversationImpl(this.privSpeechTranslationConfig);
        this.privConversation.conversationTranslator = this;
        this.privConversation.joinConversationAsync(conversation, nickname, lang, result => {
          if (!result) {
            this.handleError(new Error(this.privErrors.permissionDeniedConnect), param3);
          }
          this.privSpeechTranslationConfig.authorizationToken = result;
          this.privConversation.room.isHost = false;
          // connect to the ws
          this.privConversation.startConversationAsync(() => {
            this.handleCallback(param2, param3);
          }, error => {
            this.handleError(error, param3);
          });
        }, error => {
          this.handleError(error, param3);
        });
      } else if (typeof conversation === "object") {
        _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace("{arg}", "conversation id"));
        _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
        // save the nickname
        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId.ConversationTranslator_Name, nickname);
        // ref the conversation object
        this.privConversation = conversation;
        // ref the conversation translator object
        this.privConversation.conversationTranslator = this;
        this.privConversation.room.isHost = true;
        _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedConnect);
        _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);
        this.privSpeechTranslationConfig = conversation.config;
        this.handleCallback(param1, param2);
      } else {
        this.handleError(new Error(this.privErrors.invalidArgs.replace("{arg}", "invalid conversation type")), param2);
      }
    } catch (error) {
      this.handleError(error, typeof param1 === "string" ? param3 : param2);
    }
  }
  /**
   * Leave the conversation
   * @param cb
   * @param err
   */
  leaveConversationAsync(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_15__.marshalPromiseToCallbacks)((() => __awaiter(this, void 0, void 0, function* () {
      // stop the speech websocket
      yield this.cancelSpeech();
      // stop the websocket
      yield this.privConversation.endConversationImplAsync();
      // https delete request
      yield this.privConversation.deleteConversationImplAsync();
      this.dispose();
    }))(), cb, err);
  }
  /**
   * Send a text message
   * @param message
   * @param cb
   * @param err
   */
  sendTextMessageAsync(message, cb, err) {
    try {
      _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);
      _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace("{arg}", message));
      this.privConversation.sendTextMessageAsync(message, cb, err);
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Start speaking
   * @param cb
   * @param err
   */
  startTranscribingAsync(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_15__.marshalPromiseToCallbacks)((() => __awaiter(this, void 0, void 0, function* () {
      try {
        _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);
        _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);
        if (this.privCTRecognizer === undefined) {
          yield this.connectTranslatorRecognizer();
        }
        _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNullOrUndefined(this.privCTRecognizer, this.privErrors.permissionDeniedSend);
        if (!this.canSpeak) {
          this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
        }
        yield this.startContinuousRecognition();
        this.privIsSpeaking = true;
      } catch (error) {
        this.privIsSpeaking = false;
        yield this.cancelSpeech();
        throw error;
      }
    }))(), cb, err);
  }
  /**
   * Stop speaking
   * @param cb
   * @param err
   */
  stopTranscribingAsync(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_15__.marshalPromiseToCallbacks)((() => __awaiter(this, void 0, void 0, function* () {
      try {
        if (!this.privIsSpeaking) {
          // stop speech
          yield this.cancelSpeech();
          return;
        }
        // stop the recognition but leave the websocket open
        this.privIsSpeaking = false;
        yield new Promise((resolve, reject) => {
          this.privCTRecognizer.stopContinuousRecognitionAsync(resolve, reject);
        });
      } catch (error) {
        yield this.cancelSpeech();
      }
    }))(), cb, err);
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  dispose(reason, success, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_15__.marshalPromiseToCallbacks)((() => __awaiter(this, void 0, void 0, function* () {
      if (this.isDisposed && !this.privIsSpeaking) {
        return;
      }
      yield this.cancelSpeech();
      this.privIsDisposed = true;
      this.privSpeechTranslationConfig.close();
      this.privSpeechRecognitionLanguage = undefined;
      this.privProperties = undefined;
      this.privAudioConfig = undefined;
      this.privSpeechTranslationConfig = undefined;
      this.privConversation.dispose();
      this.privConversation = undefined;
    }))(), success, err);
  }
  /**
   * Cancel the speech websocket
   */
  cancelSpeech() {
    var _a;
    return __awaiter(this, void 0, void 0, function* () {
      try {
        this.privIsSpeaking = false;
        yield (_a = this.privCTRecognizer) === null || _a === void 0 ? void 0 : _a.onDisconnection();
        this.privCTRecognizer = undefined;
      } catch (e) {
        // ignore the error
      }
    });
  }
  /**
   * Connect to the speech translation recognizer.
   * Currently there is no language validation performed before sending the SpeechLanguage code to the service.
   * If it's an invalid language the raw error will be: 'Error during WebSocket handshake: Unexpected response code: 400'
   * e.g. pass in 'fr' instead of 'fr-FR', or a text-only language 'cy'
   */
  connectTranslatorRecognizer() {
    return __awaiter(this, void 0, void 0, function* () {
      try {
        if (this.privAudioConfig === undefined) {
          this.privAudioConfig = _Exports__WEBPACK_IMPORTED_MODULE_16__.AudioConfig.fromDefaultMicrophoneInput();
        }
        // clear the temp subscription key if it's a participant joining
        if (this.privSpeechTranslationConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId.SpeechServiceConnection_Key]) === this.privPlaceholderKey) {
          this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyId.SpeechServiceConnection_Key], "");
        }
        const convGetter = () => this.privConversation;
        this.privCTRecognizer = new ConversationTranslationRecognizer(this.privSpeechTranslationConfig, this.privAudioConfig, this, convGetter);
      } catch (error) {
        yield this.cancelSpeech();
        throw error;
      }
    });
  }
  /**
   * Handle the start speaking request
   */
  startContinuousRecognition() {
    return new Promise((resolve, reject) => {
      this.privCTRecognizer.startContinuousRecognitionAsync(resolve, reject);
    });
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Participant: () => (/* binding */ Participant),
/* harmony export */   User: () => (/* binding */ User)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
/* eslint-disable max-classes-per-file */

class User {
  constructor(userId) {
    this.privUserId = userId;
  }
  get userId() {
    return this.privUserId;
  }
}
class Participant {
  constructor(id, avatar, displayName, isHost, isMuted, isUsingTts, preferredLanguage, voice) {
    this.privId = id;
    this.privAvatar = avatar;
    this.privDisplayName = displayName;
    this.privIsHost = isHost;
    this.privIsMuted = isMuted;
    this.privIsUsingTts = isUsingTts;
    this.privPreferredLanguage = preferredLanguage;
    this.privVoice = voice;
    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();
  }
  get avatar() {
    return this.privAvatar;
  }
  get displayName() {
    return this.privDisplayName;
  }
  get id() {
    return this.privId;
  }
  get preferredLanguage() {
    return this.privPreferredLanguage;
  }
  get isHost() {
    return this.privIsHost;
  }
  get isMuted() {
    return this.privIsMuted;
  }
  get isUsingTts() {
    return this.privIsUsingTts;
  }
  get voice() {
    return this.privVoice;
  }
  get properties() {
    return this.privProperties;
  }
  static From(id, language, voice) {
    return new Participant(id, "", id, false, false, false, language, voice);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ParticipantChangedReason: () => (/* binding */ ParticipantChangedReason)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
var ParticipantChangedReason;
(function (ParticipantChangedReason) {
  /** Participant has joined the conversation. */
  ParticipantChangedReason[ParticipantChangedReason["JoinedConversation"] = 0] = "JoinedConversation";
  /** Participant has left the conversation. This could be voluntary, or involuntary
   * (e.g. they are experiencing networking issues).
   */
  ParticipantChangedReason[ParticipantChangedReason["LeftConversation"] = 1] = "LeftConversation";
  /** The participants' state has changed (e.g. they became muted, changed their nickname). */
  ParticipantChangedReason[ParticipantChangedReason["Updated"] = 2] = "Updated";
})(ParticipantChangedReason || (ParticipantChangedReason = {}));

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranslationRecognitionCanceledEventArgs: () => (/* binding */ TranslationRecognitionCanceledEventArgs)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Define payload of speech recognition canceled result events.
 * @class TranslationRecognitionCanceledEventArgs
 */
class TranslationRecognitionCanceledEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} sessionid - The session id.
   * @param {CancellationReason} cancellationReason - The cancellation reason.
   * @param {string} errorDetails - Error details, if provided.
   * @param {TranslationRecognitionResult} result - The result.
   */
  constructor(sessionid, cancellationReason, errorDetails, errorCode, result) {
    this.privCancelReason = cancellationReason;
    this.privErrorDetails = errorDetails;
    this.privResult = result;
    this.privSessionId = sessionid;
    this.privErrorCode = errorCode;
  }
  /**
   * Specifies the recognition result.
   * @member TranslationRecognitionCanceledEventArgs.prototype.result
   * @function
   * @public
   * @returns {TranslationRecognitionResult} the recognition result.
   */
  get result() {
    return this.privResult;
  }
  /**
   * Specifies the session identifier.
   * @member TranslationRecognitionCanceledEventArgs.prototype.sessionId
   * @function
   * @public
   * @returns {string} the session identifier.
   */
  get sessionId() {
    return this.privSessionId;
  }
  /**
   * The reason the recognition was canceled.
   * @member TranslationRecognitionCanceledEventArgs.prototype.reason
   * @function
   * @public
   * @returns {CancellationReason} Specifies the reason canceled.
   */
  get reason() {
    return this.privCancelReason;
  }
  /**
   * The error code in case of an unsuccessful recognition.
   * Added in version 1.1.0.
   * @return An error code that represents the error reason.
   */
  get errorCode() {
    return this.privErrorCode;
  }
  /**
   * In case of an unsuccessful recognition, provides details of the occurred error.
   * @member TranslationRecognitionCanceledEventArgs.prototype.errorDetails
   * @function
   * @public
   * @returns {string} A String that represents the error details.
   */
  get errorDetails() {
    return this.privErrorDetails;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranslationRecognitionEventArgs: () => (/* binding */ TranslationRecognitionEventArgs)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Translation text result event arguments.
 * @class TranslationRecognitionEventArgs
 */
class TranslationRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {TranslationRecognitionResult} result - The translation recognition result.
   * @param {number} offset - The offset.
   * @param {string} sessionId - The session id.
   */
  constructor(result, offset, sessionId) {
    super(offset, sessionId);
    this.privResult = result;
  }
  /**
   * Specifies the recognition result.
   * @member TranslationRecognitionEventArgs.prototype.result
   * @function
   * @public
   * @returns {TranslationRecognitionResult} the recognition result.
   */
  get result() {
    return this.privResult;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranslationRecognitionResult: () => (/* binding */ TranslationRecognitionResult)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Translation text result.
 * @class TranslationRecognitionResult
 */
class TranslationRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechRecognitionResult {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {Translations} translations - The translations.
   * @param {string} resultId - The result id.
   * @param {ResultReason} reason - The reason.
   * @param {string} text - The recognized text.
   * @param {number} duration - The duration.
   * @param {number} offset - The offset into the stream.
   * @param {string} language - Primary Language detected, if provided.
   * @param {string} languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
   * @param {string} errorDetails - Error details, if provided.
   * @param {string} json - Additional Json, if provided.
   * @param {PropertyCollection} properties - Additional properties, if provided.
   */
  constructor(translations, resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {
    super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, undefined, errorDetails, json, properties);
    this.privTranslations = translations;
  }
  static fromSpeechRecognitionResult(result) {
    return new TranslationRecognitionResult(undefined, result.resultId, result.reason, result.text, result.duration, result.offset, result.language, result.languageDetectionConfidence, result.errorDetails, result.json, result.properties);
  }
  /**
   * Presents the translation results. Each item in the dictionary represents
   * a translation result in one of target languages, where the key is the name
   * of the target language, in BCP-47 format, and the value is the translation
   * text in the specified language.
   * @member TranslationRecognitionResult.prototype.translations
   * @function
   * @public
   * @returns {Translations} the current translation map that holds all translations requested.
   */
  get translations() {
    return this.privTranslations;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranslationRecognizer: () => (/* binding */ TranslationRecognizer)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js");
/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js");
/* harmony import */ var _Connection__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Connection */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};





/**
 * Translation recognizer
 * @class TranslationRecognizer
 */
class TranslationRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {
  /**
   * Initializes an instance of the TranslationRecognizer.
   * @constructor
   * @param {SpeechTranslationConfig} speechConfig - Set of properties to configure this recognizer.
   * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer
   * @param {IConnectionFactory} connectionFactory - An optional connection factory to use to generate the endpoint URIs, headers to set, etc...
   */
  constructor(speechConfig, audioConfig, connectionFactory) {
    const configImpl = speechConfig;
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(configImpl, "speechConfig");
    super(audioConfig, configImpl.properties, connectionFactory || new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationConnectionFactory());
    this.privDisposedTranslationRecognizer = false;
    if (this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationVoice, undefined) !== undefined) {
      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationVoice), _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationVoice]);
    }
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages), _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages]);
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage), _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage]);
  }
  /**
   * TranslationRecognizer constructor.
   * @constructor
   * @param {SpeechTranslationConfig} speechTranslationConfig - an set of initial properties for this recognizer
   * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the recognizer
   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
   */
  static FromConfig(speechTranslationConfig, autoDetectSourceLanguageConfig, audioConfig) {
    const speechTranslationConfigImpl = speechTranslationConfig;
    autoDetectSourceLanguageConfig.properties.mergeTo(speechTranslationConfigImpl.properties);
    return new TranslationRecognizer(speechTranslationConfig, audioConfig);
  }
  /**
   * Gets the language name that was set when the recognizer was created.
   * @member TranslationRecognizer.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @returns {string} Gets the language name that was set when the recognizer was created.
   */
  get speechRecognitionLanguage() {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage);
  }
  /**
   * Gets target languages for translation that were set when the recognizer was created.
   * The language is specified in BCP-47 format. The translation will provide translated text for each of language.
   * @member TranslationRecognizer.prototype.targetLanguages
   * @function
   * @public
   * @returns {string[]} Gets target languages for translation that were set when the recognizer was created.
   */
  get targetLanguages() {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(",");
  }
  /**
   * Gets the name of output voice.
   * @member TranslationRecognizer.prototype.voiceName
   * @function
   * @public
   * @returns {string} the name of output voice.
   */
  get voiceName() {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationVoice, undefined);
  }
  /**
   * The collection of properties and their values defined for this TranslationRecognizer.
   * @member TranslationRecognizer.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this TranslationRecognizer.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member TranslationRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * @member TranslationRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @param {string} value - Authorization token.
   */
  set authorizationToken(value) {
    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceAuthorization_Token, value);
  }
  /**
   * Starts recognition and translation, and stops after the first utterance is recognized.
   * The task returns the translation text as result.
   * Note: recognizeOnceAsync returns when the first utterance has been recognized, so it is suitable only
   * for single shot recognition like command or query. For long-running recognition,
   * use startContinuousRecognitionAsync() instead.
   * @member TranslationRecognizer.prototype.recognizeOnceAsync
   * @function
   * @public
   * @param cb - Callback that received the result when the translation has completed.
   * @param err - Callback invoked in case of an error.
   */
  recognizeOnceAsync(cb, err) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.recognizeOnceAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation), cb, err);
  }
  /**
   * Starts recognition and translation, until stopContinuousRecognitionAsync() is called.
   * User must subscribe to events to receive translation results.
   * @member TranslationRecognizer.prototype.startContinuousRecognitionAsync
   * @function
   * @public
   * @param cb - Callback that received the translation has started.
   * @param err - Callback invoked in case of an error.
   */
  startContinuousRecognitionAsync(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation), cb, err);
  }
  /**
   * Stops continuous recognition and translation.
   * @member TranslationRecognizer.prototype.stopContinuousRecognitionAsync
   * @function
   * @public
   * @param cb - Callback that received the translation has stopped.
   * @param err - Callback invoked in case of an error.
   */
  stopContinuousRecognitionAsync(cb, err) {
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);
  }
  /**
   * dynamically remove a language from list of target language
   * (can be used while recognition is ongoing)
   * @member TranslationRecognizer.prototype.removeTargetLanguage
   * @function
   * @param lang - language to be removed
   * @public
   */
  removeTargetLanguage(lang) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(lang, "language to be removed");
    if (this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {
      const languages = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(",");
      const index = languages.indexOf(lang);
      if (index > -1) {
        languages.splice(index, 1);
        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(","));
        this.updateLanguages(languages);
      }
    }
  }
  /**
   * dynamically add a language to list of target language
   * (can be used while recognition is ongoing)
   * @member TranslationRecognizer.prototype.addTargetLanguage
   * @function
   * @param lang - language to be added
   * @public
   */
  addTargetLanguage(lang) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(lang, "language to be added");
    let languages = [];
    if (this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {
      languages = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(",");
      if (!languages.includes(lang)) {
        languages.push(lang);
        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(","));
      }
    } else {
      this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages, lang);
      languages = [lang];
    }
    this.updateLanguages(languages);
  }
  /**
   * closes all external resources held by an instance of this class.
   * @member TranslationRecognizer.prototype.close
   * @function
   * @public
   */
  close(cb, errorCb) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);
  }
  /**
   * handles ConnectionEstablishedEvent for conversation translation scenarios.
   * @member TranslationRecognizer.prototype.onConnection
   * @function
   * @public
   */
  // eslint-disable-next-line @typescript-eslint/no-empty-function
  onConnection() {}
  /**
   * handles disconnection events for conversation translation scenarios.
   * @member TranslationRecognizer.prototype.onDisconnection
   * @function
   * @public
   */
  // eslint-disable-next-line @typescript-eslint/no-empty-function
  onDisconnection() {
    return __awaiter(this, void 0, void 0, function* () {});
  }
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: {
        get: () => super.dispose
      }
    });
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privDisposedTranslationRecognizer) {
        return;
      }
      this.privDisposedTranslationRecognizer = true;
      if (disposing) {
        yield this.implRecognizerStop();
        yield _super.dispose.call(this, disposing);
      }
    });
  }
  createRecognizerConfig(speechConfig) {
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognizerConfig(speechConfig, this.privProperties);
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const configImpl = audioConfig;
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.TranslationServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);
  }
  updateLanguages(languages) {
    const conn = _Connection__WEBPACK_IMPORTED_MODULE_7__.Connection.fromRecognizer(this);
    if (!!conn) {
      conn.setMessageProperty("speech.context", "translationcontext", {
        to: languages
      });
      conn.sendMessageAsync("event", JSON.stringify({
        id: "translation",
        name: "updateLanguage",
        to: languages
      }));
    }
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranslationSynthesisEventArgs: () => (/* binding */ TranslationSynthesisEventArgs)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Translation Synthesis event arguments
 * @class TranslationSynthesisEventArgs
 */
class TranslationSynthesisEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {TranslationSynthesisResult} result - The translation synthesis result.
   * @param {string} sessionId - The session id.
   */
  constructor(result, sessionId) {
    super(sessionId);
    this.privResult = result;
  }
  /**
   * Specifies the translation synthesis result.
   * @member TranslationSynthesisEventArgs.prototype.result
   * @function
   * @public
   * @returns {TranslationSynthesisResult} Specifies the translation synthesis result.
   */
  get result() {
    return this.privResult;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TranslationSynthesisResult: () => (/* binding */ TranslationSynthesisResult)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines translation synthesis result, i.e. the voice output of the translated
 * text in the target language.
 * @class TranslationSynthesisResult
 */
class TranslationSynthesisResult {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {ResultReason} reason - The synthesis reason.
   * @param {ArrayBuffer} audio - The audio data.
   */
  constructor(reason, audio) {
    this.privReason = reason;
    this.privAudio = audio;
  }
  /**
   * Translated text in the target language.
   * @member TranslationSynthesisResult.prototype.audio
   * @function
   * @public
   * @returns {ArrayBuffer} Translated audio in the target language.
   */
  get audio() {
    return this.privAudio;
  }
  /**
   * The synthesis status.
   * @member TranslationSynthesisResult.prototype.reason
   * @function
   * @public
   * @returns {ResultReason} The synthesis status.
   */
  get reason() {
    return this.privReason;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Translations: () => (/* binding */ Translations)
/* harmony export */ });
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Represents collection of parameters and their values.
 * @class Translations
 */
class Translations {
  constructor() {
    // Use an PropertyCollection internally, just wrapping it to hide the | enum syntax it has.
    this.privMap = new _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();
  }
  /**
   * Get the languages in the object in a String array.
   * @member Translations.prototype.languages
   * @function
   * @public
   * @returns {string[]} languages in translations object.
   */
  get languages() {
    return this.privMap.keys;
  }
  /**
   * Returns the parameter value in type String. The parameter must have the same type as String.
   * Currently only String, int and bool are allowed.
   * If the name is not available, the specified defaultValue is returned.
   * @member Translations.prototype.get
   * @function
   * @public
   * @param {string} key - The parameter name.
   * @param {string} def - The default value which is returned if the parameter is not available in the collection.
   * @returns {string} value of the parameter.
   */
  get(key, def) {
    return this.privMap.getProperty(key, def);
  }
  /**
   * Sets the String value of the parameter specified by name.
   * @member Translations.prototype.set
   * @function
   * @public
   * @param {string} key - The parameter name.
   * @param {string} value - The value of the parameter.
   */
  set(key, value) {
    this.privMap.setProperty(key, value);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TurnStatusReceivedEventArgs: () => (/* binding */ TurnStatusReceivedEventArgs)
/* harmony export */ });
/* harmony import */ var _common_speech_ServiceMessages_TurnStatusPayload__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/ServiceMessages/TurnStatusPayload */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.

/**
 * Defines contents of received message/events.
 * @class TurnStatusReceivedEventArgs
 */
class TurnStatusReceivedEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} turnStatus - The JSON-encoded turn status message.
   */
  constructor(turnStatus) {
    this.privTurnStatus = _common_speech_ServiceMessages_TurnStatusPayload__WEBPACK_IMPORTED_MODULE_0__.TurnStatusResponsePayload.fromJSON(turnStatus);
  }
  /**
   * Gets the interaction identifier associated with this turn status event.
   * @member TurnStatusReceivedEventArgs.prototype.interactionId
   * @function
   * @public
   * @returns {any} the received interaction id.
   */
  get interactionId() {
    return this.privTurnStatus.interactionId;
  }
  /**
   * Gets the conversation identifier associated with this turn status event.
   * @member TurnStatusReceivedEventArgs.prototype.conversationId
   * @function
   * @public
   * @returns {any} the received conversation id.
   */
  get conversationId() {
    return this.privTurnStatus.conversationId;
  }
  /**
   * Gets the received turn status code.
   * @member TurnStatusReceivedEventArgs.prototype.statusCode
   * @function
   * @public
   * @returns {number} the received turn status.
   */
  get statusCode() {
    return this.privTurnStatus.statusCode; // eslint-disable-line @typescript-eslint/no-unsafe-return
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SynthesisVoiceGender: () => (/* binding */ SynthesisVoiceGender),
/* harmony export */   SynthesisVoiceType: () => (/* binding */ SynthesisVoiceType),
/* harmony export */   VoiceInfo: () => (/* binding */ VoiceInfo)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines the gender of synthesis voices.
 * Added in version 1.20.0.
 */
var SynthesisVoiceGender;
(function (SynthesisVoiceGender) {
  /** Gender unknown */
  SynthesisVoiceGender[SynthesisVoiceGender["Unknown"] = 0] = "Unknown";
  /** Female voice */
  SynthesisVoiceGender[SynthesisVoiceGender["Female"] = 1] = "Female";
  /** Male voice */
  SynthesisVoiceGender[SynthesisVoiceGender["Male"] = 2] = "Male";
})(SynthesisVoiceGender || (SynthesisVoiceGender = {}));
var SynthesisVoiceType;
(function (SynthesisVoiceType) {
  SynthesisVoiceType[SynthesisVoiceType["OnlineNeural"] = 1] = "OnlineNeural";
  SynthesisVoiceType[SynthesisVoiceType["OnlineStandard"] = 2] = "OnlineStandard";
  SynthesisVoiceType[SynthesisVoiceType["OfflineNeural"] = 3] = "OfflineNeural";
  SynthesisVoiceType[SynthesisVoiceType["OfflineStandard"] = 4] = "OfflineStandard";
})(SynthesisVoiceType || (SynthesisVoiceType = {}));
/**
 * Information about Speech Synthesis voice
 * Added in version 1.20.0.
 * @class VoiceInfo
 */
class VoiceInfo {
  constructor(json) {
    this.privStyleList = [];
    this.privVoicePath = "";
    if (!!json) {
      this.privName = json.Name;
      this.privLocale = json.Locale;
      this.privShortName = json.ShortName;
      this.privLocaleName = json.LocaleName;
      this.privLocalName = json.LocalName;
      this.privVoiceType = json.VoiceType.endsWith("Standard") ? SynthesisVoiceType.OnlineStandard : SynthesisVoiceType.OnlineNeural;
      this.privGender = json.Gender === "Male" ? SynthesisVoiceGender.Male : json.Gender === "Female" ? SynthesisVoiceGender.Female : SynthesisVoiceGender.Unknown;
      if (!!json.StyleList && Array.isArray(json.StyleList)) {
        for (const style of json.StyleList) {
          this.privStyleList.push(style);
        }
      }
    }
  }
  get name() {
    return this.privName;
  }
  get locale() {
    return this.privLocale;
  }
  get shortName() {
    return this.privShortName;
  }
  get localName() {
    return this.privLocalName;
  }
  get localeName() {
    return this.privLocaleName;
  }
  get gender() {
    return this.privGender;
  }
  get voiceType() {
    return this.privVoiceType;
  }
  get styleList() {
    return this.privStyleList;
  }
  get voicePath() {
    return this.privVoicePath;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   VoiceProfile: () => (/* binding */ VoiceProfile)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Defines Voice Profile class for Speaker Recognition
 * @class VoiceProfile
 */
class VoiceProfile {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} profileId - profileId of this Voice Profile.
   * @param {VoiceProfileType} profileType - profileType of this Voice Profile.
   */
  constructor(profileId, profileType) {
    this.privId = profileId;
    this.privProfileType = profileType;
  }
  /**
   * profileId of this Voice Profile instance
   * @member VoiceProfile.prototype.profileId
   * @function
   * @public
   * @returns {string} profileId of this Voice Profile instance.
   */
  get profileId() {
    return this.privId;
  }
  /**
   * profileType of this Voice Profile instance
   * @member VoiceProfile.prototype.profileType
   * @function
   * @public
   * @returns {VoiceProfileType} profile type of this Voice Profile instance.
   */
  get profileType() {
    return this.privProfileType;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   VoiceProfileClient: () => (/* binding */ VoiceProfileClient)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConnectionFactory.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/VoiceServiceRecognizer.js");
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js");
/* harmony import */ var _Audio_AudioConfig__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Audio/AudioConfig */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};




/**
 * Defines VoiceProfileClient class for Speaker Recognition
 * Handles operations from user for Voice Profile operations (e.g. createProfile, deleteProfile)
 * @class VoiceProfileClient
 */
class VoiceProfileClient extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {
  /**
   * VoiceProfileClient constructor.
   * @constructor
   * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer (authentication key, region, &c)
   */
  constructor(speechConfig) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(speechConfig, "speechConfig");
    const speechConfigImpl = speechConfig;
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(speechConfigImpl, "speechConfig");
    super(_Audio_AudioConfig__WEBPACK_IMPORTED_MODULE_2__.AudioConfig.fromStreamInput(_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioInputStream.createPushStream()), speechConfigImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.VoiceProfileConnectionFactory());
    this.privProperties = speechConfigImpl.properties.clone();
    this.privVoiceAdapter = this.privReco;
    this.privDisposedVoiceAdapter = false;
  }
  /**
   * The collection of properties and their values defined for this VoiceProfileClient.
   * @member VoiceProfileClient.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this VoiceProfileClient.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member VoiceProfileClient.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_5__.PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * @member VoiceProfileClient.prototype.authorizationToken
   * @function
   * @public
   * @param {string} token - Authorization token.
   */
  set authorizationToken(token) {
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_5__.PropertyId.SpeechServiceAuthorization_Token, token);
  }
  /**
   * Create a speaker recognition voice profile
   * @member VoiceProfileClient.prototype.createProfileAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfileType} profileType Type of Voice Profile to be created
   * @param {string} lang Language string (locale) for Voice Profile
   * @return {Promise<VoiceProfile>} - Promise of a VoiceProfile.
   */
  createProfileAsync(profileType, lang) {
    return __awaiter(this, void 0, void 0, function* () {
      const profileIds = yield this.privVoiceAdapter.createProfile(profileType, lang);
      return new _Exports__WEBPACK_IMPORTED_MODULE_6__.VoiceProfile(profileIds[0], profileType);
    });
  }
  /**
   * Get current information of a voice profile
   * @member VoiceProfileClient.prototype.retrieveEnrollmentResultAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfile} profile Voice Profile to retrieve info for
   * @return {Promise<VoiceProfileEnrollmentResult>} - Promise of a VoiceProfileEnrollmentResult.
   */
  retrieveEnrollmentResultAsync(profile) {
    return __awaiter(this, void 0, void 0, function* () {
      return this.privVoiceAdapter.retrieveEnrollmentResult(profile);
    });
  }
  /**
   * Get all voice profiles on account with given voice profile type
   * @member VoiceProfileClient.prototype.getAllProfilesAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfileType} profileType profile type (identification/verification) for which to list profiles
   * @return {Promise<VoiceProfileEnrollmentResult[]>} - Promise of an array of VoiceProfileEnrollmentResults.
   */
  getAllProfilesAsync(profileType) {
    return __awaiter(this, void 0, void 0, function* () {
      return this.privVoiceAdapter.getAllProfiles(profileType);
      /*
      const result: { json: { value: EnrollmentResultJSON[] } } = await this.privAdapter.getProfiles(profileType);
      if (profileType === VoiceProfileType.TextIndependentIdentification) {
          return VoiceProfileEnrollmentResult.FromIdentificationProfileList(result.json);
      }
      return VoiceProfileEnrollmentResult.FromVerificationProfileList(result.json);
      */
    });
  }
  /**
   * Get valid authorization phrases for voice profile enrollment
   * @member VoiceProfileClient.prototype.getActivationPhrasesAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfileType} profileType Profile Type to get activation phrases for
   * @param {string} lang Language string (locale) for Voice Profile
   */
  getActivationPhrasesAsync(profileType, lang) {
    return __awaiter(this, void 0, void 0, function* () {
      return this.privVoiceAdapter.getActivationPhrases(profileType, lang);
    });
  }
  /**
   * Create a speaker recognition voice profile
   * @member VoiceProfileClient.prototype.enrollProfileAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfile} profile Voice Profile to create enrollment for
   * @param {AudioConfig} audioConfig source info from which to create enrollment
   * @return {Promise<VoiceProfileEnrollmentResult>} - Promise of a VoiceProfileEnrollmentResult.
   */
  enrollProfileAsync(profile, audioConfig) {
    return __awaiter(this, void 0, void 0, function* () {
      const configImpl = audioConfig;
      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(configImpl, "audioConfig");
      this.audioConfig = audioConfig;
      this.privVoiceAdapter.SpeakerAudioSource = configImpl;
      return this.privVoiceAdapter.enrollProfile(profile);
    });
  }
  /**
   * Delete a speaker recognition voice profile
   * @member VoiceProfileClient.prototype.deleteProfileAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfile} profile Voice Profile to be deleted
   * @return {Promise<VoiceProfileResult>} - Promise of a VoiceProfileResult.
   */
  deleteProfileAsync(profile) {
    return __awaiter(this, void 0, void 0, function* () {
      return this.privVoiceAdapter.deleteProfile(profile);
    });
  }
  /**
   * Remove all enrollments for a speaker recognition voice profile
   * @member VoiceProfileClient.prototype.resetProfileAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfile} profile Voice Profile to be reset
   * @return {Promise<VoiceProfileResult>} - Promise of a VoiceProfileResult.
   */
  resetProfileAsync(profile) {
    return __awaiter(this, void 0, void 0, function* () {
      return this.privVoiceAdapter.resetProfile(profile);
    });
  }
  /**
   * Clean up object and close underlying connection
   * @member VoiceProfileClient.prototype.close
   * @function
   * @async
   * @public
   */
  close() {
    return __awaiter(this, void 0, void 0, function* () {
      yield this.dispose(true);
    });
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const audioImpl = audioConfig;
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.VoiceServiceRecognizer(authentication, connectionFactory, audioImpl, recognizerConfig, this);
  }
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: {
        get: () => super.dispose
      }
    });
    return __awaiter(this, void 0, void 0, function* () {
      if (this.privDisposedVoiceAdapter) {
        return;
      }
      this.privDisposedVoiceAdapter = true;
      if (disposing) {
        yield _super.dispose.call(this, disposing);
      }
    });
  }
  createRecognizerConfig(speechConfig) {
    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__.RecognizerConfig(speechConfig, this.properties);
  }
  getResult(result, successReason) {
    const response = new _Exports__WEBPACK_IMPORTED_MODULE_9__.VoiceProfileResult(result.ok ? successReason : _Exports__WEBPACK_IMPORTED_MODULE_10__.ResultReason.Canceled, result.statusText);
    return response;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   VoiceProfileEnrollmentCancellationDetails: () => (/* binding */ VoiceProfileEnrollmentCancellationDetails),
/* harmony export */   VoiceProfileEnrollmentResult: () => (/* binding */ VoiceProfileEnrollmentResult)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */


/**
 * Output format
 * @class VoiceProfileEnrollmentResult
 */
class VoiceProfileEnrollmentResult {
  constructor(reason, json, statusText) {
    this.privReason = reason;
    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();
    if (this.privReason !== _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.Canceled) {
      if (!!json) {
        this.privDetails = JSON.parse(json);
        if (this.privDetails.enrollmentStatus.toLowerCase() === "enrolling") {
          this.privReason = _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.EnrollingVoiceProfile;
        }
      }
    } else {
      this.privErrorDetails = statusText;
      this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.ServiceError]);
    }
  }
  get reason() {
    return this.privReason;
  }
  get enrollmentsCount() {
    return this.privDetails.enrollmentsCount;
  }
  get enrollmentsLength() {
    return this.privDetails.enrollmentsLength;
  }
  get properties() {
    return this.privProperties;
  }
  get enrollmentResultDetails() {
    return this.privDetails;
  }
  get errorDetails() {
    return this.privErrorDetails;
  }
  static FromIdentificationProfileList(json) {
    const results = [];
    for (const item of json.value) {
      const reason = item.enrollmentStatus.toLowerCase() === "enrolling" ? _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.EnrollingVoiceProfile : item.enrollmentStatus.toLowerCase() === "enrolled" ? _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.Canceled;
      const result = new VoiceProfileEnrollmentResult(reason, null, null);
      result.privDetails = this.getIdentificationDetails(item);
      results.push(result);
    }
    return results;
  }
  static FromVerificationProfileList(json) {
    const results = [];
    for (const item of json.value) {
      const reason = item.enrollmentStatus.toLowerCase() === "enrolling" ? _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.EnrollingVoiceProfile : item.enrollmentStatus.toLowerCase() === "enrolled" ? _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.Canceled;
      const result = new VoiceProfileEnrollmentResult(reason, null, null);
      result.privDetails = this.getVerificationDetails(item);
      results.push(result);
    }
    return results;
  }
  static getIdentificationDetails(json) {
    return {
      audioLength: json.audioLength ? parseFloat(json.audioLength) : 0,
      audioSpeechLength: json.audioSpeechLength ? parseFloat(json.audioSpeechLength) : 0,
      enrollmentStatus: json.enrollmentStatus,
      enrollmentsCount: json.enrollmentsCount || 0,
      enrollmentsLength: json.enrollmentsLength ? parseFloat(json.enrollmentsLength) : 0,
      enrollmentsSpeechLength: json.enrollmentsSpeechLength ? parseFloat(json.enrollmentsSpeechLength) : 0,
      profileId: json.profileId || json.identificationProfileId,
      remainingEnrollmentsSpeechLength: json.remainingEnrollmentsSpeechLength ? parseFloat(json.remainingEnrollmentsSpeechLength) : 0
    };
  }
  static getVerificationDetails(json) {
    return {
      audioLength: json.audioLength ? parseFloat(json.audioLength) : 0,
      audioSpeechLength: json.audioSpeechLength ? parseFloat(json.audioSpeechLength) : 0,
      enrollmentStatus: json.enrollmentStatus,
      enrollmentsCount: json.enrollmentsCount,
      enrollmentsLength: json.enrollmentsLength ? parseFloat(json.enrollmentsLength) : 0,
      enrollmentsSpeechLength: json.enrollmentsSpeechLength ? parseFloat(json.enrollmentsSpeechLength) : 0,
      profileId: json.profileId || json.verificationProfileId,
      remainingEnrollmentsCount: json.remainingEnrollments || json.remainingEnrollmentsCount,
      remainingEnrollmentsSpeechLength: json.remainingEnrollmentsSpeechLength ? parseFloat(json.remainingEnrollmentsSpeechLength) : 0
    };
  }
}
/**
 * @class VoiceProfileEnrollmentCancellationDetails
 */
class VoiceProfileEnrollmentCancellationDetails extends _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationDetailsBase {
  constructor(reason, errorDetails, errorCode) {
    super(reason, errorDetails, errorCode);
  }
  /**
   * Creates an instance of VoiceProfileEnrollmentCancellationDetails object for the canceled VoiceProfileEnrollmentResult.
   * @member VoiceProfileEnrollmentCancellationDetails.fromResult
   * @function
   * @public
   * @param {VoiceProfileEnrollmentResult} result - The result that was canceled.
   * @returns {VoiceProfileEnrollmentCancellationDetails} The cancellation details object being created.
   */
  static fromResult(result) {
    const reason = _Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error;
    let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.NoError;
    if (!!result.properties) {
      errorCode = _Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode[result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.NoError])]; //eslint-disable-line
    }

    return new VoiceProfileEnrollmentCancellationDetails(reason, result.errorDetails, errorCode);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   VoiceProfilePhraseResult: () => (/* binding */ VoiceProfilePhraseResult)
/* harmony export */ });
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.


/**
 * Output format
 * @class VoiceProfilePhraseResult
 */
class VoiceProfilePhraseResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.VoiceProfileResult {
  constructor(reason, statusText, type, phraseArray) {
    super(reason, statusText);
    this.privPhrases = [];
    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(phraseArray, "phrase array");
    this.privType = type;
    if (!!phraseArray && !!phraseArray[0]) {
      this.privPhrases = phraseArray;
    }
  }
  get phrases() {
    return this.privPhrases;
  }
  get type() {
    return this.privType;
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   VoiceProfileCancellationDetails: () => (/* binding */ VoiceProfileCancellationDetails),
/* harmony export */   VoiceProfileResult: () => (/* binding */ VoiceProfileResult)
/* harmony export */ });
/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js");
/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js");
/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js");
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */



/**
 * Output format
 * @class VoiceProfileResult
 */
class VoiceProfileResult {
  constructor(reason, statusText) {
    this.privReason = reason;
    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();
    if (reason === _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.Canceled) {
      _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(statusText, "statusText");
      this.privErrorDetails = statusText;
      this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode.ServiceError]);
    }
  }
  get reason() {
    return this.privReason;
  }
  get properties() {
    return this.privProperties;
  }
  get errorDetails() {
    return this.privErrorDetails;
  }
}
/**
 * @class VoiceProfileCancellationDetails
 */
class VoiceProfileCancellationDetails extends _Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationDetailsBase {
  constructor(reason, errorDetails, errorCode) {
    super(reason, errorDetails, errorCode);
  }
  /**
   * Creates an instance of VoiceProfileCancellationDetails object for the canceled VoiceProfileResult.
   * @member VoiceProfileCancellationDetails.fromResult
   * @function
   * @public
   * @param {VoiceProfileResult} result - The result that was canceled.
   * @returns {VoiceProfileCancellationDetails} The cancellation details object being created.
   */
  static fromResult(result) {
    const reason = _Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error;
    let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode.NoError;
    if (!!result.properties) {
      errorCode = _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode[result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode.NoError])]; //eslint-disable-line
    }

    return new VoiceProfileCancellationDetails(reason, result.errorDetails, errorCode);
  }
}

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   VoiceProfileType: () => (/* binding */ VoiceProfileType)
/* harmony export */ });
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * Output format
 * @class VoiceProfileType
 */
var VoiceProfileType;
(function (VoiceProfileType) {
  /**
   * Text independent speaker identification
   * @member VoiceProfileType.TextIndependentIdentification
   */
  VoiceProfileType[VoiceProfileType["TextIndependentIdentification"] = 0] = "TextIndependentIdentification";
  /**
   * Text dependent speaker verification
   * @member VoiceProfileType.TextDependentVerification
   */
  VoiceProfileType[VoiceProfileType["TextDependentVerification"] = 1] = "TextDependentVerification";
  /**
   * Text independent speaker verification
   * @member VoiceProfileType.TextIndependentVerification
   */
  VoiceProfileType[VoiceProfileType["TextIndependentVerification"] = 2] = "TextIndependentVerification";
})(VoiceProfileType || (VoiceProfileType = {}));

/***/ }),

/***/ "./node_modules/openai/dist/api.js":
/*!*****************************************!*\
  !*** ./node_modules/openai/dist/api.js ***!
  \*****************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


/* tslint:disable */
/* eslint-disable */
/**
 * OpenAI API
 * APIs for sampling from and fine-tuning language models
 *
 * The version of the OpenAPI document: 1.3.0
 *
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
var __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports.OpenAIApi = exports.OpenAIApiFactory = exports.OpenAIApiFp = exports.OpenAIApiAxiosParamCreator = exports.CreateImageRequestResponseFormatEnum = exports.CreateImageRequestSizeEnum = exports.ChatCompletionResponseMessageRoleEnum = exports.ChatCompletionRequestMessageRoleEnum = void 0;
const axios_1 = __webpack_require__(/*! axios */ "./node_modules/axios/index.js");
// Some imports not used depending on template conditions
// @ts-ignore
const common_1 = __webpack_require__(/*! ./common */ "./node_modules/openai/dist/common.js");
// @ts-ignore
const base_1 = __webpack_require__(/*! ./base */ "./node_modules/openai/dist/base.js");
exports.ChatCompletionRequestMessageRoleEnum = {
  System: 'system',
  User: 'user',
  Assistant: 'assistant',
  Function: 'function'
};
exports.ChatCompletionResponseMessageRoleEnum = {
  System: 'system',
  User: 'user',
  Assistant: 'assistant',
  Function: 'function'
};
exports.CreateImageRequestSizeEnum = {
  _256x256: '256x256',
  _512x512: '512x512',
  _1024x1024: '1024x1024'
};
exports.CreateImageRequestResponseFormatEnum = {
  Url: 'url',
  B64Json: 'b64_json'
};
/**
 * OpenAIApi - axios parameter creator
 * @export
 */
exports.OpenAIApiAxiosParamCreator = function (configuration) {
  return {
    /**
     *
     * @summary Immediately cancel a fine-tune job.
     * @param {string} fineTuneId The ID of the fine-tune job to cancel
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    cancelFineTune: (fineTuneId, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'fineTuneId' is not null or undefined
      common_1.assertParamExists('cancelFineTune', 'fineTuneId', fineTuneId);
      const localVarPath = `/fine-tunes/{fine_tune_id}/cancel`.replace(`{${"fine_tune_id"}}`, encodeURIComponent(String(fineTuneId)));
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Answers the specified question using the provided documents and examples.  The endpoint first [searches](/docs/api-reference/searches) over provided documents or files to find relevant context. The relevant context is combined with the provided examples and question to create the prompt for [completion](/docs/api-reference/completions).
     * @param {CreateAnswerRequest} createAnswerRequest
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    createAnswer: (createAnswerRequest, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'createAnswerRequest' is not null or undefined
      common_1.assertParamExists('createAnswer', 'createAnswerRequest', createAnswerRequest);
      const localVarPath = `/answers`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      localVarHeaderParameter['Content-Type'] = 'application/json';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = common_1.serializeDataIfNeeded(createAnswerRequest, localVarRequestOptions, configuration);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Creates a model response for the given chat conversation.
     * @param {CreateChatCompletionRequest} createChatCompletionRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createChatCompletion: (createChatCompletionRequest, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'createChatCompletionRequest' is not null or undefined
      common_1.assertParamExists('createChatCompletion', 'createChatCompletionRequest', createChatCompletionRequest);
      const localVarPath = `/chat/completions`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      localVarHeaderParameter['Content-Type'] = 'application/json';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = common_1.serializeDataIfNeeded(createChatCompletionRequest, localVarRequestOptions, configuration);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Classifies the specified `query` using provided examples.  The endpoint first [searches](/docs/api-reference/searches) over the labeled examples to select the ones most relevant for the particular query. Then, the relevant examples are combined with the query to construct a prompt to produce the final label via the [completions](/docs/api-reference/completions) endpoint.  Labeled examples can be provided via an uploaded `file`, or explicitly listed in the request using the `examples` parameter for quick tests and small scale use cases.
     * @param {CreateClassificationRequest} createClassificationRequest
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    createClassification: (createClassificationRequest, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'createClassificationRequest' is not null or undefined
      common_1.assertParamExists('createClassification', 'createClassificationRequest', createClassificationRequest);
      const localVarPath = `/classifications`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      localVarHeaderParameter['Content-Type'] = 'application/json';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = common_1.serializeDataIfNeeded(createClassificationRequest, localVarRequestOptions, configuration);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Creates a completion for the provided prompt and parameters.
     * @param {CreateCompletionRequest} createCompletionRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createCompletion: (createCompletionRequest, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'createCompletionRequest' is not null or undefined
      common_1.assertParamExists('createCompletion', 'createCompletionRequest', createCompletionRequest);
      const localVarPath = `/completions`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      localVarHeaderParameter['Content-Type'] = 'application/json';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = common_1.serializeDataIfNeeded(createCompletionRequest, localVarRequestOptions, configuration);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Creates a new edit for the provided input, instruction, and parameters.
     * @param {CreateEditRequest} createEditRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createEdit: (createEditRequest, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'createEditRequest' is not null or undefined
      common_1.assertParamExists('createEdit', 'createEditRequest', createEditRequest);
      const localVarPath = `/edits`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      localVarHeaderParameter['Content-Type'] = 'application/json';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = common_1.serializeDataIfNeeded(createEditRequest, localVarRequestOptions, configuration);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Creates an embedding vector representing the input text.
     * @param {CreateEmbeddingRequest} createEmbeddingRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createEmbedding: (createEmbeddingRequest, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'createEmbeddingRequest' is not null or undefined
      common_1.assertParamExists('createEmbedding', 'createEmbeddingRequest', createEmbeddingRequest);
      const localVarPath = `/embeddings`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      localVarHeaderParameter['Content-Type'] = 'application/json';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = common_1.serializeDataIfNeeded(createEmbeddingRequest, localVarRequestOptions, configuration);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Upload a file that contains document(s) to be used across various endpoints/features. Currently, the size of all the files uploaded by one organization can be up to 1 GB. Please contact us if you need to increase the storage limit.
     * @param {File} file Name of the [JSON Lines](https://jsonlines.readthedocs.io/en/latest/) file to be uploaded.  If the &#x60;purpose&#x60; is set to \\\&quot;fine-tune\\\&quot;, each line is a JSON record with \\\&quot;prompt\\\&quot; and \\\&quot;completion\\\&quot; fields representing your [training examples](/docs/guides/fine-tuning/prepare-training-data).
     * @param {string} purpose The intended purpose of the uploaded documents.  Use \\\&quot;fine-tune\\\&quot; for [Fine-tuning](/docs/api-reference/fine-tunes). This allows us to validate the format of the uploaded file.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createFile: (file, purpose, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'file' is not null or undefined
      common_1.assertParamExists('createFile', 'file', file);
      // verify required parameter 'purpose' is not null or undefined
      common_1.assertParamExists('createFile', 'purpose', purpose);
      const localVarPath = `/files`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      const localVarFormParams = new (configuration && configuration.formDataCtor || FormData)();
      if (file !== undefined) {
        localVarFormParams.append('file', file);
      }
      if (purpose !== undefined) {
        localVarFormParams.append('purpose', purpose);
      }
      localVarHeaderParameter['Content-Type'] = 'multipart/form-data';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), localVarFormParams.getHeaders()), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = localVarFormParams;
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Creates a job that fine-tunes a specified model from a given dataset.  Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.  [Learn more about Fine-tuning](/docs/guides/fine-tuning)
     * @param {CreateFineTuneRequest} createFineTuneRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createFineTune: (createFineTuneRequest, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'createFineTuneRequest' is not null or undefined
      common_1.assertParamExists('createFineTune', 'createFineTuneRequest', createFineTuneRequest);
      const localVarPath = `/fine-tunes`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      localVarHeaderParameter['Content-Type'] = 'application/json';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = common_1.serializeDataIfNeeded(createFineTuneRequest, localVarRequestOptions, configuration);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Creates an image given a prompt.
     * @param {CreateImageRequest} createImageRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createImage: (createImageRequest, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'createImageRequest' is not null or undefined
      common_1.assertParamExists('createImage', 'createImageRequest', createImageRequest);
      const localVarPath = `/images/generations`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      localVarHeaderParameter['Content-Type'] = 'application/json';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = common_1.serializeDataIfNeeded(createImageRequest, localVarRequestOptions, configuration);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Creates an edited or extended image given an original image and a prompt.
     * @param {File} image The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.
     * @param {string} prompt A text description of the desired image(s). The maximum length is 1000 characters.
     * @param {File} [mask] An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where &#x60;image&#x60; should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as &#x60;image&#x60;.
     * @param {number} [n] The number of images to generate. Must be between 1 and 10.
     * @param {string} [size] The size of the generated images. Must be one of &#x60;256x256&#x60;, &#x60;512x512&#x60;, or &#x60;1024x1024&#x60;.
     * @param {string} [responseFormat] The format in which the generated images are returned. Must be one of &#x60;url&#x60; or &#x60;b64_json&#x60;.
     * @param {string} [user] A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createImageEdit: (image, prompt, mask, n, size, responseFormat, user, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'image' is not null or undefined
      common_1.assertParamExists('createImageEdit', 'image', image);
      // verify required parameter 'prompt' is not null or undefined
      common_1.assertParamExists('createImageEdit', 'prompt', prompt);
      const localVarPath = `/images/edits`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      const localVarFormParams = new (configuration && configuration.formDataCtor || FormData)();
      if (image !== undefined) {
        localVarFormParams.append('image', image);
      }
      if (mask !== undefined) {
        localVarFormParams.append('mask', mask);
      }
      if (prompt !== undefined) {
        localVarFormParams.append('prompt', prompt);
      }
      if (n !== undefined) {
        localVarFormParams.append('n', n);
      }
      if (size !== undefined) {
        localVarFormParams.append('size', size);
      }
      if (responseFormat !== undefined) {
        localVarFormParams.append('response_format', responseFormat);
      }
      if (user !== undefined) {
        localVarFormParams.append('user', user);
      }
      localVarHeaderParameter['Content-Type'] = 'multipart/form-data';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), localVarFormParams.getHeaders()), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = localVarFormParams;
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Creates a variation of a given image.
     * @param {File} image The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.
     * @param {number} [n] The number of images to generate. Must be between 1 and 10.
     * @param {string} [size] The size of the generated images. Must be one of &#x60;256x256&#x60;, &#x60;512x512&#x60;, or &#x60;1024x1024&#x60;.
     * @param {string} [responseFormat] The format in which the generated images are returned. Must be one of &#x60;url&#x60; or &#x60;b64_json&#x60;.
     * @param {string} [user] A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createImageVariation: (image, n, size, responseFormat, user, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'image' is not null or undefined
      common_1.assertParamExists('createImageVariation', 'image', image);
      const localVarPath = `/images/variations`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      const localVarFormParams = new (configuration && configuration.formDataCtor || FormData)();
      if (image !== undefined) {
        localVarFormParams.append('image', image);
      }
      if (n !== undefined) {
        localVarFormParams.append('n', n);
      }
      if (size !== undefined) {
        localVarFormParams.append('size', size);
      }
      if (responseFormat !== undefined) {
        localVarFormParams.append('response_format', responseFormat);
      }
      if (user !== undefined) {
        localVarFormParams.append('user', user);
      }
      localVarHeaderParameter['Content-Type'] = 'multipart/form-data';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), localVarFormParams.getHeaders()), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = localVarFormParams;
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Classifies if text violates OpenAI\'s Content Policy
     * @param {CreateModerationRequest} createModerationRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createModeration: (createModerationRequest, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'createModerationRequest' is not null or undefined
      common_1.assertParamExists('createModeration', 'createModerationRequest', createModerationRequest);
      const localVarPath = `/moderations`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      localVarHeaderParameter['Content-Type'] = 'application/json';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = common_1.serializeDataIfNeeded(createModerationRequest, localVarRequestOptions, configuration);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary The search endpoint computes similarity scores between provided query and documents. Documents can be passed directly to the API if there are no more than 200 of them.  To go beyond the 200 document limit, documents can be processed offline and then used for efficient retrieval at query time. When `file` is set, the search endpoint searches over all the documents in the given file and returns up to the `max_rerank` number of documents. These documents will be returned along with their search scores.  The similarity score is a positive score that usually ranges from 0 to 300 (but can sometimes go higher), where a score above 200 usually means the document is semantically similar to the query.
     * @param {string} engineId The ID of the engine to use for this request.  You can select one of &#x60;ada&#x60;, &#x60;babbage&#x60;, &#x60;curie&#x60;, or &#x60;davinci&#x60;.
     * @param {CreateSearchRequest} createSearchRequest
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    createSearch: (engineId, createSearchRequest, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'engineId' is not null or undefined
      common_1.assertParamExists('createSearch', 'engineId', engineId);
      // verify required parameter 'createSearchRequest' is not null or undefined
      common_1.assertParamExists('createSearch', 'createSearchRequest', createSearchRequest);
      const localVarPath = `/engines/{engine_id}/search`.replace(`{${"engine_id"}}`, encodeURIComponent(String(engineId)));
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      localVarHeaderParameter['Content-Type'] = 'application/json';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = common_1.serializeDataIfNeeded(createSearchRequest, localVarRequestOptions, configuration);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Transcribes audio into the input language.
     * @param {File} file The audio file object (not file name) to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.
     * @param {string} model ID of the model to use. Only &#x60;whisper-1&#x60; is currently available.
     * @param {string} [prompt] An optional text to guide the model\\\&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
     * @param {string} [responseFormat] The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
     * @param {number} [temperature] The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
     * @param {string} [language] The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createTranscription: (file, model, prompt, responseFormat, temperature, language, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'file' is not null or undefined
      common_1.assertParamExists('createTranscription', 'file', file);
      // verify required parameter 'model' is not null or undefined
      common_1.assertParamExists('createTranscription', 'model', model);
      const localVarPath = `/audio/transcriptions`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      const localVarFormParams = new (configuration && configuration.formDataCtor || FormData)();
      if (file !== undefined) {
        localVarFormParams.append('file', file);
      }
      if (model !== undefined) {
        localVarFormParams.append('model', model);
      }
      if (prompt !== undefined) {
        localVarFormParams.append('prompt', prompt);
      }
      if (responseFormat !== undefined) {
        localVarFormParams.append('response_format', responseFormat);
      }
      if (temperature !== undefined) {
        localVarFormParams.append('temperature', temperature);
      }
      if (language !== undefined) {
        localVarFormParams.append('language', language);
      }
      localVarHeaderParameter['Content-Type'] = 'multipart/form-data';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), localVarFormParams.getHeaders()), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = localVarFormParams;
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Translates audio into into English.
     * @param {File} file The audio file object (not file name) translate, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.
     * @param {string} model ID of the model to use. Only &#x60;whisper-1&#x60; is currently available.
     * @param {string} [prompt] An optional text to guide the model\\\&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English.
     * @param {string} [responseFormat] The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
     * @param {number} [temperature] The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createTranslation: (file, model, prompt, responseFormat, temperature, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'file' is not null or undefined
      common_1.assertParamExists('createTranslation', 'file', file);
      // verify required parameter 'model' is not null or undefined
      common_1.assertParamExists('createTranslation', 'model', model);
      const localVarPath = `/audio/translations`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'POST'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      const localVarFormParams = new (configuration && configuration.formDataCtor || FormData)();
      if (file !== undefined) {
        localVarFormParams.append('file', file);
      }
      if (model !== undefined) {
        localVarFormParams.append('model', model);
      }
      if (prompt !== undefined) {
        localVarFormParams.append('prompt', prompt);
      }
      if (responseFormat !== undefined) {
        localVarFormParams.append('response_format', responseFormat);
      }
      if (temperature !== undefined) {
        localVarFormParams.append('temperature', temperature);
      }
      localVarHeaderParameter['Content-Type'] = 'multipart/form-data';
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), localVarFormParams.getHeaders()), headersFromBaseOptions), options.headers);
      localVarRequestOptions.data = localVarFormParams;
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Delete a file.
     * @param {string} fileId The ID of the file to use for this request
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    deleteFile: (fileId, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'fileId' is not null or undefined
      common_1.assertParamExists('deleteFile', 'fileId', fileId);
      const localVarPath = `/files/{file_id}`.replace(`{${"file_id"}}`, encodeURIComponent(String(fileId)));
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'DELETE'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Delete a fine-tuned model. You must have the Owner role in your organization.
     * @param {string} model The model to delete
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    deleteModel: (model, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'model' is not null or undefined
      common_1.assertParamExists('deleteModel', 'model', model);
      const localVarPath = `/models/{model}`.replace(`{${"model"}}`, encodeURIComponent(String(model)));
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'DELETE'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Returns the contents of the specified file
     * @param {string} fileId The ID of the file to use for this request
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    downloadFile: (fileId, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'fileId' is not null or undefined
      common_1.assertParamExists('downloadFile', 'fileId', fileId);
      const localVarPath = `/files/{file_id}/content`.replace(`{${"file_id"}}`, encodeURIComponent(String(fileId)));
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'GET'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Lists the currently available (non-finetuned) models, and provides basic information about each one such as the owner and availability.
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    listEngines: (options = {}) => __awaiter(this, void 0, void 0, function* () {
      const localVarPath = `/engines`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'GET'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Returns a list of files that belong to the user\'s organization.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    listFiles: (options = {}) => __awaiter(this, void 0, void 0, function* () {
      const localVarPath = `/files`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'GET'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Get fine-grained status updates for a fine-tune job.
     * @param {string} fineTuneId The ID of the fine-tune job to get events for.
     * @param {boolean} [stream] Whether to stream events for the fine-tune job. If set to true, events will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available. The stream will terminate with a &#x60;data: [DONE]&#x60; message when the job is finished (succeeded, cancelled, or failed).  If set to false, only events generated so far will be returned.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    listFineTuneEvents: (fineTuneId, stream, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'fineTuneId' is not null or undefined
      common_1.assertParamExists('listFineTuneEvents', 'fineTuneId', fineTuneId);
      const localVarPath = `/fine-tunes/{fine_tune_id}/events`.replace(`{${"fine_tune_id"}}`, encodeURIComponent(String(fineTuneId)));
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'GET'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      if (stream !== undefined) {
        localVarQueryParameter['stream'] = stream;
      }
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary List your organization\'s fine-tuning jobs
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    listFineTunes: (options = {}) => __awaiter(this, void 0, void 0, function* () {
      const localVarPath = `/fine-tunes`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'GET'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Lists the currently available models, and provides basic information about each one such as the owner and availability.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    listModels: (options = {}) => __awaiter(this, void 0, void 0, function* () {
      const localVarPath = `/models`;
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'GET'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Retrieves a model instance, providing basic information about it such as the owner and availability.
     * @param {string} engineId The ID of the engine to use for this request
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    retrieveEngine: (engineId, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'engineId' is not null or undefined
      common_1.assertParamExists('retrieveEngine', 'engineId', engineId);
      const localVarPath = `/engines/{engine_id}`.replace(`{${"engine_id"}}`, encodeURIComponent(String(engineId)));
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'GET'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Returns information about a specific file.
     * @param {string} fileId The ID of the file to use for this request
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    retrieveFile: (fileId, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'fileId' is not null or undefined
      common_1.assertParamExists('retrieveFile', 'fileId', fileId);
      const localVarPath = `/files/{file_id}`.replace(`{${"file_id"}}`, encodeURIComponent(String(fileId)));
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'GET'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Gets info about the fine-tune job.  [Learn more about Fine-tuning](/docs/guides/fine-tuning)
     * @param {string} fineTuneId The ID of the fine-tune job
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    retrieveFineTune: (fineTuneId, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'fineTuneId' is not null or undefined
      common_1.assertParamExists('retrieveFineTune', 'fineTuneId', fineTuneId);
      const localVarPath = `/fine-tunes/{fine_tune_id}`.replace(`{${"fine_tune_id"}}`, encodeURIComponent(String(fineTuneId)));
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'GET'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    }),
    /**
     *
     * @summary Retrieves a model instance, providing basic information about the model such as the owner and permissioning.
     * @param {string} model The ID of the model to use for this request
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    retrieveModel: (model, options = {}) => __awaiter(this, void 0, void 0, function* () {
      // verify required parameter 'model' is not null or undefined
      common_1.assertParamExists('retrieveModel', 'model', model);
      const localVarPath = `/models/{model}`.replace(`{${"model"}}`, encodeURIComponent(String(model)));
      // use dummy base URL string because the URL constructor only accepts absolute URLs.
      const localVarUrlObj = new URL(localVarPath, common_1.DUMMY_BASE_URL);
      let baseOptions;
      if (configuration) {
        baseOptions = configuration.baseOptions;
      }
      const localVarRequestOptions = Object.assign(Object.assign({
        method: 'GET'
      }, baseOptions), options);
      const localVarHeaderParameter = {};
      const localVarQueryParameter = {};
      common_1.setSearchParams(localVarUrlObj, localVarQueryParameter);
      let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
      localVarRequestOptions.headers = Object.assign(Object.assign(Object.assign({}, localVarHeaderParameter), headersFromBaseOptions), options.headers);
      return {
        url: common_1.toPathString(localVarUrlObj),
        options: localVarRequestOptions
      };
    })
  };
};
/**
 * OpenAIApi - functional programming interface
 * @export
 */
exports.OpenAIApiFp = function (configuration) {
  const localVarAxiosParamCreator = exports.OpenAIApiAxiosParamCreator(configuration);
  return {
    /**
     *
     * @summary Immediately cancel a fine-tune job.
     * @param {string} fineTuneId The ID of the fine-tune job to cancel
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    cancelFineTune(fineTuneId, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.cancelFineTune(fineTuneId, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Answers the specified question using the provided documents and examples.  The endpoint first [searches](/docs/api-reference/searches) over provided documents or files to find relevant context. The relevant context is combined with the provided examples and question to create the prompt for [completion](/docs/api-reference/completions).
     * @param {CreateAnswerRequest} createAnswerRequest
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    createAnswer(createAnswerRequest, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createAnswer(createAnswerRequest, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Creates a model response for the given chat conversation.
     * @param {CreateChatCompletionRequest} createChatCompletionRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createChatCompletion(createChatCompletionRequest, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createChatCompletion(createChatCompletionRequest, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Classifies the specified `query` using provided examples.  The endpoint first [searches](/docs/api-reference/searches) over the labeled examples to select the ones most relevant for the particular query. Then, the relevant examples are combined with the query to construct a prompt to produce the final label via the [completions](/docs/api-reference/completions) endpoint.  Labeled examples can be provided via an uploaded `file`, or explicitly listed in the request using the `examples` parameter for quick tests and small scale use cases.
     * @param {CreateClassificationRequest} createClassificationRequest
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    createClassification(createClassificationRequest, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createClassification(createClassificationRequest, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Creates a completion for the provided prompt and parameters.
     * @param {CreateCompletionRequest} createCompletionRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createCompletion(createCompletionRequest, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createCompletion(createCompletionRequest, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Creates a new edit for the provided input, instruction, and parameters.
     * @param {CreateEditRequest} createEditRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createEdit(createEditRequest, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createEdit(createEditRequest, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Creates an embedding vector representing the input text.
     * @param {CreateEmbeddingRequest} createEmbeddingRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createEmbedding(createEmbeddingRequest, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createEmbedding(createEmbeddingRequest, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Upload a file that contains document(s) to be used across various endpoints/features. Currently, the size of all the files uploaded by one organization can be up to 1 GB. Please contact us if you need to increase the storage limit.
     * @param {File} file Name of the [JSON Lines](https://jsonlines.readthedocs.io/en/latest/) file to be uploaded.  If the &#x60;purpose&#x60; is set to \\\&quot;fine-tune\\\&quot;, each line is a JSON record with \\\&quot;prompt\\\&quot; and \\\&quot;completion\\\&quot; fields representing your [training examples](/docs/guides/fine-tuning/prepare-training-data).
     * @param {string} purpose The intended purpose of the uploaded documents.  Use \\\&quot;fine-tune\\\&quot; for [Fine-tuning](/docs/api-reference/fine-tunes). This allows us to validate the format of the uploaded file.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createFile(file, purpose, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createFile(file, purpose, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Creates a job that fine-tunes a specified model from a given dataset.  Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.  [Learn more about Fine-tuning](/docs/guides/fine-tuning)
     * @param {CreateFineTuneRequest} createFineTuneRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createFineTune(createFineTuneRequest, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createFineTune(createFineTuneRequest, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Creates an image given a prompt.
     * @param {CreateImageRequest} createImageRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createImage(createImageRequest, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createImage(createImageRequest, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Creates an edited or extended image given an original image and a prompt.
     * @param {File} image The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.
     * @param {string} prompt A text description of the desired image(s). The maximum length is 1000 characters.
     * @param {File} [mask] An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where &#x60;image&#x60; should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as &#x60;image&#x60;.
     * @param {number} [n] The number of images to generate. Must be between 1 and 10.
     * @param {string} [size] The size of the generated images. Must be one of &#x60;256x256&#x60;, &#x60;512x512&#x60;, or &#x60;1024x1024&#x60;.
     * @param {string} [responseFormat] The format in which the generated images are returned. Must be one of &#x60;url&#x60; or &#x60;b64_json&#x60;.
     * @param {string} [user] A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createImageEdit(image, prompt, mask, n, size, responseFormat, user, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createImageEdit(image, prompt, mask, n, size, responseFormat, user, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Creates a variation of a given image.
     * @param {File} image The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.
     * @param {number} [n] The number of images to generate. Must be between 1 and 10.
     * @param {string} [size] The size of the generated images. Must be one of &#x60;256x256&#x60;, &#x60;512x512&#x60;, or &#x60;1024x1024&#x60;.
     * @param {string} [responseFormat] The format in which the generated images are returned. Must be one of &#x60;url&#x60; or &#x60;b64_json&#x60;.
     * @param {string} [user] A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createImageVariation(image, n, size, responseFormat, user, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createImageVariation(image, n, size, responseFormat, user, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Classifies if text violates OpenAI\'s Content Policy
     * @param {CreateModerationRequest} createModerationRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createModeration(createModerationRequest, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createModeration(createModerationRequest, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary The search endpoint computes similarity scores between provided query and documents. Documents can be passed directly to the API if there are no more than 200 of them.  To go beyond the 200 document limit, documents can be processed offline and then used for efficient retrieval at query time. When `file` is set, the search endpoint searches over all the documents in the given file and returns up to the `max_rerank` number of documents. These documents will be returned along with their search scores.  The similarity score is a positive score that usually ranges from 0 to 300 (but can sometimes go higher), where a score above 200 usually means the document is semantically similar to the query.
     * @param {string} engineId The ID of the engine to use for this request.  You can select one of &#x60;ada&#x60;, &#x60;babbage&#x60;, &#x60;curie&#x60;, or &#x60;davinci&#x60;.
     * @param {CreateSearchRequest} createSearchRequest
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    createSearch(engineId, createSearchRequest, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createSearch(engineId, createSearchRequest, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Transcribes audio into the input language.
     * @param {File} file The audio file object (not file name) to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.
     * @param {string} model ID of the model to use. Only &#x60;whisper-1&#x60; is currently available.
     * @param {string} [prompt] An optional text to guide the model\\\&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
     * @param {string} [responseFormat] The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
     * @param {number} [temperature] The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
     * @param {string} [language] The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createTranscription(file, model, prompt, responseFormat, temperature, language, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createTranscription(file, model, prompt, responseFormat, temperature, language, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Translates audio into into English.
     * @param {File} file The audio file object (not file name) translate, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.
     * @param {string} model ID of the model to use. Only &#x60;whisper-1&#x60; is currently available.
     * @param {string} [prompt] An optional text to guide the model\\\&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English.
     * @param {string} [responseFormat] The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
     * @param {number} [temperature] The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createTranslation(file, model, prompt, responseFormat, temperature, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.createTranslation(file, model, prompt, responseFormat, temperature, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Delete a file.
     * @param {string} fileId The ID of the file to use for this request
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    deleteFile(fileId, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.deleteFile(fileId, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Delete a fine-tuned model. You must have the Owner role in your organization.
     * @param {string} model The model to delete
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    deleteModel(model, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.deleteModel(model, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Returns the contents of the specified file
     * @param {string} fileId The ID of the file to use for this request
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    downloadFile(fileId, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.downloadFile(fileId, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Lists the currently available (non-finetuned) models, and provides basic information about each one such as the owner and availability.
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    listEngines(options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.listEngines(options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Returns a list of files that belong to the user\'s organization.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    listFiles(options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.listFiles(options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Get fine-grained status updates for a fine-tune job.
     * @param {string} fineTuneId The ID of the fine-tune job to get events for.
     * @param {boolean} [stream] Whether to stream events for the fine-tune job. If set to true, events will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available. The stream will terminate with a &#x60;data: [DONE]&#x60; message when the job is finished (succeeded, cancelled, or failed).  If set to false, only events generated so far will be returned.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    listFineTuneEvents(fineTuneId, stream, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.listFineTuneEvents(fineTuneId, stream, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary List your organization\'s fine-tuning jobs
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    listFineTunes(options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.listFineTunes(options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Lists the currently available models, and provides basic information about each one such as the owner and availability.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    listModels(options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.listModels(options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Retrieves a model instance, providing basic information about it such as the owner and availability.
     * @param {string} engineId The ID of the engine to use for this request
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    retrieveEngine(engineId, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.retrieveEngine(engineId, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Returns information about a specific file.
     * @param {string} fileId The ID of the file to use for this request
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    retrieveFile(fileId, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.retrieveFile(fileId, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Gets info about the fine-tune job.  [Learn more about Fine-tuning](/docs/guides/fine-tuning)
     * @param {string} fineTuneId The ID of the fine-tune job
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    retrieveFineTune(fineTuneId, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.retrieveFineTune(fineTuneId, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    },
    /**
     *
     * @summary Retrieves a model instance, providing basic information about the model such as the owner and permissioning.
     * @param {string} model The ID of the model to use for this request
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    retrieveModel(model, options) {
      return __awaiter(this, void 0, void 0, function* () {
        const localVarAxiosArgs = yield localVarAxiosParamCreator.retrieveModel(model, options);
        return common_1.createRequestFunction(localVarAxiosArgs, axios_1.default, base_1.BASE_PATH, configuration);
      });
    }
  };
};
/**
 * OpenAIApi - factory interface
 * @export
 */
exports.OpenAIApiFactory = function (configuration, basePath, axios) {
  const localVarFp = exports.OpenAIApiFp(configuration);
  return {
    /**
     *
     * @summary Immediately cancel a fine-tune job.
     * @param {string} fineTuneId The ID of the fine-tune job to cancel
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    cancelFineTune(fineTuneId, options) {
      return localVarFp.cancelFineTune(fineTuneId, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Answers the specified question using the provided documents and examples.  The endpoint first [searches](/docs/api-reference/searches) over provided documents or files to find relevant context. The relevant context is combined with the provided examples and question to create the prompt for [completion](/docs/api-reference/completions).
     * @param {CreateAnswerRequest} createAnswerRequest
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    createAnswer(createAnswerRequest, options) {
      return localVarFp.createAnswer(createAnswerRequest, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Creates a model response for the given chat conversation.
     * @param {CreateChatCompletionRequest} createChatCompletionRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createChatCompletion(createChatCompletionRequest, options) {
      return localVarFp.createChatCompletion(createChatCompletionRequest, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Classifies the specified `query` using provided examples.  The endpoint first [searches](/docs/api-reference/searches) over the labeled examples to select the ones most relevant for the particular query. Then, the relevant examples are combined with the query to construct a prompt to produce the final label via the [completions](/docs/api-reference/completions) endpoint.  Labeled examples can be provided via an uploaded `file`, or explicitly listed in the request using the `examples` parameter for quick tests and small scale use cases.
     * @param {CreateClassificationRequest} createClassificationRequest
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    createClassification(createClassificationRequest, options) {
      return localVarFp.createClassification(createClassificationRequest, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Creates a completion for the provided prompt and parameters.
     * @param {CreateCompletionRequest} createCompletionRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createCompletion(createCompletionRequest, options) {
      return localVarFp.createCompletion(createCompletionRequest, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Creates a new edit for the provided input, instruction, and parameters.
     * @param {CreateEditRequest} createEditRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createEdit(createEditRequest, options) {
      return localVarFp.createEdit(createEditRequest, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Creates an embedding vector representing the input text.
     * @param {CreateEmbeddingRequest} createEmbeddingRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createEmbedding(createEmbeddingRequest, options) {
      return localVarFp.createEmbedding(createEmbeddingRequest, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Upload a file that contains document(s) to be used across various endpoints/features. Currently, the size of all the files uploaded by one organization can be up to 1 GB. Please contact us if you need to increase the storage limit.
     * @param {File} file Name of the [JSON Lines](https://jsonlines.readthedocs.io/en/latest/) file to be uploaded.  If the &#x60;purpose&#x60; is set to \\\&quot;fine-tune\\\&quot;, each line is a JSON record with \\\&quot;prompt\\\&quot; and \\\&quot;completion\\\&quot; fields representing your [training examples](/docs/guides/fine-tuning/prepare-training-data).
     * @param {string} purpose The intended purpose of the uploaded documents.  Use \\\&quot;fine-tune\\\&quot; for [Fine-tuning](/docs/api-reference/fine-tunes). This allows us to validate the format of the uploaded file.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createFile(file, purpose, options) {
      return localVarFp.createFile(file, purpose, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Creates a job that fine-tunes a specified model from a given dataset.  Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.  [Learn more about Fine-tuning](/docs/guides/fine-tuning)
     * @param {CreateFineTuneRequest} createFineTuneRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createFineTune(createFineTuneRequest, options) {
      return localVarFp.createFineTune(createFineTuneRequest, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Creates an image given a prompt.
     * @param {CreateImageRequest} createImageRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createImage(createImageRequest, options) {
      return localVarFp.createImage(createImageRequest, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Creates an edited or extended image given an original image and a prompt.
     * @param {File} image The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.
     * @param {string} prompt A text description of the desired image(s). The maximum length is 1000 characters.
     * @param {File} [mask] An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where &#x60;image&#x60; should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as &#x60;image&#x60;.
     * @param {number} [n] The number of images to generate. Must be between 1 and 10.
     * @param {string} [size] The size of the generated images. Must be one of &#x60;256x256&#x60;, &#x60;512x512&#x60;, or &#x60;1024x1024&#x60;.
     * @param {string} [responseFormat] The format in which the generated images are returned. Must be one of &#x60;url&#x60; or &#x60;b64_json&#x60;.
     * @param {string} [user] A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createImageEdit(image, prompt, mask, n, size, responseFormat, user, options) {
      return localVarFp.createImageEdit(image, prompt, mask, n, size, responseFormat, user, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Creates a variation of a given image.
     * @param {File} image The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.
     * @param {number} [n] The number of images to generate. Must be between 1 and 10.
     * @param {string} [size] The size of the generated images. Must be one of &#x60;256x256&#x60;, &#x60;512x512&#x60;, or &#x60;1024x1024&#x60;.
     * @param {string} [responseFormat] The format in which the generated images are returned. Must be one of &#x60;url&#x60; or &#x60;b64_json&#x60;.
     * @param {string} [user] A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createImageVariation(image, n, size, responseFormat, user, options) {
      return localVarFp.createImageVariation(image, n, size, responseFormat, user, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Classifies if text violates OpenAI\'s Content Policy
     * @param {CreateModerationRequest} createModerationRequest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createModeration(createModerationRequest, options) {
      return localVarFp.createModeration(createModerationRequest, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary The search endpoint computes similarity scores between provided query and documents. Documents can be passed directly to the API if there are no more than 200 of them.  To go beyond the 200 document limit, documents can be processed offline and then used for efficient retrieval at query time. When `file` is set, the search endpoint searches over all the documents in the given file and returns up to the `max_rerank` number of documents. These documents will be returned along with their search scores.  The similarity score is a positive score that usually ranges from 0 to 300 (but can sometimes go higher), where a score above 200 usually means the document is semantically similar to the query.
     * @param {string} engineId The ID of the engine to use for this request.  You can select one of &#x60;ada&#x60;, &#x60;babbage&#x60;, &#x60;curie&#x60;, or &#x60;davinci&#x60;.
     * @param {CreateSearchRequest} createSearchRequest
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    createSearch(engineId, createSearchRequest, options) {
      return localVarFp.createSearch(engineId, createSearchRequest, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Transcribes audio into the input language.
     * @param {File} file The audio file object (not file name) to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.
     * @param {string} model ID of the model to use. Only &#x60;whisper-1&#x60; is currently available.
     * @param {string} [prompt] An optional text to guide the model\\\&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
     * @param {string} [responseFormat] The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
     * @param {number} [temperature] The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
     * @param {string} [language] The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createTranscription(file, model, prompt, responseFormat, temperature, language, options) {
      return localVarFp.createTranscription(file, model, prompt, responseFormat, temperature, language, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Translates audio into into English.
     * @param {File} file The audio file object (not file name) translate, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.
     * @param {string} model ID of the model to use. Only &#x60;whisper-1&#x60; is currently available.
     * @param {string} [prompt] An optional text to guide the model\\\&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English.
     * @param {string} [responseFormat] The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
     * @param {number} [temperature] The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    createTranslation(file, model, prompt, responseFormat, temperature, options) {
      return localVarFp.createTranslation(file, model, prompt, responseFormat, temperature, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Delete a file.
     * @param {string} fileId The ID of the file to use for this request
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    deleteFile(fileId, options) {
      return localVarFp.deleteFile(fileId, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Delete a fine-tuned model. You must have the Owner role in your organization.
     * @param {string} model The model to delete
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    deleteModel(model, options) {
      return localVarFp.deleteModel(model, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Returns the contents of the specified file
     * @param {string} fileId The ID of the file to use for this request
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    downloadFile(fileId, options) {
      return localVarFp.downloadFile(fileId, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Lists the currently available (non-finetuned) models, and provides basic information about each one such as the owner and availability.
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    listEngines(options) {
      return localVarFp.listEngines(options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Returns a list of files that belong to the user\'s organization.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    listFiles(options) {
      return localVarFp.listFiles(options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Get fine-grained status updates for a fine-tune job.
     * @param {string} fineTuneId The ID of the fine-tune job to get events for.
     * @param {boolean} [stream] Whether to stream events for the fine-tune job. If set to true, events will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available. The stream will terminate with a &#x60;data: [DONE]&#x60; message when the job is finished (succeeded, cancelled, or failed).  If set to false, only events generated so far will be returned.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    listFineTuneEvents(fineTuneId, stream, options) {
      return localVarFp.listFineTuneEvents(fineTuneId, stream, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary List your organization\'s fine-tuning jobs
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    listFineTunes(options) {
      return localVarFp.listFineTunes(options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Lists the currently available models, and provides basic information about each one such as the owner and availability.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    listModels(options) {
      return localVarFp.listModels(options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Retrieves a model instance, providing basic information about it such as the owner and availability.
     * @param {string} engineId The ID of the engine to use for this request
     * @param {*} [options] Override http request option.
     * @deprecated
     * @throws {RequiredError}
     */
    retrieveEngine(engineId, options) {
      return localVarFp.retrieveEngine(engineId, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Returns information about a specific file.
     * @param {string} fileId The ID of the file to use for this request
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    retrieveFile(fileId, options) {
      return localVarFp.retrieveFile(fileId, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Gets info about the fine-tune job.  [Learn more about Fine-tuning](/docs/guides/fine-tuning)
     * @param {string} fineTuneId The ID of the fine-tune job
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    retrieveFineTune(fineTuneId, options) {
      return localVarFp.retrieveFineTune(fineTuneId, options).then(request => request(axios, basePath));
    },
    /**
     *
     * @summary Retrieves a model instance, providing basic information about the model such as the owner and permissioning.
     * @param {string} model The ID of the model to use for this request
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     */
    retrieveModel(model, options) {
      return localVarFp.retrieveModel(model, options).then(request => request(axios, basePath));
    }
  };
};
/**
 * OpenAIApi - object-oriented interface
 * @export
 * @class OpenAIApi
 * @extends {BaseAPI}
 */
class OpenAIApi extends base_1.BaseAPI {
  /**
   *
   * @summary Immediately cancel a fine-tune job.
   * @param {string} fineTuneId The ID of the fine-tune job to cancel
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  cancelFineTune(fineTuneId, options) {
    return exports.OpenAIApiFp(this.configuration).cancelFineTune(fineTuneId, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Answers the specified question using the provided documents and examples.  The endpoint first [searches](/docs/api-reference/searches) over provided documents or files to find relevant context. The relevant context is combined with the provided examples and question to create the prompt for [completion](/docs/api-reference/completions).
   * @param {CreateAnswerRequest} createAnswerRequest
   * @param {*} [options] Override http request option.
   * @deprecated
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createAnswer(createAnswerRequest, options) {
    return exports.OpenAIApiFp(this.configuration).createAnswer(createAnswerRequest, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Creates a model response for the given chat conversation.
   * @param {CreateChatCompletionRequest} createChatCompletionRequest
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createChatCompletion(createChatCompletionRequest, options) {
    return exports.OpenAIApiFp(this.configuration).createChatCompletion(createChatCompletionRequest, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Classifies the specified `query` using provided examples.  The endpoint first [searches](/docs/api-reference/searches) over the labeled examples to select the ones most relevant for the particular query. Then, the relevant examples are combined with the query to construct a prompt to produce the final label via the [completions](/docs/api-reference/completions) endpoint.  Labeled examples can be provided via an uploaded `file`, or explicitly listed in the request using the `examples` parameter for quick tests and small scale use cases.
   * @param {CreateClassificationRequest} createClassificationRequest
   * @param {*} [options] Override http request option.
   * @deprecated
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createClassification(createClassificationRequest, options) {
    return exports.OpenAIApiFp(this.configuration).createClassification(createClassificationRequest, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Creates a completion for the provided prompt and parameters.
   * @param {CreateCompletionRequest} createCompletionRequest
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createCompletion(createCompletionRequest, options) {
    return exports.OpenAIApiFp(this.configuration).createCompletion(createCompletionRequest, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Creates a new edit for the provided input, instruction, and parameters.
   * @param {CreateEditRequest} createEditRequest
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createEdit(createEditRequest, options) {
    return exports.OpenAIApiFp(this.configuration).createEdit(createEditRequest, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Creates an embedding vector representing the input text.
   * @param {CreateEmbeddingRequest} createEmbeddingRequest
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createEmbedding(createEmbeddingRequest, options) {
    return exports.OpenAIApiFp(this.configuration).createEmbedding(createEmbeddingRequest, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Upload a file that contains document(s) to be used across various endpoints/features. Currently, the size of all the files uploaded by one organization can be up to 1 GB. Please contact us if you need to increase the storage limit.
   * @param {File} file Name of the [JSON Lines](https://jsonlines.readthedocs.io/en/latest/) file to be uploaded.  If the &#x60;purpose&#x60; is set to \\\&quot;fine-tune\\\&quot;, each line is a JSON record with \\\&quot;prompt\\\&quot; and \\\&quot;completion\\\&quot; fields representing your [training examples](/docs/guides/fine-tuning/prepare-training-data).
   * @param {string} purpose The intended purpose of the uploaded documents.  Use \\\&quot;fine-tune\\\&quot; for [Fine-tuning](/docs/api-reference/fine-tunes). This allows us to validate the format of the uploaded file.
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createFile(file, purpose, options) {
    return exports.OpenAIApiFp(this.configuration).createFile(file, purpose, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Creates a job that fine-tunes a specified model from a given dataset.  Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.  [Learn more about Fine-tuning](/docs/guides/fine-tuning)
   * @param {CreateFineTuneRequest} createFineTuneRequest
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createFineTune(createFineTuneRequest, options) {
    return exports.OpenAIApiFp(this.configuration).createFineTune(createFineTuneRequest, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Creates an image given a prompt.
   * @param {CreateImageRequest} createImageRequest
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createImage(createImageRequest, options) {
    return exports.OpenAIApiFp(this.configuration).createImage(createImageRequest, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Creates an edited or extended image given an original image and a prompt.
   * @param {File} image The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.
   * @param {string} prompt A text description of the desired image(s). The maximum length is 1000 characters.
   * @param {File} [mask] An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where &#x60;image&#x60; should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as &#x60;image&#x60;.
   * @param {number} [n] The number of images to generate. Must be between 1 and 10.
   * @param {string} [size] The size of the generated images. Must be one of &#x60;256x256&#x60;, &#x60;512x512&#x60;, or &#x60;1024x1024&#x60;.
   * @param {string} [responseFormat] The format in which the generated images are returned. Must be one of &#x60;url&#x60; or &#x60;b64_json&#x60;.
   * @param {string} [user] A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createImageEdit(image, prompt, mask, n, size, responseFormat, user, options) {
    return exports.OpenAIApiFp(this.configuration).createImageEdit(image, prompt, mask, n, size, responseFormat, user, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Creates a variation of a given image.
   * @param {File} image The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.
   * @param {number} [n] The number of images to generate. Must be between 1 and 10.
   * @param {string} [size] The size of the generated images. Must be one of &#x60;256x256&#x60;, &#x60;512x512&#x60;, or &#x60;1024x1024&#x60;.
   * @param {string} [responseFormat] The format in which the generated images are returned. Must be one of &#x60;url&#x60; or &#x60;b64_json&#x60;.
   * @param {string} [user] A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createImageVariation(image, n, size, responseFormat, user, options) {
    return exports.OpenAIApiFp(this.configuration).createImageVariation(image, n, size, responseFormat, user, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Classifies if text violates OpenAI\'s Content Policy
   * @param {CreateModerationRequest} createModerationRequest
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createModeration(createModerationRequest, options) {
    return exports.OpenAIApiFp(this.configuration).createModeration(createModerationRequest, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary The search endpoint computes similarity scores between provided query and documents. Documents can be passed directly to the API if there are no more than 200 of them.  To go beyond the 200 document limit, documents can be processed offline and then used for efficient retrieval at query time. When `file` is set, the search endpoint searches over all the documents in the given file and returns up to the `max_rerank` number of documents. These documents will be returned along with their search scores.  The similarity score is a positive score that usually ranges from 0 to 300 (but can sometimes go higher), where a score above 200 usually means the document is semantically similar to the query.
   * @param {string} engineId The ID of the engine to use for this request.  You can select one of &#x60;ada&#x60;, &#x60;babbage&#x60;, &#x60;curie&#x60;, or &#x60;davinci&#x60;.
   * @param {CreateSearchRequest} createSearchRequest
   * @param {*} [options] Override http request option.
   * @deprecated
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createSearch(engineId, createSearchRequest, options) {
    return exports.OpenAIApiFp(this.configuration).createSearch(engineId, createSearchRequest, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Transcribes audio into the input language.
   * @param {File} file The audio file object (not file name) to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.
   * @param {string} model ID of the model to use. Only &#x60;whisper-1&#x60; is currently available.
   * @param {string} [prompt] An optional text to guide the model\\\&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
   * @param {string} [responseFormat] The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
   * @param {number} [temperature] The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
   * @param {string} [language] The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createTranscription(file, model, prompt, responseFormat, temperature, language, options) {
    return exports.OpenAIApiFp(this.configuration).createTranscription(file, model, prompt, responseFormat, temperature, language, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Translates audio into into English.
   * @param {File} file The audio file object (not file name) translate, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.
   * @param {string} model ID of the model to use. Only &#x60;whisper-1&#x60; is currently available.
   * @param {string} [prompt] An optional text to guide the model\\\&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English.
   * @param {string} [responseFormat] The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
   * @param {number} [temperature] The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  createTranslation(file, model, prompt, responseFormat, temperature, options) {
    return exports.OpenAIApiFp(this.configuration).createTranslation(file, model, prompt, responseFormat, temperature, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Delete a file.
   * @param {string} fileId The ID of the file to use for this request
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  deleteFile(fileId, options) {
    return exports.OpenAIApiFp(this.configuration).deleteFile(fileId, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Delete a fine-tuned model. You must have the Owner role in your organization.
   * @param {string} model The model to delete
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  deleteModel(model, options) {
    return exports.OpenAIApiFp(this.configuration).deleteModel(model, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Returns the contents of the specified file
   * @param {string} fileId The ID of the file to use for this request
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  downloadFile(fileId, options) {
    return exports.OpenAIApiFp(this.configuration).downloadFile(fileId, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Lists the currently available (non-finetuned) models, and provides basic information about each one such as the owner and availability.
   * @param {*} [options] Override http request option.
   * @deprecated
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  listEngines(options) {
    return exports.OpenAIApiFp(this.configuration).listEngines(options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Returns a list of files that belong to the user\'s organization.
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  listFiles(options) {
    return exports.OpenAIApiFp(this.configuration).listFiles(options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Get fine-grained status updates for a fine-tune job.
   * @param {string} fineTuneId The ID of the fine-tune job to get events for.
   * @param {boolean} [stream] Whether to stream events for the fine-tune job. If set to true, events will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available. The stream will terminate with a &#x60;data: [DONE]&#x60; message when the job is finished (succeeded, cancelled, or failed).  If set to false, only events generated so far will be returned.
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  listFineTuneEvents(fineTuneId, stream, options) {
    return exports.OpenAIApiFp(this.configuration).listFineTuneEvents(fineTuneId, stream, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary List your organization\'s fine-tuning jobs
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  listFineTunes(options) {
    return exports.OpenAIApiFp(this.configuration).listFineTunes(options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Lists the currently available models, and provides basic information about each one such as the owner and availability.
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  listModels(options) {
    return exports.OpenAIApiFp(this.configuration).listModels(options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Retrieves a model instance, providing basic information about it such as the owner and availability.
   * @param {string} engineId The ID of the engine to use for this request
   * @param {*} [options] Override http request option.
   * @deprecated
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  retrieveEngine(engineId, options) {
    return exports.OpenAIApiFp(this.configuration).retrieveEngine(engineId, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Returns information about a specific file.
   * @param {string} fileId The ID of the file to use for this request
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  retrieveFile(fileId, options) {
    return exports.OpenAIApiFp(this.configuration).retrieveFile(fileId, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Gets info about the fine-tune job.  [Learn more about Fine-tuning](/docs/guides/fine-tuning)
   * @param {string} fineTuneId The ID of the fine-tune job
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  retrieveFineTune(fineTuneId, options) {
    return exports.OpenAIApiFp(this.configuration).retrieveFineTune(fineTuneId, options).then(request => request(this.axios, this.basePath));
  }
  /**
   *
   * @summary Retrieves a model instance, providing basic information about the model such as the owner and permissioning.
   * @param {string} model The ID of the model to use for this request
   * @param {*} [options] Override http request option.
   * @throws {RequiredError}
   * @memberof OpenAIApi
   */
  retrieveModel(model, options) {
    return exports.OpenAIApiFp(this.configuration).retrieveModel(model, options).then(request => request(this.axios, this.basePath));
  }
}
exports.OpenAIApi = OpenAIApi;

/***/ }),

/***/ "./node_modules/openai/dist/base.js":
/*!******************************************!*\
  !*** ./node_modules/openai/dist/base.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";


/* tslint:disable */
/* eslint-disable */
/**
 * OpenAI API
 * APIs for sampling from and fine-tuning language models
 *
 * The version of the OpenAPI document: 1.3.0
 *
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports.RequiredError = exports.BaseAPI = exports.COLLECTION_FORMATS = exports.BASE_PATH = void 0;
const axios_1 = __webpack_require__(/*! axios */ "./node_modules/axios/index.js");
exports.BASE_PATH = "https://api.openai.com/v1".replace(/\/+$/, "");
/**
 *
 * @export
 */
exports.COLLECTION_FORMATS = {
  csv: ",",
  ssv: " ",
  tsv: "\t",
  pipes: "|"
};
/**
 *
 * @export
 * @class BaseAPI
 */
class BaseAPI {
  constructor(configuration, basePath = exports.BASE_PATH, axios = axios_1.default) {
    this.basePath = basePath;
    this.axios = axios;
    if (configuration) {
      this.configuration = configuration;
      this.basePath = configuration.basePath || this.basePath;
    }
  }
}
exports.BaseAPI = BaseAPI;
;
/**
 *
 * @export
 * @class RequiredError
 * @extends {Error}
 */
class RequiredError extends Error {
  constructor(field, msg) {
    super(msg);
    this.field = field;
    this.name = "RequiredError";
  }
}
exports.RequiredError = RequiredError;

/***/ }),

/***/ "./node_modules/openai/dist/common.js":
/*!********************************************!*\
  !*** ./node_modules/openai/dist/common.js ***!
  \********************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


/* tslint:disable */
/* eslint-disable */
/**
 * OpenAI API
 * APIs for sampling from and fine-tuning language models
 *
 * The version of the OpenAPI document: 1.3.0
 *
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
var __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function (resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function (resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports.createRequestFunction = exports.toPathString = exports.serializeDataIfNeeded = exports.setSearchParams = exports.setOAuthToObject = exports.setBearerAuthToObject = exports.setBasicAuthToObject = exports.setApiKeyToObject = exports.assertParamExists = exports.DUMMY_BASE_URL = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./node_modules/openai/dist/base.js");
/**
 *
 * @export
 */
exports.DUMMY_BASE_URL = 'https://example.com';
/**
 *
 * @throws {RequiredError}
 * @export
 */
exports.assertParamExists = function (functionName, paramName, paramValue) {
  if (paramValue === null || paramValue === undefined) {
    throw new base_1.RequiredError(paramName, `Required parameter ${paramName} was null or undefined when calling ${functionName}.`);
  }
};
/**
 *
 * @export
 */
exports.setApiKeyToObject = function (object, keyParamName, configuration) {
  return __awaiter(this, void 0, void 0, function* () {
    if (configuration && configuration.apiKey) {
      const localVarApiKeyValue = typeof configuration.apiKey === 'function' ? yield configuration.apiKey(keyParamName) : yield configuration.apiKey;
      object[keyParamName] = localVarApiKeyValue;
    }
  });
};
/**
 *
 * @export
 */
exports.setBasicAuthToObject = function (object, configuration) {
  if (configuration && (configuration.username || configuration.password)) {
    object["auth"] = {
      username: configuration.username,
      password: configuration.password
    };
  }
};
/**
 *
 * @export
 */
exports.setBearerAuthToObject = function (object, configuration) {
  return __awaiter(this, void 0, void 0, function* () {
    if (configuration && configuration.accessToken) {
      const accessToken = typeof configuration.accessToken === 'function' ? yield configuration.accessToken() : yield configuration.accessToken;
      object["Authorization"] = "Bearer " + accessToken;
    }
  });
};
/**
 *
 * @export
 */
exports.setOAuthToObject = function (object, name, scopes, configuration) {
  return __awaiter(this, void 0, void 0, function* () {
    if (configuration && configuration.accessToken) {
      const localVarAccessTokenValue = typeof configuration.accessToken === 'function' ? yield configuration.accessToken(name, scopes) : yield configuration.accessToken;
      object["Authorization"] = "Bearer " + localVarAccessTokenValue;
    }
  });
};
function setFlattenedQueryParams(urlSearchParams, parameter, key = "") {
  if (parameter == null) return;
  if (typeof parameter === "object") {
    if (Array.isArray(parameter)) {
      parameter.forEach(item => setFlattenedQueryParams(urlSearchParams, item, key));
    } else {
      Object.keys(parameter).forEach(currentKey => setFlattenedQueryParams(urlSearchParams, parameter[currentKey], `${key}${key !== '' ? '.' : ''}${currentKey}`));
    }
  } else {
    if (urlSearchParams.has(key)) {
      urlSearchParams.append(key, parameter);
    } else {
      urlSearchParams.set(key, parameter);
    }
  }
}
/**
 *
 * @export
 */
exports.setSearchParams = function (url, ...objects) {
  const searchParams = new URLSearchParams(url.search);
  setFlattenedQueryParams(searchParams, objects);
  url.search = searchParams.toString();
};
/**
 *
 * @export
 */
exports.serializeDataIfNeeded = function (value, requestOptions, configuration) {
  const nonString = typeof value !== 'string';
  const needsSerialization = nonString && configuration && configuration.isJsonMime ? configuration.isJsonMime(requestOptions.headers['Content-Type']) : nonString;
  return needsSerialization ? JSON.stringify(value !== undefined ? value : {}) : value || "";
};
/**
 *
 * @export
 */
exports.toPathString = function (url) {
  return url.pathname + url.search + url.hash;
};
/**
 *
 * @export
 */
exports.createRequestFunction = function (axiosArgs, globalAxios, BASE_PATH, configuration) {
  return (axios = globalAxios, basePath = BASE_PATH) => {
    const axiosRequestArgs = Object.assign(Object.assign({}, axiosArgs.options), {
      url: ((configuration === null || configuration === void 0 ? void 0 : configuration.basePath) || basePath) + axiosArgs.url
    });
    return axios.request(axiosRequestArgs);
  };
};

/***/ }),

/***/ "./node_modules/openai/dist/configuration.js":
/*!***************************************************!*\
  !*** ./node_modules/openai/dist/configuration.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";


/* tslint:disable */
/* eslint-disable */
/**
 * OpenAI API
 * APIs for sampling from and fine-tuning language models
 *
 * The version of the OpenAPI document: 1.3.0
 *
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports.Configuration = void 0;
const packageJson = __webpack_require__(/*! ../package.json */ "./node_modules/openai/package.json");
class Configuration {
  constructor(param = {}) {
    this.apiKey = param.apiKey;
    this.organization = param.organization;
    this.username = param.username;
    this.password = param.password;
    this.accessToken = param.accessToken;
    this.basePath = param.basePath;
    this.baseOptions = param.baseOptions;
    this.formDataCtor = param.formDataCtor;
    if (!this.baseOptions) {
      this.baseOptions = {};
    }
    this.baseOptions.headers = Object.assign({
      'User-Agent': `OpenAI/NodeJS/${packageJson.version}`,
      'Authorization': `Bearer ${this.apiKey}`
    }, this.baseOptions.headers);
    if (this.organization) {
      this.baseOptions.headers['OpenAI-Organization'] = this.organization;
    }
    if (!this.formDataCtor) {
      this.formDataCtor = __webpack_require__(/*! form-data */ "./node_modules/form-data/lib/browser.js");
    }
  }
  /**
   * Check if the given MIME is a JSON MIME.
   * JSON MIME examples:
   *   application/json
   *   application/json; charset=UTF8
   *   APPLICATION/JSON
   *   application/vnd.company+json
   * @param mime - MIME (Multipurpose Internet Mail Extensions)
   * @return True if the given MIME is JSON, false otherwise.
   */
  isJsonMime(mime) {
    const jsonMime = new RegExp('^(application\/json|[^;/ \t]+\/[^;/ \t]+[+]json)[ \t]*(;.*)?$', 'i');
    return mime !== null && (jsonMime.test(mime) || mime.toLowerCase() === 'application/json-patch+json');
  }
}
exports.Configuration = Configuration;

/***/ }),

/***/ "./node_modules/openai/dist/index.js":
/*!*******************************************!*\
  !*** ./node_modules/openai/dist/index.js ***!
  \*******************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


/* tslint:disable */
/* eslint-disable */
/**
 * OpenAI API
 * APIs for sampling from and fine-tuning language models
 *
 * The version of the OpenAPI document: 1.3.0
 *
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
var __createBinding = this && this.__createBinding || (Object.create ? function (o, m, k, k2) {
  if (k2 === undefined) k2 = k;
  Object.defineProperty(o, k2, {
    enumerable: true,
    get: function () {
      return m[k];
    }
  });
} : function (o, m, k, k2) {
  if (k2 === undefined) k2 = k;
  o[k2] = m[k];
});
var __exportStar = this && this.__exportStar || function (m, exports) {
  for (var p in m) if (p !== "default" && !exports.hasOwnProperty(p)) __createBinding(exports, m, p);
};
Object.defineProperty(exports, "__esModule", ({
  value: true
}));
__exportStar(__webpack_require__(/*! ./api */ "./node_modules/openai/dist/api.js"), exports);
__exportStar(__webpack_require__(/*! ./configuration */ "./node_modules/openai/dist/configuration.js"), exports);

/***/ }),

/***/ "./node_modules/tiktoken/tiktoken.js":
/*!*******************************************!*\
  !*** ./node_modules/tiktoken/tiktoken.js ***!
  \*******************************************/
/***/ ((module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.a(module, async (__webpack_handle_async_dependencies__, __webpack_async_result__) => { try {
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Tiktoken: () => (/* reexport safe */ _tiktoken_bg_js__WEBPACK_IMPORTED_MODULE_1__.Tiktoken),
/* harmony export */   __wbg_parse_670c19d4e984792e: () => (/* reexport safe */ _tiktoken_bg_js__WEBPACK_IMPORTED_MODULE_1__.__wbg_parse_670c19d4e984792e),
/* harmony export */   __wbg_set_wasm: () => (/* reexport safe */ _tiktoken_bg_js__WEBPACK_IMPORTED_MODULE_1__.__wbg_set_wasm),
/* harmony export */   __wbg_stringify_e25465938f3f611f: () => (/* reexport safe */ _tiktoken_bg_js__WEBPACK_IMPORTED_MODULE_1__.__wbg_stringify_e25465938f3f611f),
/* harmony export */   __wbindgen_error_new: () => (/* reexport safe */ _tiktoken_bg_js__WEBPACK_IMPORTED_MODULE_1__.__wbindgen_error_new),
/* harmony export */   __wbindgen_is_undefined: () => (/* reexport safe */ _tiktoken_bg_js__WEBPACK_IMPORTED_MODULE_1__.__wbindgen_is_undefined),
/* harmony export */   __wbindgen_object_drop_ref: () => (/* reexport safe */ _tiktoken_bg_js__WEBPACK_IMPORTED_MODULE_1__.__wbindgen_object_drop_ref),
/* harmony export */   __wbindgen_string_get: () => (/* reexport safe */ _tiktoken_bg_js__WEBPACK_IMPORTED_MODULE_1__.__wbindgen_string_get),
/* harmony export */   __wbindgen_throw: () => (/* reexport safe */ _tiktoken_bg_js__WEBPACK_IMPORTED_MODULE_1__.__wbindgen_throw),
/* harmony export */   encoding_for_model: () => (/* reexport safe */ _tiktoken_bg_js__WEBPACK_IMPORTED_MODULE_1__.encoding_for_model),
/* harmony export */   get_encoding: () => (/* reexport safe */ _tiktoken_bg_js__WEBPACK_IMPORTED_MODULE_1__.get_encoding)
/* harmony export */ });
/* harmony import */ var _tiktoken_bg_wasm__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./tiktoken_bg.wasm */ "./node_modules/tiktoken/tiktoken_bg.wasm");
/* harmony import */ var _tiktoken_bg_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./tiktoken_bg.js */ "./node_modules/tiktoken/tiktoken_bg.js");
var __webpack_async_dependencies__ = __webpack_handle_async_dependencies__([_tiktoken_bg_wasm__WEBPACK_IMPORTED_MODULE_0__]);
_tiktoken_bg_wasm__WEBPACK_IMPORTED_MODULE_0__ = (__webpack_async_dependencies__.then ? (await __webpack_async_dependencies__)() : __webpack_async_dependencies__)[0];


(0,_tiktoken_bg_js__WEBPACK_IMPORTED_MODULE_1__.__wbg_set_wasm)(_tiktoken_bg_wasm__WEBPACK_IMPORTED_MODULE_0__);

__webpack_async_result__();
} catch(e) { __webpack_async_result__(e); } });

/***/ }),

/***/ "./node_modules/tiktoken/tiktoken_bg.js":
/*!**********************************************!*\
  !*** ./node_modules/tiktoken/tiktoken_bg.js ***!
  \**********************************************/
/***/ ((module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Tiktoken: () => (/* binding */ Tiktoken),
/* harmony export */   __wbg_parse_670c19d4e984792e: () => (/* binding */ __wbg_parse_670c19d4e984792e),
/* harmony export */   __wbg_set_wasm: () => (/* binding */ __wbg_set_wasm),
/* harmony export */   __wbg_stringify_e25465938f3f611f: () => (/* binding */ __wbg_stringify_e25465938f3f611f),
/* harmony export */   __wbindgen_error_new: () => (/* binding */ __wbindgen_error_new),
/* harmony export */   __wbindgen_is_undefined: () => (/* binding */ __wbindgen_is_undefined),
/* harmony export */   __wbindgen_object_drop_ref: () => (/* binding */ __wbindgen_object_drop_ref),
/* harmony export */   __wbindgen_string_get: () => (/* binding */ __wbindgen_string_get),
/* harmony export */   __wbindgen_throw: () => (/* binding */ __wbindgen_throw),
/* harmony export */   encoding_for_model: () => (/* binding */ encoding_for_model),
/* harmony export */   get_encoding: () => (/* binding */ get_encoding)
/* harmony export */ });
/* module decorator */ module = __webpack_require__.hmd(module);
let wasm;
function __wbg_set_wasm(val) {
  wasm = val;
}
const heap = new Array(128).fill(undefined);
heap.push(undefined, null, true, false);
function getObject(idx) {
  return heap[idx];
}
let heap_next = heap.length;
function dropObject(idx) {
  if (idx < 132) return;
  heap[idx] = heap_next;
  heap_next = idx;
}
function takeObject(idx) {
  const ret = getObject(idx);
  dropObject(idx);
  return ret;
}
let WASM_VECTOR_LEN = 0;
let cachedUint8Memory0 = null;
function getUint8Memory0() {
  if (cachedUint8Memory0 === null || cachedUint8Memory0.byteLength === 0) {
    cachedUint8Memory0 = new Uint8Array(wasm.memory.buffer);
  }
  return cachedUint8Memory0;
}
const lTextEncoder = typeof TextEncoder === 'undefined' ? (0, module.require)('util').TextEncoder : TextEncoder;
let cachedTextEncoder = new lTextEncoder('utf-8');
const encodeString = typeof cachedTextEncoder.encodeInto === 'function' ? function (arg, view) {
  return cachedTextEncoder.encodeInto(arg, view);
} : function (arg, view) {
  const buf = cachedTextEncoder.encode(arg);
  view.set(buf);
  return {
    read: arg.length,
    written: buf.length
  };
};
function passStringToWasm0(arg, malloc, realloc) {
  if (realloc === undefined) {
    const buf = cachedTextEncoder.encode(arg);
    const ptr = malloc(buf.length, 1) >>> 0;
    getUint8Memory0().subarray(ptr, ptr + buf.length).set(buf);
    WASM_VECTOR_LEN = buf.length;
    return ptr;
  }
  let len = arg.length;
  let ptr = malloc(len, 1) >>> 0;
  const mem = getUint8Memory0();
  let offset = 0;
  for (; offset < len; offset++) {
    const code = arg.charCodeAt(offset);
    if (code > 0x7F) break;
    mem[ptr + offset] = code;
  }
  if (offset !== len) {
    if (offset !== 0) {
      arg = arg.slice(offset);
    }
    ptr = realloc(ptr, len, len = offset + arg.length * 3, 1) >>> 0;
    const view = getUint8Memory0().subarray(ptr + offset, ptr + len);
    const ret = encodeString(arg, view);
    offset += ret.written;
  }
  WASM_VECTOR_LEN = offset;
  return ptr;
}
function isLikeNone(x) {
  return x === undefined || x === null;
}
let cachedInt32Memory0 = null;
function getInt32Memory0() {
  if (cachedInt32Memory0 === null || cachedInt32Memory0.byteLength === 0) {
    cachedInt32Memory0 = new Int32Array(wasm.memory.buffer);
  }
  return cachedInt32Memory0;
}
const lTextDecoder = typeof TextDecoder === 'undefined' ? (0, module.require)('util').TextDecoder : TextDecoder;
let cachedTextDecoder = new lTextDecoder('utf-8', {
  ignoreBOM: true,
  fatal: true
});
cachedTextDecoder.decode();
function getStringFromWasm0(ptr, len) {
  ptr = ptr >>> 0;
  return cachedTextDecoder.decode(getUint8Memory0().subarray(ptr, ptr + len));
}
function addHeapObject(obj) {
  if (heap_next === heap.length) heap.push(heap.length + 1);
  const idx = heap_next;
  heap_next = heap[idx];
  heap[idx] = obj;
  return idx;
}
let cachedUint32Memory0 = null;
function getUint32Memory0() {
  if (cachedUint32Memory0 === null || cachedUint32Memory0.byteLength === 0) {
    cachedUint32Memory0 = new Uint32Array(wasm.memory.buffer);
  }
  return cachedUint32Memory0;
}
function getArrayU32FromWasm0(ptr, len) {
  ptr = ptr >>> 0;
  return getUint32Memory0().subarray(ptr / 4, ptr / 4 + len);
}
function passArray8ToWasm0(arg, malloc) {
  const ptr = malloc(arg.length * 1, 1) >>> 0;
  getUint8Memory0().set(arg, ptr / 1);
  WASM_VECTOR_LEN = arg.length;
  return ptr;
}
function passArray32ToWasm0(arg, malloc) {
  const ptr = malloc(arg.length * 4, 4) >>> 0;
  getUint32Memory0().set(arg, ptr / 4);
  WASM_VECTOR_LEN = arg.length;
  return ptr;
}
function getArrayU8FromWasm0(ptr, len) {
  ptr = ptr >>> 0;
  return getUint8Memory0().subarray(ptr / 1, ptr / 1 + len);
}
/**
* @param {string} encoding
* @param {any} extend_special_tokens
* @returns {Tiktoken}
*/
function get_encoding(encoding, extend_special_tokens) {
  if (wasm == null) throw new Error("tiktoken: WASM binary has not been propery initialized.");
  try {
    const retptr = wasm.__wbindgen_add_to_stack_pointer(-16);
    const ptr0 = passStringToWasm0(encoding, wasm.__wbindgen_export_0, wasm.__wbindgen_export_1);
    const len0 = WASM_VECTOR_LEN;
    wasm.get_encoding(retptr, ptr0, len0, addHeapObject(extend_special_tokens));
    var r0 = getInt32Memory0()[retptr / 4 + 0];
    var r1 = getInt32Memory0()[retptr / 4 + 1];
    var r2 = getInt32Memory0()[retptr / 4 + 2];
    if (r2) {
      throw takeObject(r1);
    }
    return Tiktoken.__wrap(r0);
  } finally {
    wasm.__wbindgen_add_to_stack_pointer(16);
  }
}

/**
* @param {string} model
* @param {any} extend_special_tokens
* @returns {Tiktoken}
*/
function encoding_for_model(model, extend_special_tokens) {
  if (wasm == null) throw new Error("tiktoken: WASM binary has not been propery initialized.");
  try {
    const retptr = wasm.__wbindgen_add_to_stack_pointer(-16);
    const ptr0 = passStringToWasm0(model, wasm.__wbindgen_export_0, wasm.__wbindgen_export_1);
    const len0 = WASM_VECTOR_LEN;
    wasm.encoding_for_model(retptr, ptr0, len0, addHeapObject(extend_special_tokens));
    var r0 = getInt32Memory0()[retptr / 4 + 0];
    var r1 = getInt32Memory0()[retptr / 4 + 1];
    var r2 = getInt32Memory0()[retptr / 4 + 2];
    if (r2) {
      throw takeObject(r1);
    }
    return Tiktoken.__wrap(r0);
  } finally {
    wasm.__wbindgen_add_to_stack_pointer(16);
  }
}
function handleError(f, args) {
  try {
    return f.apply(this, args);
  } catch (e) {
    wasm.__wbindgen_export_3(addHeapObject(e));
  }
}
const TiktokenFinalization = new FinalizationRegistry(ptr => wasm.__wbg_tiktoken_free(ptr >>> 0));
/**
*/
class Tiktoken {
  static __wrap(ptr) {
    ptr = ptr >>> 0;
    const obj = Object.create(Tiktoken.prototype);
    obj.__wbg_ptr = ptr;
    TiktokenFinalization.register(obj, obj.__wbg_ptr, obj);
    return obj;
  }
  __destroy_into_raw() {
    const ptr = this.__wbg_ptr;
    this.__wbg_ptr = 0;
    TiktokenFinalization.unregister(this);
    return ptr;
  }
  free() {
    if (wasm == null) throw new Error("tiktoken: WASM binary has not been propery initialized.");
    const ptr = this.__destroy_into_raw();
    wasm.__wbg_tiktoken_free(ptr);
  }
  /**
  * @param {string} tiktoken_bfe
  * @param {any} special_tokens
  * @param {string} pat_str
  */
  constructor(tiktoken_bfe, special_tokens, pat_str) {
    if (wasm == null) throw new Error("tiktoken: WASM binary has not been propery initialized.");
    const ptr0 = passStringToWasm0(tiktoken_bfe, wasm.__wbindgen_export_0, wasm.__wbindgen_export_1);
    const len0 = WASM_VECTOR_LEN;
    const ptr1 = passStringToWasm0(pat_str, wasm.__wbindgen_export_0, wasm.__wbindgen_export_1);
    const len1 = WASM_VECTOR_LEN;
    const ret = wasm.tiktoken_new(ptr0, len0, addHeapObject(special_tokens), ptr1, len1);
    return Tiktoken.__wrap(ret);
  }
  /**
  * @returns {string | undefined}
  */
  get name() {
    try {
      const retptr = wasm.__wbindgen_add_to_stack_pointer(-16);
      wasm.tiktoken_name(retptr, this.__wbg_ptr);
      var r0 = getInt32Memory0()[retptr / 4 + 0];
      var r1 = getInt32Memory0()[retptr / 4 + 1];
      let v1;
      if (r0 !== 0) {
        v1 = getStringFromWasm0(r0, r1).slice();
        wasm.__wbindgen_export_2(r0, r1 * 1);
      }
      return v1;
    } finally {
      wasm.__wbindgen_add_to_stack_pointer(16);
    }
  }
  /**
  * @param {string} text
  * @param {any} allowed_special
  * @param {any} disallowed_special
  * @returns {Uint32Array}
  */
  encode(text, allowed_special, disallowed_special) {
    if (wasm == null) throw new Error("tiktoken: WASM binary has not been propery initialized.");
    try {
      const retptr = wasm.__wbindgen_add_to_stack_pointer(-16);
      const ptr0 = passStringToWasm0(text, wasm.__wbindgen_export_0, wasm.__wbindgen_export_1);
      const len0 = WASM_VECTOR_LEN;
      wasm.tiktoken_encode(retptr, this.__wbg_ptr, ptr0, len0, addHeapObject(allowed_special), addHeapObject(disallowed_special));
      var r0 = getInt32Memory0()[retptr / 4 + 0];
      var r1 = getInt32Memory0()[retptr / 4 + 1];
      var r2 = getInt32Memory0()[retptr / 4 + 2];
      var r3 = getInt32Memory0()[retptr / 4 + 3];
      if (r3) {
        throw takeObject(r2);
      }
      var v2 = getArrayU32FromWasm0(r0, r1).slice();
      wasm.__wbindgen_export_2(r0, r1 * 4);
      return v2;
    } finally {
      wasm.__wbindgen_add_to_stack_pointer(16);
    }
  }
  /**
  * @param {string} text
  * @returns {Uint32Array}
  */
  encode_ordinary(text) {
    if (wasm == null) throw new Error("tiktoken: WASM binary has not been propery initialized.");
    try {
      const retptr = wasm.__wbindgen_add_to_stack_pointer(-16);
      const ptr0 = passStringToWasm0(text, wasm.__wbindgen_export_0, wasm.__wbindgen_export_1);
      const len0 = WASM_VECTOR_LEN;
      wasm.tiktoken_encode_ordinary(retptr, this.__wbg_ptr, ptr0, len0);
      var r0 = getInt32Memory0()[retptr / 4 + 0];
      var r1 = getInt32Memory0()[retptr / 4 + 1];
      var v2 = getArrayU32FromWasm0(r0, r1).slice();
      wasm.__wbindgen_export_2(r0, r1 * 4);
      return v2;
    } finally {
      wasm.__wbindgen_add_to_stack_pointer(16);
    }
  }
  /**
  * @param {string} text
  * @param {any} allowed_special
  * @param {any} disallowed_special
  * @returns {any}
  */
  encode_with_unstable(text, allowed_special, disallowed_special) {
    if (wasm == null) throw new Error("tiktoken: WASM binary has not been propery initialized.");
    try {
      const retptr = wasm.__wbindgen_add_to_stack_pointer(-16);
      const ptr0 = passStringToWasm0(text, wasm.__wbindgen_export_0, wasm.__wbindgen_export_1);
      const len0 = WASM_VECTOR_LEN;
      wasm.tiktoken_encode_with_unstable(retptr, this.__wbg_ptr, ptr0, len0, addHeapObject(allowed_special), addHeapObject(disallowed_special));
      var r0 = getInt32Memory0()[retptr / 4 + 0];
      var r1 = getInt32Memory0()[retptr / 4 + 1];
      var r2 = getInt32Memory0()[retptr / 4 + 2];
      if (r2) {
        throw takeObject(r1);
      }
      return takeObject(r0);
    } finally {
      wasm.__wbindgen_add_to_stack_pointer(16);
    }
  }
  /**
  * @param {Uint8Array} bytes
  * @returns {number}
  */
  encode_single_token(bytes) {
    if (wasm == null) throw new Error("tiktoken: WASM binary has not been propery initialized.");
    const ptr0 = passArray8ToWasm0(bytes, wasm.__wbindgen_export_0);
    const len0 = WASM_VECTOR_LEN;
    const ret = wasm.tiktoken_encode_single_token(this.__wbg_ptr, ptr0, len0);
    return ret >>> 0;
  }
  /**
  * @param {Uint32Array} tokens
  * @returns {Uint8Array}
  */
  decode(tokens) {
    if (wasm == null) throw new Error("tiktoken: WASM binary has not been propery initialized.");
    try {
      const retptr = wasm.__wbindgen_add_to_stack_pointer(-16);
      const ptr0 = passArray32ToWasm0(tokens, wasm.__wbindgen_export_0);
      const len0 = WASM_VECTOR_LEN;
      wasm.tiktoken_decode(retptr, this.__wbg_ptr, ptr0, len0);
      var r0 = getInt32Memory0()[retptr / 4 + 0];
      var r1 = getInt32Memory0()[retptr / 4 + 1];
      var v2 = getArrayU8FromWasm0(r0, r1).slice();
      wasm.__wbindgen_export_2(r0, r1 * 1);
      return v2;
    } finally {
      wasm.__wbindgen_add_to_stack_pointer(16);
    }
  }
  /**
  * @param {number} token
  * @returns {Uint8Array}
  */
  decode_single_token_bytes(token) {
    if (wasm == null) throw new Error("tiktoken: WASM binary has not been propery initialized.");
    try {
      const retptr = wasm.__wbindgen_add_to_stack_pointer(-16);
      wasm.tiktoken_decode_single_token_bytes(retptr, this.__wbg_ptr, token);
      var r0 = getInt32Memory0()[retptr / 4 + 0];
      var r1 = getInt32Memory0()[retptr / 4 + 1];
      var v1 = getArrayU8FromWasm0(r0, r1).slice();
      wasm.__wbindgen_export_2(r0, r1 * 1);
      return v1;
    } finally {
      wasm.__wbindgen_add_to_stack_pointer(16);
    }
  }
  /**
  * @returns {any}
  */
  token_byte_values() {
    if (wasm == null) throw new Error("tiktoken: WASM binary has not been propery initialized.");
    const ret = wasm.tiktoken_token_byte_values(this.__wbg_ptr);
    return takeObject(ret);
  }
}
function __wbindgen_object_drop_ref(arg0) {
  takeObject(arg0);
}
;
function __wbindgen_is_undefined(arg0) {
  const ret = getObject(arg0) === undefined;
  return ret;
}
;
function __wbg_stringify_e25465938f3f611f() {
  return handleError(function (arg0) {
    const ret = JSON.stringify(getObject(arg0));
    return addHeapObject(ret);
  }, arguments);
}
;
function __wbindgen_string_get(arg0, arg1) {
  if (wasm == null) throw new Error("tiktoken: WASM binary has not been propery initialized.");
  const obj = getObject(arg1);
  const ret = typeof obj === 'string' ? obj : undefined;
  var ptr1 = isLikeNone(ret) ? 0 : passStringToWasm0(ret, wasm.__wbindgen_export_0, wasm.__wbindgen_export_1);
  var len1 = WASM_VECTOR_LEN;
  getInt32Memory0()[arg0 / 4 + 1] = len1;
  getInt32Memory0()[arg0 / 4 + 0] = ptr1;
}
;
function __wbindgen_error_new(arg0, arg1) {
  const ret = new Error(getStringFromWasm0(arg0, arg1));
  return addHeapObject(ret);
}
;
function __wbg_parse_670c19d4e984792e() {
  return handleError(function (arg0, arg1) {
    const ret = JSON.parse(getStringFromWasm0(arg0, arg1));
    return addHeapObject(ret);
  }, arguments);
}
;
function __wbindgen_throw(arg0, arg1) {
  throw new Error(getStringFromWasm0(arg0, arg1));
}
;

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/native.js":
/*!******************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/native.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
const randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({
  randomUUID
});

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/regex.js":
/*!*****************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/regex.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i);

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/rng.js":
/*!***************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/rng.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ rng)
/* harmony export */ });
// Unique ID creation requires a high quality random # generator. In the browser we therefore
// require the crypto API and do not support built-in fallback to lower quality random number
// generators (like Math.random()).
let getRandomValues;
const rnds8 = new Uint8Array(16);
function rng() {
  // lazy load so that environments that need to polyfill have a chance to do so
  if (!getRandomValues) {
    // getRandomValues needs to be invoked in a context where "this" is a Crypto implementation.
    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);
    if (!getRandomValues) {
      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');
    }
  }
  return getRandomValues(rnds8);
}

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/stringify.js":
/*!*********************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/stringify.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__),
/* harmony export */   unsafeStringify: () => (/* binding */ unsafeStringify)
/* harmony export */ });
/* harmony import */ var _validate_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./validate.js */ "./node_modules/uuid/dist/esm-browser/validate.js");

/**
 * Convert array of 16 byte values to UUID string format of the form:
 * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
 */

const byteToHex = [];
for (let i = 0; i < 256; ++i) {
  byteToHex.push((i + 0x100).toString(16).slice(1));
}
function unsafeStringify(arr, offset = 0) {
  // Note: Be careful editing this code!  It's been tuned for performance
  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434
  return (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase();
}
function stringify(arr, offset = 0) {
  const uuid = unsafeStringify(arr, offset); // Consistency check for valid UUID.  If this throws, it's likely due to one
  // of the following:
  // - One or more input array values don't map to a hex octet (leading to
  // "undefined" in the uuid)
  // - Invalid input values for the RFC `version` or `variant` fields

  if (!(0,_validate_js__WEBPACK_IMPORTED_MODULE_0__["default"])(uuid)) {
    throw TypeError('Stringified UUID is invalid');
  }
  return uuid;
}
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (stringify);

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/v4.js":
/*!**************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/v4.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _native_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./native.js */ "./node_modules/uuid/dist/esm-browser/native.js");
/* harmony import */ var _rng_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./rng.js */ "./node_modules/uuid/dist/esm-browser/rng.js");
/* harmony import */ var _stringify_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./stringify.js */ "./node_modules/uuid/dist/esm-browser/stringify.js");



function v4(options, buf, offset) {
  if (_native_js__WEBPACK_IMPORTED_MODULE_0__["default"].randomUUID && !buf && !options) {
    return _native_js__WEBPACK_IMPORTED_MODULE_0__["default"].randomUUID();
  }
  options = options || {};
  const rnds = options.random || (options.rng || _rng_js__WEBPACK_IMPORTED_MODULE_1__["default"])(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`

  rnds[6] = rnds[6] & 0x0f | 0x40;
  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided

  if (buf) {
    offset = offset || 0;
    for (let i = 0; i < 16; ++i) {
      buf[offset + i] = rnds[i];
    }
    return buf;
  }
  return (0,_stringify_js__WEBPACK_IMPORTED_MODULE_2__.unsafeStringify)(rnds);
}
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (v4);

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/validate.js":
/*!********************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/validate.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _regex_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./regex.js */ "./node_modules/uuid/dist/esm-browser/regex.js");

function validate(uuid) {
  return typeof uuid === 'string' && _regex_js__WEBPACK_IMPORTED_MODULE_0__["default"].test(uuid);
}
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (validate);

/***/ }),

/***/ "./node_modules/webm-to-wav-converter/WavRecorder.js":
/*!***********************************************************!*\
  !*** ./node_modules/webm-to-wav-converter/WavRecorder.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

const getWaveBlob = __webpack_require__(/*! ./wavBlobUtil */ "./node_modules/webm-to-wav-converter/wavBlobUtil.js");
const downloadWav = __webpack_require__(/*! ./downloadUtil */ "./node_modules/webm-to-wav-converter/downloadUtil.js");

/** Class Representing a WavRecorder */
class WavRecorder {
  /**
   * @property {MediaRecorder} mediaRecorder - MediaRecorder instance
   */
  mediaRecorder;

  /**
   * @property {MediaStream} - stream User's MediaStream
   */
  stream;

  /**
   * @property {Blob} __data - Recorded WEBM data
   */
  __data;

  /**
   * Access user media from the audio input, will be asking audio permission if not available already
   * @param {MediaTrackConstraints} constraints - MediaTrackConstraints to be applied, if any defaults = { audio: true, video: false }
   * @return - Got User MediaStream or not
   */
  async start(constraints = {
    audio: true,
    video: false
  }) {
    if (this.mediaRecorder?.state === "recording") return true;
    const mediaTrackConstraints = constraints || {
      audio: true,
      video: false
    };
    try {
      this.stream = await navigator.mediaDevices.getUserMedia(mediaTrackConstraints);
      this.mediaRecorder = new MediaRecorder(this.stream);
      this.mediaRecorder.ondataavailable = e => this.__data = e.data;
    } catch (err) {
      console.error(err);
      return false;
    }
    this.mediaRecorder?.start();
    return true;
  }

  /**
   * Stop recording the audio
   * @returns {void}
   */
  stop() {
    if (this.mediaRecorder?.state !== "recording") return true;
    this.mediaRecorder.stop();
    this.mediaRecorder.onstop = () => {
      this.stream.getTracks().forEach(track => track.stop());
      this.mediaRecorder = undefined;
      this.stream = undefined;
    };
  }

  /**
   * Download the wav audio file
   * @param {string} filename - Optional name of the file to be downloaded, without extension 
   * @param {boolean} as32Bit - Audio required in 32-bit, default is 16-bit.
   * @param {AudioContextOptions} contextOptions - optiosn needs to be used for encoding
   * @returns {void}
   */
  async download(filename = null, as32Bit = false, contextOptions = undefined) {
    if (this.__data) return await downloadWav(this.__data, as32Bit, filename, contextOptions);
  }

  /**
   * Get the recorded wav audio Blob
   * @param {boolean} as32Bit - Get 32-bit audio, default is 16-bit
   * @param {AudioContextOptions} contextOptions - optiosn needs to be used for encoding
   * @returns {void}
   */
  async getBlob(as32Bit = false, contextOptions = undefined) {
    if (this.__data) return await getWaveBlob(this.__data, as32Bit, contextOptions);
  }
}
module.exports = WavRecorder;

/***/ }),

/***/ "./node_modules/webm-to-wav-converter/downloadUtil.js":
/*!************************************************************!*\
  !*** ./node_modules/webm-to-wav-converter/downloadUtil.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

const getWaveBlob = __webpack_require__(/*! ./wavBlobUtil */ "./node_modules/webm-to-wav-converter/wavBlobUtil.js");

/**
 * @param {Blob | Blob[]} blobData - Blob or Blob[] to be converted to audio/wave Blob
 * @param {boolean} as32BitFloat - Convert to 16-bit or 32-bit file
 * @param {string} filename - Name of the file
 * @param {AudioContextOptions} contextOptions - audio context options for encoding
 * @returns
 */
async function downloadWav(blobData, as32BitFloat, filename = null, contextOptions = undefined) {
  const blob = await getWaveBlob(blobData, as32BitFloat, contextOptions);
  const anchorElement = document.createElement('a');
  anchorElement.href = window.URL.createObjectURL(blob);
  anchorElement.download = filename || `recording('${as32BitFloat ? '32bit' : '16bit'}).wav`;
  anchorElement.style.display = 'none';
  document.body.appendChild(anchorElement);
  anchorElement.click();
  document.body.removeChild(anchorElement);
}
module.exports = downloadWav;

/***/ }),

/***/ "./node_modules/webm-to-wav-converter/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/webm-to-wav-converter/index.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

module.exports.WavRecorder = __webpack_require__(/*! ./WavRecorder */ "./node_modules/webm-to-wav-converter/WavRecorder.js");
module.exports.getWaveBlob = __webpack_require__(/*! ./wavBlobUtil */ "./node_modules/webm-to-wav-converter/wavBlobUtil.js");
module.exports.downloadWav = __webpack_require__(/*! ./downloadUtil */ "./node_modules/webm-to-wav-converter/downloadUtil.js");

/***/ }),

/***/ "./node_modules/webm-to-wav-converter/wavBlobUtil.js":
/*!***********************************************************!*\
  !*** ./node_modules/webm-to-wav-converter/wavBlobUtil.js ***!
  \***********************************************************/
/***/ ((module) => {

function _writeStringToArray(aString, targetArray, offset) {
  for (let i = 0; i < aString.length; ++i) targetArray[offset + i] = aString.charCodeAt(i);
}
function _writeInt16ToArray(aNumber, targetArray, offset) {
  aNumber = Math.floor(aNumber);
  targetArray[offset + 0] = aNumber & 255; // byte 1
  targetArray[offset + 1] = aNumber >> 8 & 255; // byte 2
}

function _writeInt32ToArray(aNumber, targetArray, offset) {
  aNumber = Math.floor(aNumber);
  targetArray[offset + 0] = aNumber & 255; // byte 1
  targetArray[offset + 1] = aNumber >> 8 & 255; // byte 2
  targetArray[offset + 2] = aNumber >> 16 & 255; // byte 3
  targetArray[offset + 3] = aNumber >> 24 & 255; // byte 4
}

// Return the bits of the float as a 32-bit integer value.  This
// produces the raw bits; no intepretation of the value is done.
function _floatBits(f) {
  const buf = new ArrayBuffer(4);
  new Float32Array(buf)[0] = f;
  const bits = new Uint32Array(buf)[0];
  // Return as a signed integer.
  return bits | 0;
}
function _writeAudioBufferToArray(audioBuffer, targetArray, offset, bitDepth) {
  let index = 0,
    channel = 0;
  const length = audioBuffer.length;
  const channels = audioBuffer.numberOfChannels;
  let channelData, sample;

  // Clamping samples onto the 16-bit resolution.
  for (index = 0; index < length; ++index) {
    for (channel = 0; channel < channels; ++channel) {
      channelData = audioBuffer.getChannelData(channel);

      // Branches upon the requested bit depth
      if (bitDepth === 16) {
        sample = channelData[index] * 32768.0;
        if (sample < -32768) sample = -32768;else if (sample > 32767) sample = 32767;
        _writeInt16ToArray(sample, targetArray, offset);
        offset += 2;
      } else if (bitDepth === 32) {
        // This assumes we're going to out 32-float, not 32-bit linear.
        sample = _floatBits(channelData[index]);
        _writeInt32ToArray(sample, targetArray, offset);
        offset += 4;
      } else {
        console.log('Invalid bit depth for PCM encoding.');
        return;
      }
    }
  }
}

// Converts the Blob data to AudioBuffer
async function _getAudioBuffer(blobData, contextOptions = undefined) {
  let blob = blobData;
  if (!(blob instanceof Blob)) blob = new Blob([blobData]);
  const url = URL.createObjectURL(blob);
  const response = await fetch(url);
  const arrayBuffer = await response.arrayBuffer();
  const audioContext = new AudioContext(contextOptions);
  const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
  return audioBuffer;
}

/**
 * 
 * @param {Blob | Blob[]} blobData - Blob or Blob[] to be converted to audio/wave Blob
 * @param {boolean} as32BitFloat - Convert to 16-bit or 32-bit file, default 16-bit
 * @param {AudioContextOptions} contextOptions - optiosn needs to be used for encoding
 * @returns 
 */
async function getWaveBlob(blobData, as32BitFloat, contextOptions = undefined) {
  const audioBuffer = await _getAudioBuffer(blobData, contextOptions);

  // Encoding setup.
  const frameLength = audioBuffer.length;
  const numberOfChannels = audioBuffer.numberOfChannels;
  const sampleRate = audioBuffer.sampleRate;
  const bitsPerSample = as32BitFloat ? 32 : 16;
  const bytesPerSample = bitsPerSample / 8;
  const byteRate = sampleRate * numberOfChannels * bitsPerSample / 8;
  const blockAlign = numberOfChannels * bitsPerSample / 8;
  const wavDataByteLength = frameLength * numberOfChannels * bytesPerSample;
  const headerByteLength = 44;
  const totalLength = headerByteLength + wavDataByteLength;
  const waveFileData = new Uint8Array(totalLength);
  const subChunk1Size = 16;
  const subChunk2Size = wavDataByteLength;
  const chunkSize = 4 + (8 + subChunk1Size) + (8 + subChunk2Size);
  _writeStringToArray('RIFF', waveFileData, 0);
  _writeInt32ToArray(chunkSize, waveFileData, 4);
  _writeStringToArray('WAVE', waveFileData, 8);
  _writeStringToArray('fmt ', waveFileData, 12);

  // SubChunk1Size (4)
  _writeInt32ToArray(subChunk1Size, waveFileData, 16);
  // AudioFormat (2): 3 means 32-bit float, 1 means integer PCM.
  _writeInt16ToArray(as32BitFloat ? 3 : 1, waveFileData, 20);
  // NumChannels (2)
  _writeInt16ToArray(numberOfChannels, waveFileData, 22);
  // SampleRate (4)
  _writeInt32ToArray(sampleRate, waveFileData, 24);
  // ByteRate (4)
  _writeInt32ToArray(byteRate, waveFileData, 28);
  // BlockAlign (2)
  _writeInt16ToArray(blockAlign, waveFileData, 32);
  // BitsPerSample (4)
  _writeInt32ToArray(bitsPerSample, waveFileData, 34);
  _writeStringToArray('data', waveFileData, 36);
  // SubChunk2Size (4)
  _writeInt32ToArray(subChunk2Size, waveFileData, 40);

  // Write actual audio data starting at offset 44.
  _writeAudioBufferToArray(audioBuffer, waveFileData, 44, bitsPerSample);
  return new Blob([waveFileData], {
    type: 'audio/wave'
  });
}
module.exports = getWaveBlob;

/***/ }),

/***/ "./src/AMRecorder.js":
/*!***************************!*\
  !*** ./src/AMRecorder.js ***!
  \***************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
function _typeof(obj) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof(obj); }
function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }
function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor); } }
function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, "prototype", { writable: false }); return Constructor; }
function _toPropertyKey(arg) { var key = _toPrimitive(arg, "string"); return _typeof(key) === "symbol" ? key : String(key); }
function _toPrimitive(input, hint) { if (_typeof(input) !== "object" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || "default"); if (_typeof(res) !== "object") return res; throw new TypeError("@@toPrimitive must return a primitive value."); } return (hint === "string" ? String : Number)(input); }
var AMRecorder = /*#__PURE__*/function () {
  function AMRecorder(start, stop) {
    _classCallCheck(this, AMRecorder);
    // state: init | trans | rec | shot | err
    this.state = "init";
    this.start = start;
    this.stop = stop;
  }
  _createClass(AMRecorder, [{
    key: "toInit",
    value: function toInit() {
      switch (this.state) {
        case "init":
          return true;
        case "rec":
        case "shot":
          var res = this.stop();
          if (res) {
            this.state = "init";
            return true;
          } else {
            this.state = "err";
            return false;
          }
        default:
          this.state = "err";
          return false;
      }
    }
  }, {
    key: "toTrans",
    value: function toTrans() {
      switch (this.state) {
        case "init":
          var res = this.start();
          if (res) {
            this.state = "trans";
            return true;
          } else {
            this.state = "err";
            return false;
          }
        default:
          this.state = "err";
          return false;
      }
    }
  }, {
    key: "toRec",
    value: function toRec() {
      switch (this.state) {
        case "trans":
          this.state = "rec";
          return true;
        default:
          this.state = "err";
          return false;
      }
    }
  }, {
    key: "toShot",
    value: function toShot() {
      switch (this.state) {
        case "trans":
          this.state = "shot";
          return true;
        default:
          this.state = "err";
          return false;
      }
    }
  }, {
    key: "isRecording",
    value: function isRecording() {
      switch (this.state) {
        case "init":
          return false;
        case "trans":
        case "rec":
        case "shot":
          return true;
        case "err":
          return false;
      }
    }
  }, {
    key: "isErr",
    value: function isErr() {
      return this.state == "err";
    }
  }, {
    key: "reset",
    value: function reset() {
      this.state = "init";
    }
  }]);
  return AMRecorder;
}();
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AMRecorder);

/***/ }),

/***/ "./src/API.js":
/*!********************!*\
  !*** ./src/API.js ***!
  \********************/
/***/ ((module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.a(module, async (__webpack_handle_async_dependencies__, __webpack_async_result__) => { try {
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js");
/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js");
/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js");
/* harmony import */ var openai__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! openai */ "./node_modules/openai/dist/index.js");
/* harmony import */ var openai__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(openai__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _Credential__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Credential */ "./src/Credential.js");
/* harmony import */ var _Conversation__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Conversation */ "./src/Conversation.ts");
var __webpack_async_dependencies__ = __webpack_handle_async_dependencies__([_Conversation__WEBPACK_IMPORTED_MODULE_2__]);
_Conversation__WEBPACK_IMPORTED_MODULE_2__ = (__webpack_async_dependencies__.then ? (await __webpack_async_dependencies__)() : __webpack_async_dependencies__)[0];
function _typeof(obj) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof(obj); }
function _regeneratorRuntime() { "use strict"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return exports; }; var exports = {}, Op = Object.prototype, hasOwn = Op.hasOwnProperty, defineProperty = Object.defineProperty || function (obj, key, desc) { obj[key] = desc.value; }, $Symbol = "function" == typeof Symbol ? Symbol : {}, iteratorSymbol = $Symbol.iterator || "@@iterator", asyncIteratorSymbol = $Symbol.asyncIterator || "@@asyncIterator", toStringTagSymbol = $Symbol.toStringTag || "@@toStringTag"; function define(obj, key, value) { return Object.defineProperty(obj, key, { value: value, enumerable: !0, configurable: !0, writable: !0 }), obj[key]; } try { define({}, ""); } catch (err) { define = function define(obj, key, value) { return obj[key] = value; }; } function wrap(innerFn, outerFn, self, tryLocsList) { var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator, generator = Object.create(protoGenerator.prototype), context = new Context(tryLocsList || []); return defineProperty(generator, "_invoke", { value: makeInvokeMethod(innerFn, self, context) }), generator; } function tryCatch(fn, obj, arg) { try { return { type: "normal", arg: fn.call(obj, arg) }; } catch (err) { return { type: "throw", arg: err }; } } exports.wrap = wrap; var ContinueSentinel = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var IteratorPrototype = {}; define(IteratorPrototype, iteratorSymbol, function () { return this; }); var getProto = Object.getPrototypeOf, NativeIteratorPrototype = getProto && getProto(getProto(values([]))); NativeIteratorPrototype && NativeIteratorPrototype !== Op && hasOwn.call(NativeIteratorPrototype, iteratorSymbol) && (IteratorPrototype = NativeIteratorPrototype); var Gp = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(IteratorPrototype); function defineIteratorMethods(prototype) { ["next", "throw", "return"].forEach(function (method) { define(prototype, method, function (arg) { return this._invoke(method, arg); }); }); } function AsyncIterator(generator, PromiseImpl) { function invoke(method, arg, resolve, reject) { var record = tryCatch(generator[method], generator, arg); if ("throw" !== record.type) { var result = record.arg, value = result.value; return value && "object" == _typeof(value) && hasOwn.call(value, "__await") ? PromiseImpl.resolve(value.__await).then(function (value) { invoke("next", value, resolve, reject); }, function (err) { invoke("throw", err, resolve, reject); }) : PromiseImpl.resolve(value).then(function (unwrapped) { result.value = unwrapped, resolve(result); }, function (error) { return invoke("throw", error, resolve, reject); }); } reject(record.arg); } var previousPromise; defineProperty(this, "_invoke", { value: function value(method, arg) { function callInvokeWithMethodAndArg() { return new PromiseImpl(function (resolve, reject) { invoke(method, arg, resolve, reject); }); } return previousPromise = previousPromise ? previousPromise.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); } }); } function makeInvokeMethod(innerFn, self, context) { var state = "suspendedStart"; return function (method, arg) { if ("executing" === state) throw new Error("Generator is already running"); if ("completed" === state) { if ("throw" === method) throw arg; return doneResult(); } for (context.method = method, context.arg = arg;;) { var delegate = context.delegate; if (delegate) { var delegateResult = maybeInvokeDelegate(delegate, context); if (delegateResult) { if (delegateResult === ContinueSentinel) continue; return delegateResult; } } if ("next" === context.method) context.sent = context._sent = context.arg;else if ("throw" === context.method) { if ("suspendedStart" === state) throw state = "completed", context.arg; context.dispatchException(context.arg); } else "return" === context.method && context.abrupt("return", context.arg); state = "executing"; var record = tryCatch(innerFn, self, context); if ("normal" === record.type) { if (state = context.done ? "completed" : "suspendedYield", record.arg === ContinueSentinel) continue; return { value: record.arg, done: context.done }; } "throw" === record.type && (state = "completed", context.method = "throw", context.arg = record.arg); } }; } function maybeInvokeDelegate(delegate, context) { var methodName = context.method, method = delegate.iterator[methodName]; if (undefined === method) return context.delegate = null, "throw" === methodName && delegate.iterator["return"] && (context.method = "return", context.arg = undefined, maybeInvokeDelegate(delegate, context), "throw" === context.method) || "return" !== methodName && (context.method = "throw", context.arg = new TypeError("The iterator does not provide a '" + methodName + "' method")), ContinueSentinel; var record = tryCatch(method, delegate.iterator, context.arg); if ("throw" === record.type) return context.method = "throw", context.arg = record.arg, context.delegate = null, ContinueSentinel; var info = record.arg; return info ? info.done ? (context[delegate.resultName] = info.value, context.next = delegate.nextLoc, "return" !== context.method && (context.method = "next", context.arg = undefined), context.delegate = null, ContinueSentinel) : info : (context.method = "throw", context.arg = new TypeError("iterator result is not an object"), context.delegate = null, ContinueSentinel); } function pushTryEntry(locs) { var entry = { tryLoc: locs[0] }; 1 in locs && (entry.catchLoc = locs[1]), 2 in locs && (entry.finallyLoc = locs[2], entry.afterLoc = locs[3]), this.tryEntries.push(entry); } function resetTryEntry(entry) { var record = entry.completion || {}; record.type = "normal", delete record.arg, entry.completion = record; } function Context(tryLocsList) { this.tryEntries = [{ tryLoc: "root" }], tryLocsList.forEach(pushTryEntry, this), this.reset(!0); } function values(iterable) { if (iterable) { var iteratorMethod = iterable[iteratorSymbol]; if (iteratorMethod) return iteratorMethod.call(iterable); if ("function" == typeof iterable.next) return iterable; if (!isNaN(iterable.length)) { var i = -1, next = function next() { for (; ++i < iterable.length;) if (hasOwn.call(iterable, i)) return next.value = iterable[i], next.done = !1, next; return next.value = undefined, next.done = !0, next; }; return next.next = next; } } return { next: doneResult }; } function doneResult() { return { value: undefined, done: !0 }; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, defineProperty(Gp, "constructor", { value: GeneratorFunctionPrototype, configurable: !0 }), defineProperty(GeneratorFunctionPrototype, "constructor", { value: GeneratorFunction, configurable: !0 }), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, toStringTagSymbol, "GeneratorFunction"), exports.isGeneratorFunction = function (genFun) { var ctor = "function" == typeof genFun && genFun.constructor; return !!ctor && (ctor === GeneratorFunction || "GeneratorFunction" === (ctor.displayName || ctor.name)); }, exports.mark = function (genFun) { return Object.setPrototypeOf ? Object.setPrototypeOf(genFun, GeneratorFunctionPrototype) : (genFun.__proto__ = GeneratorFunctionPrototype, define(genFun, toStringTagSymbol, "GeneratorFunction")), genFun.prototype = Object.create(Gp), genFun; }, exports.awrap = function (arg) { return { __await: arg }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, asyncIteratorSymbol, function () { return this; }), exports.AsyncIterator = AsyncIterator, exports.async = function (innerFn, outerFn, self, tryLocsList, PromiseImpl) { void 0 === PromiseImpl && (PromiseImpl = Promise); var iter = new AsyncIterator(wrap(innerFn, outerFn, self, tryLocsList), PromiseImpl); return exports.isGeneratorFunction(outerFn) ? iter : iter.next().then(function (result) { return result.done ? result.value : iter.next(); }); }, defineIteratorMethods(Gp), define(Gp, toStringTagSymbol, "Generator"), define(Gp, iteratorSymbol, function () { return this; }), define(Gp, "toString", function () { return "[object Generator]"; }), exports.keys = function (val) { var object = Object(val), keys = []; for (var key in object) keys.push(key); return keys.reverse(), function next() { for (; keys.length;) { var key = keys.pop(); if (key in object) return next.value = key, next.done = !1, next; } return next.done = !0, next; }; }, exports.values = values, Context.prototype = { constructor: Context, reset: function reset(skipTempReset) { if (this.prev = 0, this.next = 0, this.sent = this._sent = undefined, this.done = !1, this.delegate = null, this.method = "next", this.arg = undefined, this.tryEntries.forEach(resetTryEntry), !skipTempReset) for (var name in this) "t" === name.charAt(0) && hasOwn.call(this, name) && !isNaN(+name.slice(1)) && (this[name] = undefined); }, stop: function stop() { this.done = !0; var rootRecord = this.tryEntries[0].completion; if ("throw" === rootRecord.type) throw rootRecord.arg; return this.rval; }, dispatchException: function dispatchException(exception) { if (this.done) throw exception; var context = this; function handle(loc, caught) { return record.type = "throw", record.arg = exception, context.next = loc, caught && (context.method = "next", context.arg = undefined), !!caught; } for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i], record = entry.completion; if ("root" === entry.tryLoc) return handle("end"); if (entry.tryLoc <= this.prev) { var hasCatch = hasOwn.call(entry, "catchLoc"), hasFinally = hasOwn.call(entry, "finallyLoc"); if (hasCatch && hasFinally) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } else if (hasCatch) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); } else { if (!hasFinally) throw new Error("try statement without catch or finally"); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } } } }, abrupt: function abrupt(type, arg) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc <= this.prev && hasOwn.call(entry, "finallyLoc") && this.prev < entry.finallyLoc) { var finallyEntry = entry; break; } } finallyEntry && ("break" === type || "continue" === type) && finallyEntry.tryLoc <= arg && arg <= finallyEntry.finallyLoc && (finallyEntry = null); var record = finallyEntry ? finallyEntry.completion : {}; return record.type = type, record.arg = arg, finallyEntry ? (this.method = "next", this.next = finallyEntry.finallyLoc, ContinueSentinel) : this.complete(record); }, complete: function complete(record, afterLoc) { if ("throw" === record.type) throw record.arg; return "break" === record.type || "continue" === record.type ? this.next = record.arg : "return" === record.type ? (this.rval = this.arg = record.arg, this.method = "return", this.next = "end") : "normal" === record.type && afterLoc && (this.next = afterLoc), ContinueSentinel; }, finish: function finish(finallyLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.finallyLoc === finallyLoc) return this.complete(entry.completion, entry.afterLoc), resetTryEntry(entry), ContinueSentinel; } }, "catch": function _catch(tryLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc === tryLoc) { var record = entry.completion; if ("throw" === record.type) { var thrown = record.arg; resetTryEntry(entry); } return thrown; } } throw new Error("illegal catch attempt"); }, delegateYield: function delegateYield(iterable, resultName, nextLoc) { return this.delegate = { iterator: values(iterable), resultName: resultName, nextLoc: nextLoc }, "next" === this.method && (this.arg = undefined), ContinueSentinel; } }, exports; }
function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }
function _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err); } _next(undefined); }); }; }
function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }
function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor); } }
function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, "prototype", { writable: false }); return Constructor; }
function _toPropertyKey(arg) { var key = _toPrimitive(arg, "string"); return _typeof(key) === "symbol" ? key : String(key); }
function _toPrimitive(input, hint) { if (_typeof(input) !== "object" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || "default"); if (_typeof(res) !== "object") return res; throw new TypeError("@@toPrimitive must return a primitive value."); } return (hint === "string" ? String : Number)(input); }
var SDK = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js");




var API = function () {
  var secret = undefined;
  var speechConfig = undefined;
  var openaiClient = undefined;
  return /*#__PURE__*/function () {
    function _class() {
      _classCallCheck(this, _class);
      this.speech_key = new _Credential__WEBPACK_IMPORTED_MODULE_1__["default"]("speech_key");
      this.speech_region = new _Credential__WEBPACK_IMPORTED_MODULE_1__["default"]("speech_region");
      this.openai_key = new _Credential__WEBPACK_IMPORTED_MODULE_1__["default"]("openai_key");
    }
    _createClass(_class, [{
      key: "init",
      value: function init() {
        var speech_key = this.speech_key.load(secret);
        var speech_region = this.speech_region.load(secret);
        speechConfig = microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_3__.SpeechConfig.fromSubscription(speech_key, speech_region);
        speechConfig.speechRecognitionLanguage = "ja-JP";
        var openai_key = this.openai_key.load(secret);
        var openaiConfig = new openai__WEBPACK_IMPORTED_MODULE_0__.Configuration({
          apiKey: openai_key
        });
        openaiClient = new openai__WEBPACK_IMPORTED_MODULE_0__.OpenAIApi(openaiConfig);
      }
    }, {
      key: "ready",
      value: function ready() {
        return !!speechConfig && !!openaiClient;
      }
    }, {
      key: "signup",
      value: function signup(speech_key, speech_region, openai_key, passwd) {
        this.speech_key.store(speech_key, passwd);
        this.speech_region.store(speech_region, passwd);
        this.openai_key.store(openai_key, passwd);
        secret = passwd;
        this.init();
      }
    }, {
      key: "logout",
      value: function logout() {
        secret = undefined;
        speechConfig = undefined;
        openaiClient = undefined;
      }
    }, {
      key: "login",
      value: function login(passwd) {
        if (!this.speech_key.login(passwd)) {
          return false;
        }
        if (!this.speech_region.login(passwd)) {
          return false;
        }
        if (!this.openai_key.login(passwd)) {
          return false;
        }
        secret = passwd;
        this.init();
        return true;
      }
    }, {
      key: "loggedin",
      value: function loggedin() {
        if (!secret) {
          return false;
        }
        return this.login(secret);
      }
    }, {
      key: "exists",
      value: function exists() {
        if (!this.speech_key.exists()) {
          return false;
        }
        if (!this.speech_region.exists()) {
          return false;
        }
        if (!this.openai_key.exists()) {
          return false;
        }
        return true;
      }
    }, {
      key: "recognize",
      value: function () {
        var _recognize = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(file) {
          var audioConfig, speechRecognizer;
          return _regeneratorRuntime().wrap(function _callee$(_context) {
            while (1) switch (_context.prev = _context.next) {
              case 0:
                if (this.ready()) {
                  _context.next = 2;
                  break;
                }
                return _context.abrupt("return", null);
              case 2:
                audioConfig = microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_4__.AudioConfig.fromWavFileInput(file);
                speechRecognizer = new microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_5__.SpeechRecognizer(speechConfig, audioConfig);
                return _context.abrupt("return", new Promise(function (resolve, reject) {
                  speechRecognizer.recognizeOnceAsync(function (result) {
                    switch (result.reason) {
                      case SDK.ResultReason.RecognizedSpeech:
                        resolve(result.text);
                        break;
                      case SDK.ResultReason.NoMatch:
                        console.log("NOMATCH: Speech could not be recognized.");
                        reject(result);
                        break;
                      case SDK.ResultReason.Canceled:
                        var cancellation = SDK.CancellationDetails.fromResult(result);
                        console.log("CANCELED: Reason=".concat(cancellation.reason));
                        if (cancellation.reason == SDK.CancellationReason.Error) {
                          console.log("CANCELED: ErrorCode=".concat(cancellation.ErrorCode));
                          console.log("CANCELED: ErrorDetails=".concat(cancellation.errorDetails));
                          console.log("CANCELED: Did you set the speech resource key and region values?");
                        }
                        reject(result);
                        break;
                    }
                    speechRecognizer.close();
                  });
                }));
              case 5:
              case "end":
                return _context.stop();
            }
          }, _callee, this);
        }));
        function recognize(_x) {
          return _recognize.apply(this, arguments);
        }
        return recognize;
      }()
    }, {
      key: "conversation",
      value: function conversation() {
        var context = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : [];
        var model = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "gpt-3.5-turbo";
        if (!this.ready()) {
          return null;
        }
        return new _Conversation__WEBPACK_IMPORTED_MODULE_2__["default"](openaiClient, context, model);
      }
    }, {
      key: "debug",
      value: function debug() {
        if (!this.loggedin()) {
          return null;
        }
        var speech_key = this.speech_key.load(secret);
        var speech_region = this.speech_region.load(secret);
        var openai_key = this.openai_key.load(secret);

        //
        // Commented out for security reason.
        //
        // console.log([speech_key, speech_region, openai_key]);
      }
    }]);
    return _class;
  }();
}();
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (API);
__webpack_async_result__();
} catch(e) { __webpack_async_result__(e); } });

/***/ }),

/***/ "./src/BtnControl.js":
/*!***************************!*\
  !*** ./src/BtnControl.js ***!
  \***************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
function _typeof(obj) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof(obj); }
function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }
function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor); } }
function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, "prototype", { writable: false }); return Constructor; }
function _toPropertyKey(arg) { var key = _toPrimitive(arg, "string"); return _typeof(key) === "symbol" ? key : String(key); }
function _toPrimitive(input, hint) { if (_typeof(input) !== "object" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || "default"); if (_typeof(res) !== "object") return res; throw new TypeError("@@toPrimitive must return a primitive value."); } return (hint === "string" ? String : Number)(input); }
var BtnControl = /*#__PURE__*/function () {
  function BtnControl(button, onDown, onLong, onUp) {
    var _this = this;
    var thTime = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 500;
    _classCallCheck(this, BtnControl);
    this.button = button;
    this.thTime = thTime;
    this.isDown = false;
    this.downTime = 0;
    this.isTouch = false;
    var _onDown = function _onDown(event) {
      event.preventDefault();
      if (_this.isDown) {
        return;
      }
      _this.isDown = true;
      _this.downTime = new Date().getTime();
      onDown();
      setTimeout(function () {
        if (_this.isLongDown()) {
          onLong();
        }
      }, _this.thTime);
    };
    var _onUp = function _onUp(event) {
      event.preventDefault();
      if (!_this.isDown) {
        return;
      }
      _this.isDown = false;
      onUp();
    };
    if (button.ontouchstart === undefined) {
      button.onmousedown = _onDown;
      button.onmouseup = _onUp;
    } else {
      button.ontouchstart = _onDown;
      button.ontouchend = _onUp;
    }
  }
  _createClass(BtnControl, [{
    key: "isShortDown",
    value: function isShortDown() {
      if (!this.isDown) {
        return false;
      }
      var nowTime = new Date().getTime();
      var duration = nowTime - this.downTime;
      return duration < this.thTime;
    }
  }, {
    key: "isLongDown",
    value: function isLongDown() {
      if (!this.isDown) {
        return false;
      }
      var nowTime = new Date().getTime();
      var duration = nowTime - this.downTime;
      return duration >= this.thTime;
    }
  }]);
  return BtnControl;
}();
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (BtnControl);

/***/ }),

/***/ "./src/Credential.js":
/*!***************************!*\
  !*** ./src/Credential.js ***!
  \***************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var crypto_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! crypto-js */ "./node_modules/crypto-js/index.js");
/* harmony import */ var crypto_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(crypto_js__WEBPACK_IMPORTED_MODULE_0__);
function _typeof(obj) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof(obj); }
function _slicedToArray(arr, i) { return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _unsupportedIterableToArray(arr, i) || _nonIterableRest(); }
function _nonIterableRest() { throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); }
function _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === "string") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === "Object" && o.constructor) n = o.constructor.name; if (n === "Map" || n === "Set") return Array.from(o); if (n === "Arguments" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }
function _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) arr2[i] = arr[i]; return arr2; }
function _iterableToArrayLimit(arr, i) { var _i = null == arr ? null : "undefined" != typeof Symbol && arr[Symbol.iterator] || arr["@@iterator"]; if (null != _i) { var _s, _e, _x, _r, _arr = [], _n = !0, _d = !1; try { if (_x = (_i = _i.call(arr)).next, 0 === i) { if (Object(_i) !== _i) return; _n = !1; } else for (; !(_n = (_s = _x.call(_i)).done) && (_arr.push(_s.value), _arr.length !== i); _n = !0); } catch (err) { _d = !0, _e = err; } finally { try { if (!_n && null != _i["return"] && (_r = _i["return"](), Object(_r) !== _r)) return; } finally { if (_d) throw _e; } } return _arr; } }
function _arrayWithHoles(arr) { if (Array.isArray(arr)) return arr; }
function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }
function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor); } }
function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, "prototype", { writable: false }); return Constructor; }
function _toPropertyKey(arg) { var key = _toPrimitive(arg, "string"); return _typeof(key) === "symbol" ? key : String(key); }
function _toPrimitive(input, hint) { if (_typeof(input) !== "object" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || "default"); if (_typeof(res) !== "object") return res; throw new TypeError("@@toPrimitive must return a primitive value."); } return (hint === "string" ? String : Number)(input); }

var Credential = /*#__PURE__*/function () {
  function Credential(key) {
    _classCallCheck(this, Credential);
    this.key = key;
  }
  _createClass(Credential, [{
    key: "store",
    value: function store(value, passwd) {
      var data = [value, passwd];
      var cipher = crypto_js__WEBPACK_IMPORTED_MODULE_0___default().AES.encrypt(JSON.stringify(data), passwd).toString();
      localStorage.setItem(this.key, cipher);
    }
  }, {
    key: "load",
    value: function load(passwd) {
      var cipher = localStorage.getItem(this.key);
      var bytes = crypto_js__WEBPACK_IMPORTED_MODULE_0___default().AES.decrypt(cipher, passwd);
      try {
        var data = JSON.parse(bytes.toString((crypto_js__WEBPACK_IMPORTED_MODULE_0___default().enc).Utf8));
        var _data = _slicedToArray(data, 2),
          value = _data[0],
          expected = _data[1];
        if (passwd == expected) {
          return value;
        } else {
          return null;
        }
      } catch (_unused) {
        return null;
      }
    }
  }, {
    key: "login",
    value: function login(passwd) {
      return !!this.load(passwd);
    }
  }, {
    key: "exists",
    value: function exists() {
      return !!localStorage.getItem(this.key);
    }
  }], [{
    key: "available",
    value: function available() {
      return !(localStorage === undefined);
    }
  }]);
  return Credential;
}();
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Credential);

/***/ }),

/***/ "./src/DB.js":
/*!*******************!*\
  !*** ./src/DB.js ***!
  \*******************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__),
/* harmony export */   wait: () => (/* binding */ wait)
/* harmony export */ });
function _typeof(obj) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof(obj); }
function _regeneratorRuntime() { "use strict"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return exports; }; var exports = {}, Op = Object.prototype, hasOwn = Op.hasOwnProperty, defineProperty = Object.defineProperty || function (obj, key, desc) { obj[key] = desc.value; }, $Symbol = "function" == typeof Symbol ? Symbol : {}, iteratorSymbol = $Symbol.iterator || "@@iterator", asyncIteratorSymbol = $Symbol.asyncIterator || "@@asyncIterator", toStringTagSymbol = $Symbol.toStringTag || "@@toStringTag"; function define(obj, key, value) { return Object.defineProperty(obj, key, { value: value, enumerable: !0, configurable: !0, writable: !0 }), obj[key]; } try { define({}, ""); } catch (err) { define = function define(obj, key, value) { return obj[key] = value; }; } function wrap(innerFn, outerFn, self, tryLocsList) { var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator, generator = Object.create(protoGenerator.prototype), context = new Context(tryLocsList || []); return defineProperty(generator, "_invoke", { value: makeInvokeMethod(innerFn, self, context) }), generator; } function tryCatch(fn, obj, arg) { try { return { type: "normal", arg: fn.call(obj, arg) }; } catch (err) { return { type: "throw", arg: err }; } } exports.wrap = wrap; var ContinueSentinel = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var IteratorPrototype = {}; define(IteratorPrototype, iteratorSymbol, function () { return this; }); var getProto = Object.getPrototypeOf, NativeIteratorPrototype = getProto && getProto(getProto(values([]))); NativeIteratorPrototype && NativeIteratorPrototype !== Op && hasOwn.call(NativeIteratorPrototype, iteratorSymbol) && (IteratorPrototype = NativeIteratorPrototype); var Gp = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(IteratorPrototype); function defineIteratorMethods(prototype) { ["next", "throw", "return"].forEach(function (method) { define(prototype, method, function (arg) { return this._invoke(method, arg); }); }); } function AsyncIterator(generator, PromiseImpl) { function invoke(method, arg, resolve, reject) { var record = tryCatch(generator[method], generator, arg); if ("throw" !== record.type) { var result = record.arg, value = result.value; return value && "object" == _typeof(value) && hasOwn.call(value, "__await") ? PromiseImpl.resolve(value.__await).then(function (value) { invoke("next", value, resolve, reject); }, function (err) { invoke("throw", err, resolve, reject); }) : PromiseImpl.resolve(value).then(function (unwrapped) { result.value = unwrapped, resolve(result); }, function (error) { return invoke("throw", error, resolve, reject); }); } reject(record.arg); } var previousPromise; defineProperty(this, "_invoke", { value: function value(method, arg) { function callInvokeWithMethodAndArg() { return new PromiseImpl(function (resolve, reject) { invoke(method, arg, resolve, reject); }); } return previousPromise = previousPromise ? previousPromise.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); } }); } function makeInvokeMethod(innerFn, self, context) { var state = "suspendedStart"; return function (method, arg) { if ("executing" === state) throw new Error("Generator is already running"); if ("completed" === state) { if ("throw" === method) throw arg; return doneResult(); } for (context.method = method, context.arg = arg;;) { var delegate = context.delegate; if (delegate) { var delegateResult = maybeInvokeDelegate(delegate, context); if (delegateResult) { if (delegateResult === ContinueSentinel) continue; return delegateResult; } } if ("next" === context.method) context.sent = context._sent = context.arg;else if ("throw" === context.method) { if ("suspendedStart" === state) throw state = "completed", context.arg; context.dispatchException(context.arg); } else "return" === context.method && context.abrupt("return", context.arg); state = "executing"; var record = tryCatch(innerFn, self, context); if ("normal" === record.type) { if (state = context.done ? "completed" : "suspendedYield", record.arg === ContinueSentinel) continue; return { value: record.arg, done: context.done }; } "throw" === record.type && (state = "completed", context.method = "throw", context.arg = record.arg); } }; } function maybeInvokeDelegate(delegate, context) { var methodName = context.method, method = delegate.iterator[methodName]; if (undefined === method) return context.delegate = null, "throw" === methodName && delegate.iterator["return"] && (context.method = "return", context.arg = undefined, maybeInvokeDelegate(delegate, context), "throw" === context.method) || "return" !== methodName && (context.method = "throw", context.arg = new TypeError("The iterator does not provide a '" + methodName + "' method")), ContinueSentinel; var record = tryCatch(method, delegate.iterator, context.arg); if ("throw" === record.type) return context.method = "throw", context.arg = record.arg, context.delegate = null, ContinueSentinel; var info = record.arg; return info ? info.done ? (context[delegate.resultName] = info.value, context.next = delegate.nextLoc, "return" !== context.method && (context.method = "next", context.arg = undefined), context.delegate = null, ContinueSentinel) : info : (context.method = "throw", context.arg = new TypeError("iterator result is not an object"), context.delegate = null, ContinueSentinel); } function pushTryEntry(locs) { var entry = { tryLoc: locs[0] }; 1 in locs && (entry.catchLoc = locs[1]), 2 in locs && (entry.finallyLoc = locs[2], entry.afterLoc = locs[3]), this.tryEntries.push(entry); } function resetTryEntry(entry) { var record = entry.completion || {}; record.type = "normal", delete record.arg, entry.completion = record; } function Context(tryLocsList) { this.tryEntries = [{ tryLoc: "root" }], tryLocsList.forEach(pushTryEntry, this), this.reset(!0); } function values(iterable) { if (iterable) { var iteratorMethod = iterable[iteratorSymbol]; if (iteratorMethod) return iteratorMethod.call(iterable); if ("function" == typeof iterable.next) return iterable; if (!isNaN(iterable.length)) { var i = -1, next = function next() { for (; ++i < iterable.length;) if (hasOwn.call(iterable, i)) return next.value = iterable[i], next.done = !1, next; return next.value = undefined, next.done = !0, next; }; return next.next = next; } } return { next: doneResult }; } function doneResult() { return { value: undefined, done: !0 }; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, defineProperty(Gp, "constructor", { value: GeneratorFunctionPrototype, configurable: !0 }), defineProperty(GeneratorFunctionPrototype, "constructor", { value: GeneratorFunction, configurable: !0 }), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, toStringTagSymbol, "GeneratorFunction"), exports.isGeneratorFunction = function (genFun) { var ctor = "function" == typeof genFun && genFun.constructor; return !!ctor && (ctor === GeneratorFunction || "GeneratorFunction" === (ctor.displayName || ctor.name)); }, exports.mark = function (genFun) { return Object.setPrototypeOf ? Object.setPrototypeOf(genFun, GeneratorFunctionPrototype) : (genFun.__proto__ = GeneratorFunctionPrototype, define(genFun, toStringTagSymbol, "GeneratorFunction")), genFun.prototype = Object.create(Gp), genFun; }, exports.awrap = function (arg) { return { __await: arg }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, asyncIteratorSymbol, function () { return this; }), exports.AsyncIterator = AsyncIterator, exports.async = function (innerFn, outerFn, self, tryLocsList, PromiseImpl) { void 0 === PromiseImpl && (PromiseImpl = Promise); var iter = new AsyncIterator(wrap(innerFn, outerFn, self, tryLocsList), PromiseImpl); return exports.isGeneratorFunction(outerFn) ? iter : iter.next().then(function (result) { return result.done ? result.value : iter.next(); }); }, defineIteratorMethods(Gp), define(Gp, toStringTagSymbol, "Generator"), define(Gp, iteratorSymbol, function () { return this; }), define(Gp, "toString", function () { return "[object Generator]"; }), exports.keys = function (val) { var object = Object(val), keys = []; for (var key in object) keys.push(key); return keys.reverse(), function next() { for (; keys.length;) { var key = keys.pop(); if (key in object) return next.value = key, next.done = !1, next; } return next.done = !0, next; }; }, exports.values = values, Context.prototype = { constructor: Context, reset: function reset(skipTempReset) { if (this.prev = 0, this.next = 0, this.sent = this._sent = undefined, this.done = !1, this.delegate = null, this.method = "next", this.arg = undefined, this.tryEntries.forEach(resetTryEntry), !skipTempReset) for (var name in this) "t" === name.charAt(0) && hasOwn.call(this, name) && !isNaN(+name.slice(1)) && (this[name] = undefined); }, stop: function stop() { this.done = !0; var rootRecord = this.tryEntries[0].completion; if ("throw" === rootRecord.type) throw rootRecord.arg; return this.rval; }, dispatchException: function dispatchException(exception) { if (this.done) throw exception; var context = this; function handle(loc, caught) { return record.type = "throw", record.arg = exception, context.next = loc, caught && (context.method = "next", context.arg = undefined), !!caught; } for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i], record = entry.completion; if ("root" === entry.tryLoc) return handle("end"); if (entry.tryLoc <= this.prev) { var hasCatch = hasOwn.call(entry, "catchLoc"), hasFinally = hasOwn.call(entry, "finallyLoc"); if (hasCatch && hasFinally) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } else if (hasCatch) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); } else { if (!hasFinally) throw new Error("try statement without catch or finally"); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } } } }, abrupt: function abrupt(type, arg) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc <= this.prev && hasOwn.call(entry, "finallyLoc") && this.prev < entry.finallyLoc) { var finallyEntry = entry; break; } } finallyEntry && ("break" === type || "continue" === type) && finallyEntry.tryLoc <= arg && arg <= finallyEntry.finallyLoc && (finallyEntry = null); var record = finallyEntry ? finallyEntry.completion : {}; return record.type = type, record.arg = arg, finallyEntry ? (this.method = "next", this.next = finallyEntry.finallyLoc, ContinueSentinel) : this.complete(record); }, complete: function complete(record, afterLoc) { if ("throw" === record.type) throw record.arg; return "break" === record.type || "continue" === record.type ? this.next = record.arg : "return" === record.type ? (this.rval = this.arg = record.arg, this.method = "return", this.next = "end") : "normal" === record.type && afterLoc && (this.next = afterLoc), ContinueSentinel; }, finish: function finish(finallyLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.finallyLoc === finallyLoc) return this.complete(entry.completion, entry.afterLoc), resetTryEntry(entry), ContinueSentinel; } }, "catch": function _catch(tryLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc === tryLoc) { var record = entry.completion; if ("throw" === record.type) { var thrown = record.arg; resetTryEntry(entry); } return thrown; } } throw new Error("illegal catch attempt"); }, delegateYield: function delegateYield(iterable, resultName, nextLoc) { return this.delegate = { iterator: values(iterable), resultName: resultName, nextLoc: nextLoc }, "next" === this.method && (this.arg = undefined), ContinueSentinel; } }, exports; }
function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }
function _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err); } _next(undefined); }); }; }
function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }
function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor); } }
function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, "prototype", { writable: false }); return Constructor; }
function _toPropertyKey(arg) { var key = _toPrimitive(arg, "string"); return _typeof(key) === "symbol" ? key : String(key); }
function _toPrimitive(input, hint) { if (_typeof(input) !== "object" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || "default"); if (_typeof(res) !== "object") return res; throw new TypeError("@@toPrimitive must return a primitive value."); } return (hint === "string" ? String : Number)(input); }
function _inherits(subClass, superClass) { if (typeof superClass !== "function" && superClass !== null) { throw new TypeError("Super expression must either be null or a function"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); Object.defineProperty(subClass, "prototype", { writable: false }); if (superClass) _setPrototypeOf(subClass, superClass); }
function _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }
function _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === "object" || typeof call === "function")) { return call; } else if (call !== void 0) { throw new TypeError("Derived constructors may only return object or undefined"); } return _assertThisInitialized(self); }
function _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError("this hasn't been initialised - super() hasn't been called"); } return self; }
function _wrapNativeSuper(Class) { var _cache = typeof Map === "function" ? new Map() : undefined; _wrapNativeSuper = function _wrapNativeSuper(Class) { if (Class === null || !_isNativeFunction(Class)) return Class; if (typeof Class !== "function") { throw new TypeError("Super expression must either be null or a function"); } if (typeof _cache !== "undefined") { if (_cache.has(Class)) return _cache.get(Class); _cache.set(Class, Wrapper); } function Wrapper() { return _construct(Class, arguments, _getPrototypeOf(this).constructor); } Wrapper.prototype = Object.create(Class.prototype, { constructor: { value: Wrapper, enumerable: false, writable: true, configurable: true } }); return _setPrototypeOf(Wrapper, Class); }; return _wrapNativeSuper(Class); }
function _construct(Parent, args, Class) { if (_isNativeReflectConstruct()) { _construct = Reflect.construct.bind(); } else { _construct = function _construct(Parent, args, Class) { var a = [null]; a.push.apply(a, args); var Constructor = Function.bind.apply(Parent, a); var instance = new Constructor(); if (Class) _setPrototypeOf(instance, Class.prototype); return instance; }; } return _construct.apply(null, arguments); }
function _isNativeReflectConstruct() { if (typeof Reflect === "undefined" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === "function") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }
function _isNativeFunction(fn) { return Function.toString.call(fn).indexOf("[native code]") !== -1; }
function _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf ? Object.setPrototypeOf.bind() : function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }
function _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf.bind() : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }
function wait(request) {
  return new Promise(function (resolve, reject) {
    request.onsuccess = function (event) {
      return resolve(event.target.transaction);
    };
    request.onerror = reject;
  });
}
var DB = /*#__PURE__*/function (_EventTarget) {
  _inherits(DB, _EventTarget);
  var _super = _createSuper(DB);
  function DB(name, version) {
    var _this;
    _classCallCheck(this, DB);
    _this = _super.call(this);
    _this.name = name;
    _this.version = version;
    _this.db = null;
    return _this;
  }
  _createClass(DB, [{
    key: "ready",
    value: function ready() {
      return !(this.db === null);
    }
  }, {
    key: "destroy",
    value: function destroy() {
      if (!DB.available()) {
        var msg = "IndexedDB is not available";
        throw new Error(msg);
      }
      window.indexedDB.deleteDatabase(this.name);
    }
  }, {
    key: "connect",
    value: function () {
      var _connect = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(migration) {
        var _this2 = this;
        return _regeneratorRuntime().wrap(function _callee$(_context) {
          while (1) switch (_context.prev = _context.next) {
            case 0:
              return _context.abrupt("return", new Promise(function (resolve, reject) {
                if (!DB.available()) {
                  var msg = "IndexedDB is not available";
                  reject(new Error(msg));
                }
                var request = window.indexedDB.open(_this2.name, _this2.version);
                request.onupgradeneeded = function (event) {
                  var db = event.target.result;
                  var transaction = event.target.transaction;
                  migration.migrate(event.oldVersion, event.newVersion, db, transaction);
                };
                request.onsuccess = function (event) {
                  var db = event.target.result;
                  _this2.db = db;
                  resolve(db);
                };
                request.onerror = reject;
              }));
            case 1:
            case "end":
              return _context.stop();
          }
        }, _callee);
      }));
      function connect(_x) {
        return _connect.apply(this, arguments);
      }
      return connect;
    }()
  }, {
    key: "add",
    value: function () {
      var _add = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(store, value) {
        var _this3 = this;
        return _regeneratorRuntime().wrap(function _callee2$(_context2) {
          while (1) switch (_context2.prev = _context2.next) {
            case 0:
              return _context2.abrupt("return", new Promise(function (resolve, reject) {
                var transaction = _this3.db.transaction(store, "readwrite");
                var request = transaction.objectStore(store).add(value);
                request.onsuccess = function (event) {
                  event.stopPropagation();
                  resolve(request.result);
                };
                request.onerror = function (event) {
                  event.stopPropagation();
                  reject(event);
                };
              }));
            case 1:
            case "end":
              return _context2.stop();
          }
        }, _callee2);
      }));
      function add(_x2, _x3) {
        return _add.apply(this, arguments);
      }
      return add;
    }()
  }, {
    key: "get",
    value: function () {
      var _get = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3(store, key) {
        var _this4 = this;
        return _regeneratorRuntime().wrap(function _callee3$(_context3) {
          while (1) switch (_context3.prev = _context3.next) {
            case 0:
              return _context3.abrupt("return", new Promise(function (resolve, reject) {
                var transaction = _this4.db.transaction(store, "readwrite");
                var request = transaction.objectStore(store).get(key);
                request.onsuccess = function (event) {
                  event.stopPropagation();
                  resolve(request.result);
                };
                request.onerror = function (event) {
                  event.stopPropagation();
                  reject(event);
                };
              }));
            case 1:
            case "end":
              return _context3.stop();
          }
        }, _callee3);
      }));
      function get(_x4, _x5) {
        return _get.apply(this, arguments);
      }
      return get;
    }()
  }, {
    key: "getAll",
    value: function () {
      var _getAll = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee4(store) {
        var _this5 = this;
        return _regeneratorRuntime().wrap(function _callee4$(_context4) {
          while (1) switch (_context4.prev = _context4.next) {
            case 0:
              return _context4.abrupt("return", new Promise(function (resolve, reject) {
                var transaction = _this5.db.transaction(store, "readwrite");
                var request = transaction.objectStore(store).getAll();
                request.onsuccess = function (event) {
                  event.stopPropagation();
                  resolve(request.result);
                };
                request.onerror = function (event) {
                  event.stopPropagation();
                  reject(event);
                };
              }));
            case 1:
            case "end":
              return _context4.stop();
          }
        }, _callee4);
      }));
      function getAll(_x6) {
        return _getAll.apply(this, arguments);
      }
      return getAll;
    }()
  }, {
    key: "delete",
    value: function () {
      var _delete2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee5(store, key) {
        var _this6 = this;
        return _regeneratorRuntime().wrap(function _callee5$(_context5) {
          while (1) switch (_context5.prev = _context5.next) {
            case 0:
              return _context5.abrupt("return", new Promise(function (resolve, reject) {
                var transaction = _this6.db.transaction(store, "readwrite");
                var request = transaction.objectStore(store)["delete"](key);
                request.onsuccess = function (event) {
                  event.stopPropagation();
                  resolve(event);
                };
                request.onerror = function (event) {
                  event.stopPropagation();
                  reject(event);
                };
              }));
            case 1:
            case "end":
              return _context5.stop();
          }
        }, _callee5);
      }));
      function _delete(_x7, _x8) {
        return _delete2.apply(this, arguments);
      }
      return _delete;
    }()
  }], [{
    key: "available",
    value: function available() {
      return !(window.indexedDB === undefined);
    }
  }]);
  return DB;
}( /*#__PURE__*/_wrapNativeSuper(EventTarget));
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (DB);

/***/ }),

/***/ "./src/Migration.js":
/*!**************************!*\
  !*** ./src/Migration.js ***!
  \**************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
function _regeneratorRuntime() { "use strict"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return exports; }; var exports = {}, Op = Object.prototype, hasOwn = Op.hasOwnProperty, defineProperty = Object.defineProperty || function (obj, key, desc) { obj[key] = desc.value; }, $Symbol = "function" == typeof Symbol ? Symbol : {}, iteratorSymbol = $Symbol.iterator || "@@iterator", asyncIteratorSymbol = $Symbol.asyncIterator || "@@asyncIterator", toStringTagSymbol = $Symbol.toStringTag || "@@toStringTag"; function define(obj, key, value) { return Object.defineProperty(obj, key, { value: value, enumerable: !0, configurable: !0, writable: !0 }), obj[key]; } try { define({}, ""); } catch (err) { define = function define(obj, key, value) { return obj[key] = value; }; } function wrap(innerFn, outerFn, self, tryLocsList) { var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator, generator = Object.create(protoGenerator.prototype), context = new Context(tryLocsList || []); return defineProperty(generator, "_invoke", { value: makeInvokeMethod(innerFn, self, context) }), generator; } function tryCatch(fn, obj, arg) { try { return { type: "normal", arg: fn.call(obj, arg) }; } catch (err) { return { type: "throw", arg: err }; } } exports.wrap = wrap; var ContinueSentinel = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var IteratorPrototype = {}; define(IteratorPrototype, iteratorSymbol, function () { return this; }); var getProto = Object.getPrototypeOf, NativeIteratorPrototype = getProto && getProto(getProto(values([]))); NativeIteratorPrototype && NativeIteratorPrototype !== Op && hasOwn.call(NativeIteratorPrototype, iteratorSymbol) && (IteratorPrototype = NativeIteratorPrototype); var Gp = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(IteratorPrototype); function defineIteratorMethods(prototype) { ["next", "throw", "return"].forEach(function (method) { define(prototype, method, function (arg) { return this._invoke(method, arg); }); }); } function AsyncIterator(generator, PromiseImpl) { function invoke(method, arg, resolve, reject) { var record = tryCatch(generator[method], generator, arg); if ("throw" !== record.type) { var result = record.arg, value = result.value; return value && "object" == _typeof(value) && hasOwn.call(value, "__await") ? PromiseImpl.resolve(value.__await).then(function (value) { invoke("next", value, resolve, reject); }, function (err) { invoke("throw", err, resolve, reject); }) : PromiseImpl.resolve(value).then(function (unwrapped) { result.value = unwrapped, resolve(result); }, function (error) { return invoke("throw", error, resolve, reject); }); } reject(record.arg); } var previousPromise; defineProperty(this, "_invoke", { value: function value(method, arg) { function callInvokeWithMethodAndArg() { return new PromiseImpl(function (resolve, reject) { invoke(method, arg, resolve, reject); }); } return previousPromise = previousPromise ? previousPromise.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); } }); } function makeInvokeMethod(innerFn, self, context) { var state = "suspendedStart"; return function (method, arg) { if ("executing" === state) throw new Error("Generator is already running"); if ("completed" === state) { if ("throw" === method) throw arg; return doneResult(); } for (context.method = method, context.arg = arg;;) { var delegate = context.delegate; if (delegate) { var delegateResult = maybeInvokeDelegate(delegate, context); if (delegateResult) { if (delegateResult === ContinueSentinel) continue; return delegateResult; } } if ("next" === context.method) context.sent = context._sent = context.arg;else if ("throw" === context.method) { if ("suspendedStart" === state) throw state = "completed", context.arg; context.dispatchException(context.arg); } else "return" === context.method && context.abrupt("return", context.arg); state = "executing"; var record = tryCatch(innerFn, self, context); if ("normal" === record.type) { if (state = context.done ? "completed" : "suspendedYield", record.arg === ContinueSentinel) continue; return { value: record.arg, done: context.done }; } "throw" === record.type && (state = "completed", context.method = "throw", context.arg = record.arg); } }; } function maybeInvokeDelegate(delegate, context) { var methodName = context.method, method = delegate.iterator[methodName]; if (undefined === method) return context.delegate = null, "throw" === methodName && delegate.iterator["return"] && (context.method = "return", context.arg = undefined, maybeInvokeDelegate(delegate, context), "throw" === context.method) || "return" !== methodName && (context.method = "throw", context.arg = new TypeError("The iterator does not provide a '" + methodName + "' method")), ContinueSentinel; var record = tryCatch(method, delegate.iterator, context.arg); if ("throw" === record.type) return context.method = "throw", context.arg = record.arg, context.delegate = null, ContinueSentinel; var info = record.arg; return info ? info.done ? (context[delegate.resultName] = info.value, context.next = delegate.nextLoc, "return" !== context.method && (context.method = "next", context.arg = undefined), context.delegate = null, ContinueSentinel) : info : (context.method = "throw", context.arg = new TypeError("iterator result is not an object"), context.delegate = null, ContinueSentinel); } function pushTryEntry(locs) { var entry = { tryLoc: locs[0] }; 1 in locs && (entry.catchLoc = locs[1]), 2 in locs && (entry.finallyLoc = locs[2], entry.afterLoc = locs[3]), this.tryEntries.push(entry); } function resetTryEntry(entry) { var record = entry.completion || {}; record.type = "normal", delete record.arg, entry.completion = record; } function Context(tryLocsList) { this.tryEntries = [{ tryLoc: "root" }], tryLocsList.forEach(pushTryEntry, this), this.reset(!0); } function values(iterable) { if (iterable) { var iteratorMethod = iterable[iteratorSymbol]; if (iteratorMethod) return iteratorMethod.call(iterable); if ("function" == typeof iterable.next) return iterable; if (!isNaN(iterable.length)) { var i = -1, next = function next() { for (; ++i < iterable.length;) if (hasOwn.call(iterable, i)) return next.value = iterable[i], next.done = !1, next; return next.value = undefined, next.done = !0, next; }; return next.next = next; } } return { next: doneResult }; } function doneResult() { return { value: undefined, done: !0 }; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, defineProperty(Gp, "constructor", { value: GeneratorFunctionPrototype, configurable: !0 }), defineProperty(GeneratorFunctionPrototype, "constructor", { value: GeneratorFunction, configurable: !0 }), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, toStringTagSymbol, "GeneratorFunction"), exports.isGeneratorFunction = function (genFun) { var ctor = "function" == typeof genFun && genFun.constructor; return !!ctor && (ctor === GeneratorFunction || "GeneratorFunction" === (ctor.displayName || ctor.name)); }, exports.mark = function (genFun) { return Object.setPrototypeOf ? Object.setPrototypeOf(genFun, GeneratorFunctionPrototype) : (genFun.__proto__ = GeneratorFunctionPrototype, define(genFun, toStringTagSymbol, "GeneratorFunction")), genFun.prototype = Object.create(Gp), genFun; }, exports.awrap = function (arg) { return { __await: arg }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, asyncIteratorSymbol, function () { return this; }), exports.AsyncIterator = AsyncIterator, exports.async = function (innerFn, outerFn, self, tryLocsList, PromiseImpl) { void 0 === PromiseImpl && (PromiseImpl = Promise); var iter = new AsyncIterator(wrap(innerFn, outerFn, self, tryLocsList), PromiseImpl); return exports.isGeneratorFunction(outerFn) ? iter : iter.next().then(function (result) { return result.done ? result.value : iter.next(); }); }, defineIteratorMethods(Gp), define(Gp, toStringTagSymbol, "Generator"), define(Gp, iteratorSymbol, function () { return this; }), define(Gp, "toString", function () { return "[object Generator]"; }), exports.keys = function (val) { var object = Object(val), keys = []; for (var key in object) keys.push(key); return keys.reverse(), function next() { for (; keys.length;) { var key = keys.pop(); if (key in object) return next.value = key, next.done = !1, next; } return next.done = !0, next; }; }, exports.values = values, Context.prototype = { constructor: Context, reset: function reset(skipTempReset) { if (this.prev = 0, this.next = 0, this.sent = this._sent = undefined, this.done = !1, this.delegate = null, this.method = "next", this.arg = undefined, this.tryEntries.forEach(resetTryEntry), !skipTempReset) for (var name in this) "t" === name.charAt(0) && hasOwn.call(this, name) && !isNaN(+name.slice(1)) && (this[name] = undefined); }, stop: function stop() { this.done = !0; var rootRecord = this.tryEntries[0].completion; if ("throw" === rootRecord.type) throw rootRecord.arg; return this.rval; }, dispatchException: function dispatchException(exception) { if (this.done) throw exception; var context = this; function handle(loc, caught) { return record.type = "throw", record.arg = exception, context.next = loc, caught && (context.method = "next", context.arg = undefined), !!caught; } for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i], record = entry.completion; if ("root" === entry.tryLoc) return handle("end"); if (entry.tryLoc <= this.prev) { var hasCatch = hasOwn.call(entry, "catchLoc"), hasFinally = hasOwn.call(entry, "finallyLoc"); if (hasCatch && hasFinally) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } else if (hasCatch) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); } else { if (!hasFinally) throw new Error("try statement without catch or finally"); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } } } }, abrupt: function abrupt(type, arg) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc <= this.prev && hasOwn.call(entry, "finallyLoc") && this.prev < entry.finallyLoc) { var finallyEntry = entry; break; } } finallyEntry && ("break" === type || "continue" === type) && finallyEntry.tryLoc <= arg && arg <= finallyEntry.finallyLoc && (finallyEntry = null); var record = finallyEntry ? finallyEntry.completion : {}; return record.type = type, record.arg = arg, finallyEntry ? (this.method = "next", this.next = finallyEntry.finallyLoc, ContinueSentinel) : this.complete(record); }, complete: function complete(record, afterLoc) { if ("throw" === record.type) throw record.arg; return "break" === record.type || "continue" === record.type ? this.next = record.arg : "return" === record.type ? (this.rval = this.arg = record.arg, this.method = "return", this.next = "end") : "normal" === record.type && afterLoc && (this.next = afterLoc), ContinueSentinel; }, finish: function finish(finallyLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.finallyLoc === finallyLoc) return this.complete(entry.completion, entry.afterLoc), resetTryEntry(entry), ContinueSentinel; } }, "catch": function _catch(tryLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc === tryLoc) { var record = entry.completion; if ("throw" === record.type) { var thrown = record.arg; resetTryEntry(entry); } return thrown; } } throw new Error("illegal catch attempt"); }, delegateYield: function delegateYield(iterable, resultName, nextLoc) { return this.delegate = { iterator: values(iterable), resultName: resultName, nextLoc: nextLoc }, "next" === this.method && (this.arg = undefined), ContinueSentinel; } }, exports; }
function _createForOfIteratorHelper(o, allowArrayLike) { var it = typeof Symbol !== "undefined" && o[Symbol.iterator] || o["@@iterator"]; if (!it) { if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === "number") { if (it) o = it; var i = 0; var F = function F() {}; return { s: F, n: function n() { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }, e: function e(_e) { throw _e; }, f: F }; } throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); } var normalCompletion = true, didErr = false, err; return { s: function s() { it = it.call(o); }, n: function n() { var step = it.next(); normalCompletion = step.done; return step; }, e: function e(_e2) { didErr = true; err = _e2; }, f: function f() { try { if (!normalCompletion && it["return"] != null) it["return"](); } finally { if (didErr) throw err; } } }; }
function _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === "string") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === "Object" && o.constructor) n = o.constructor.name; if (n === "Map" || n === "Set") return Array.from(o); if (n === "Arguments" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }
function _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) arr2[i] = arr[i]; return arr2; }
function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }
function _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err); } _next(undefined); }); }; }
function _typeof(obj) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof(obj); }
function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }
function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor); } }
function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, "prototype", { writable: false }); return Constructor; }
function _toPropertyKey(arg) { var key = _toPrimitive(arg, "string"); return _typeof(key) === "symbol" ? key : String(key); }
function _toPrimitive(input, hint) { if (_typeof(input) !== "object" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || "default"); if (_typeof(res) !== "object") return res; throw new TypeError("@@toPrimitive must return a primitive value."); } return (hint === "string" ? String : Number)(input); }
var Graph = /*#__PURE__*/function () {
  function Graph() {
    _classCallCheck(this, Graph);
    this.map = {};
  }
  _createClass(Graph, [{
    key: "add",
    value: function add(before, after, value) {
      this.map[before] = this.map[before] || {};
      this.map[before][after] = value;
    }
  }, {
    key: "trace",
    value: function trace(before, after) {
      var hs = [{
        ps: [before],
        vs: []
      }];
      while (hs.length > 0) {
        var _hs$shift = hs.shift(),
          ps = _hs$shift.ps,
          vs = _hs$shift.vs;
        var p = ps.slice(-1)[0];
        for (var n in this.map[p]) {
          var v = this.map[p][n];
          if (n == after) {
            return vs.concat([v]);
          }
          if (ps.includes(n)) {
            continue;
          }
          hs.push({
            ps: ps.concat([n]),
            vs: vs.concat([v])
          });
        }
      }
      return null;
    }
  }]);
  return Graph;
}();
var Migration = /*#__PURE__*/function () {
  function Migration() {
    _classCallCheck(this, Migration);
    this.updates = new Graph();
  }
  _createClass(Migration, [{
    key: "add",
    value: function add(before, after, update) {
      var value = function value(db, transaction) {
        console.log("Migrating from ".concat(before, " to ").concat(after, "."));
        return update(db, transaction);
      };
      this.updates.add(before, after, value);
    }
  }, {
    key: "migrate",
    value: function () {
      var _migrate = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(before, after, db, transaction) {
        var trace, _iterator, _step, update;
        return _regeneratorRuntime().wrap(function _callee$(_context) {
          while (1) switch (_context.prev = _context.next) {
            case 0:
              trace = this.updates.trace(before, after);
              if (!(trace === null)) {
                _context.next = 3;
                break;
              }
              throw new Error("Migration path is not found: from ".concat(before, " to ").concat(after, "."));
            case 3:
              _iterator = _createForOfIteratorHelper(trace);
              _context.prev = 4;
              _iterator.s();
            case 6:
              if ((_step = _iterator.n()).done) {
                _context.next = 13;
                break;
              }
              update = _step.value;
              _context.next = 10;
              return update(db, transaction);
            case 10:
              transaction = _context.sent;
            case 11:
              _context.next = 6;
              break;
            case 13:
              _context.next = 18;
              break;
            case 15:
              _context.prev = 15;
              _context.t0 = _context["catch"](4);
              _iterator.e(_context.t0);
            case 18:
              _context.prev = 18;
              _iterator.f();
              return _context.finish(18);
            case 21:
              return _context.abrupt("return", transaction);
            case 22:
            case "end":
              return _context.stop();
          }
        }, _callee, this, [[4, 15, 18, 21]]);
      }));
      function migrate(_x, _x2, _x3, _x4) {
        return _migrate.apply(this, arguments);
      }
      return migrate;
    }()
  }]);
  return Migration;
}();
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Migration);

/***/ }),

/***/ "./src/MockStream.js":
/*!***************************!*\
  !*** ./src/MockStream.js ***!
  \***************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
function _typeof(obj) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof(obj); }
function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor); } }
function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, "prototype", { writable: false }); return Constructor; }
function _toPropertyKey(arg) { var key = _toPrimitive(arg, "string"); return _typeof(key) === "symbol" ? key : String(key); }
function _toPrimitive(input, hint) { if (_typeof(input) !== "object" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || "default"); if (_typeof(res) !== "object") return res; throw new TypeError("@@toPrimitive must return a primitive value."); } return (hint === "string" ? String : Number)(input); }
function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }
var MockStream = /*#__PURE__*/_createClass(function MockStream(audioElement) {
  _classCallCheck(this, MockStream);
  var audioContext = new window.AudioContext();
  var track = audioContext.createMediaElementSource(audioElement);
  var dest = audioContext.createMediaStreamDestination();
  track.connect(audioContext.destination);
  track.connect(dest);
  this.stream = dest.stream;
});
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (MockStream);

/***/ }),

/***/ "./src/Record.js":
/*!***********************!*\
  !*** ./src/Record.js ***!
  \***********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _DB_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./DB.js */ "./src/DB.js");
/* harmony import */ var _Migration_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Migration.js */ "./src/Migration.js");
function _typeof(obj) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof(obj); }
function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }
function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor); } }
function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, "prototype", { writable: false }); return Constructor; }
function _defineProperty(obj, key, value) { key = _toPropertyKey(key); if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }
function _toPropertyKey(arg) { var key = _toPrimitive(arg, "string"); return _typeof(key) === "symbol" ? key : String(key); }
function _toPrimitive(input, hint) { if (_typeof(input) !== "object" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || "default"); if (_typeof(res) !== "object") return res; throw new TypeError("@@toPrimitive must return a primitive value."); } return (hint === "string" ? String : Number)(input); }
function _createForOfIteratorHelper(o, allowArrayLike) { var it = typeof Symbol !== "undefined" && o[Symbol.iterator] || o["@@iterator"]; if (!it) { if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === "number") { if (it) o = it; var i = 0; var F = function F() {}; return { s: F, n: function n() { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }, e: function e(_e) { throw _e; }, f: F }; } throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); } var normalCompletion = true, didErr = false, err; return { s: function s() { it = it.call(o); }, n: function n() { var step = it.next(); normalCompletion = step.done; return step; }, e: function e(_e2) { didErr = true; err = _e2; }, f: function f() { try { if (!normalCompletion && it["return"] != null) it["return"](); } finally { if (didErr) throw err; } } }; }
function _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === "string") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === "Object" && o.constructor) n = o.constructor.name; if (n === "Map" || n === "Set") return Array.from(o); if (n === "Arguments" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }
function _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) arr2[i] = arr[i]; return arr2; }
function _regeneratorRuntime() { "use strict"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return exports; }; var exports = {}, Op = Object.prototype, hasOwn = Op.hasOwnProperty, defineProperty = Object.defineProperty || function (obj, key, desc) { obj[key] = desc.value; }, $Symbol = "function" == typeof Symbol ? Symbol : {}, iteratorSymbol = $Symbol.iterator || "@@iterator", asyncIteratorSymbol = $Symbol.asyncIterator || "@@asyncIterator", toStringTagSymbol = $Symbol.toStringTag || "@@toStringTag"; function define(obj, key, value) { return Object.defineProperty(obj, key, { value: value, enumerable: !0, configurable: !0, writable: !0 }), obj[key]; } try { define({}, ""); } catch (err) { define = function define(obj, key, value) { return obj[key] = value; }; } function wrap(innerFn, outerFn, self, tryLocsList) { var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator, generator = Object.create(protoGenerator.prototype), context = new Context(tryLocsList || []); return defineProperty(generator, "_invoke", { value: makeInvokeMethod(innerFn, self, context) }), generator; } function tryCatch(fn, obj, arg) { try { return { type: "normal", arg: fn.call(obj, arg) }; } catch (err) { return { type: "throw", arg: err }; } } exports.wrap = wrap; var ContinueSentinel = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var IteratorPrototype = {}; define(IteratorPrototype, iteratorSymbol, function () { return this; }); var getProto = Object.getPrototypeOf, NativeIteratorPrototype = getProto && getProto(getProto(values([]))); NativeIteratorPrototype && NativeIteratorPrototype !== Op && hasOwn.call(NativeIteratorPrototype, iteratorSymbol) && (IteratorPrototype = NativeIteratorPrototype); var Gp = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(IteratorPrototype); function defineIteratorMethods(prototype) { ["next", "throw", "return"].forEach(function (method) { define(prototype, method, function (arg) { return this._invoke(method, arg); }); }); } function AsyncIterator(generator, PromiseImpl) { function invoke(method, arg, resolve, reject) { var record = tryCatch(generator[method], generator, arg); if ("throw" !== record.type) { var result = record.arg, value = result.value; return value && "object" == _typeof(value) && hasOwn.call(value, "__await") ? PromiseImpl.resolve(value.__await).then(function (value) { invoke("next", value, resolve, reject); }, function (err) { invoke("throw", err, resolve, reject); }) : PromiseImpl.resolve(value).then(function (unwrapped) { result.value = unwrapped, resolve(result); }, function (error) { return invoke("throw", error, resolve, reject); }); } reject(record.arg); } var previousPromise; defineProperty(this, "_invoke", { value: function value(method, arg) { function callInvokeWithMethodAndArg() { return new PromiseImpl(function (resolve, reject) { invoke(method, arg, resolve, reject); }); } return previousPromise = previousPromise ? previousPromise.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); } }); } function makeInvokeMethod(innerFn, self, context) { var state = "suspendedStart"; return function (method, arg) { if ("executing" === state) throw new Error("Generator is already running"); if ("completed" === state) { if ("throw" === method) throw arg; return doneResult(); } for (context.method = method, context.arg = arg;;) { var delegate = context.delegate; if (delegate) { var delegateResult = maybeInvokeDelegate(delegate, context); if (delegateResult) { if (delegateResult === ContinueSentinel) continue; return delegateResult; } } if ("next" === context.method) context.sent = context._sent = context.arg;else if ("throw" === context.method) { if ("suspendedStart" === state) throw state = "completed", context.arg; context.dispatchException(context.arg); } else "return" === context.method && context.abrupt("return", context.arg); state = "executing"; var record = tryCatch(innerFn, self, context); if ("normal" === record.type) { if (state = context.done ? "completed" : "suspendedYield", record.arg === ContinueSentinel) continue; return { value: record.arg, done: context.done }; } "throw" === record.type && (state = "completed", context.method = "throw", context.arg = record.arg); } }; } function maybeInvokeDelegate(delegate, context) { var methodName = context.method, method = delegate.iterator[methodName]; if (undefined === method) return context.delegate = null, "throw" === methodName && delegate.iterator["return"] && (context.method = "return", context.arg = undefined, maybeInvokeDelegate(delegate, context), "throw" === context.method) || "return" !== methodName && (context.method = "throw", context.arg = new TypeError("The iterator does not provide a '" + methodName + "' method")), ContinueSentinel; var record = tryCatch(method, delegate.iterator, context.arg); if ("throw" === record.type) return context.method = "throw", context.arg = record.arg, context.delegate = null, ContinueSentinel; var info = record.arg; return info ? info.done ? (context[delegate.resultName] = info.value, context.next = delegate.nextLoc, "return" !== context.method && (context.method = "next", context.arg = undefined), context.delegate = null, ContinueSentinel) : info : (context.method = "throw", context.arg = new TypeError("iterator result is not an object"), context.delegate = null, ContinueSentinel); } function pushTryEntry(locs) { var entry = { tryLoc: locs[0] }; 1 in locs && (entry.catchLoc = locs[1]), 2 in locs && (entry.finallyLoc = locs[2], entry.afterLoc = locs[3]), this.tryEntries.push(entry); } function resetTryEntry(entry) { var record = entry.completion || {}; record.type = "normal", delete record.arg, entry.completion = record; } function Context(tryLocsList) { this.tryEntries = [{ tryLoc: "root" }], tryLocsList.forEach(pushTryEntry, this), this.reset(!0); } function values(iterable) { if (iterable) { var iteratorMethod = iterable[iteratorSymbol]; if (iteratorMethod) return iteratorMethod.call(iterable); if ("function" == typeof iterable.next) return iterable; if (!isNaN(iterable.length)) { var i = -1, next = function next() { for (; ++i < iterable.length;) if (hasOwn.call(iterable, i)) return next.value = iterable[i], next.done = !1, next; return next.value = undefined, next.done = !0, next; }; return next.next = next; } } return { next: doneResult }; } function doneResult() { return { value: undefined, done: !0 }; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, defineProperty(Gp, "constructor", { value: GeneratorFunctionPrototype, configurable: !0 }), defineProperty(GeneratorFunctionPrototype, "constructor", { value: GeneratorFunction, configurable: !0 }), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, toStringTagSymbol, "GeneratorFunction"), exports.isGeneratorFunction = function (genFun) { var ctor = "function" == typeof genFun && genFun.constructor; return !!ctor && (ctor === GeneratorFunction || "GeneratorFunction" === (ctor.displayName || ctor.name)); }, exports.mark = function (genFun) { return Object.setPrototypeOf ? Object.setPrototypeOf(genFun, GeneratorFunctionPrototype) : (genFun.__proto__ = GeneratorFunctionPrototype, define(genFun, toStringTagSymbol, "GeneratorFunction")), genFun.prototype = Object.create(Gp), genFun; }, exports.awrap = function (arg) { return { __await: arg }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, asyncIteratorSymbol, function () { return this; }), exports.AsyncIterator = AsyncIterator, exports.async = function (innerFn, outerFn, self, tryLocsList, PromiseImpl) { void 0 === PromiseImpl && (PromiseImpl = Promise); var iter = new AsyncIterator(wrap(innerFn, outerFn, self, tryLocsList), PromiseImpl); return exports.isGeneratorFunction(outerFn) ? iter : iter.next().then(function (result) { return result.done ? result.value : iter.next(); }); }, defineIteratorMethods(Gp), define(Gp, toStringTagSymbol, "Generator"), define(Gp, iteratorSymbol, function () { return this; }), define(Gp, "toString", function () { return "[object Generator]"; }), exports.keys = function (val) { var object = Object(val), keys = []; for (var key in object) keys.push(key); return keys.reverse(), function next() { for (; keys.length;) { var key = keys.pop(); if (key in object) return next.value = key, next.done = !1, next; } return next.done = !0, next; }; }, exports.values = values, Context.prototype = { constructor: Context, reset: function reset(skipTempReset) { if (this.prev = 0, this.next = 0, this.sent = this._sent = undefined, this.done = !1, this.delegate = null, this.method = "next", this.arg = undefined, this.tryEntries.forEach(resetTryEntry), !skipTempReset) for (var name in this) "t" === name.charAt(0) && hasOwn.call(this, name) && !isNaN(+name.slice(1)) && (this[name] = undefined); }, stop: function stop() { this.done = !0; var rootRecord = this.tryEntries[0].completion; if ("throw" === rootRecord.type) throw rootRecord.arg; return this.rval; }, dispatchException: function dispatchException(exception) { if (this.done) throw exception; var context = this; function handle(loc, caught) { return record.type = "throw", record.arg = exception, context.next = loc, caught && (context.method = "next", context.arg = undefined), !!caught; } for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i], record = entry.completion; if ("root" === entry.tryLoc) return handle("end"); if (entry.tryLoc <= this.prev) { var hasCatch = hasOwn.call(entry, "catchLoc"), hasFinally = hasOwn.call(entry, "finallyLoc"); if (hasCatch && hasFinally) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } else if (hasCatch) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); } else { if (!hasFinally) throw new Error("try statement without catch or finally"); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } } } }, abrupt: function abrupt(type, arg) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc <= this.prev && hasOwn.call(entry, "finallyLoc") && this.prev < entry.finallyLoc) { var finallyEntry = entry; break; } } finallyEntry && ("break" === type || "continue" === type) && finallyEntry.tryLoc <= arg && arg <= finallyEntry.finallyLoc && (finallyEntry = null); var record = finallyEntry ? finallyEntry.completion : {}; return record.type = type, record.arg = arg, finallyEntry ? (this.method = "next", this.next = finallyEntry.finallyLoc, ContinueSentinel) : this.complete(record); }, complete: function complete(record, afterLoc) { if ("throw" === record.type) throw record.arg; return "break" === record.type || "continue" === record.type ? this.next = record.arg : "return" === record.type ? (this.rval = this.arg = record.arg, this.method = "return", this.next = "end") : "normal" === record.type && afterLoc && (this.next = afterLoc), ContinueSentinel; }, finish: function finish(finallyLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.finallyLoc === finallyLoc) return this.complete(entry.completion, entry.afterLoc), resetTryEntry(entry), ContinueSentinel; } }, "catch": function _catch(tryLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc === tryLoc) { var record = entry.completion; if ("throw" === record.type) { var thrown = record.arg; resetTryEntry(entry); } return thrown; } } throw new Error("illegal catch attempt"); }, delegateYield: function delegateYield(iterable, resultName, nextLoc) { return this.delegate = { iterator: values(iterable), resultName: resultName, nextLoc: nextLoc }, "next" === this.method && (this.arg = undefined), ContinueSentinel; } }, exports; }
function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }
function _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err); } _next(undefined); }); }; }


var version = 3;
var migration = new _Migration_js__WEBPACK_IMPORTED_MODULE_1__["default"]();
migration.add(0, 1, /*#__PURE__*/function () {
  var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(db, transaction) {
    return _regeneratorRuntime().wrap(function _callee$(_context) {
      while (1) switch (_context.prev = _context.next) {
        case 0:
          db.createObjectStore("records", {
            autoIncrement: true
          });
          return _context.abrupt("return", transaction);
        case 2:
        case "end":
          return _context.stop();
      }
    }, _callee);
  }));
  return function (_x, _x2) {
    return _ref.apply(this, arguments);
  };
}());
migration.add(1, 2, /*#__PURE__*/function () {
  var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(db, transaction) {
    var request, blobs, promises, _iterator, _step, blob, data, transactions;
    return _regeneratorRuntime().wrap(function _callee2$(_context2) {
      while (1) switch (_context2.prev = _context2.next) {
        case 0:
          request = transaction.objectStore("records").getAll();
          _context2.next = 3;
          return (0,_DB_js__WEBPACK_IMPORTED_MODULE_0__.wait)(request);
        case 3:
          transaction = _context2.sent;
          blobs = request.result;
          db.deleteObjectStore("records");
          db.createObjectStore("records", {
            autoIncrement: true
          });
          promises = [];
          _iterator = _createForOfIteratorHelper(blobs);
          try {
            for (_iterator.s(); !(_step = _iterator.n()).done;) {
              blob = _step.value;
              data = {
                blob: blob,
                script: null
              };
              request = transaction.objectStore("records").add(data);
              promises.push((0,_DB_js__WEBPACK_IMPORTED_MODULE_0__.wait)(request));
            }
          } catch (err) {
            _iterator.e(err);
          } finally {
            _iterator.f();
          }
          _context2.next = 12;
          return Promise.all(promises);
        case 12:
          transactions = _context2.sent;
          transactions.push(transaction);
          return _context2.abrupt("return", transactions[0]);
        case 15:
        case "end":
          return _context2.stop();
      }
    }, _callee2);
  }));
  return function (_x3, _x4) {
    return _ref2.apply(this, arguments);
  };
}());
migration.add(0, 2, /*#__PURE__*/function () {
  var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3(db, transaction) {
    return _regeneratorRuntime().wrap(function _callee3$(_context3) {
      while (1) switch (_context3.prev = _context3.next) {
        case 0:
          db.createObjectStore("records", {
            autoIncrement: true
          });
          return _context3.abrupt("return", transaction);
        case 2:
        case "end":
          return _context3.stop();
      }
    }, _callee3);
  }));
  return function (_x5, _x6) {
    return _ref3.apply(this, arguments);
  };
}());
migration.add(2, 3, /*#__PURE__*/function () {
  var _ref4 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee4(db, transaction) {
    var request, data, promises, _iterator2, _step2, rec, transactions;
    return _regeneratorRuntime().wrap(function _callee4$(_context4) {
      while (1) switch (_context4.prev = _context4.next) {
        case 0:
          request = transaction.objectStore("records").getAll();
          _context4.next = 3;
          return (0,_DB_js__WEBPACK_IMPORTED_MODULE_0__.wait)(request);
        case 3:
          transaction = _context4.sent;
          data = request.result;
          db.deleteObjectStore("records");
          db.createObjectStore("records", {
            keyPath: "id",
            autoIncrement: true
          });
          promises = [];
          _iterator2 = _createForOfIteratorHelper(data);
          try {
            for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {
              rec = _step2.value;
              request = transaction.objectStore("records").add(rec);
              promises.push((0,_DB_js__WEBPACK_IMPORTED_MODULE_0__.wait)(request));
            }
          } catch (err) {
            _iterator2.e(err);
          } finally {
            _iterator2.f();
          }
          _context4.next = 12;
          return Promise.all(promises);
        case 12:
          transactions = _context4.sent;
          transactions.push(transaction);
          return _context4.abrupt("return", transactions[0]);
        case 15:
        case "end":
          return _context4.stop();
      }
    }, _callee4);
  }));
  return function (_x7, _x8) {
    return _ref4.apply(this, arguments);
  };
}());
migration.add(0, 3, /*#__PURE__*/function () {
  var _ref5 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee5(db, transaction) {
    return _regeneratorRuntime().wrap(function _callee5$(_context5) {
      while (1) switch (_context5.prev = _context5.next) {
        case 0:
          db.createObjectStore("records", {
            keyPath: "id",
            autoIncrement: true
          });
          return _context5.abrupt("return", transaction);
        case 2:
        case "end":
          return _context5.stop();
      }
    }, _callee5);
  }));
  return function (_x9, _x10) {
    return _ref5.apply(this, arguments);
  };
}());
var Record = /*#__PURE__*/function () {
  function Record() {
    _classCallCheck(this, Record);
    this.db = new _DB_js__WEBPACK_IMPORTED_MODULE_0__["default"](Record.name, Record.version);
  }
  _createClass(Record, [{
    key: "connect",
    value: function () {
      var _connect = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee6() {
        return _regeneratorRuntime().wrap(function _callee6$(_context6) {
          while (1) switch (_context6.prev = _context6.next) {
            case 0:
              _context6.next = 2;
              return this.db.connect(migration);
            case 2:
              return _context6.abrupt("return", _context6.sent);
            case 3:
            case "end":
              return _context6.stop();
          }
        }, _callee6, this);
      }));
      function connect() {
        return _connect.apply(this, arguments);
      }
      return connect;
    }()
  }, {
    key: "get",
    value: function () {
      var _get = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee7(key) {
        return _regeneratorRuntime().wrap(function _callee7$(_context7) {
          while (1) switch (_context7.prev = _context7.next) {
            case 0:
              _context7.next = 2;
              return this.db.get(Record.store, key);
            case 2:
              return _context7.abrupt("return", _context7.sent);
            case 3:
            case "end":
              return _context7.stop();
          }
        }, _callee7, this);
      }));
      function get(_x11) {
        return _get.apply(this, arguments);
      }
      return get;
    }()
  }, {
    key: "list",
    value: function () {
      var _list = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee8() {
        return _regeneratorRuntime().wrap(function _callee8$(_context8) {
          while (1) switch (_context8.prev = _context8.next) {
            case 0:
              _context8.next = 2;
              return this.db.getAll(Record.store);
            case 2:
              return _context8.abrupt("return", _context8.sent);
            case 3:
            case "end":
              return _context8.stop();
          }
        }, _callee8, this);
      }));
      function list() {
        return _list.apply(this, arguments);
      }
      return list;
    }()
  }, {
    key: "save",
    value: function () {
      var _save = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee9(data) {
        return _regeneratorRuntime().wrap(function _callee9$(_context9) {
          while (1) switch (_context9.prev = _context9.next) {
            case 0:
              _context9.next = 2;
              return this.db.add(Record.store, data);
            case 2:
              return _context9.abrupt("return", _context9.sent);
            case 3:
            case "end":
              return _context9.stop();
          }
        }, _callee9, this);
      }));
      function save(_x12) {
        return _save.apply(this, arguments);
      }
      return save;
    }()
  }, {
    key: "delete",
    value: function () {
      var _delete2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee10(key) {
        return _regeneratorRuntime().wrap(function _callee10$(_context10) {
          while (1) switch (_context10.prev = _context10.next) {
            case 0:
              _context10.next = 2;
              return this.db["delete"](Record.store, key);
            case 2:
            case "end":
              return _context10.stop();
          }
        }, _callee10, this);
      }));
      function _delete(_x13) {
        return _delete2.apply(this, arguments);
      }
      return _delete;
    }()
  }]);
  return Record;
}();
_defineProperty(Record, "name", "BouncyDB");
_defineProperty(Record, "version", version);
_defineProperty(Record, "store", "records");
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Record);

/***/ }),

/***/ "./node_modules/openai/package.json":
/*!******************************************!*\
  !*** ./node_modules/openai/package.json ***!
  \******************************************/
/***/ ((module) => {

module.exports = {"name":"openai","version":"3.3.0","description":"Node.js library for the OpenAI API","repository":{"type":"git","url":"git@github.com:openai/openai-node.git"},"keywords":["openai","open","ai","gpt-3","gpt3"],"author":"OpenAI","license":"MIT","main":"./dist/index.js","types":"./dist/index.d.ts","scripts":{"build":"tsc --outDir dist/"},"dependencies":{"axios":"^0.26.0","form-data":"^4.0.0"},"devDependencies":{"@types/node":"^12.11.5","typescript":"^3.6.4"}}

/***/ }),

/***/ "./index.scss":
/*!********************!*\
  !*** ./index.scss ***!
  \********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
// extracted by mini-css-extract-plugin


/***/ }),

/***/ "./src/Conversation.ts":
/*!*****************************!*\
  !*** ./src/Conversation.ts ***!
  \*****************************/
/***/ ((module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.a(module, async (__webpack_handle_async_dependencies__, __webpack_async_result__) => { try {
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _node_modules_tiktoken_tiktoken__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../node_modules/tiktoken/tiktoken */ "./node_modules/tiktoken/tiktoken.js");
var __webpack_async_dependencies__ = __webpack_handle_async_dependencies__([_node_modules_tiktoken_tiktoken__WEBPACK_IMPORTED_MODULE_0__]);
_node_modules_tiktoken_tiktoken__WEBPACK_IMPORTED_MODULE_0__ = (__webpack_async_dependencies__.then ? (await __webpack_async_dependencies__)() : __webpack_async_dependencies__)[0];
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};

class Conversation {
    constructor(openai, context = [], model = "gpt-3.5-turbo") {
        this.api = openai;
        this.model = model;
        this.encoding = (0,_node_modules_tiktoken_tiktoken__WEBPACK_IMPORTED_MODULE_0__.encoding_for_model)(model);
        this.history = context.map(content => ({
            role: 'system',
            content,
            token_len: this.getTokenLen(content)
        }));
    }
    getTokenLen(str) {
        return this.encoding.encode(str).length;
    }
    addHistory(msg) {
        this.history.push(Object.assign(Object.assign({}, msg), { token_len: this.getTokenLen(msg.content) }));
    }
    getHistoryMessages() {
        return this.history.map(({ role, content }) => ({ role, content }));
    }
    say(msg) {
        return __awaiter(this, void 0, void 0, function* () {
            const message = { role: 'user', content: msg };
            const res = yield this.api.createChatCompletion({
                model: this.model,
                messages: [
                    ...this.getHistoryMessages(),
                    message
                ]
            });
            this.addHistory(message);
            const reply = res.data.choices[0].message;
            this.addHistory(reply);
            return reply.content;
        });
    }
}
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Conversation);

__webpack_async_result__();
} catch(e) { __webpack_async_result__(e); } });

/***/ }),

/***/ "?9157":
/*!************************!*\
  !*** crypto (ignored) ***!
  \************************/
/***/ (() => {

/* (ignored) */

/***/ }),

/***/ "?6483":
/*!****************************!*\
  !*** agent-base (ignored) ***!
  \****************************/
/***/ (() => {

/* (ignored) */

/***/ }),

/***/ "?0825":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

/* (ignored) */

/***/ }),

/***/ "?72ad":
/*!***********************************!*\
  !*** https-proxy-agent (ignored) ***!
  \***********************************/
/***/ (() => {

/* (ignored) */

/***/ }),

/***/ "?a1bf":
/*!*********************!*\
  !*** net (ignored) ***!
  \*********************/
/***/ (() => {

/* (ignored) */

/***/ }),

/***/ "?14d6":
/*!*********************!*\
  !*** tls (ignored) ***!
  \*********************/
/***/ (() => {

/* (ignored) */

/***/ }),

/***/ "?e42a":
/*!********************!*\
  !*** ws (ignored) ***!
  \********************/
/***/ (() => {

/* (ignored) */

/***/ }),

/***/ "?9463":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

/* (ignored) */

/***/ }),

/***/ "./node_modules/tiktoken/tiktoken_bg.wasm":
/*!************************************************!*\
  !*** ./node_modules/tiktoken/tiktoken_bg.wasm ***!
  \************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
/* harmony import */ var WEBPACK_IMPORTED_MODULE_0 = __webpack_require__(/*! ./tiktoken_bg.js */ "./node_modules/tiktoken/tiktoken_bg.js");
module.exports = __webpack_require__.v(exports, module.id, "3cb395e365c820687fbc", {
	"./tiktoken_bg.js": {
		"__wbindgen_object_drop_ref": WEBPACK_IMPORTED_MODULE_0.__wbindgen_object_drop_ref,
		"__wbindgen_is_undefined": WEBPACK_IMPORTED_MODULE_0.__wbindgen_is_undefined,
		"__wbg_stringify_e25465938f3f611f": WEBPACK_IMPORTED_MODULE_0.__wbg_stringify_e25465938f3f611f,
		"__wbindgen_string_get": WEBPACK_IMPORTED_MODULE_0.__wbindgen_string_get,
		"__wbindgen_error_new": WEBPACK_IMPORTED_MODULE_0.__wbindgen_error_new,
		"__wbg_parse_670c19d4e984792e": WEBPACK_IMPORTED_MODULE_0.__wbg_parse_670c19d4e984792e,
		"__wbindgen_throw": WEBPACK_IMPORTED_MODULE_0.__wbindgen_throw
	}
});

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			id: moduleId,
/******/ 			loaded: false,
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Flag the module as loaded
/******/ 		module.loaded = true;
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = __webpack_modules__;
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/async module */
/******/ 	(() => {
/******/ 		var webpackQueues = typeof Symbol === "function" ? Symbol("webpack queues") : "__webpack_queues__";
/******/ 		var webpackExports = typeof Symbol === "function" ? Symbol("webpack exports") : "__webpack_exports__";
/******/ 		var webpackError = typeof Symbol === "function" ? Symbol("webpack error") : "__webpack_error__";
/******/ 		var resolveQueue = (queue) => {
/******/ 			if(queue && !queue.d) {
/******/ 				queue.d = 1;
/******/ 				queue.forEach((fn) => (fn.r--));
/******/ 				queue.forEach((fn) => (fn.r-- ? fn.r++ : fn()));
/******/ 			}
/******/ 		}
/******/ 		var wrapDeps = (deps) => (deps.map((dep) => {
/******/ 			if(dep !== null && typeof dep === "object") {
/******/ 				if(dep[webpackQueues]) return dep;
/******/ 				if(dep.then) {
/******/ 					var queue = [];
/******/ 					queue.d = 0;
/******/ 					dep.then((r) => {
/******/ 						obj[webpackExports] = r;
/******/ 						resolveQueue(queue);
/******/ 					}, (e) => {
/******/ 						obj[webpackError] = e;
/******/ 						resolveQueue(queue);
/******/ 					});
/******/ 					var obj = {};
/******/ 					obj[webpackQueues] = (fn) => (fn(queue));
/******/ 					return obj;
/******/ 				}
/******/ 			}
/******/ 			var ret = {};
/******/ 			ret[webpackQueues] = x => {};
/******/ 			ret[webpackExports] = dep;
/******/ 			return ret;
/******/ 		}));
/******/ 		__webpack_require__.a = (module, body, hasAwait) => {
/******/ 			var queue;
/******/ 			hasAwait && ((queue = []).d = 1);
/******/ 			var depQueues = new Set();
/******/ 			var exports = module.exports;
/******/ 			var currentDeps;
/******/ 			var outerResolve;
/******/ 			var reject;
/******/ 			var promise = new Promise((resolve, rej) => {
/******/ 				reject = rej;
/******/ 				outerResolve = resolve;
/******/ 			});
/******/ 			promise[webpackExports] = exports;
/******/ 			promise[webpackQueues] = (fn) => (queue && fn(queue), depQueues.forEach(fn), promise["catch"](x => {}));
/******/ 			module.exports = promise;
/******/ 			body((deps) => {
/******/ 				currentDeps = wrapDeps(deps);
/******/ 				var fn;
/******/ 				var getResult = () => (currentDeps.map((d) => {
/******/ 					if(d[webpackError]) throw d[webpackError];
/******/ 					return d[webpackExports];
/******/ 				}))
/******/ 				var promise = new Promise((resolve) => {
/******/ 					fn = () => (resolve(getResult));
/******/ 					fn.r = 0;
/******/ 					var fnQueue = (q) => (q !== queue && !depQueues.has(q) && (depQueues.add(q), q && !q.d && (fn.r++, q.push(fn))));
/******/ 					currentDeps.map((dep) => (dep[webpackQueues](fnQueue)));
/******/ 				});
/******/ 				return fn.r ? promise : getResult();
/******/ 			}, (err) => ((err ? reject(promise[webpackError] = err) : outerResolve(exports)), resolveQueue(queue)));
/******/ 			queue && (queue.d = 0);
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/create fake namespace object */
/******/ 	(() => {
/******/ 		var getProto = Object.getPrototypeOf ? (obj) => (Object.getPrototypeOf(obj)) : (obj) => (obj.__proto__);
/******/ 		var leafPrototypes;
/******/ 		// create a fake namespace object
/******/ 		// mode & 1: value is a module id, require it
/******/ 		// mode & 2: merge all properties of value into the ns
/******/ 		// mode & 4: return value when already ns object
/******/ 		// mode & 16: return value when it's Promise-like
/******/ 		// mode & 8|1: behave like require
/******/ 		__webpack_require__.t = function(value, mode) {
/******/ 			if(mode & 1) value = this(value);
/******/ 			if(mode & 8) return value;
/******/ 			if(typeof value === 'object' && value) {
/******/ 				if((mode & 4) && value.__esModule) return value;
/******/ 				if((mode & 16) && typeof value.then === 'function') return value;
/******/ 			}
/******/ 			var ns = Object.create(null);
/******/ 			__webpack_require__.r(ns);
/******/ 			var def = {};
/******/ 			leafPrototypes = leafPrototypes || [null, getProto({}), getProto([]), getProto(getProto)];
/******/ 			for(var current = mode & 2 && value; typeof current == 'object' && !~leafPrototypes.indexOf(current); current = getProto(current)) {
/******/ 				Object.getOwnPropertyNames(current).forEach((key) => (def[key] = () => (value[key])));
/******/ 			}
/******/ 			def['default'] = () => (value);
/******/ 			__webpack_require__.d(ns, def);
/******/ 			return ns;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/ensure chunk */
/******/ 	(() => {
/******/ 		__webpack_require__.f = {};
/******/ 		// This file contains only the entry chunk.
/******/ 		// The chunk loading function for additional chunks
/******/ 		__webpack_require__.e = (chunkId) => {
/******/ 			return Promise.all(Object.keys(__webpack_require__.f).reduce((promises, key) => {
/******/ 				__webpack_require__.f[key](chunkId, promises);
/******/ 				return promises;
/******/ 			}, []));
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/get javascript chunk filename */
/******/ 	(() => {
/******/ 		// This function allow to reference async chunks
/******/ 		__webpack_require__.u = (chunkId) => {
/******/ 			// return url for filenames based on template
/******/ 			return "" + chunkId + ".js";
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/get mini-css chunk filename */
/******/ 	(() => {
/******/ 		// This function allow to reference async chunks
/******/ 		__webpack_require__.miniCssF = (chunkId) => {
/******/ 			// return url for filenames based on template
/******/ 			return undefined;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/global */
/******/ 	(() => {
/******/ 		__webpack_require__.g = (function() {
/******/ 			if (typeof globalThis === 'object') return globalThis;
/******/ 			try {
/******/ 				return this || new Function('return this')();
/******/ 			} catch (e) {
/******/ 				if (typeof window === 'object') return window;
/******/ 			}
/******/ 		})();
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/harmony module decorator */
/******/ 	(() => {
/******/ 		__webpack_require__.hmd = (module) => {
/******/ 			module = Object.create(module);
/******/ 			if (!module.children) module.children = [];
/******/ 			Object.defineProperty(module, 'exports', {
/******/ 				enumerable: true,
/******/ 				set: () => {
/******/ 					throw new Error('ES Modules may not assign module.exports or exports.*, Use ESM export syntax, instead: ' + module.id);
/******/ 				}
/******/ 			});
/******/ 			return module;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/load script */
/******/ 	(() => {
/******/ 		var inProgress = {};
/******/ 		var dataWebpackPrefix = "my-webpack-project:";
/******/ 		// loadScript function to load a script via script tag
/******/ 		__webpack_require__.l = (url, done, key, chunkId) => {
/******/ 			if(inProgress[url]) { inProgress[url].push(done); return; }
/******/ 			var script, needAttach;
/******/ 			if(key !== undefined) {
/******/ 				var scripts = document.getElementsByTagName("script");
/******/ 				for(var i = 0; i < scripts.length; i++) {
/******/ 					var s = scripts[i];
/******/ 					if(s.getAttribute("src") == url || s.getAttribute("data-webpack") == dataWebpackPrefix + key) { script = s; break; }
/******/ 				}
/******/ 			}
/******/ 			if(!script) {
/******/ 				needAttach = true;
/******/ 				script = document.createElement('script');
/******/ 		
/******/ 				script.charset = 'utf-8';
/******/ 				script.timeout = 120;
/******/ 				if (__webpack_require__.nc) {
/******/ 					script.setAttribute("nonce", __webpack_require__.nc);
/******/ 				}
/******/ 				script.setAttribute("data-webpack", dataWebpackPrefix + key);
/******/ 				script.src = url;
/******/ 			}
/******/ 			inProgress[url] = [done];
/******/ 			var onScriptComplete = (prev, event) => {
/******/ 				// avoid mem leaks in IE.
/******/ 				script.onerror = script.onload = null;
/******/ 				clearTimeout(timeout);
/******/ 				var doneFns = inProgress[url];
/******/ 				delete inProgress[url];
/******/ 				script.parentNode && script.parentNode.removeChild(script);
/******/ 				doneFns && doneFns.forEach((fn) => (fn(event)));
/******/ 				if(prev) return prev(event);
/******/ 			}
/******/ 			var timeout = setTimeout(onScriptComplete.bind(null, undefined, { type: 'timeout', target: script }), 120000);
/******/ 			script.onerror = onScriptComplete.bind(null, script.onerror);
/******/ 			script.onload = onScriptComplete.bind(null, script.onload);
/******/ 			needAttach && document.head.appendChild(script);
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/wasm loading */
/******/ 	(() => {
/******/ 		__webpack_require__.v = (exports, wasmModuleId, wasmModuleHash, importsObj) => {
/******/ 			var req = fetch(__webpack_require__.p + "" + wasmModuleHash + ".module.wasm");
/******/ 			if (typeof WebAssembly.instantiateStreaming === 'function') {
/******/ 				return WebAssembly.instantiateStreaming(req, importsObj)
/******/ 					.then((res) => (Object.assign(exports, res.instance.exports)));
/******/ 			}
/******/ 			return req
/******/ 				.then((x) => (x.arrayBuffer()))
/******/ 				.then((bytes) => (WebAssembly.instantiate(bytes, importsObj)))
/******/ 				.then((res) => (Object.assign(exports, res.instance.exports)));
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/publicPath */
/******/ 	(() => {
/******/ 		var scriptUrl;
/******/ 		if (__webpack_require__.g.importScripts) scriptUrl = __webpack_require__.g.location + "";
/******/ 		var document = __webpack_require__.g.document;
/******/ 		if (!scriptUrl && document) {
/******/ 			if (document.currentScript)
/******/ 				scriptUrl = document.currentScript.src;
/******/ 			if (!scriptUrl) {
/******/ 				var scripts = document.getElementsByTagName("script");
/******/ 				if(scripts.length) {
/******/ 					var i = scripts.length - 1;
/******/ 					while (i > -1 && !scriptUrl) scriptUrl = scripts[i--].src;
/******/ 				}
/******/ 			}
/******/ 		}
/******/ 		// When supporting browsers where an automatic publicPath is not supported you must specify an output.publicPath manually via configuration
/******/ 		// or pass an empty string ("") and set the __webpack_public_path__ variable from your code to use your own logic.
/******/ 		if (!scriptUrl) throw new Error("Automatic publicPath is not supported in this browser");
/******/ 		scriptUrl = scriptUrl.replace(/#.*$/, "").replace(/\?.*$/, "").replace(/\/[^\/]+$/, "/");
/******/ 		__webpack_require__.p = scriptUrl;
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/jsonp chunk loading */
/******/ 	(() => {
/******/ 		// no baseURI
/******/ 		
/******/ 		// object to store loaded and loading chunks
/******/ 		// undefined = chunk not loaded, null = chunk preloaded/prefetched
/******/ 		// [resolve, reject, Promise] = chunk loading, 0 = chunk loaded
/******/ 		var installedChunks = {
/******/ 			"main": 0
/******/ 		};
/******/ 		
/******/ 		__webpack_require__.f.j = (chunkId, promises) => {
/******/ 				// JSONP chunk loading for javascript
/******/ 				var installedChunkData = __webpack_require__.o(installedChunks, chunkId) ? installedChunks[chunkId] : undefined;
/******/ 				if(installedChunkData !== 0) { // 0 means "already installed".
/******/ 		
/******/ 					// a Promise means "currently loading".
/******/ 					if(installedChunkData) {
/******/ 						promises.push(installedChunkData[2]);
/******/ 					} else {
/******/ 						if(true) { // all chunks have JS
/******/ 							// setup Promise in chunk cache
/******/ 							var promise = new Promise((resolve, reject) => (installedChunkData = installedChunks[chunkId] = [resolve, reject]));
/******/ 							promises.push(installedChunkData[2] = promise);
/******/ 		
/******/ 							// start chunk loading
/******/ 							var url = __webpack_require__.p + __webpack_require__.u(chunkId);
/******/ 							// create error before stack unwound to get useful stacktrace later
/******/ 							var error = new Error();
/******/ 							var loadingEnded = (event) => {
/******/ 								if(__webpack_require__.o(installedChunks, chunkId)) {
/******/ 									installedChunkData = installedChunks[chunkId];
/******/ 									if(installedChunkData !== 0) installedChunks[chunkId] = undefined;
/******/ 									if(installedChunkData) {
/******/ 										var errorType = event && (event.type === 'load' ? 'missing' : event.type);
/******/ 										var realSrc = event && event.target && event.target.src;
/******/ 										error.message = 'Loading chunk ' + chunkId + ' failed.\n(' + errorType + ': ' + realSrc + ')';
/******/ 										error.name = 'ChunkLoadError';
/******/ 										error.type = errorType;
/******/ 										error.request = realSrc;
/******/ 										installedChunkData[1](error);
/******/ 									}
/******/ 								}
/******/ 							};
/******/ 							__webpack_require__.l(url, loadingEnded, "chunk-" + chunkId, chunkId);
/******/ 						}
/******/ 					}
/******/ 				}
/******/ 		};
/******/ 		
/******/ 		// no prefetching
/******/ 		
/******/ 		// no preloaded
/******/ 		
/******/ 		// no HMR
/******/ 		
/******/ 		// no HMR manifest
/******/ 		
/******/ 		// no on chunks loaded
/******/ 		
/******/ 		// install a JSONP callback for chunk loading
/******/ 		var webpackJsonpCallback = (parentChunkLoadingFunction, data) => {
/******/ 			var [chunkIds, moreModules, runtime] = data;
/******/ 			// add "moreModules" to the modules object,
/******/ 			// then flag all "chunkIds" as loaded and fire callback
/******/ 			var moduleId, chunkId, i = 0;
/******/ 			if(chunkIds.some((id) => (installedChunks[id] !== 0))) {
/******/ 				for(moduleId in moreModules) {
/******/ 					if(__webpack_require__.o(moreModules, moduleId)) {
/******/ 						__webpack_require__.m[moduleId] = moreModules[moduleId];
/******/ 					}
/******/ 				}
/******/ 				if(runtime) var result = runtime(__webpack_require__);
/******/ 			}
/******/ 			if(parentChunkLoadingFunction) parentChunkLoadingFunction(data);
/******/ 			for(;i < chunkIds.length; i++) {
/******/ 				chunkId = chunkIds[i];
/******/ 				if(__webpack_require__.o(installedChunks, chunkId) && installedChunks[chunkId]) {
/******/ 					installedChunks[chunkId][0]();
/******/ 				}
/******/ 				installedChunks[chunkId] = 0;
/******/ 			}
/******/ 		
/******/ 		}
/******/ 		
/******/ 		var chunkLoadingGlobal = self["webpackChunkmy_webpack_project"] = self["webpackChunkmy_webpack_project"] || [];
/******/ 		chunkLoadingGlobal.forEach(webpackJsonpCallback.bind(null, 0));
/******/ 		chunkLoadingGlobal.push = webpackJsonpCallback.bind(null, chunkLoadingGlobal.push.bind(chunkLoadingGlobal));
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module used 'module' so it can't be inlined
/******/ 	__webpack_require__("./index.js");
/******/ 	var __webpack_exports__ = __webpack_require__("./index.scss");
/******/ 	
/******/ })()
;
//# sourceMappingURL=main.js.map